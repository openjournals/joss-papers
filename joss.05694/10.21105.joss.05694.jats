<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5694</article-id>
<article-id pub-id-type="doi">10.21105/joss.05694</article-id>
<title-group>
<article-title>PyBADS: Fast and robust black-box optimization in
Python</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-2340-5867</contrib-id>
<name>
<surname>Singh</surname>
<given-names>Gurjeet Sangra</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7471-7336</contrib-id>
<name>
<surname>Acerbi</surname>
<given-names>Luigi</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-2"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University of Geneva</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>University of Helsinki</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of Applied Sciences and Arts Western Switzerland
(HES-SO)</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
<corresp id="cor-2">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-06-10">
<day>10</day>
<month>6</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>94</issue>
<fpage>5694</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Bayesian optimization</kwd>
<kwd>Black-box optimization</kwd>
<kwd>Optimization</kwd>
<kwd>Machine learning</kwd>
<kwd>Gaussian Processes</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>PyBADS is a Python implementation of the Bayesian Adaptive Direct
  Search (BADS) algorithm for fast and robust <italic>black-box</italic>
  optimization
  (<xref alt="Acerbi &amp; Ma, 2017" rid="ref-acerbi2017practical" ref-type="bibr">Acerbi
  &amp; Ma, 2017</xref>). BADS is an optimization algorithm designed to
  efficiently solve difficult optimization problems where the objective
  function is rough (non-convex, non-smooth), mildly expensive (e.g.,
  the function evaluation requires more than 0.1 seconds), possibly
  noisy, and gradient information is unavailable. With BADS, these
  issues are well addressed, making it an excellent choice for fitting
  computational models using methods such as maximum-likelihood
  estimation. The algorithm scales efficiently to black-box functions
  with up to <inline-formula><alternatives>
  <tex-math><![CDATA[D \approx 20]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>D</mml:mi><mml:mo>≈</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  continuous input parameters and supports bounds or no constraints.
  PyBADS builds on the previous MATLAB implementation with an
  easy-to-use Pythonic interface for running the algorithm and
  inspecting its results. PyBADS only requires the user to provide a
  Python function for evaluating the target function, and optionally
  other constraints.</p>
  <p>Extensive benchmarks on both artificial test problems and large
  real model-fitting problems models drawn from cognitive, behavioural,
  and computational neuroscience, show that BADS performs on par with or
  better than many other common and state-of-the-art optimizers
  (<xref alt="Acerbi &amp; Ma, 2017" rid="ref-acerbi2017practical" ref-type="bibr">Acerbi
  &amp; Ma, 2017</xref>), making it a general model-fitting tool which
  provides fast and robust solutions.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Many optimization problems in science and engineering involve
  complex and expensive simulations or numerical approximations such
  that the target function can only be evaluated at a point with
  moderate to high cost, possibly yielding stochastic outcomes, and
  gradients are unavailable (or exceedingly expensive) – the typical
  <italic>black-box</italic> scenario. There is a large landscape of
  derivative-free optimization algorithms for tackling black-box
  problems
  (<xref alt="Rios &amp; Sahinidis, 2013" rid="ref-Rios2013" ref-type="bibr">Rios
  &amp; Sahinidis, 2013</xref>), many of which follow variants of
  direct-search methods
  (<xref alt="Abramson et al., 2009" rid="ref-orthoMADS" ref-type="bibr">Abramson
  et al., 2009</xref>;
  <xref alt="Audet et al., 2021" rid="ref-stoMADS" ref-type="bibr">Audet
  et al., 2021</xref>;
  <xref alt="Audet &amp; Dennis, 2006" rid="ref-MADS" ref-type="bibr">Audet
  &amp; Dennis, 2006</xref>;
  <xref alt="Deng &amp; Ferris, 2006" rid="ref-deng2006adaptation" ref-type="bibr">Deng
  &amp; Ferris, 2006</xref>). Despite their theoretical guarantees,
  direct-search methods require a large number of function evaluations
  and have limited support for handling stochastic targets.</p>
  <p>Conversely, Bayesian Optimization is a recently popular family of
  methods that has shown effectiveness in solving <italic>very</italic>
  costly black-box problems in machine learning and engineering with
  very few, possibly noisy, function evaluations
  (<xref alt="Agnihotri &amp; Batra, 2020" rid="ref-agnihotri2020exploring" ref-type="bibr">Agnihotri
  &amp; Batra, 2020</xref>;
  <xref alt="Garnett, 2023" rid="ref-garnett_bayesoptbook_2023" ref-type="bibr">Garnett,
  2023</xref>;
  <xref alt="Shahriari et al., 2016" rid="ref-reviewBO" ref-type="bibr">Shahriari
  et al., 2016</xref>). However, Bayesian Optimization requires specific
  technical knowledge to be implemented or tuned beyond simple tasks,
  since vanilla Bayesian Optimization applied to complex real-world
  problems can be strongly affected by deviations from the algorithm’s
  assumptions (model misspecification), a problem rarely dealt with in
  current implementations. Moreover, traditional Bayesian Optimization
  methods assume <italic>highly expensive</italic> target functions
  (e.g., with evaluation costs of hours or more), whereas many
  computational models might only have a <italic>moderate</italic>
  evaluation cost (e.g., from a fraction of a second to a few seconds),
  meaning that the optimization algorithm should add only a relatively
  small overhead.</p>
  <p>PyBADS addresses all these problems as a fast hybrid algorithm that
  combines the strengths of Bayesian Optimization and the Mesh Adaptive
  Direct Search
  (<xref alt="Audet &amp; Dennis, 2006" rid="ref-MADS" ref-type="bibr">Audet
  &amp; Dennis, 2006</xref>) method. In contrast to other black-box
  optimization algorithms, PyBADS is both <italic>fast</italic> in terms
  of wall-clock time and <italic>sample-efficient</italic> in terms of
  the number of target evaluations (typically of the order of a few
  hundred), with support for noisy targets. Moreover, PyBADS does not
  require any specific tuning and runs off-the-shelf with its
  well-modularized Python API.</p>
  <sec id="method">
    <title>Method</title>
    <p>PyBADS follows the Mesh Adaptive Direct Search (MADS,
    <xref alt="Audet &amp; Dennis, 2006" rid="ref-MADS" ref-type="bibr">Audet
    &amp; Dennis, 2006</xref>) schema for minimizing the given objective
    function. The algorithm alternates between a series of fast local
    Bayesian Optimization steps, referred to as <italic>search
    stage</italic>, and systematic exploration of the mesh space in a
    neighborhood of the current point, known as <italic>poll
    stage</italic>, based on the MADS poll method
    (<xref alt="Audet &amp; Dennis, 2006" rid="ref-MADS" ref-type="bibr">Audet
    &amp; Dennis, 2006</xref>); see Figure
    <xref alt="[fig:example]" rid="figU003Aexample">[fig:example]</xref>.
    Briefly:</p>
    <list list-type="bullet">
      <list-item>
        <p>In the poll stage, points are evaluated on a mesh by taking
        steps in one (non-orthogonal) direction at a time, until an
        improvement is found or all directions have been tried. The step
        size is doubled in case of success, halved otherwise.</p>
      </list-item>
      <list-item>
        <p>In the search stage, a Gaussian process (GP) surrogate model
        (<xref alt="Rasmussen &amp; Williams, 2006" rid="ref-rasmussen_gaussian_2006" ref-type="bibr">Rasmussen
        &amp; Williams, 2006</xref>) of the target function is fit to a
        local subset of the points evaluated so far. New points to
        evaluate are quickly chosen according to a <italic>lower
        confidence bound</italic> strategy that trades off between
        exploration of uncertain regions (high GP uncertainty) and
        exploitation of promising solutions (low GP mean). The search
        switches back to the poll stage after repeated failures to find
        an improvement over the current point.</p>
      </list-item>
    </list>
    <fig>
      <caption><p>Contour plots and PyBADS exploration of a
      two-dimensional
      <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Rosenbrock_function">Rosenbrock</ext-link>
      function. Lines represent the contours of the true target (left)
      and of the GP surrogate model built during the search stage
      (right). The solid black diamonds indicate new points chosen by
      the poll method (here for simplicity a simple orthogonal poll),
      the grey circles represent the previously sampled points, and the
      orange solid star represents the global minimum of the function.
      When switching to the search stage, the blue diamond describes the
      point selected by the active sampling method based on the lower
      confidence bound obtained from the GP surrogate model (green
      region).
      <styled-content id="figU003Aexample"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/bads-optimization.png" />
    </fig>
    <p>This alternation between the two stages makes BADS uniquely
    robust and effective. The poll stage follows a slow but steady
    “model-free” optimization with theoretical guarantees. Conversely,
    the search stage exploits a powerful “model-based” GP surrogate to
    propose potentially large steps, which can be extremely effective if
    the surrogate is able to approximate the target well. Notably, this
    strategy is fail-safe in that if the GP fails to locally model the
    target, the search will fail and PyBADS will fall back to the safer
    poll method. The points acquired during the poll will afford a
    construction of a better surrogate at the next search, and so on. In
    addition, when the target is noisy, BADS follows some effective
    heuristics for calibrating the surrogate model, checking the
    reliability of the predictions, and reassessing the estimated value
    of the current point in light of the new points.</p>
    <p>Thanks to these techniques, our algorithm has demonstrated high
    robustness and effectiveness in solving optimization problems with
    noisy and complex non-convex objective functions.</p>
  </sec>
  <sec id="related-work">
    <title>Related work</title>
    <p>Similarly to PyBADS, relevant libraries have been developed over
    the years in the area of Bayesian Optimization, such as BoTorch
    (<xref alt="Balandat et al., 2020" rid="ref-balandat2020botorch" ref-type="bibr">Balandat
    et al., 2020</xref>), GPflowOpt
    (<xref alt="Knudde et al., 2017" rid="ref-GPflowOpt2017" ref-type="bibr">Knudde
    et al., 2017</xref>), Spearmint
    (<xref alt="Snoek et al., 2014" rid="ref-pmlr-v32-snoek14" ref-type="bibr">Snoek
    et al., 2014</xref>), among others. Instead, NOMAD
    (<xref alt="Audet et al., 2022" rid="ref-nomad4paper" ref-type="bibr">Audet
    et al., 2022</xref>) is the main reference library for
    <italic>pattern search</italic> algorithms, and it implements
    several variants of MADS in C++, by providing Python and Julia
    interface bindings.</p>
    <p>Differently to these algorithms, PyBADS comes with a unique
    hybrid, fast and robust combination of direct search (MADS) and
    Bayesian Optimization. This combination of strategies protects
    against failures of the GP surrogate models – whereas vanilla
    Bayesian Optimization does not have such fail-safe mechanisms, and
    can be strongly affected by misspecification of the surrogate GP
    model. PyBADS has also been designed to avoid problem-specific
    tuning, making it a generic tool for model fitting. Compared to
    other approaches, PyBADS also has the advantage of natively
    accommodating target functions with heteroskedastic
    (input-dependent) observation noise. The results of our approach
    demonstrate that a hybrid Bayesian approach to optimization can be
    beneficial beyond the domain of costly black-box functions. Finally,
    unlike most other Bayesian Optimization packages, targeted to an
    audience of machine learning researchers, PyBADS comes with a neat
    API library and well-structured, user-friendly documentation.</p>
    <p>PyBADS was developed in parallel to PyVBMC, a new software for
    sample-efficient Bayesian inference
    (<xref alt="Acerbi, 2018" rid="ref-acerbi2018variational" ref-type="bibr">Acerbi,
    2018</xref>,
    <xref alt="2019" rid="ref-acerbi2019exploration" ref-type="bibr">2019</xref>,
    <xref alt="2020" rid="ref-acerbi2020variational" ref-type="bibr">2020</xref>;
    <xref alt="Huggins et al., 2023" rid="ref-huggins2023pyvbmc" ref-type="bibr">Huggins
    et al., 2023</xref>). PyBADS can be used in combination with PyVBMC,
    by providing an effective way of initializing the inference
    algorithm at the maximum-a-posteriori (MAP) solution.</p>
  </sec>
  <sec id="applications-and-usage">
    <title>Applications and usage</title>
    <p>The BADS algorithm, in its MATLAB implementation, has already
    been applied in multiple fields, especially in neuroscience where it
    finds a broad audience by efficiently solving difficult
    model-fitting problems
    (<xref alt="Cao et al., 2019" rid="ref-cao2019causal" ref-type="bibr">Cao
    et al., 2019</xref>;
    <xref alt="Daube et al., 2019" rid="ref-DAUBE20191924" ref-type="bibr">Daube
    et al., 2019</xref>;
    <xref alt="J.-A. Li et al., 2020" rid="ref-Li2020" ref-type="bibr">J.-A.
    Li et al., 2020</xref>;
    <xref alt="Tajima et al., 2019" rid="ref-Tajima2019" ref-type="bibr">Tajima
    et al., 2019</xref>). Other fields in which BADS has been
    successfully applied include control engineering
    (<xref alt="Stenger &amp; Abel, 2022" rid="ref-stenger2022benchmark" ref-type="bibr">Stenger
    &amp; Abel, 2022</xref>), electrical engineering
    (<xref alt="M. Li et al., 2022" rid="ref-li2022topology" ref-type="bibr">M.
    Li et al., 2022</xref>), materials engineering
    (<xref alt="Ren et al., 2021" rid="ref-ren2021novel" ref-type="bibr">Ren
    et al., 2021</xref>), robotics
    (<xref alt="Ren et al., 2020" rid="ref-REN2020575" ref-type="bibr">Ren
    et al., 2020</xref>), petroleum science
    (<xref alt="Feng et al., 2022" rid="ref-FENG20222879" ref-type="bibr">Feng
    et al., 2022</xref>), environmental economics
    (<xref alt="Nobel et al., 2020" rid="ref-nobel2020" ref-type="bibr">Nobel
    et al., 2020</xref>), and cognitive science
    (<xref alt="Stengård et al., 2022" rid="ref-STENGARD2022105160" ref-type="bibr">Stengård
    et al., 2022</xref>;
    <xref alt="van Opheusden et al., 2023" rid="ref-vanOpheusden2023" ref-type="bibr">van
    Opheusden et al., 2023</xref>). Moreover, BADS has been shown to
    perform best in most settings of a black-box optimization benchmark
    for control engineering
    (<xref alt="Stenger &amp; Abel, 2022" rid="ref-stenger2022benchmark" ref-type="bibr">Stenger
    &amp; Abel, 2022</xref>), highlighting the effectiveness of our
    algorithm compared to other Bayesian Optimization and direct-search
    approaches. With PyBADS, we bring the same sample-efficient and
    robust optimization to the wider open-source Python community, while
    improving the interface, test coverage, and documentation.</p>
    <p>The package is available on both PyPI
    (<monospace>pip install pybads</monospace>) and
    <monospace>conda-forge</monospace>, and provides an idiomatic and
    accessible interface, depending only on NumPy and SciPy, which are
    standard widely-available scientific Python packages
    (<xref alt="Harris et al., 2020" rid="ref-harris_array_2020" ref-type="bibr">Harris
    et al., 2020</xref>;
    <xref alt="Virtanen et al., 2020" rid="ref-scipy-2020" ref-type="bibr">Virtanen
    et al., 2020</xref>). The user only needs to give a few basic
    details about the objective function and its parameter space, and
    PyBADS handles the rest of the optimization task. PyBADS includes
    automatic handling of bounded variables, robust termination
    conditions, sensible default settings, and does not need tunable
    parameters. At the same time, experienced users can easily supply
    their own options. We have extensively tested the algorithm and
    implementation details for correctness and performance. We provide
    detailed
    <ext-link ext-link-type="uri" xlink:href="https://github.com/acerbilab/pybads/tree/main/examples">tutorials</ext-link>,
    so that PyBADS may be accessible to those not already familiar with
    black-box optimization, and our comprehensive
    <ext-link ext-link-type="uri" xlink:href="https://acerbilab.github.io/pybads">documentation</ext-link>
    will aid not only new users but future contributors as well.</p>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>We thank Bobby Huggins, Chengkun Li, Marlon Tobaben and Mikko
  Aarnos for helpful comments and feedback. We also acknowledge support
  from CSC – IT Center for Science, Finland, for computational
  resources. Work on the PyBADS package was supported by the Research
  Council of Finland Flagship programme: Finnish Center for Artificial
  Intelligence FCAI, and additionally by project grants 356498 and
  358980.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-acerbi2017practical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Acerbi</surname><given-names>Luigi</given-names></name>
        <name><surname>Ma</surname><given-names>Wei Ji</given-names></name>
      </person-group>
      <article-title>Practical Bayesian optimization for model fitting with Bayesian adaptive direct search</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2017">2017</year>
      <volume>30</volume>
      <fpage>1834</fpage>
      <lpage>1844</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Rios2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rios</surname><given-names>Luis Miguel</given-names></name>
        <name><surname>Sahinidis</surname><given-names>Nikolaos V.</given-names></name>
      </person-group>
      <article-title>Derivative-free optimization: a review of algorithms and comparison of software implementations</article-title>
      <source>Journal of Global Optimization</source>
      <year iso-8601-date="2013-07-01">2013</year><month>07</month><day>01</day>
      <volume>56</volume>
      <issue>3</issue>
      <issn>1573-2916</issn>
      <pub-id pub-id-type="doi">10.1007/s10898-012-9951-y</pub-id>
      <fpage>1247</fpage>
      <lpage>1293</lpage>
    </element-citation>
  </ref>
  <ref id="ref-li2022topology">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Mince</given-names></name>
        <name><surname>Yu</surname><given-names>Pengli</given-names></name>
        <name><surname>Wang</surname><given-names>Yujie</given-names></name>
        <name><surname>Sun</surname><given-names>Zhendong</given-names></name>
        <name><surname>Chen</surname><given-names>Zonghai</given-names></name>
      </person-group>
      <article-title>Topology comparison and sensitivity analysis of fuel cell hybrid systems for electric vehicles</article-title>
      <source>IEEE Transactions on Transportation Electrification</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1109/TTE.2022.3218341</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-FENG20222879">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Feng</surname><given-names>Qi-Hong</given-names></name>
        <name><surname>Li</surname><given-names>Shan-Shan</given-names></name>
        <name><surname>Zhang</surname><given-names>Xian-Min</given-names></name>
        <name><surname>Gao</surname><given-names>Xiao-Fei</given-names></name>
        <name><surname>Ni</surname><given-names>Ji-Hui</given-names></name>
      </person-group>
      <article-title>Well production optimization using streamline features-based objective function and Bayesian adaptive direct search algorithm</article-title>
      <source>Petroleum Science</source>
      <year iso-8601-date="2022">2022</year>
      <volume>19</volume>
      <issue>6</issue>
      <issn>1995-8226</issn>
      <pub-id pub-id-type="doi">10.1016/j.petsci.2022.06.016</pub-id>
      <fpage>2879</fpage>
      <lpage>2894</lpage>
    </element-citation>
  </ref>
  <ref id="ref-STENGARD2022105160">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stengård</surname><given-names>Elina</given-names></name>
        <name><surname>Juslin</surname><given-names>Peter</given-names></name>
        <name><surname>Hahn</surname><given-names>Ulrike</given-names></name>
        <name><surname>van den Berg</surname><given-names>Ronald</given-names></name>
      </person-group>
      <article-title>On the generality and cognitive basis of base-rate neglect</article-title>
      <source>Cognition</source>
      <year iso-8601-date="2022">2022</year>
      <volume>226</volume>
      <issn>0010-0277</issn>
      <pub-id pub-id-type="doi">10.1101/2021.03.11.434913</pub-id>
      <fpage>105160</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-nobel2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nobel</surname><given-names>Anne</given-names></name>
        <name><surname>Lizin</surname><given-names>Sebastien</given-names></name>
        <name><surname>Witters</surname><given-names>Nele</given-names></name>
        <name><surname>Rineau</surname><given-names>Francois</given-names></name>
        <name><surname>Malina</surname><given-names>Robert</given-names></name>
      </person-group>
      <article-title>The impact of wildfires on the recreational value of heathland: A discrete factor approach with adjustment for on-site sampling</article-title>
      <source>Journal of Environmental Economics and Management</source>
      <year iso-8601-date="2020">2020</year>
      <volume>101</volume>
      <issn>0095-0696</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0095069620300401</uri>
      <pub-id pub-id-type="doi">10.1016/j.jeem.2020.102317</pub-id>
      <fpage>102317</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ren2021novel">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ren</surname><given-names>Xukai</given-names></name>
        <name><surname>Huang</surname><given-names>Xiaokang</given-names></name>
        <name><surname>Feng</surname><given-names>Hengjian</given-names></name>
        <name><surname>Chai</surname><given-names>Ze</given-names></name>
        <name><surname>He</surname><given-names>Yanbing</given-names></name>
        <name><surname>Chen</surname><given-names>Huabin</given-names></name>
        <name><surname>Chen</surname><given-names>Xiaoqi</given-names></name>
      </person-group>
      <article-title>A novel energy partition model for belt grinding of Inconel 718</article-title>
      <source>Journal of Manufacturing Processes</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>64</volume>
      <pub-id pub-id-type="doi">10.1016/j.jmapro.2021.02.052</pub-id>
      <fpage>1296</fpage>
      <lpage>1306</lpage>
    </element-citation>
  </ref>
  <ref id="ref-MADS">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Audet</surname><given-names>Charles</given-names></name>
        <name><surname>Dennis</surname><given-names>J.</given-names></name>
      </person-group>
      <article-title>Mesh adaptive direct search algorithms for constrained optimization</article-title>
      <source>SIAM Journal on Optimization</source>
      <year iso-8601-date="2006-01">2006</year><month>01</month>
      <volume>17</volume>
      <pub-id pub-id-type="doi">10.1137/040603371</pub-id>
      <fpage>188</fpage>
      <lpage>217</lpage>
    </element-citation>
  </ref>
  <ref id="ref-deng2006adaptation">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Deng</surname><given-names>Geng</given-names></name>
        <name><surname>Ferris</surname><given-names>Michael C</given-names></name>
      </person-group>
      <article-title>Adaptation of the UOBYQA algorithm for noisy functions</article-title>
      <source>Proceedings of the 2006 winter simulation conference</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2006">2006</year>
      <pub-id pub-id-type="doi">10.1109/wsc.2006.323088</pub-id>
      <fpage>312</fpage>
      <lpage>319</lpage>
    </element-citation>
  </ref>
  <ref id="ref-orthoMADS">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abramson</surname><given-names>Mark A</given-names></name>
        <name><surname>Audet</surname><given-names>Charles</given-names></name>
        <name><surname>Digabel</surname><given-names>Sébastien Le</given-names></name>
      </person-group>
      <article-title>OrthoMADS: a deterministic MADS instance with orthogonal directions</article-title>
      <source>SIAM Journal on Optimization</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2009">2009</year>
      <volume>20</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/080716980</pub-id>
      <fpage>948</fpage>
      <lpage>966</lpage>
    </element-citation>
  </ref>
  <ref id="ref-stoMADS">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Audet</surname><given-names>Charles</given-names></name>
        <name><surname>Dzahini</surname><given-names>Kwassi Joseph</given-names></name>
        <name><surname>Kokkolaras</surname><given-names>Michael</given-names></name>
        <name><surname>Le Digabel</surname><given-names>Sébastien</given-names></name>
      </person-group>
      <article-title>Stochastic mesh adaptive direct search for blackbox optimization using probabilistic estimates</article-title>
      <source>Computational Optimization and Applications</source>
      <year iso-8601-date="2021-05-01">2021</year><month>05</month><day>01</day>
      <volume>79</volume>
      <issue>1</issue>
      <issn>1573-2894</issn>
      <pub-id pub-id-type="doi">10.1007/s10589-020-00249-0</pub-id>
      <fpage>1</fpage>
      <lpage>34</lpage>
    </element-citation>
  </ref>
  <ref id="ref-huggins2023pyvbmc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Huggins</surname><given-names>Bobby</given-names></name>
        <name><surname>Li</surname><given-names>Chengkun</given-names></name>
        <name><surname>Tobaben</surname><given-names>Marlon</given-names></name>
        <name><surname>Aarnos</surname><given-names>Mikko J.</given-names></name>
        <name><surname>Acerbi</surname><given-names>Luigi</given-names></name>
      </person-group>
      <article-title>PyVBMC: efficient Bayesian inference in Python</article-title>
      <source>arXiv</source>
      <publisher-name>preprint</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2303.09519</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.2303.09519</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-acerbi2018variational">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Acerbi</surname><given-names>Luigi</given-names></name>
      </person-group>
      <article-title>Variational Bayesian Monte Carlo</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2018">2018</year>
      <volume>31</volume>
      <fpage>8222</fpage>
      <lpage>8232</lpage>
    </element-citation>
  </ref>
  <ref id="ref-acerbi2020variational">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Acerbi</surname><given-names>Luigi</given-names></name>
      </person-group>
      <article-title>Variational Bayesian Monte Carlo with noisy likelihoods</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2020">2020</year>
      <volume>33</volume>
      <fpage>8211</fpage>
      <lpage>8222</lpage>
    </element-citation>
  </ref>
  <ref id="ref-acerbi2019exploration">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Acerbi</surname><given-names>Luigi</given-names></name>
      </person-group>
      <article-title>An exploration of acquisition and mean functions in Variational Bayesian Monte Carlo</article-title>
      <source>PMLR</source>
      <year iso-8601-date="2019">2019</year>
      <volume>96</volume>
      <fpage>1</fpage>
      <lpage>10</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nomad4paper">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Audet</surname><given-names>Charles</given-names></name>
        <name><surname>Le Digabel</surname><given-names>Sébastien</given-names></name>
        <name><surname>Montplaisir</surname><given-names>Viviane Rochon</given-names></name>
        <name><surname>Tribes</surname><given-names>Christophe</given-names></name>
      </person-group>
      <article-title>NOMAD version 4: nonlinear optimization with the MADS algorithm</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2022-09">2022</year><month>09</month>
      <volume>48</volume>
      <issue>3</issue>
      <issn>0098-3500</issn>
      <uri>https://doi.org/10.1145/3544489</uri>
      <pub-id pub-id-type="doi">10.1145/3544489</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-vanOpheusden2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>van Opheusden</surname><given-names>Bas</given-names></name>
        <name><surname>Kuperwajs</surname><given-names>Ionatan</given-names></name>
        <name><surname>Galbiati</surname><given-names>Gianni</given-names></name>
        <name><surname>Bnaya</surname><given-names>Zahy</given-names></name>
        <name><surname>Li</surname><given-names>Yunqi</given-names></name>
        <name><surname>Ma</surname><given-names>Wei Ji</given-names></name>
      </person-group>
      <article-title>Expertise increases planning depth in human gameplay</article-title>
      <source>Nature</source>
      <year iso-8601-date="2023">2023</year>
      <volume></volume>
      <issue></issue>
      <issn>1476-4687</issn>
      <pub-id pub-id-type="doi">10.1038/s41586-023-06124-2</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-balandat2020botorch">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Balandat</surname><given-names>Maximilian</given-names></name>
        <name><surname>Karrer</surname><given-names>Brian</given-names></name>
        <name><surname>Jiang</surname><given-names>Daniel R.</given-names></name>
        <name><surname>Daulton</surname><given-names>Samuel</given-names></name>
        <name><surname>Letham</surname><given-names>Benjamin</given-names></name>
        <name><surname>Wilson</surname><given-names>Andrew Gordon</given-names></name>
        <name><surname>Bakshy</surname><given-names>Eytan</given-names></name>
      </person-group>
      <article-title>BoTorch: a framework for efficient Monte Carlo Bayesian optimization</article-title>
      <source>Advances in neural information processing systems 33</source>
      <year iso-8601-date="2020">2020</year>
      <uri>http://arxiv.org/abs/1910.06403</uri>
    </element-citation>
  </ref>
  <ref id="ref-pmlr-v32-snoek14">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Snoek</surname><given-names>Jasper</given-names></name>
        <name><surname>Swersky</surname><given-names>Kevin</given-names></name>
        <name><surname>Zemel</surname><given-names>Rich</given-names></name>
        <name><surname>Adams</surname><given-names>Ryan</given-names></name>
      </person-group>
      <article-title>Input warping for Bayesian optimization of non-stationary functions</article-title>
      <source>Proceedings of the 31st international conference on machine learning</source>
      <person-group person-group-type="editor">
        <name><surname>Xing</surname><given-names>Eric P.</given-names></name>
        <name><surname>Jebara</surname><given-names>Tony</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <publisher-loc>Bejing, China</publisher-loc>
      <year iso-8601-date="2014">2014</year>
      <volume>32</volume>
      <fpage>1674</fpage>
      <lpage>1682</lpage>
    </element-citation>
  </ref>
  <ref id="ref-GPflowOpt2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Knudde</surname><given-names>Nicolas</given-names></name>
        <name><surname>van der Herten</surname><given-names>Joachim</given-names></name>
        <name><surname>Dhaene</surname><given-names>Tom</given-names></name>
        <name><surname>Couckuyt</surname><given-names>Ivo</given-names></name>
      </person-group>
      <article-title>GPflowOpt: a Bayesian optimization library using TensorFlow</article-title>
      <source>arXiv preprint – arXiv:1711.03845</source>
      <year iso-8601-date="2017">2017</year>
      <uri>https://arxiv.org/abs/1711.03845</uri>
    </element-citation>
  </ref>
  <ref id="ref-cao2019causal">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cao</surname><given-names>Yinan</given-names></name>
        <name><surname>Summerfield</surname><given-names>Christopher</given-names></name>
        <name><surname>Park</surname><given-names>Hame</given-names></name>
        <name><surname>Giordano</surname><given-names>Bruno Lucio</given-names></name>
        <name><surname>Kayser</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Causal inference in the multisensory brain</article-title>
      <source>Neuron</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>102</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1016/j.neuron.2019.03.043</pub-id>
      <fpage>1076</fpage>
      <lpage>1087</lpage>
    </element-citation>
  </ref>
  <ref id="ref-stenger2022benchmark">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Stenger</surname><given-names>David</given-names></name>
        <name><surname>Abel</surname><given-names>Dirk</given-names></name>
      </person-group>
      <article-title>Benchmark of Bayesian optimization and metaheuristics for control engineering tuning problems with crash constraints</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://arxiv.org/abs/2211.02571</uri>
    </element-citation>
  </ref>
  <ref id="ref-Tajima2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tajima</surname><given-names>Satohiro</given-names></name>
        <name><surname>Drugowitsch</surname><given-names>Jan</given-names></name>
        <name><surname>Patel</surname><given-names>Nisheet</given-names></name>
        <name><surname>Pouget</surname><given-names>Alexandre</given-names></name>
      </person-group>
      <article-title>Optimal policy for multi-alternative decisions</article-title>
      <source>Nature Neuroscience</source>
      <year iso-8601-date="2019-09-01">2019</year><month>09</month><day>01</day>
      <volume>22</volume>
      <issue>9</issue>
      <issn>1546-1726</issn>
      <pub-id pub-id-type="doi">10.1038/s41593-019-0453-9</pub-id>
      <fpage>1503</fpage>
      <lpage>1511</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Li2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Ji-An</given-names></name>
        <name><surname>Dong</surname><given-names>Daoyi</given-names></name>
        <name><surname>Wei</surname><given-names>Zhengde</given-names></name>
        <name><surname>Liu</surname><given-names>Ying</given-names></name>
        <name><surname>Pan</surname><given-names>Yu</given-names></name>
        <name><surname>Nori</surname><given-names>Franco</given-names></name>
        <name><surname>Zhang</surname><given-names>Xiaochu</given-names></name>
      </person-group>
      <article-title>Quantum reinforcement learning during human decision-making</article-title>
      <source>Nature Human Behaviour</source>
      <year iso-8601-date="2020-03-01">2020</year><month>03</month><day>01</day>
      <volume>4</volume>
      <issue>3</issue>
      <issn>2397-3374</issn>
      <pub-id pub-id-type="doi">10.1038/s41562-019-0804-2</pub-id>
      <fpage>294</fpage>
      <lpage>307</lpage>
    </element-citation>
  </ref>
  <ref id="ref-DAUBE20191924">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Daube</surname><given-names>Christoph</given-names></name>
        <name><surname>Ince</surname><given-names>Robin A. A.</given-names></name>
        <name><surname>Gross</surname><given-names>Joachim</given-names></name>
      </person-group>
      <article-title>Simple acoustic features can explain phoneme-based predictions of cortical responses to speech</article-title>
      <source>Current Biology</source>
      <year iso-8601-date="2019">2019</year>
      <volume>29</volume>
      <issue>12</issue>
      <issn>0960-9822</issn>
      <pub-id pub-id-type="doi">10.1016/j.cub.2019.04.067</pub-id>
      <fpage>1924</fpage>
      <lpage>1937.e9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-REN2020575">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ren</surname><given-names>Xukai</given-names></name>
        <name><surname>Chai</surname><given-names>Ze</given-names></name>
        <name><surname>Xu</surname><given-names>Jijin</given-names></name>
        <name><surname>Zhang</surname><given-names>Xiaoqiang</given-names></name>
        <name><surname>He</surname><given-names>Yanbing</given-names></name>
        <name><surname>Chen</surname><given-names>Huabin</given-names></name>
        <name><surname>Chen</surname><given-names>Xiaoqi</given-names></name>
      </person-group>
      <article-title>A new method to achieve dynamic heat input monitoring in robotic belt grinding of Inconel 718</article-title>
      <source>Journal of Manufacturing Processes</source>
      <year iso-8601-date="2020">2020</year>
      <volume>57</volume>
      <issn>1526-6125</issn>
      <pub-id pub-id-type="doi">10.1016/j.jmapro.2020.07.018</pub-id>
      <fpage>575</fpage>
      <lpage>588</lpage>
    </element-citation>
  </ref>
  <ref id="ref-reviewBO">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Shahriari</surname><given-names>Bobak</given-names></name>
        <name><surname>Swersky</surname><given-names>Kevin</given-names></name>
        <name><surname>Wang</surname><given-names>Ziyu</given-names></name>
        <name><surname>Adams</surname><given-names>Ryan P.</given-names></name>
        <name><surname>Freitas</surname><given-names>Nando de</given-names></name>
      </person-group>
      <article-title>Taking the human out of the loop: a review of Bayesian optimization</article-title>
      <source>Proceedings of the IEEE</source>
      <year iso-8601-date="2016">2016</year>
      <volume>104</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1109/JPROC.2015.2494218</pub-id>
      <fpage>148</fpage>
      <lpage>175</lpage>
    </element-citation>
  </ref>
  <ref id="ref-agnihotri2020exploring">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Agnihotri</surname><given-names>Apoorv</given-names></name>
        <name><surname>Batra</surname><given-names>Nipun</given-names></name>
      </person-group>
      <article-title>Exploring Bayesian optimization</article-title>
      <source>Distill</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.23915/distill.00026</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-garnett_bayesoptbook_2023">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Garnett</surname><given-names>Roman</given-names></name>
      </person-group>
      <source>Bayesian optimization</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-rasmussen_gaussian_2006">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Rasmussen</surname><given-names>Carl Edward</given-names></name>
        <name><surname>Williams</surname><given-names>Christopher K. I.</given-names></name>
      </person-group>
      <source>Gaussian processes for machine learning</source>
      <publisher-name>MIT Press</publisher-name>
      <publisher-loc>Cambridge, Mass</publisher-loc>
      <year iso-8601-date="2006">2006</year>
      <isbn>978-0-262-18253-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-scipy-2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
        <name><surname>Haberland</surname><given-names>Matt</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Burovski</surname><given-names>Evgeni</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Bright</surname><given-names>Jonathan</given-names></name>
        <name><surname>van der Walt</surname><given-names>Stéfan J.</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Wilson</surname><given-names>Joshua</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Mayorov</surname><given-names>Nikolay</given-names></name>
        <name><surname>Nelson</surname><given-names>Andrew R. J.</given-names></name>
        <name><surname>Jones</surname><given-names>Eric</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Larson</surname><given-names>Eric</given-names></name>
        <name><surname>Carey</surname><given-names>C J</given-names></name>
        <name><surname>Polat</surname><given-names>İlhan</given-names></name>
        <name><surname>Feng</surname><given-names>Yu</given-names></name>
        <name><surname>Moore</surname><given-names>Eric W.</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Laxalde</surname><given-names>Denis</given-names></name>
        <name><surname>Perktold</surname><given-names>Josef</given-names></name>
        <name><surname>Cimrman</surname><given-names>Robert</given-names></name>
        <name><surname>Henriksen</surname><given-names>Ian</given-names></name>
        <name><surname>Quintero</surname><given-names>E. A.</given-names></name>
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Archibald</surname><given-names>Anne M.</given-names></name>
        <name><surname>Ribeiro</surname><given-names>Antônio H.</given-names></name>
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>van Mulbregt</surname><given-names>Paul</given-names></name>
        <string-name>SciPy 1.0 Contributors</string-name>
      </person-group>
      <article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2020">2020</year>
      <volume>17</volume>
      <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>
      <fpage>261</fpage>
      <lpage>272</lpage>
    </element-citation>
  </ref>
  <ref id="ref-harris_array_2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Walt</surname><given-names>Stéfan J. van der</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Wieser</surname><given-names>Eric</given-names></name>
        <name><surname>Taylor</surname><given-names>Julian</given-names></name>
        <name><surname>Berg</surname><given-names>Sebastian</given-names></name>
        <name><surname>Smith</surname><given-names>Nathaniel J.</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Picus</surname><given-names>Matti</given-names></name>
        <name><surname>Hoyer</surname><given-names>Stephan</given-names></name>
        <name><surname>Kerkwijk</surname><given-names>Marten H. van</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Haldane</surname><given-names>Allan</given-names></name>
        <name><surname>Río</surname><given-names>Jaime Fernández del</given-names></name>
        <name><surname>Wiebe</surname><given-names>Mark</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>Gérard-Marchant</surname><given-names>Pierre</given-names></name>
        <name><surname>Sheppard</surname><given-names>Kevin</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Abbasi</surname><given-names>Hameer</given-names></name>
        <name><surname>Gohlke</surname><given-names>Christoph</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <year iso-8601-date="2020-09-01">2020</year><month>09</month><day>01</day>
      <volume>585</volume>
      <issue>7825</issue>
      <issn>1476-4687</issn>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
