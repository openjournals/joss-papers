<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8389</article-id>
<article-id pub-id-type="doi">10.21105/joss.08389</article-id>
<title-group>
<article-title>geospaNN: A Python package for geospatial neural
networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zhan</surname>
<given-names>Wentao</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Datta</surname>
<given-names>Abhirup</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Statistics, University of
Wisconsin-Madison</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Biostatistics, Johns Hopkins Bloomberg School
of Public Health</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>11</volume>
<issue>117</issue>
<fpage>8389</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Pytorch</kwd>
<kwd>Graph neural networks</kwd>
<kwd>Geospatial data</kwd>
<kwd>Gaussian Process</kwd>
<kwd>Kriging</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Geostatistical models are essential for analyzing data with spatial
  structure across the geosciences, such as climate, ecology, and
  environmental science. At the same time, modern machine learning
  methods, especially neural networks (NNs), offer powerful tools for
  capturing complex, nonlinear relationships. Our package
  <monospace>geospaNN</monospace> bridges these two worlds by providing
  a Python library that integrates NN modeling with scalable spatial
  statistics. The software enables users to fit flexible spatial
  regression models, estimate complex mean structures, and generate
  Gaussian process (GP)–based spatial predictions with uncertainty
  quantification. Built on the <monospace>PyG</monospace> library
  designed for efficient graph neural network (GNN) training,
  <monospace>geospaNN</monospace> supports efficient computation on
  large, irregular spatial datasets. To handle modern geospatial data
  sizes, <monospace>geospaNN</monospace> incorporates the Nearest
  Neighbor Gaussian Process (NNGP) approximation
  (<xref alt="Datta et al., 2016" rid="ref-datta2016nearest" ref-type="bibr">Datta
  et al., 2016</xref>) for fast covariance computations. </p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Researchers in geoscience and related fields frequently need to
  model relationships among spatially distributed variables and generate
  reliable spatial predictions. Although many Python machine learning
  libraries can fit complex nonlinear regression models, they typically
  ignore spatial correlation, leading to biased estimates and misleading
  inference when applied to geospatial data. Existing spatial modeling
  tools in Python provide only partial solutions: some rely on complex
  neural architectures that sacrifice scientific interpretability, while
  others use full GP models whose computational demands make them
  impractical for large datasets.</p>
  <p><monospace>geospaNN</monospace> addresses these limitations by
  providing a spatial regression framework that combines the flexibility
  of NNs with the interpretability and statistical rigor of
  geostatistical models. It is designed for geoscientists, environmental
  researchers, and machine learning practitioners who need scalable and
  principled spatial modeling tools in Python.
  <monospace>geospaNN</monospace> enables geometry-aware covariance
  estimation and spatial prediction at scales—tens of thousands of
  locations—that are feasible on a personal laptop. This makes advanced
  spatial analysis accessible to individual researchers without
  specialized computing infrastructure.</p>
  <p>The NNGP implementation within <monospace>geospaNN</monospace> also
  fills a notable gap in the Python ecosystem. While widely used R
  packages such as <monospace>spNNGP</monospace>
  (<xref alt="Finley et al., 2019" rid="ref-finley2019efficient" ref-type="bibr">Finley
  et al., 2019</xref>) and <monospace>BRISC</monospace>
  (<xref alt="Saha &amp; Datta, 2018" rid="ref-saha2018brisc" ref-type="bibr">Saha
  &amp; Datta, 2018</xref>) provide efficient NNGP-based spatial models,
  no comparable Python implementation currently exists.
  <monospace>geospaNN</monospace> therefore offers the first
  Python-based pathway for NNGP modeling in geospatial applications,
  meeting the growing demand for large-scale spatial analysis.</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the field</title>
  <p>Integrating geospatial data with modern deep learning has motivated
  the development of several specialized Python tools. For example,
  <monospace>TorchGeo</monospace>
  (<xref alt="Stewart et al., 2022" rid="ref-TorchGeo2022" ref-type="bibr">Stewart
  et al., 2022</xref>) extends <monospace>PyTorch</monospace>
  (<xref alt="Paszke et al., 2019" rid="ref-paszke2019pytorch" ref-type="bibr">Paszke
  et al., 2019</xref>) for tasks such as land cover classification,
  object detection, and geospatial segmentation, while the R package
  <monospace>geodl</monospace>
  (<xref alt="Maxwell et al., 2024" rid="ref-maxwell2024geodl" ref-type="bibr">Maxwell
  et al., 2024</xref>) was recently introduced for analyzing geospatial
  and spatiotemporal datasets. However, these frameworks are primarily
  designed for raster and vector data—especially satellite
  imagery—rather than for general geostatistical modeling or spatial
  regression. Their scope is therefore limited when working with
  point-referenced geospatial data or when statistical interpretability
  is essential.</p>
  <p>For irregular spatial data, GNNs have emerged as a powerful
  modeling approach. <monospace>PyTorch-Geometric</monospace>
  (<monospace>PyG</monospace>)
  (<xref alt="Fey &amp; Lenssen, 2019" rid="ref-PyG2019" ref-type="bibr">Fey
  &amp; Lenssen, 2019</xref>) provides a flexible and efficient
  framework for implementing GNNs, and these models have been
  successfully applied to a range of geospatial tasks, including crop
  yield prediction
  (<xref alt="Fan et al., 2022" rid="ref-fan2022gnn" ref-type="bibr">Fan
  et al., 2022</xref>) and traffic flow modeling
  (<xref alt="Wang et al., 2020" rid="ref-wang2020traffic" ref-type="bibr">Wang
  et al., 2020</xref>). Despite their popularity, there is still no
  unified, statistically oriented GNN software designed specifically for
  geospatial regression or rigorous covariance modeling. This leaves a
  gap between machine learning–focused GNN libraries and the needs of
  statistical geoscience.</p>
  <p>GP–based tools provide another major category of spatial modeling
  software. <monospace>PyKrige</monospace>
  (<xref alt="Murphy, 2014" rid="ref-murphy2014pykrige" ref-type="bibr">Murphy,
  2014</xref>) offers classical kriging prediction but is limited to
  predefined mean functions and lacks scalable covariance computation
  for large datasets. <monospace>GPyTorch</monospace>
  (<xref alt="Gardner et al., 2018" rid="ref-gardner2018gpytorch" ref-type="bibr">Gardner
  et al., 2018</xref>) supports flexible mean modeling and GP inference
  within a mixed-model framework, but its functionality is highly
  modular and requires substantial custom implementation, making it
  difficult for general users to apply. Moreover, its covariance
  approximations are not explicitly designed to exploit spatial
  geometry, which can reduce efficiency and accuracy compared with
  approaches tailored to geostatistical structure.</p>
</sec>
<sec id="the-geospann-package">
  <title>The geospaNN Package</title>
  <p>This section provides an overview of the
  <monospace>geospaNN</monospace> package, including the model
  architecture and several technical details. For practical examples and
  detailed documentation, visit the
  <ext-link ext-link-type="uri" xlink:href="https://wentaozhan1998.github.io/geospaNN-doc"><monospace>geospaNN</monospace>
  website</ext-link>. </p>
  <sec id="nn-gls-overview">
    <title>NN-GLS Overview</title>
    <p>In methodology, <monospace>geospaNN</monospace> uses NN-GLS
    (<xref alt="Zhan &amp; Datta, 2025" rid="ref-zhan2024neural" ref-type="bibr">Zhan
    &amp; Datta, 2025</xref>), a novel and scalable class of NNs
    explicitly designed to account for spatial correlation in the data.
    NN-GLS embeds NN with the following spatial mixed model:
    <disp-formula><alternatives>
    <tex-math><![CDATA[
    Y(s) = m(X(s)) + \epsilon(s)
    ]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
    where <inline-formula><alternatives>
    <tex-math><![CDATA[Y(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[X(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>X</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    are respectively the outcome and covariates observed at location
    <inline-formula><alternatives>
    <tex-math><![CDATA[s]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[m]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>m</mml:mi></mml:math></alternatives></inline-formula>
    is a non-linear function relating <inline-formula><alternatives>
    <tex-math><![CDATA[X(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>X</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    to <inline-formula><alternatives>
    <tex-math><![CDATA[Y(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    to be estimated using a NN. The key distinction from the standard
    non-linear regression setup is that here the errors
    <inline-formula><alternatives>
    <tex-math><![CDATA[\epsilon(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    is a GP that models spatial correlation. </p>
    <p>To solve the model, NN-GLS replaces the original loss function
    with a GLS-style version, which naturally equates to a specialized
    GNN. For computational efficiency, NNGP is introduced to approximate
    the covariance,. In NN-GLS, we assume that the parameters of the
    covariance matrix is unknown. These covariance parameters
    <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>
    for spatial process <inline-formula><alternatives>
    <tex-math><![CDATA[\epsilon(s)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    and the weights parameters of the NN used to model
    <inline-formula><alternatives>
    <tex-math><![CDATA[m]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>m</mml:mi></mml:math></alternatives></inline-formula>
    are estimated iteratively, and training proceeds until the
    validation loss converges. Once estimation is complete,
    nearest-neighbor-based kriging is used to generate spatial
    predictions at new locations.</p>
  </sec>
  <sec id="core-features-of-geospann">
    <title>Core features of <monospace>geospaNN</monospace></title>
    <p>The <monospace>geospaNN</monospace> workflow begins by preparing
    the data and constructing the model inputs. Users may supply
    covariates, responses, and coordinates in simple matrix form. The
    function <monospace>geospaNN.make_graph</monospace> then creates a
    <monospace>DataLoader</monospace> object that organizes the data and
    handles batching efficiently:</p>
    <code language="python">data = geospaNN.make_graph(X, Y, coord, nn)</code>
    <p><monospace>geospaNN</monospace> provides flexible tools for
    specifying neural network architectures and defining training
    routines, all fully compatible with the
    <monospace>PyTorch</monospace> ecosystem. The code example below
    illustrates a typical training setup. Here, a two-layer multilayer
    perceptron is used to model the nonlinear mean structure. The
    <monospace>nngls_model</monospace> object implements the NN–GLS
    model, and <monospace>trainer_nngls</monospace> manages the
    iterative training process. Users may rely on default
    hyperparameters or customize them as needed.</p>
    <code language="python">mlp_nngls = torch.nn.Sequential(
    torch.nn.Linear(p, 100),
    torch.nn.ReLU(),
    torch.nn.Linear(100, 20),
    torch.nn.ReLU(),
    torch.nn.Linear(20, 1),
)
nngls_model = geospaNN.nngls(p=p, neighbor_size=nn, coord_dimensions=2, 
                             mlp=mlp_nngls, theta=torch.tensor(theta0))
trainer_nngls = geospaNN.nngls_train(nngls_model, lr=0.1, min_delta=0.001)
training_log = trainer_nngls.train(data_train, data_val, epoch_num= 200, 
                                   Update_init=10, Update_step=2, 
                                   batch_size = 60, seed = 2025)</code>
    <p>Once training is complete, the fitted model provides three key
    capabilities:</p>
    <list list-type="order">
      <list-item>
        <p>estimate the non-linear mean function by
        <inline-formula><alternatives>
        <tex-math><![CDATA[\hat{m}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>m</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
      </list-item>
      <list-item>
        <p>estimate the spatial parameters by
        <inline-formula><alternatives>
        <tex-math><![CDATA[\hat{\theta}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>θ</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
      </list-item>
      <list-item>
        <p>predict the outcome at new locations by
        <inline-formula><alternatives>
        <tex-math><![CDATA[\hat{Y}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>Y</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
      </list-item>
    </list>
    <p>The mean function <inline-formula><alternatives>
    <tex-math><![CDATA[m(x)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>m</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    represents the non-spatial component of the spatial mixed model,
    representing the non-spatial relationship between
    <inline-formula><alternatives>
    <tex-math><![CDATA[Y]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
    and covariates <inline-formula><alternatives>
    <tex-math><![CDATA[X]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>.
    To obtain predictions of the mean function for a given matrix of
    covariates <monospace>X</monospace>, users may call:</p>
    <code language="python">estimate = nngls_model.estimate(X)</code>
    <p>The estimated spatial parameters <inline-formula><alternatives>
    <tex-math><![CDATA[\hat{\theta}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>θ</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
    characterize the spatial correlation structure implied by the model.
    They are stored internally and can be accessed directly:</p>
    <code language="python">nngls_model.theta</code>
    <p>These parameters can be used to reconstruct the implied
    covariance matrix or inform further geostatistical analyses.</p>
    <p>While mean function estimation reflect the connection between
    variables, to predict the value of response
    <inline-formula><alternatives>
    <tex-math><![CDATA[Y]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
    at new locations with uncertainty quantification,
    <monospace>geospaNN</monospace> uses
    <monospace>predict()</monospace> method:</p>
    <code language="python">[test_predict, test_PI_U, test_PI_L] = nngls_model.predict(data_train, data_test, 
                                                           PI = True)</code>
  </sec>
  <sec id="other-features">
    <title>Other Features</title>
    <p>In addition to estimation and prediction for the NN-GLS spatial
    mixed models, <monospace>geospaNN</monospace> offers a suite of
    additional features that support a wide range of geospatial
    analyses. <monospace>geospaNN</monospace> provides simulation module
    allowing users to customize the spatial parameters and mean
    functions to generate <inline-formula><alternatives>
    <tex-math><![CDATA[Y]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[X]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>,
    and <inline-formula><alternatives>
    <tex-math><![CDATA[s]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>.
    Users are allowed to customize the spatial coordinates to simulate
    under different context. <monospace>geospaNN</monospace> implements
    nearest neighbor kriging, an alternate to full kriging, which has
    been shown in Zhan &amp; Datta
    (<xref alt="2025" rid="ref-zhan2024neural" ref-type="bibr">2025</xref>)
    to guarantee accurate prediction interval under various settings.
    For essential machine learning tasks,
    <monospace>geospaNN</monospace> offers modules including NN
    architecture design, training log report, and result visualization.
    <monospace>geospaNN</monospace> also implements spatial linear mixed
    model (SPLMM) as a special case of NN-GLS. It should be an optimal
    choice for the Python users if efficient SPLMM solution is wanted
    for large geospatial datasets.</p>
    <p>Because the above code snippets rely on additional setup, they
    are not meant to run independently. Users can find complete,
    reproducible examples and detailed documentation in the project
    <ext-link ext-link-type="uri" xlink:href="https://github.com/WentaoZhan1998/geospaNN/blob/main/vignette/vignette.pdf">vignette</ext-link>.</p>
  </sec>
</sec>
<sec id="discussion">
  <title>Discussion</title>
  <p>The <monospace>geospaNN</monospace> package provides a machine
  learning toolkit for geostatistical analysis. Built on an efficient
  implementation of the NN–GLS approach proposed in Zhan &amp; Datta
  (<xref alt="2025" rid="ref-zhan2024neural" ref-type="bibr">2025</xref>),
  <monospace>geospaNN</monospace> supports a range of core statistical
  tasks, including nonlinear mean-function estimation, covariance
  parameter estimation, and spatial prediction with uncertainty
  quantification. Leveraging the sparsity of the NNGP approximation, the
  software integrates naturally into the GNN framework, enabling the use
  of graph-based operations and opening the door to more advanced neural
  architectures in geospatial modeling.</p>
  <p>Despite these strengths, the current version of
  <monospace>geospaNN</monospace> has several limitations. At present,
  the package supports only a limited set of stationary, parametric
  covariance models and does not handle non-stationary or non-Gaussian
  spatial processes. The neural network component is designed and tested
  mainly for simple architectures such as multilayer perceptrons, which
  work well for moderate-scale spatial data but limit applicability to
  more complex or high-dimensional input structures. One important
  future direction is to increase the flexibility of our model and add
  features to the main steps in <monospace>geospaNN</monospace> to adopt
  more general estimation and prediction tasks. In addition,
  <monospace>geospaNN</monospace> currently requires R-dependency and
  does not support GPU acceleration. In the future releases, we will
  address these key issues to further improve the performance of the
  software.</p>
  <p>Conceptually, a longer-term direction for
  <monospace>geospaNN</monospace> is to evolve into a general framework
  for geospatially informed deep learning, where spatially structured
  message passing can be incorporated while maintaining statistical
  interpretability. We also plan to extend the methodology to additional
  data types and distributional settings beyond the current Gaussian
  framework.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work is supported by National Institute of Environmental
  Health Sciences grant R01ES033739. The authors report there are no
  competing interests to declare.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-datta2016nearest">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Datta</surname><given-names>Abhirup</given-names></name>
        <name><surname>Banerjee</surname><given-names>Sudipto</given-names></name>
        <name><surname>Finley</surname><given-names>Andrew O</given-names></name>
        <name><surname>Gelfand</surname><given-names>Alan E</given-names></name>
      </person-group>
      <article-title>On nearest-neighbor Gaussian process models for massive spatial data</article-title>
      <source>Wiley Interdisciplinary Reviews: Computational Statistics</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>8</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1002/wics.1383</pub-id>
      <fpage>162</fpage>
      <lpage>171</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fan2022gnn">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Fan</surname><given-names>Joshua</given-names></name>
        <name><surname>Bai</surname><given-names>Junwen</given-names></name>
        <name><surname>Li</surname><given-names>Zhiyun</given-names></name>
        <name><surname>Ortiz-Bobea</surname><given-names>Ariel</given-names></name>
        <name><surname>Gomes</surname><given-names>Carla P</given-names></name>
      </person-group>
      <article-title>A GNN-RNN approach for harnessing geospatial and temporal information: Application to crop yield prediction</article-title>
      <source>Proceedings of the AAAI conference on artificial intelligence</source>
      <year iso-8601-date="2022">2022</year>
      <volume>36</volume>
      <pub-id pub-id-type="doi">10.1609/aaai.v36i11.21444</pub-id>
      <fpage>11873</fpage>
      <lpage>11881</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PyG2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fey</surname><given-names>Matthias</given-names></name>
        <name><surname>Lenssen</surname><given-names>Jan E.</given-names></name>
      </person-group>
      <article-title>Fast graph representation learning with PyTorch Geometric</article-title>
      <source>arXiv preprint arXiv:1903.02428</source>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-finley2019efficient">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Finley</surname><given-names>Andrew O</given-names></name>
        <name><surname>Datta</surname><given-names>Abhirup</given-names></name>
        <name><surname>Cook</surname><given-names>Bruce D</given-names></name>
        <name><surname>Morton</surname><given-names>Douglas C</given-names></name>
        <name><surname>Andersen</surname><given-names>Hans E</given-names></name>
        <name><surname>Banerjee</surname><given-names>Sudipto</given-names></name>
      </person-group>
      <article-title>Efficient algorithms for Bayesian nearest neighbor Gaussian processes</article-title>
      <source>Journal of Computational and Graphical Statistics</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>28</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1080/10618600.2018.1537924</pub-id>
      <fpage>401</fpage>
      <lpage>414</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gardner2018gpytorch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gardner</surname><given-names>Jacob</given-names></name>
        <name><surname>Pleiss</surname><given-names>Geoff</given-names></name>
        <name><surname>Weinberger</surname><given-names>Kilian Q</given-names></name>
        <name><surname>Bindel</surname><given-names>David</given-names></name>
        <name><surname>Wilson</surname><given-names>Andrew G</given-names></name>
      </person-group>
      <article-title>GPyTorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2018">2018</year>
      <volume>31</volume>
    </element-citation>
  </ref>
  <ref id="ref-maxwell2024geodl">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Maxwell</surname><given-names>Aaron E</given-names></name>
        <name><surname>Farhadpour</surname><given-names>Sarah</given-names></name>
        <name><surname>Das</surname><given-names>Srinjoy</given-names></name>
        <name><surname>Yang</surname><given-names>Yalin</given-names></name>
      </person-group>
      <article-title>Geodl: An R package for geospatial deep learning semantic segmentation using torch and terra</article-title>
      <source>PloS one</source>
      <publisher-name>Public Library of Science San Francisco, CA USA</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>19</volume>
      <issue>12</issue>
      <pub-id pub-id-type="doi">10.31223/x53m6t</pub-id>
      <fpage>e0315127</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-murphy2014pykrige">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Murphy</surname><given-names>Benjamin S</given-names></name>
      </person-group>
      <article-title>PyKrige: Development of a kriging toolkit for Python</article-title>
      <source>AGU fall meeting abstracts</source>
      <year iso-8601-date="2014">2014</year>
      <volume>2014</volume>
      <fpage>H51K</fpage>
      <lpage>0753</lpage>
    </element-citation>
  </ref>
  <ref id="ref-paszke2019pytorch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>32</volume>
    </element-citation>
  </ref>
  <ref id="ref-saha2018brisc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Saha</surname><given-names>Arkajyoti</given-names></name>
        <name><surname>Datta</surname><given-names>Abhirup</given-names></name>
      </person-group>
      <article-title>BRISC: Bootstrap for rapid inference on spatial covariances</article-title>
      <source>Stat</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>7</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1002/sta4.184</pub-id>
      <fpage>e184</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-TorchGeo2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Stewart</surname><given-names>Adam J.</given-names></name>
        <name><surname>Robinson</surname><given-names>Caleb</given-names></name>
        <name><surname>Corley</surname><given-names>Isaac A.</given-names></name>
        <name><surname>Ortiz</surname><given-names>Anthony</given-names></name>
        <name><surname>Lavista Ferres</surname><given-names>Juan M.</given-names></name>
        <name><surname>Banerjee</surname><given-names>Arindam</given-names></name>
      </person-group>
      <article-title>TorchGeo: Deep learning with geospatial data</article-title>
      <source>Proceedings of the 30th international conference on advances in geographic information systems</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>Seattle, Washington</publisher-loc>
      <year iso-8601-date="2022-11">2022</year><month>11</month>
      <uri>https://dl.acm.org/doi/10.1145/3557915.3560953</uri>
      <pub-id pub-id-type="doi">10.1145/3557915.3560953</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2020traffic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Xiaoyang</given-names></name>
        <name><surname>Ma</surname><given-names>Yao</given-names></name>
        <name><surname>Wang</surname><given-names>Yiqi</given-names></name>
        <name><surname>Jin</surname><given-names>Wei</given-names></name>
        <name><surname>Wang</surname><given-names>Xin</given-names></name>
        <name><surname>Tang</surname><given-names>Jiliang</given-names></name>
        <name><surname>Jia</surname><given-names>Caiyan</given-names></name>
        <name><surname>Yu</surname><given-names>Jian</given-names></name>
      </person-group>
      <article-title>Traffic flow prediction via spatial temporal graph neural network</article-title>
      <source>Proceedings of the web conference 2020</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.1145/3366423.3380186</pub-id>
      <fpage>1082</fpage>
      <lpage>1092</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhan2024neural">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhan</surname><given-names>Wentao</given-names></name>
        <name><surname>Datta</surname><given-names>Abhirup</given-names></name>
      </person-group>
      <article-title>Neural networks for geospatial data</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <volume>120</volume>
      <issue>549</issue>
      <pub-id pub-id-type="doi">10.1080/01621459.2024.2356293</pub-id>
      <fpage>535</fpage>
      <lpage>547</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
