<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4455</article-id>
<article-id pub-id-type="doi">10.21105/joss.04455</article-id>
<title-group>
<article-title>GPJax: A Gaussian Process Framework in
JAX</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Pinder</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dodd</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Mathematics and Statistics, Lancaster
University, United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>STOR-i Centre for Doctoral Training, Lancaster University,
United Kingdom</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-05-24">
<day>24</day>
<month>5</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>75</issue>
<fpage>4455</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Gaussian processes</kwd>
<kwd>JAX</kwd>
<kwd>Bayesian inference</kwd>
<kwd>Machine learning</kwd>
<kwd>Statistics</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Gaussian processes (GPs,
  <xref alt="Rasmussen &amp; Williams, 2006" rid="ref-rasmussen2006gaussian" ref-type="bibr">Rasmussen
  &amp; Williams, 2006</xref>) are Bayesian nonparametric models that
  have been successfully used in applications such as geostatistics
  (<xref alt="Matheron, 1963" rid="ref-matheron1963principles" ref-type="bibr">Matheron,
  1963</xref>), Bayesian optimisation
  (<xref alt="Mockus et al., 1978" rid="ref-mockus1978application" ref-type="bibr">Mockus
  et al., 1978</xref>), and reinforcement learning
  (<xref alt="Deisenroth &amp; Rasmussen, 2011" rid="ref-deisenroth2011pilco" ref-type="bibr">Deisenroth
  &amp; Rasmussen, 2011</xref>). <monospace>GPJax</monospace> is a
  didactic GP library targeted at researchers who wish to develop novel
  GP methodology. The scope of <monospace>GPJax</monospace> is to
  provide users with a set of composable objects for constructing GP
  models that closely resemble the underlying maths that one would write
  on paper. Furthermore, by the virtue of being written in JAX
  (<xref alt="Bradbury et al., 2018" rid="ref-jax2018github" ref-type="bibr">Bradbury
  et al., 2018</xref>), <monospace>GPJax</monospace> natively supports
  CPUs, GPUs and TPUs through efficient compilation to XLA, automatic
  differentiation and vectorised operations. Consequently,
  <monospace>GPJax</monospace> provides a modern GP package that can
  effortlessly be tailored, extended and interleaved with other
  libraries to meet the individual needs of researchers and
  scientists.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>From both an applied and methodological perspective, GPs are widely
  employed in the statistics and machine learning communities.
  High-quality software packages that promote GP modelling are
  accountable for much of their success. However, there currently exists
  a gap within the JAX ecosystem for a Gaussian process package to be
  developed that incorporates scalable inference techniques.
  <monospace>GPJax</monospace> seeks to resolve this.</p>
  <p><monospace>GPJax</monospace> has been carefully tailored to
  amalgamate with the JAX ecosystem. For efficient Markov Chain Monte
  Carlo inference, <monospace>GPJax</monospace> can utilise samplers
  from BlackJax
  (<xref alt="BlackJax, 2021" rid="ref-blackjax2021" ref-type="bibr">BlackJax,
  2021</xref>) and TensorFlow Probability
  (<xref alt="Abadi et al., 2016" rid="ref-abadi2016tensorflow" ref-type="bibr">Abadi
  et al., 2016</xref>). For gradient-based optimisation,
  <monospace>GPJax</monospace> integrates seamlessly with Optax
  (<xref alt="Babuschkin et al., 2020" rid="ref-deepmind2020jax" ref-type="bibr">Babuschkin
  et al., 2020</xref>), providing a vast suite of optimisers and
  learning rate schedules. To efficiently represent probability
  distributions, <monospace>GPJax</monospace> leverages Distrax
  (<xref alt="Babuschkin et al., 2020" rid="ref-deepmind2020jax" ref-type="bibr">Babuschkin
  et al., 2020</xref>) and TensorFlow Probability
  (<xref alt="Abadi et al., 2016" rid="ref-abadi2016tensorflow" ref-type="bibr">Abadi
  et al., 2016</xref>). To combine GPs with deep learning methods,
  <monospace>GPJax</monospace> can incorporate the functionality
  provided within Haiku
  (<xref alt="Babuschkin et al., 2020" rid="ref-deepmind2020jax" ref-type="bibr">Babuschkin
  et al., 2020</xref>). The <monospace>GPJax</monospace> documentation
  includes examples of each of these integrations.</p>
  <p>The foundation of each abstraction given in
  <monospace>GPJax</monospace> is a Chex
  (<xref alt="Babuschkin et al., 2020" rid="ref-deepmind2020jax" ref-type="bibr">Babuschkin
  et al., 2020</xref>) dataclass object. These require significantly
  less boilerplate code than regular Python classes, leading to a more
  readable codebase. Moreover, Chex dataclasses are registered as PyTree
  nodes, facilitating the applications of JAX operations such as
  just-in-time compilation and automatic differentiation to any
  <monospace>GPJax</monospace> object.</p>
  <p>The intimacy between <monospace>GPJax</monospace> and the
  underlying maths also makes <monospace>GPJax</monospace> an excellent
  package for people new to GP modelling. Having the ability to easily
  cross-reference the contents of a textbook with the code that one is
  writing is invaluable when trying to build an intuition for a new
  statistical method. We further support this effort in
  <monospace>GPJax</monospace> through documentation that provides
  detailed explanations of the operations conducted within each
  notebook.</p>
</sec>
<sec id="wider-software-ecosystem">
  <title>Wider Software Ecosystem</title>
  <p>Within the Python community, the three most popular packages for GP
  modelling are GPFlow
  (<xref alt="Matthews et al., 2017" rid="ref-matthews2017gpflow" ref-type="bibr">Matthews
  et al., 2017</xref>), GPyTorch
  (<xref alt="Gardner et al., 2018" rid="ref-gardner2018gpytorch" ref-type="bibr">Gardner
  et al., 2018</xref>), and GPy
  (<xref alt="GPy, 2012" rid="ref-gpy2014" ref-type="bibr">GPy,
  2012</xref>). Despite these packages being indispensable tools for the
  community, none support integration with a JAX-based workflow. On the
  other hand, BayesNewton
  (<xref alt="Wilkinson et al., 2021" rid="ref-wilkinson2021bayesnewton" ref-type="bibr">Wilkinson
  et al., 2021</xref>) and TinyGP
  (<xref alt="Foreman-Mackey, 2021" rid="ref-dfm2021tinygp" ref-type="bibr">Foreman-Mackey,
  2021</xref>) packages utilise a Jax backend. However, BayesNewton is
  designed on top of ObJax
  (<xref alt="Objax Developers, 2020" rid="ref-objax2020github" ref-type="bibr">Objax
  Developers, 2020</xref>), making integration with the broader Jax
  ecosystem challenging. Meanwhile, TinyGP offers excellent integration
  with inference frameworks such as NumPyro
  (<xref alt="Phan et al., 2019" rid="ref-phan2019composable" ref-type="bibr">Phan
  et al., 2019</xref>) but does not yet support inducing points
  frameworks (e.g.,
  <xref alt="Hensman et al., 2013" rid="ref-hensman2013gaussian" ref-type="bibr">Hensman
  et al., 2013</xref>). <monospace>GPJax</monospace> exists to resolve
  these issues. Furthermore, modern research from the GP literature,
  graph kernels
  (<xref alt="Borovitskiy et al., 2021" rid="ref-borovitskiy2021matern" ref-type="bibr">Borovitskiy
  et al., 2021</xref>) and Wasserstein barycentres for GPs
  (<xref alt="Mallasto &amp; Feragen, 2017" rid="ref-mallasto2017learning" ref-type="bibr">Mallasto
  &amp; Feragen, 2017</xref>), for example, are supported within
  <monospace>GPJax</monospace> but absent from these packages. Finally,
  the Stheno package
  (<xref alt="Bruinsma, 2022" rid="ref-stheno2022bruinsma" ref-type="bibr">Bruinsma,
  2022</xref>) supports a JAX backend along with TensorFlow, PyTorch and
  Numpy. Whilst this integrates GPs into an extensive JAX workflow,
  <monospace>GPJax</monospace> has the advantage of being a pure JAX
  codebase, whereas Stheno requires using a custom linear algebra
  framework.</p>
  <p>For completeness, packages written for languages other than Python
  include GPML
  (<xref alt="Rasmussen &amp; Nickisch, 2010" rid="ref-rasmussen2010gaussian" ref-type="bibr">Rasmussen
  &amp; Nickisch, 2010</xref>) and GPStuff
  (<xref alt="Vanhatalo et al., 2013" rid="ref-vanhatalo2013gpstuff" ref-type="bibr">Vanhatalo
  et al., 2013</xref>) in MATLAB. An R port also exists for GPStuff.
  Within Julia, there exists GaussianProcesses.jl
  (<xref alt="Fairbrother et al., 2022" rid="ref-fairbrother2022gaussianprocesses" ref-type="bibr">Fairbrother
  et al., 2022</xref>), AugmentedGaussianProcesses.jl
  (<xref alt="Galy-Fajou et al., 2020" rid="ref-fajou20a" ref-type="bibr">Galy-Fajou
  et al., 2020</xref>) and Stheno.jl
  (<xref alt="Tebbutt W, 2022" rid="ref-stheno2022tebbutt" ref-type="bibr">Tebbutt
  W, 2022</xref>).</p>
  <p>GP implementations are available in numerous modern probabilistic
  programming languages such as NumPyro
  (<xref alt="Phan et al., 2019" rid="ref-phan2019composable" ref-type="bibr">Phan
  et al., 2019</xref>), Stan
  (<xref alt="Carpenter et al., 2017" rid="ref-carpenter2017stan" ref-type="bibr">Carpenter
  et al., 2017</xref>), and PyMC
  (<xref alt="Salvatier et al., 2016" rid="ref-Salvatier2016" ref-type="bibr">Salvatier
  et al., 2016</xref>).</p>
</sec>
<sec id="external-usage">
  <title>External Usage</title>
  <p>Two recent research papers
  (<xref alt="Pinder et al., 2021" rid="ref-pinder2021gaussian" ref-type="bibr">Pinder
  et al., 2021</xref>,
  <xref alt="2022" rid="ref-pinder2022street" ref-type="bibr">2022</xref>)
  utilise the graph kernel functionality provided by
  <monospace>GPJax</monospace>. Furthermore,
  <monospace>GPJax</monospace> is being used to build probabilistic
  ensembles of climate models
  (<xref alt="Amos et al., 2022" rid="ref-amos2022ensembles" ref-type="bibr">Amos
  et al., 2022</xref>) and perform adaptive sampling in deep-sea
  environmental
  (<xref alt="Dodd et al., 2022" rid="ref-dodd2022ensembles" ref-type="bibr">Dodd
  et al., 2022</xref>).</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>As an open-source project, <monospace>GPJax</monospace> has
  benefitted from contributions made by the wider community. We
  especially thank Juan Emmanuel Johnson and are grateful for the
  thoughts and advice from the wider GP community.</p>
</sec>
<sec id="funding-statement">
  <title>Funding Statement</title>
  <p>TP is supported by the Data Science for the Natural Environment
  project (EPSRC grant number EP/R01860X/1). DD is supported by the
  STOR-i Centre for Doctoral Training (EPSRC grant number EP/S022252/1)
  and the Research Hub for Transforming Energy Infrastructure through
  Digital Engineering (ARC grant number IH200100009).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-rasmussen2006gaussian">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Rasmussen</surname><given-names>Carl Edward</given-names></name>
        <name><surname>Williams</surname><given-names>Christopher K</given-names></name>
      </person-group>
      <source>Gaussian processes for machine learning</source>
      <publisher-name>MIT press Cambridge, MA</publisher-name>
      <year iso-8601-date="2006">2006</year>
      <pub-id pub-id-type="doi">10.7551/mitpress/3206.001.0001</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-matthews2017gpflow">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Matthews</surname><given-names>Alexander G de G</given-names></name>
        <name><surname>Van Der Wilk</surname><given-names>Mark</given-names></name>
        <name><surname>Nickson</surname><given-names>Tom</given-names></name>
        <name><surname>Fujii</surname><given-names>Keisuke</given-names></name>
        <name><surname>Boukouvalas</surname><given-names>Alexis</given-names></name>
        <name><surname>León-Villagrá</surname><given-names>Pablo</given-names></name>
        <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
        <name><surname>Hensman</surname><given-names>James</given-names></name>
      </person-group>
      <article-title>GPflow: A Gaussian process library using TensorFlow.</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2017">2017</year>
      <volume>18</volume>
      <issue>40</issue>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-abadi2016tensorflow">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Abadi</surname><given-names>Martı́n</given-names></name>
        <name><surname>Barham</surname><given-names>Paul</given-names></name>
        <name><surname>Chen</surname><given-names>Jianmin</given-names></name>
        <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>
        <name><surname>Davis</surname><given-names>Andy</given-names></name>
        <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
        <name><surname>Devin</surname><given-names>Matthieu</given-names></name>
        <name><surname>Ghemawat</surname><given-names>Sanjay</given-names></name>
        <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
        <name><surname>Isard</surname><given-names>Michael</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>TensorFlow: A system for large-scale machine learning</article-title>
      <source>12th USENIX symposium on operating systems design and implementation (OSDI 16)</source>
      <year iso-8601-date="2016">2016</year>
      <fpage>265</fpage>
      <lpage>283</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gardner2018gpytorch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gardner</surname><given-names>Jacob</given-names></name>
        <name><surname>Pleiss</surname><given-names>Geoff</given-names></name>
        <name><surname>Weinberger</surname><given-names>Kilian Q</given-names></name>
        <name><surname>Bindel</surname><given-names>David</given-names></name>
        <name><surname>Wilson</surname><given-names>Andrew G</given-names></name>
      </person-group>
      <article-title>GPyTorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2018">2018</year>
      <volume>31</volume>
    </element-citation>
  </ref>
  <ref id="ref-deepmind2020jax">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Babuschkin</surname><given-names>Igor</given-names></name>
        <name><surname>Baumli</surname><given-names>Kate</given-names></name>
        <name><surname>Bell</surname><given-names>Alison</given-names></name>
        <name><surname>Bhupatiraju</surname><given-names>Surya</given-names></name>
        <name><surname>Bruce</surname><given-names>Jake</given-names></name>
        <name><surname>Buchlovsky</surname><given-names>Peter</given-names></name>
        <name><surname>Budden</surname><given-names>David</given-names></name>
        <name><surname>Cai</surname><given-names>Trevor</given-names></name>
        <name><surname>Clark</surname><given-names>Aidan</given-names></name>
        <name><surname>Danihelka</surname><given-names>Ivo</given-names></name>
        <name><surname>Fantacci</surname><given-names>Claudio</given-names></name>
        <name><surname>Godwin</surname><given-names>Jonathan</given-names></name>
        <name><surname>Jones</surname><given-names>Chris</given-names></name>
        <name><surname>Hennigan</surname><given-names>Tom</given-names></name>
        <name><surname>Hessel</surname><given-names>Matteo</given-names></name>
        <name><surname>Kapturowski</surname><given-names>Steven</given-names></name>
        <name><surname>Keck</surname><given-names>Thomas</given-names></name>
        <name><surname>Kemaev</surname><given-names>Iurii</given-names></name>
        <name><surname>King</surname><given-names>Michael</given-names></name>
        <name><surname>Martens</surname><given-names>Lena</given-names></name>
        <name><surname>Mikulik</surname><given-names>Vladimir</given-names></name>
        <name><surname>Norman</surname><given-names>Tamara</given-names></name>
        <name><surname>Quan</surname><given-names>John</given-names></name>
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Ring</surname><given-names>Roman</given-names></name>
        <name><surname>Ruiz</surname><given-names>Francisco</given-names></name>
        <name><surname>Sanchez</surname><given-names>Alvaro</given-names></name>
        <name><surname>Schneider</surname><given-names>Rosalia</given-names></name>
        <name><surname>Sezener</surname><given-names>Eren</given-names></name>
        <name><surname>Spencer</surname><given-names>Stephen</given-names></name>
        <name><surname>Srinivasan</surname><given-names>Srivatsan</given-names></name>
        <name><surname>Stokowiec</surname><given-names>Wojciech</given-names></name>
        <name><surname>Viola</surname><given-names>Fabio</given-names></name>
      </person-group>
      <source>The DeepMind JAX Ecosystem</source>
      <year iso-8601-date="2020">2020</year>
      <uri>http://github.com/deepmind</uri>
    </element-citation>
  </ref>
  <ref id="ref-jax2018github">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Hawkins</surname><given-names>Peter</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew James</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Necula</surname><given-names>George</given-names></name>
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Wanderman-Milne</surname><given-names>Skye</given-names></name>
        <name><surname>Zhang</surname><given-names>Qiao</given-names></name>
      </person-group>
      <source>JAX: Composable transformations of Python+NumPy programs</source>
      <year iso-8601-date="2018">2018</year>
      <uri>http://github.com/google/jax</uri>
    </element-citation>
  </ref>
  <ref id="ref-phan2019composable">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Phan</surname><given-names>Du</given-names></name>
        <name><surname>Pradhan</surname><given-names>Neeraj</given-names></name>
        <name><surname>Jankowiak</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Composable effects for flexible and accelerated probabilistic programming in NumPyro</article-title>
      <source>arXiv preprint arXiv:1912.11554</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arxiv.1912.11554</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-carpenter2017stan">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Carpenter</surname><given-names>Bob</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Hoffman</surname><given-names>Matthew D</given-names></name>
        <name><surname>Lee</surname><given-names>Daniel</given-names></name>
        <name><surname>Goodrich</surname><given-names>Ben</given-names></name>
        <name><surname>Betancourt</surname><given-names>Michael</given-names></name>
        <name><surname>Brubaker</surname><given-names>Marcus</given-names></name>
        <name><surname>Guo</surname><given-names>Jiqiang</given-names></name>
        <name><surname>Li</surname><given-names>Peter</given-names></name>
        <name><surname>Riddell</surname><given-names>Allen</given-names></name>
      </person-group>
      <article-title>Stan: A probabilistic programming language</article-title>
      <source>Journal of Statistical Software</source>
      <publisher-name>Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA …</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>76</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v076.i01</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Salvatier2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Salvatier</surname><given-names>John</given-names></name>
        <name><surname>Wiecki</surname><given-names>Thomas V.</given-names></name>
        <name><surname>Fonnesbeck</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>Probabilistic programming in Python using PyMC3</article-title>
      <source>PeerJ Computer Science</source>
      <publisher-name>PeerJ</publisher-name>
      <year iso-8601-date="2016-04">2016</year><month>04</month>
      <volume>2</volume>
      <uri>https://doi.org/10.7717/peerj-cs.55</uri>
      <pub-id pub-id-type="doi">10.7717/peerj-cs.55</pub-id>
      <fpage>e55</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-wilkinson2021bayesnewton">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wilkinson</surname><given-names>William J.</given-names></name>
        <name><surname>Särkkä</surname><given-names>Simo</given-names></name>
        <name><surname>Solin</surname><given-names>Arno</given-names></name>
      </person-group>
      <article-title>Bayes-Newton methods for approximate Bayesian inference with PSD guarantees</article-title>
      <source>arXiv preprint arXiv:2111.01721</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arxiv.2111.01721</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-fairbrother2022gaussianprocesses">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fairbrother</surname><given-names>Jamie</given-names></name>
        <name><surname>Nemeth</surname><given-names>Christopher</given-names></name>
        <name><surname>Rischard</surname><given-names>Maxime</given-names></name>
        <name><surname>Brea</surname><given-names>Johanni</given-names></name>
        <name><surname>Pinder</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>GaussianProcesses.jl: A nonparametric bayes package for the julia language</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2022">2022</year>
      <volume>102</volume>
      <issue>1</issue>
      <uri>https://www.jstatsoft.org/index.php/jss/article/view/v102i01</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v102.i01</pub-id>
      <fpage>1</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-vanhatalo2013gpstuff">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Vanhatalo</surname><given-names>Juho</given-names></name>
        <name><surname>Riihimäki</surname><given-names>Jaako</given-names></name>
        <name><surname>Hartikainen</surname><given-names>Jouni</given-names></name>
        <name><surname>Jylänki</surname><given-names>Pasi</given-names></name>
        <name><surname>Tolvanen</surname><given-names>Ville</given-names></name>
        <name><surname>Vehtari</surname><given-names>Aki</given-names></name>
      </person-group>
      <article-title>GPstuff: Bayesian modeling with Gaussian processes</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2013">2013</year>
    </element-citation>
  </ref>
  <ref id="ref-pinder2022street">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pinder</surname><given-names>Thomas</given-names></name>
        <name><surname>Turnbull</surname><given-names>Kathryn</given-names></name>
        <name><surname>Nemeth</surname><given-names>Christopher</given-names></name>
        <name><surname>Leslie</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>Street-level air pollution modelling with graph Gaussian processes</article-title>
      <source>ICLR: AI for Earth and Space Science</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-pinder2021gaussian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pinder</surname><given-names>Thomas</given-names></name>
        <name><surname>Turnbull</surname><given-names>Kathryn</given-names></name>
        <name><surname>Nemeth</surname><given-names>Christopher</given-names></name>
        <name><surname>Leslie</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>Gaussian processes on hypergraphs</article-title>
      <source>arXiv preprint arXiv:2106.01982</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arxiv.2106.01982</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gpy2014">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>GPy</string-name>
      </person-group>
      <article-title>GPy: A Gaussian process framework in Python</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <uri>http://github.com/SheffieldML/GPy</uri>
    </element-citation>
  </ref>
  <ref id="ref-blackjax2021">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>BlackJax</string-name>
      </person-group>
      <article-title>BlackJAX; a sampling library designed for ease of use, speed and modularity.</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://github.com/blackjax-devs/blackjax/</uri>
    </element-citation>
  </ref>
  <ref id="ref-stheno2022tebbutt">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Tebbutt W</surname><given-names>Turner RE</given-names><suffix>Bruinsma W</suffix></name>
      </person-group>
      <article-title>Stheno.jl.</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/JuliaGaussianProcesses/Stheno.jl</uri>
    </element-citation>
  </ref>
  <ref id="ref-stheno2022bruinsma">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Bruinsma</surname><given-names>Wessel</given-names></name>
      </person-group>
      <article-title>Stheno</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/wesselb/stheno</uri>
    </element-citation>
  </ref>
  <ref id="ref-dfm2021tinygp">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Foreman-Mackey</surname><given-names>Dan</given-names></name>
      </person-group>
      <article-title>TinyGP</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://github.com/dfm/tinygp</uri>
    </element-citation>
  </ref>
  <ref id="ref-objax2020github">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Objax Developers</string-name>
      </person-group>
      <article-title>Objax</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/google/objax</uri>
    </element-citation>
  </ref>
  <ref id="ref-hensman2013gaussian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hensman</surname><given-names>James</given-names></name>
        <name><surname>Fusi</surname><given-names>Nicoló</given-names></name>
        <name><surname>Lawrence</surname><given-names>Neil D.</given-names></name>
      </person-group>
      <article-title>Gaussian processes for big data</article-title>
      <person-group person-group-type="editor">
        <name><surname>Nicholson</surname><given-names>Ann E.</given-names></name>
        <name><surname>Smyth</surname><given-names>Padhraic</given-names></name>
      </person-group>
      <publisher-name>AUAI Press</publisher-name>
      <year iso-8601-date="2013">2013</year>
    </element-citation>
  </ref>
  <ref id="ref-rasmussen2010gaussian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rasmussen</surname><given-names>Carl Edward</given-names></name>
        <name><surname>Nickisch</surname><given-names>Hannes</given-names></name>
      </person-group>
      <article-title>Gaussian processes for machine learning (GPML) toolbox</article-title>
      <source>The Journal of Machine Learning Research</source>
      <publisher-name>JMLR. org</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>11</volume>
      <fpage>3011</fpage>
      <lpage>3015</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fajou20a">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Galy-Fajou</surname><given-names>Theo</given-names></name>
        <name><surname>Wenzel</surname><given-names>Florian</given-names></name>
        <name><surname>Opper</surname><given-names>Manfred</given-names></name>
      </person-group>
      <article-title>Automated augmented conjugate inference for non-conjugate Gaussian process models</article-title>
      <source>Proceedings of the twenty third international conference on artificial intelligence and statistics</source>
      <person-group person-group-type="editor">
        <name><surname>Chiappa</surname><given-names>Silvia</given-names></name>
        <name><surname>Calandra</surname><given-names>Roberto</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>108</volume>
      <uri> http://proceedings.mlr.press/v108/galy-fajou20a.html </uri>
      <fpage>3025</fpage>
      <lpage>3035</lpage>
    </element-citation>
  </ref>
  <ref id="ref-borovitskiy2021matern">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Borovitskiy</surname><given-names>Viacheslav</given-names></name>
        <name><surname>Azangulov</surname><given-names>Iskander</given-names></name>
        <name><surname>Terenin</surname><given-names>Alexander</given-names></name>
        <name><surname>Mostowsky</surname><given-names>Peter</given-names></name>
        <name><surname>Deisenroth</surname><given-names>Marc</given-names></name>
        <name><surname>Durrande</surname><given-names>Nicolas</given-names></name>
      </person-group>
      <article-title>Matérn Gaussian processes on graphs</article-title>
      <source>International conference on artificial intelligence and statistics</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <fpage>2593</fpage>
      <lpage>2601</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mallasto2017learning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mallasto</surname><given-names>Anton</given-names></name>
        <name><surname>Feragen</surname><given-names>Aasa</given-names></name>
      </person-group>
      <article-title>Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2017">2017</year>
      <volume>30</volume>
    </element-citation>
  </ref>
  <ref id="ref-matheron1963principles">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Matheron</surname><given-names>Georges</given-names></name>
      </person-group>
      <article-title>Principles of geostatistics</article-title>
      <source>Economic geology</source>
      <publisher-name>Society of Economic Geologists</publisher-name>
      <year iso-8601-date="1963">1963</year>
      <volume>58</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.2113/gsecongeo.58.8.1246</pub-id>
      <fpage>1246</fpage>
      <lpage>1266</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mockus1978application">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mockus</surname><given-names>Jonas</given-names></name>
        <name><surname>Tiesis</surname><given-names>Vytautas</given-names></name>
        <name><surname>Zilinskas</surname><given-names>Antanas</given-names></name>
      </person-group>
      <article-title>The application of Bayesian methods for seeking the extremum</article-title>
      <source>Towards global optimization</source>
      <year iso-8601-date="1978">1978</year>
      <volume>2</volume>
      <issue>117-129</issue>
      <pub-id pub-id-type="doi">10.1007/3-540-07165-2_55</pub-id>
      <fpage>2</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-deisenroth2011pilco">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Deisenroth</surname><given-names>Marc</given-names></name>
        <name><surname>Rasmussen</surname><given-names>Carl E</given-names></name>
      </person-group>
      <article-title>PILCO: A model-based and data-efficient approach to policy search</article-title>
      <source>Proceedings of the 28th international conference on machine learning (ICML-11)</source>
      <publisher-name>Citeseer</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <fpage>465</fpage>
      <lpage>472</lpage>
    </element-citation>
  </ref>
  <ref id="ref-amos2022ensembles">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Amos</surname><given-names>Matthew</given-names></name>
        <name><surname>Pinder</surname><given-names>Thomas</given-names></name>
        <name><surname>Nemeth</surname><given-names>Christopher</given-names></name>
        <name><surname>Leslie</surname><given-names>David</given-names></name>
        <name><surname>Young</surname><given-names>Paul</given-names></name>
      </person-group>
      <article-title>Probabilistic climate model projections, using Gaussian processes and optimal transport</article-title>
      <source>In preparation</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-dodd2022ensembles">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dodd</surname><given-names>Daniel</given-names></name>
        <name><surname>Cripps</surname><given-names>Edward</given-names></name>
        <name><surname>Jonathan</surname><given-names>Phil</given-names></name>
        <name><surname>Leslie</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>Bayesian adaptive sampling in a hostile deep-sea environment</article-title>
      <source>In preparation</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
