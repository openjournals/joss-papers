<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20250403174856-498657e3b51504f8df237c3205725f6667e46266</doi_batch_id>
    <timestamp>20250403174856</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>04</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>108</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>Fundus Image Toolbox: A Python package for fundus image processing</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Julius</given_name>
            <surname>Gervelmeyer</surname>
            <affiliations>
              <institution><institution_name>Hertie Institute for AI in Brain Health, University of Tübingen, Tübingen, Germany</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0007-7286-0017</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Sarah</given_name>
            <surname>Müller</surname>
            <affiliations>
              <institution><institution_name>Hertie Institute for AI in Brain Health, University of Tübingen, Tübingen, Germany</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0003-1500-8673</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Ziwei</given_name>
            <surname>Huang</surname>
            <affiliations>
              <institution><institution_name>Hertie Institute for AI in Brain Health, University of Tübingen, Tübingen, Germany</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0001-7517-0395</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Philipp</given_name>
            <surname>Berens</surname>
            <affiliations>
              <institution><institution_name>Hertie Institute for AI in Brain Health, University of Tübingen, Tübingen, Germany</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-0199-4727</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>04</month>
          <day>03</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>7101</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.07101</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.15046292</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/7101</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.07101</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.07101</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.07101.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="liu2022">
            <article_title>Semi-supervised keypoint detector and descriptor for retinal image matching</article_title>
            <author>Liu</author>
            <journal_title>Computer vision – ECCV 2022</journal_title>
            <doi>10.1007/978-3-031-19803-8_35</doi>
            <isbn>978-3-031-19803-8</isbn>
            <cYear>2022</cYear>
            <unstructured_citation>Liu, J., Li, X., Wei, Q., Xu, J., &amp; Ding, D. (2022). Semi-supervised keypoint detector and descriptor for retinal image matching. Computer Vision – ECCV 2022, 593–609. https://doi.org/10.1007/978-3-031-19803-8_35</unstructured_citation>
          </citation>
          <citation key="koehler2024">
            <article_title>Efficiently correcting patch-based segmentation errors to control image-level performance</article_title>
            <author>Köhler</author>
            <journal_title>Accepted at medical imaging with deep learning</journal_title>
            <cYear>2024</cYear>
            <unstructured_citation>Köhler, P., Fadugba, J., Berens, P., &amp; Koch, L. M. (2024). Efficiently correcting patch-based segmentation errors to control image-level performance. Accepted at Medical Imaging with Deep Learning. https://openreview.net/forum?id=DDHRGHfwji</unstructured_citation>
          </citation>
          <citation key="fu2019">
            <article_title>Evaluation of retinal image quality assessment networks in different color-spaces</article_title>
            <author>Fu</author>
            <journal_title>Medical image computing and computer assisted intervention – MICCAI 2019</journal_title>
            <doi>10.1007/978-3-030-32239-7_6</doi>
            <issn>1611-3349</issn>
            <isbn>9783030322397</isbn>
            <cYear>2019</cYear>
            <unstructured_citation>Fu, H., Wang, B., Shen, J., Cui, S., Xu, Y., Liu, J., &amp; Shao, L. (2019). Evaluation of retinal image quality assessment networks in different color-spaces. In Medical image computing and computer assisted intervention – MICCAI 2019 (pp. 48–56). Springer International Publishing. https://doi.org/10.1007/978-3-030-32239-7_6</unstructured_citation>
          </citation>
          <citation key="zhou2022">
            <article_title>AutoMorph: Automated retinal vascular morphology quantification via a deep learning pipeline</article_title>
            <author>Zhou</author>
            <journal_title>Translational vision science &amp; technology</journal_title>
            <issue>7</issue>
            <volume>11</volume>
            <doi>10.1167/tvst.11.7.12</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Zhou, Y., Wagner, S. K., Chia, M. A., Zhao, A., Xu, M., Struyven, R., Alexander, D. C., Keane, P. A., &amp; others. (2022). AutoMorph: Automated retinal vascular morphology quantification via a deep learning pipeline. Translational Vision Science &amp; Technology, 11(7), 12–12. https://doi.org/10.1167/tvst.11.7.12</unstructured_citation>
          </citation>
          <citation key="adam">
            <article_title>ADAM challenge: Detecting age-related macular degeneration from fundus images</article_title>
            <author>Fang</author>
            <journal_title>IEEE Transactions on Medical Imaging</journal_title>
            <issue>10</issue>
            <volume>41</volume>
            <doi>10.1109/tmi.2022.3172773</doi>
            <issn>1558-254X</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Fang, H., Li, F., Fu, H., Sun, X., Cao, X., Lin, F., Son, J., Kim, S., Quellec, G., Matta, S., Shankaranarayana, S. M., Chen, Y.-T., Wang, C.-H., Shah, N. A., Lee, C.-Y., Hsu, C.-C., Xie, H., Lei, B., Baid, U., … Xu, Y. (2022). ADAM challenge: Detecting age-related macular degeneration from fundus images. IEEE Transactions on Medical Imaging, 41(10), 2828–2847. https://doi.org/10.1109/tmi.2022.3172773</unstructured_citation>
          </citation>
          <citation key="refuge">
            <article_title>REFUGE challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs</article_title>
            <author>Orlando</author>
            <journal_title>Medical Image Analysis</journal_title>
            <volume>59</volume>
            <doi>10.1016/j.media.2019.101570</doi>
            <issn>1361-8415</issn>
            <cYear>2020</cYear>
            <unstructured_citation>Orlando, J. I., Fu, H., Barbosa Breda, J., Keer, K. van, Bathula, D. R., Diaz-Pinto, A., Fang, R., Heng, P.-A., Kim, J., Lee, J., Lee, J., Li, X., Liu, P., Lu, S., Murugesan, B., Naranjo, V., Phaye, S. S. R., Shankaranarayana, S. M., Sikka, A., … Bogunović, H. (2020). REFUGE challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs. Medical Image Analysis, 59, 101570. https://doi.org/10.1016/j.media.2019.101570</unstructured_citation>
          </citation>
          <citation key="idrid">
            <article_title>IDRiD: Diabetic retinopathy – segmentation and grading challenge</article_title>
            <author>Porwal</author>
            <journal_title>Medical Image Analysis</journal_title>
            <volume>59</volume>
            <doi>10.1016/j.media.2019.101561</doi>
            <issn>1361-8415</issn>
            <cYear>2020</cYear>
            <unstructured_citation>Porwal, P., Pachade, S., Kokare, M., Deshmukh, G., Son, J., Bae, W., Liu, L., Wang, J., Liu, X., Gao, L., Wu, T., Xiao, J., Wang, F., Yin, B., Wang, Y., Danala, G., He, L., Choi, Y. H., Lee, Y. C., … Mériaudeau, F. (2020). IDRiD: Diabetic retinopathy – segmentation and grading challenge. Medical Image Analysis, 59, 101561. https://doi.org/10.1016/j.media.2019.101561</unstructured_citation>
          </citation>
          <citation key="deepdrid">
            <article_title>DeepDRiD: Diabetic retinopathy—grading and image quality estimation challenge</article_title>
            <author>Liu</author>
            <journal_title>Patterns</journal_title>
            <issue>6</issue>
            <volume>3</volume>
            <doi>10.1016/j.patter.2022.100512</doi>
            <issn>2666-3899</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Liu, R., Wang, X., Wu, Q., Dai, L., Fang, X., Yan, T., Son, J., Tang, S., Li, J., Gao, Z., Galdran, A., Poorneshwaran, J. M., Liu, H., Wang, J., Chen, Y., Porwal, P., Wei Tan, G. S., Yang, X., Dai, C., … Zhang, P. (2022). DeepDRiD: Diabetic retinopathy—grading and image quality estimation challenge. Patterns, 3(6), 100512. https://doi.org/10.1016/j.patter.2022.100512</unstructured_citation>
          </citation>
          <citation key="drimdb">
            <article_title>Identification of suitable fundus images using automated quality assessment methods</article_title>
            <author>Sevik</author>
            <journal_title>Journal of Biomedical Optics</journal_title>
            <issue>4</issue>
            <volume>19</volume>
            <doi>10.1117/1.JBO.19.4.046006</doi>
            <cYear>2014</cYear>
            <unstructured_citation>Sevik, U., Kose, C., Berber, T., &amp; Erdol, H. (2014). Identification of suitable fundus images using automated quality assessment methods. Journal of Biomedical Optics, 19(4), 046006. https://doi.org/10.1117/1.JBO.19.4.046006</unstructured_citation>
          </citation>
          <citation key="fives">
            <article_title>Fives: A fundus image dataset for artificial intelligence based vessel segmentation</article_title>
            <author>Jin</author>
            <journal_title>Scientific data</journal_title>
            <issue>1</issue>
            <volume>9</volume>
            <doi>10.1038/s41597-022-01564-3</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Jin, K., Huang, X., Zhou, J., Li, Y., Yan, Y., Sun, Y., Zhang, Q., Wang, Y., &amp; Ye, J. (2022). Fives: A fundus image dataset for artificial intelligence based vessel segmentation. Scientific Data, 9(1), 475. https://doi.org/10.1038/s41597-022-01564-3</unstructured_citation>
          </citation>
          <citation key="fire">
            <article_title>FIRE: Fundus image registration dataset</article_title>
            <author>Hernandez-Matas</author>
            <journal_title>Modeling and Artificial Intelligence in Ophthalmology</journal_title>
            <issue>4</issue>
            <volume>1</volume>
            <doi>10.35119/maio.v1i4.42</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Hernandez-Matas, C., Zabulis, X., Triantafyllou, A., Anyfanti, P., Douma, S., &amp; Argyros, A. A. (2017). FIRE: Fundus image registration dataset. Modeling and Artificial Intelligence in Ophthalmology, 1(4), 16–28. https://doi.org/10.35119/maio.v1i4.42</unstructured_citation>
          </citation>
          <citation key="tummala2023">
            <article_title>EfficientNetV2 based ensemble model for quality estimation of diabetic retinopathy images from DeepDRiD</article_title>
            <author>Tummala</author>
            <journal_title>Diagnostics</journal_title>
            <issue>4</issue>
            <volume>13</volume>
            <doi>10.3390/diagnostics13040622</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Tummala, S., Thadikemalla, V. S. G., Kadry, S., Sharaf, M., &amp; Rauf, H. T. (2023). EfficientNetV2 based ensemble model for quality estimation of diabetic retinopathy images from DeepDRiD. Diagnostics, 13(4), 622. https://doi.org/10.3390/diagnostics13040622</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
