<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4480</article-id>
<article-id pub-id-type="doi">10.21105/joss.04480</article-id>
<title-group>
<article-title>Ipyannotator: the infinitely hackable annotation
framework</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Epifânio</surname>
<given-names>Ítalo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pysarenko</surname>
<given-names>Oleksandr</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bayer</surname>
<given-names>Immanuel</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Palaimon GmbH</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-02-28">
<day>28</day>
<month>2</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>76</issue>
<fpage>4480</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Jupyter Notebook</kwd>
<kwd>Annotator</kwd>
<kwd>Annotations</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Annotation is a task that associates semantic tags to a digital
  representation (image, video, text, and others). This process is
  important for supervised machine learning (ML) approaches, since the
  model learns, and successively improves, from data examples in form of
  input-output pairs.</p>
  <p>The variety of digital representations makes it difficult to
  develop a tool that is flexible and meets all requirements for machine
  learning applications in different projects. Ipyannotator is an
  open-source tool that allows manual annotation in multiple data
  formats, enabling researchers/users to explore, create, and improve
  their datasets without leaving their own development environment, and
  empowering them to extend and customize the annotation process.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Many breakthroughs in machine learning (ML) applications such as
  image classification, text understanding, and recommender systems
  belong to the class of supervised machine learning. These ML methods
  often require an extensive basis of annotated data from which the
  model learns. The amount and quality of the annotated data is
  essential to generate a model that yields accurate prediction
  (<xref alt="Wong et al., 2015" rid="ref-wong2015smartannotator" ref-type="bibr">Wong
  et al., 2015</xref>).</p>
  <p>The variety of annotation taks, data formats, and the respective
  visualization of data is enormous. When dealing with multiple domains
  of supervised ML, the large variety of applications is a challenging
  task, especially considering that the tooling is potentially not
  flexible enough, which imposes limitations to the user.</p>
  <p>Ipyannotator is a library developed to provide a solution to this
  problem. Ipyannotator can be used to visualize, create, and improve
  datasets, providing a flexible solution that can be extended and
  customized by the user within the Jupyter development environment.</p>
  <p>Jupyter is one of the most popular tools for data science
  (<xref alt="Wang et al., 2019" rid="ref-wang2019how" ref-type="bibr">Wang
  et al., 2019</xref>) and is currently in used in more than 7850000
  public repositories on GitHub
  (<xref alt="Parente, 2022" rid="ref-parente2022nbestimate" ref-type="bibr">Parente,
  2022</xref>). Ipyannotator is a tool developed to be used with Jupyter
  Notebooks, allowing researchers and developers to integrate the
  library into their ML projects quickly and easily. The solution,
  however, is not limited to research and developement teams. Since the
  Ipyannotator runs also on a web server, it can by used for annotation
  purposes by any user.</p>
  <p>Lahtinen et al.
  (<xref alt="2021" rid="ref-lahtinen2021brima" ref-type="bibr">2021</xref>)
  developed an annotator as a browser plugin, Dutta &amp; Zisserman
  (<xref alt="2019" rid="ref-dutta2019via" ref-type="bibr">2019</xref>)
  built an annotator as a program that runs on the browser, and Bernal
  et al.
  (<xref alt="2019" rid="ref-bernal2019gtcreator" ref-type="bibr">2019</xref>)
  developed a desktop application for domain-specific medical image
  annotation. These previous annotation tools are restricted to fixed
  data types and a specific type of annotation. Ipyannotator was
  designed to be executed in Jupyter notebooks and allows users to
  change its iterations on runtime, allowing extensions and
  customization, creating an “infinitely hackable annotation framework”
  <xref ref-type="fn" rid="fn1">1</xref>.</p>
</sec>
<sec id="infinitely-hackable-annotation-framework">
  <title>Infinitely hackable annotation framework</title>
  <p>Ipyannotator uses Python libraries, such as Ipywidgets
  (<xref alt="Widgets, 2022" rid="ref-ipywidgets2022" ref-type="bibr">Widgets,
  2022</xref>), Ipycanvas
  (<xref alt="Renou, 2022" rid="ref-ipycanvas2022" ref-type="bibr">Renou,
  2022</xref>), and Ipyevents
  (<xref alt="Craig, 2022" rid="ref-ipyevents2022" ref-type="bibr">Craig,
  2022</xref>), that abstract the HTML and Javascript interactions,
  allowing developers to design UI interactions and elements using
  Python. Python’s dynamic nature allows users to modify classes or
  modules at runtime, and due to the libraries mentioned, users can
  change the default behavior of Ipyannotator’s UI, hacking the library.
  Browser interaction such as mouse moving and HTML elements such as
  dropdowns are some of the examples that can be changed at runtime when
  using Ipyannotator.</p>
  <p>Being integrated with Jupyter notebooks makes Ipyannotator usage
  easy to modify at different abstraction levels. The data science team
  can change the library’s behavior while writing their own scripts on a
  platform and programming language that they already know.</p>
  <p>In addition to the ability to change Ipyannotator’s browser
  interaction using Python, the library also provides a flexible API
  that enables adding custom annotators. With a custom pair of input and
  output classes, the user can create and register a new annotator while
  reusing the library resources.</p>
</sec>
<sec id="a-simple-but-flexible-api-to-define-annotation-tasks">
  <title>A simple but flexible API to define annotation tasks</title>
  <p>Ipyannotator provides a simple API (application programming
  interface), which is based on three steps that describe general tasks
  in the data annotation process. These are denoted as the explore,
  create, and improve phases.</p>
  <p>These three steps in conjuction with domain-specific annotation
  types define the inputs and outputs of the annotation process,
  providing a very flexible and extendable API to set up annotation
  tasks.</p>
  <p>The following code examples illustrate the main actions around
  which the Ipyannotator API is built. Please keep in mind that
  Ipyannotator aims to be flexible enought that these generic aspects
  can be extented to much complexer and domain-specific tasks and
  interfaces. An exemplary application, a standard image classification
  task, is used in the following.</p>
  <code language="python">from pathlib import Path
from ipyannotator.base import Settings
from ipyannotator.annotator import Annotator
from ipyannotator.mltypes import InputImage, OutputImageLabel

input = InputImage(image_dir='images', image_width=200, image_height=200)
output = OutputImageLabel(label_dir='labels', label_width=30, label_height=30)
settings = Settings(project_path=Path('data'))

annotator = Annotator(input, output, settings)</code>
  <sec id="explore">
    <title>Explore</title>
    <p>The explore step provides the ability to visualize and navigate
    through images and datasets.
    <xref alt="Figure 1" rid="figU003Aimage-classification-explore">Figure 1</xref>
    displays an example of an image classification task using one of
    Ipyannotator’s built-in artificial demonstration datasets. The
    dataset consists of images showing simple shapes in different
    colors. The annotation task is to assign to each image the color
    that is closest to the provided labels.</p>
    <fig>
      <caption><p>Explore step for image classification
      task<styled-content id="figU003Aimage-classification-explore"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="image-classification-explore.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="create">
    <title>Create</title>
    <p>In the create step new annotation datasets can be created by the
    user.
    <xref alt="Figure 2" rid="figU003Aimage-classification-create">Figure 2</xref>
    presents an example of an image classfication task, allowing the
    user to manually select multiple options and save the results in the
    dataset.</p>
    <fig>
      <caption><p>Create step for image classification task
      <styled-content id="figU003Aimage-classification-create"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="image-classification-create.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="improve">
    <title>Improve</title>
    <p>The improve step enables the user to refine datasets and thereby
    improve the annotation quality.
    <xref alt="Figure 3" rid="figU003Aimage-classification-improve">Figure 3</xref>
    displays the usage of improve, allowing users to iterate over every
    class and identify incorrect results.</p>
    <p>Inspecting large batches of pre-annotated data allows a user to
    very quickly improve the quality of datasets that were generated by
    an insufficient ML model. It also allows a domain expert to verify
    and improve the annotation work of less specialized annotators.</p>
    <fig>
      <caption><p>Improve step for image classification task
      <styled-content id="figU003Aimage-classification-improve"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="image-classification-improve.png" xlink:title="" />
    </fig>
  </sec>
</sec>
<sec id="key-design-decisions">
  <title>Key Design Decisions</title>
  <sec id="jupyter-notebook-all-the-way-down">
    <title>Jupyter Notebook all the way down</title>
    <p>Jupyter Notebooks are used by many researcher relaying on open
    source software to create and document their work. Ipyannotator not
    only runs directly in Jupyter Notebooks but is also developed as a
    collection of notebooks. This collection constitues a library, user
    documentation, and executable tutorials. This workflow is enabled by
    the innovative fastai library
    (<xref alt="Fastai, 2022" rid="ref-nbdev2022" ref-type="bibr">Fastai,
    2022</xref>) that turns Jupyter Notebook into a literate programming
    environment.</p>
    <p>For the development of the user interface (UI), the Ipywidget
    library
    (<xref alt="Widgets, 2022" rid="ref-ipywidgets2022" ref-type="bibr">Widgets,
    2022</xref>) was used to build a graphical user interface (GUI) in
    Jupyter Notebook. Furthermore, the voila library
    (<xref alt="Dashboards, 2022" rid="ref-voila2022" ref-type="bibr">Dashboards,
    2022</xref>), which uses Jupyter Notebook as a web-app, was also
    incorporated in the Ipyannotator project to create the GUI for an
    easy to access web application.</p>
  </sec>
  <sec id="architecture">
    <title>Architecture</title>
    <p>Ipyannotator’s architecture consists of three main systems
    components that comprise the user interface (UI), the server, and
    the data storage. These components are targeted at two different
    user types. A non-code architecture, which is schematically
    illustrated in
    <xref alt="Figure 4" rid="figU003Anon-technical-annotator">Figure 4</xref>,
    is included for non-technical annotators. The setup for a wide range
    of technically experienced annotators, schematically shown in
    <xref alt="Figure 5" rid="figU003Atechnical-user-architecture">Figure 5</xref>,
    targets users typically involved in research projects, e.g., data
    scientists, domain experts, and software developers.</p>
    <fig>
      <caption><p>Non-technical user architecture
      <styled-content id="figU003Anon-technical-annotator"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="non-technical-user-architecture.png" xlink:title="" />
    </fig>
    <fig>
      <caption><p>Technical user architecture
      <styled-content id="figU003Atechnical-user-architecture"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="technical-user-architecture.png" xlink:title="" />
    </fig>
    <p>For the technical user, multiple tutorials are provided,
    demonstrating Ipyannotator’s utilization. The tutorials make it
    easier for new users get started and adapt the notebooks to their
    tasks. They also demonstrate the annotation workflow and different
    features.</p>
  </sec>
</sec>
<sec id="usage">
  <title>Usage</title>
  <p>Currently, Ipyannotator is used for supervised ML projects by the
  devloper Palaimon GmbH. Multiple tutorials and use cases have been
  tested and published to improve and validate the usage of Ipyannotator
  on other real world projects.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors acknowledge the financial support by the Federal
  Ministry for Digital and Transport of Germany under the program mFUND
  for the project OS-VAT (project number 19F2160A).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-wong2015smartannotator">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wong</surname><given-names>Yu-Shiang</given-names></name>
        <name><surname>Chu</surname><given-names>Hung-Kuo</given-names></name>
        <name><surname>Mitra</surname><given-names>Niloy J</given-names></name>
      </person-group>
      <article-title>SmartAnnotator an interactive tool for annotating indoor RGBD images</article-title>
      <source>Computer graphics forum</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>34</volume>
      <pub-id pub-id-type="doi">10.1111/cgf.12574</pub-id>
      <fpage>447</fpage>
      <lpage>457</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2019how">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>April Yi</given-names></name>
        <name><surname>Mittal</surname><given-names>Anant</given-names></name>
        <name><surname>Brooks</surname><given-names>Christopher</given-names></name>
        <name><surname>Oney</surname><given-names>Steve</given-names></name>
      </person-group>
      <article-title>How data scientists use computational notebooks for real-time collaboration</article-title>
      <source>Proc. ACM Hum.-Comput. Interact.</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2019-11">2019</year><month>11</month>
      <volume>3</volume>
      <issue>CSCW</issue>
      <uri>https://doi.org/10.1145/3359141</uri>
      <pub-id pub-id-type="doi">10.1145/3359141</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-parente2022nbestimate">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Parente</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>Nbestimate</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/parente/nbestimate; GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-lahtinen2021brima">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lahtinen</surname><given-names>Tuomo</given-names></name>
        <name><surname>Turtiainen</surname><given-names>Hannu</given-names></name>
        <name><surname>Costin</surname><given-names>Andrei</given-names></name>
      </person-group>
      <article-title>BRIMA: Low-overhead BRowser-only IMage annotation tool (preprint)</article-title>
      <source>2021 IEEE international conference on image processing (ICIP)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.1109/icip42928.2021.9506683</pub-id>
      <fpage>2633</fpage>
      <lpage>2637</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dutta2019via">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dutta</surname><given-names>Abhishek</given-names></name>
        <name><surname>Zisserman</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>The VIA annotation software for images, audio and video</article-title>
      <source>Proceedings of the 27th ACM international conference on multimedia</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.1145/3343031.3350535</pub-id>
      <fpage>2276</fpage>
      <lpage>2279</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bernal2019gtcreator">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bernal</surname><given-names>Jorge</given-names></name>
        <name><surname>Histace</surname><given-names>Aymeric</given-names></name>
        <name><surname>Masana</surname><given-names>Marc</given-names></name>
        <name><surname>Angermann</surname><given-names>Quentin</given-names></name>
        <name><surname>Sánchez-Montes</surname><given-names>Cristina</given-names></name>
        <name><surname>Rodrı́guez de Miguel</surname><given-names>Cristina</given-names></name>
        <name><surname>Hammami</surname><given-names>Maroua</given-names></name>
        <name><surname>Garcı́a-Rodrı́guez</surname><given-names>Ana</given-names></name>
        <name><surname>Córdova</surname><given-names>Henry</given-names></name>
        <name><surname>Romain</surname><given-names>Olivier</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>GTCreator: A flexible annotation tool for image-based datasets</article-title>
      <source>International journal of computer assisted radiology and surgery</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>14</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1007/s11548-018-1864-x</pub-id>
      <fpage>191</fpage>
      <lpage>201</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nbdev2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Fastai</surname></name>
      </person-group>
      <source>Nbdev</source>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <uri>https://github.com/fastai/nbdev</uri>
    </element-citation>
  </ref>
  <ref id="ref-ipywidgets2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Widgets</surname><given-names>Jupyter</given-names></name>
      </person-group>
      <source>Ipywidgets</source>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <uri>https://github.com/jupyter-widgets/ipywidgets</uri>
    </element-citation>
  </ref>
  <ref id="ref-ipycanvas2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Renou</surname><given-names>Martin</given-names></name>
      </person-group>
      <source>Ipycanvas</source>
      <year iso-8601-date="2022-07">2022</year><month>07</month>
      <uri>https://github.com/martinRenou/ipycanvas</uri>
    </element-citation>
  </ref>
  <ref id="ref-ipyevents2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Craig</surname><given-names>Matt</given-names></name>
      </person-group>
      <source>Ipycanvas</source>
      <year iso-8601-date="2022-07">2022</year><month>07</month>
      <uri>https://github.com/mwcraig/ipyevents</uri>
    </element-citation>
  </ref>
  <ref id="ref-voila2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Dashboards</surname><given-names>Voila</given-names></name>
      </person-group>
      <source>Voila</source>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <uri>https://github.com/voila-dashboards/voila</uri>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>“infinitely hackable” is one of the key design
    principles used. Even through using very thin Python wrappers, e.g.,
    Renou
    (<xref alt="2022" rid="ref-ipycanvas2022" ref-type="bibr">2022</xref>)
    for the JavaScript Web Canvas API, ipyannotator still has to obey
    the finite limitations of the Python language.</p>
  </fn>
</fn-group>
</back>
</article>
