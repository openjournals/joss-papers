<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9605</article-id>
<article-id pub-id-type="doi">10.21105/joss.09605</article-id>
<title-group>
<article-title>GeoAI: A Python package for integrating artificial
intelligence with geospatial data analysis and
visualization</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5437-4073</contrib-id>
<name>
<surname>Wu</surname>
<given-names>Qiusheng</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Geography &amp; Sustainability, University of
Tennessee, Knoxville, TN 37996, United States</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-09-12">
<day>12</day>
<month>9</month>
<year>2025</year>
</pub-date>
<volume>11</volume>
<issue>117</issue>
<fpage>9605</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>geospatial</kwd>
<kwd>artificial intelligence</kwd>
<kwd>deep learning</kwd>
<kwd>Jupyter</kwd>
<kwd>visualization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>GeoAI</monospace> is a comprehensive Python package
  designed to bridge artificial intelligence (AI) and geospatial data
  analysis, providing researchers and practitioners with intuitive tools
  for applying machine learning techniques to geographic data. The
  package offers a unified framework for processing satellite imagery,
  aerial photographs, and vector data using state-of-the-art deep
  learning models. <monospace>GeoAI</monospace> integrates popular AI
  frameworks including <monospace>PyTorch</monospace>
  (<xref alt="Paszke et al., 2019" rid="ref-Paszke2019" ref-type="bibr">Paszke
  et al., 2019</xref>), <monospace>Transformers</monospace>
  (<xref alt="Wolf et al., 2019" rid="ref-Wolf2019" ref-type="bibr">Wolf
  et al., 2019</xref>),
  <monospace>PyTorch Segmentation Models</monospace>
  (<xref alt="Iakubovskii, 2019" rid="ref-Iakubovskii2019" ref-type="bibr">Iakubovskii,
  2019</xref>), and specialized geospatial libraries like
  <monospace>torchange</monospace>
  (<xref alt="Zheng et al., 2024" rid="ref-Zheng2024" ref-type="bibr">Zheng
  et al., 2024</xref>), enabling users to perform complex geospatial
  analyses with minimal code.</p>
  <p>The package provides six core capabilities:</p>
  <list list-type="order">
    <list-item>
      <p>Interactive and programmatic search and download of remote
      sensing imagery and geospatial data.</p>
    </list-item>
    <list-item>
      <p>Automated dataset preparation with image chips and label
      generation.</p>
    </list-item>
    <list-item>
      <p>Model training for tasks such as classification, detection, and
      segmentation.</p>
    </list-item>
    <list-item>
      <p>Inference pipelines for applying models to new geospatial
      datasets.</p>
    </list-item>
    <list-item>
      <p>Interactive visualization through integration with
      <monospace>Leafmap</monospace>
      (<xref alt="Wu, 2021" rid="ref-Wu2021" ref-type="bibr">Wu,
      2021</xref>) and <monospace>MapLibre</monospace>.</p>
    </list-item>
    <list-item>
      <p>Seamless <monospace>QGIS</monospace> integration via a
      dedicated <monospace>GeoAI</monospace> plugin, enabling users to
      run AI-powered geospatial workflows directly within the
      <monospace>QGIS</monospace> desktop environment, without writing
      code.</p>
    </list-item>
  </list>
  <p><monospace>GeoAI</monospace> addresses the growing demand for
  accessible AI tools in geospatial research by providing high-level
  APIs that abstract complex machine learning workflows while
  maintaining flexibility for advanced users. The package supports
  multiple data formats (GeoTIFF, JPEG2000, GeoJSON, Shapefile,
  GeoPackage) and includes automatic device management for GPU
  acceleration when available. With over 10 modules and extensive
  notebook examples, <monospace>GeoAI</monospace> serves as both a
  research tool and educational resource for the geospatial AI
  community.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The integration of artificial intelligence with geospatial data
  analysis has become increasingly critical across numerous scientific
  disciplines, from environmental monitoring and urban planning to
  disaster response and climate research
  (<xref alt="Li &amp; Hsu, 2022" rid="ref-Li2022" ref-type="bibr">Li
  &amp; Hsu, 2022</xref>;
  <xref alt="Mai et al., 2024" rid="ref-Mai2024" ref-type="bibr">Mai et
  al., 2024</xref>). However, applying AI techniques to geospatial data
  presents unique challenges including data preprocessing complexities,
  specialized model architectures, and the need for domain-specific
  knowledge in both machine learning and geographic information systems
  (<xref alt="Ma et al., 2019" rid="ref-Ma2019" ref-type="bibr">Ma et
  al., 2019</xref>;
  <xref alt="Zhu et al., 2017" rid="ref-Zhu2017" ref-type="bibr">Zhu et
  al., 2017</xref>).</p>
  <p>Existing solutions often require researchers to navigate fragmented
  ecosystems of tools, combining general-purpose machine learning
  libraries with specialized geospatial packages, leading to steep
  learning curves and reproducibility challenges. While packages like
  <monospace>TorchGeo</monospace>
  (<xref alt="Stewart et al., 2022" rid="ref-Stewart2022" ref-type="bibr">Stewart
  et al., 2022</xref>), <monospace>TerraTorch</monospace>
  (<xref alt="Gomes et al., 2025" rid="ref-Gomes2025" ref-type="bibr">Gomes
  et al., 2025</xref>), and <monospace>SRAI</monospace>
  (<xref alt="Gramacki et al., 2023" rid="ref-Gramacki2023" ref-type="bibr">Gramacki
  et al., 2023</xref>) provide excellent foundational tools for
  geospatial deep learning, there remains a gap for comprehensive,
  high-level interfaces that can democratize access to advanced AI
  techniques for the broader geospatial community.</p>
  <p><monospace>GeoAI</monospace> addresses this need by providing a
  unified, user-friendly interface that abstracts the complexity of
  integrating multiple AI frameworks with geospatial data processing
  workflows. It lowers barriers for: (1) geospatial researchers who need
  accessible AI workflows without deep ML expertise; (2) AI
  practitioners who want streamlined geospatial preprocessing and
  domain-specific datasets; and (3) educators seeking reproducible
  examples and teaching-ready workflows.</p>
  <p>The package’s design philosophy emphasizes simplicity without
  sacrificing functionality, enabling users to perform sophisticated
  analyses such as building footprint extraction from satellite imagery,
  land cover classification, and change detection with just a few lines
  of code. By integrating cutting-edge AI models and providing seamless
  access to major geospatial data sources, <monospace>GeoAI</monospace>
  significantly lowers the barrier to entry for geospatial AI
  applications while maintaining the flexibility needed for advanced
  research applications.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We gratefully acknowledge the support of the National Aeronautics
  and Space Administration (NASA) through Grant No. 80NSSC22K1742,
  awarded under the Open Source Tools, Frameworks, and Libraries
  Program. Additional support was provided by the U.S. Geological Survey
  through Grant/Cooperative Agreement No. G23AP00683 (GY23-GY27) in
  collaboration with AmericaView. We also thank the broader open-source
  geospatial community for their contributions and feedback during the
  development of this package.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Iakubovskii2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Iakubovskii</surname><given-names>Pavel</given-names></name>
      </person-group>
      <article-title>Segmentation models pytorch</article-title>
      <publisher-name>https://github.com/qubvel/segmentation_models.pytorch</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-Paszke2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Köpf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Neural Information Processing Systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>abs/1912.01703</volume>
      <uri>https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.01703</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Wolf2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wolf</surname><given-names>Thomas</given-names></name>
        <name><surname>Debut</surname><given-names>Lysandre</given-names></name>
        <name><surname>Sanh</surname><given-names>Victor</given-names></name>
        <name><surname>Chaumond</surname><given-names>Julien</given-names></name>
        <name><surname>Delangue</surname><given-names>Clement</given-names></name>
        <name><surname>Moi</surname><given-names>Anthony</given-names></name>
        <name><surname>Cistac</surname><given-names>Pierric</given-names></name>
        <name><surname>Rault</surname><given-names>Tim</given-names></name>
        <name><surname>Louf</surname><given-names>Rémi</given-names></name>
        <name><surname>Funtowicz</surname><given-names>Morgan</given-names></name>
        <name><surname>Davison</surname><given-names>Joe</given-names></name>
        <name><surname>Shleifer</surname><given-names>Sam</given-names></name>
        <name><surname>Platen</surname><given-names>Patrick von</given-names></name>
        <name><surname>Ma</surname><given-names>Clara</given-names></name>
        <name><surname>Jernite</surname><given-names>Yacine</given-names></name>
        <name><surname>Plu</surname><given-names>Julien</given-names></name>
        <name><surname>Xu</surname><given-names>Canwen</given-names></name>
        <name><surname>Le Scao</surname><given-names>Teven</given-names></name>
        <name><surname>Gugger</surname><given-names>Sylvain</given-names></name>
        <name><surname>Drame</surname><given-names>Mariama</given-names></name>
        <name><surname>Lhoest</surname><given-names>Quentin</given-names></name>
        <name><surname>Rush</surname><given-names>Alexander M</given-names></name>
      </person-group>
      <article-title>HuggingFace’s transformers: State-of-the-art natural language processing</article-title>
      <source>arXiv preprint arXiv:1910.03771</source>
      <year iso-8601-date="2019">2019</year>
      <uri>http://arxiv.org/abs/1910.03771</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1910.03771</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Zheng2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zheng</surname><given-names>Zhuo</given-names></name>
        <name><surname>Zhong</surname><given-names>Yanfei</given-names></name>
        <name><surname>Zhao</surname><given-names>Ji</given-names></name>
        <name><surname>Ma</surname><given-names>Ailong</given-names></name>
        <name><surname>Zhang</surname><given-names>Liangpei</given-names></name>
      </person-group>
      <article-title>Unifying remote sensing change detection via deep probabilistic change models: From principles, models to applications</article-title>
      <source>ISPRS Journal of Photogrammetry and Remote Sensing</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>215</volume>
      <issn>0924-2716</issn>
      <uri>http://dx.doi.org/10.1016/j.isprsjprs.2024.07.001</uri>
      <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2024.07.001</pub-id>
      <fpage>239</fpage>
      <lpage>255</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Wu2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Qiusheng</given-names></name>
      </person-group>
      <article-title>Leafmap: A python package for interactive mapping and geospatial analysis with minimal coding in a jupyter environment</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://joss.theoj.org/papers/10.21105/joss.03414.pdf</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03414</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Li2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Wenwen</given-names></name>
        <name><surname>Hsu</surname><given-names>Chia-Yu</given-names></name>
      </person-group>
      <article-title>GeoAI for large-scale image analysis and machine vision: Recent progress of artificial intelligence in geography</article-title>
      <source>ISPRS International Journal of Geo-Information</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>11</volume>
      <uri>http://dx.doi.org/10.3390/ijgi11070385</uri>
      <pub-id pub-id-type="doi">10.3390/ijgi11070385</pub-id>
      <fpage>385</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Mai2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mai</surname><given-names>Gengchen</given-names></name>
        <name><surname>Huang</surname><given-names>Weiming</given-names></name>
        <name><surname>Sun</surname><given-names>Jin</given-names></name>
        <name><surname>Song</surname><given-names>Suhang</given-names></name>
        <name><surname>Mishra</surname><given-names>Deepak</given-names></name>
        <name><surname>Liu</surname><given-names>Ninghao</given-names></name>
        <name><surname>Gao</surname><given-names>Song</given-names></name>
        <name><surname>Liu</surname><given-names>Tianming</given-names></name>
        <name><surname>Cong</surname><given-names>Gao</given-names></name>
        <name><surname>Hu</surname><given-names>Yingjie</given-names></name>
        <name><surname>Cundy</surname><given-names>Chris</given-names></name>
        <name><surname>Li</surname><given-names>Ziyuan</given-names></name>
        <name><surname>Zhu</surname><given-names>Rui</given-names></name>
        <name><surname>Lao</surname><given-names>Ni</given-names></name>
      </person-group>
      <article-title>On the opportunities and challenges of foundation models for GeoAI (vision paper)</article-title>
      <source>ACM Transactions on Spatial Algorithms and Systems</source>
      <publisher-name>ACM</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2024">2024</year>
      <issn>2374-0353</issn>
      <uri>https://doi.org/10.1145/3653070</uri>
      <pub-id pub-id-type="doi">10.1145/3653070</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Zhu2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhu</surname><given-names>Xiao Xiang</given-names></name>
        <name><surname>Tuia</surname><given-names>Devis</given-names></name>
        <name><surname>Mou</surname><given-names>Lichao</given-names></name>
        <name><surname>Xia</surname><given-names>Gui-Song</given-names></name>
        <name><surname>Zhang</surname><given-names>Liangpei</given-names></name>
        <name><surname>Xu</surname><given-names>Feng</given-names></name>
        <name><surname>Fraundorfer</surname><given-names>Friedrich</given-names></name>
      </person-group>
      <article-title>Deep learning in remote sensing: A comprehensive review and list of resources</article-title>
      <source>IEEE Geoscience and Remote Sensing Magazine</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>5</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1109/MGRS.2017.2762307</pub-id>
      <fpage>8</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Ma2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ma</surname><given-names>Lei</given-names></name>
        <name><surname>Liu</surname><given-names>Yu</given-names></name>
        <name><surname>Zhang</surname><given-names>Xueliang</given-names></name>
        <name><surname>Ye</surname><given-names>Yuanxin</given-names></name>
        <name><surname>Yin</surname><given-names>Gaofei</given-names></name>
        <name><surname>Johnson</surname><given-names>Brian Alan</given-names></name>
      </person-group>
      <article-title>Deep learning in remote sensing applications: A meta-analysis and review</article-title>
      <source>ISPRS Journal of Photogrammetry and Remote Sensing</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>152</volume>
      <pub-id pub-id-type="doi">10.1016/j.isprsjprs.2019.04.015</pub-id>
      <fpage>166</fpage>
      <lpage>177</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Stewart2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stewart</surname><given-names>Adam J</given-names></name>
        <name><surname>Robinson</surname><given-names>Caleb</given-names></name>
        <name><surname>Corley</surname><given-names>Isaac A</given-names></name>
        <name><surname>Ortiz</surname><given-names>Anthony</given-names></name>
        <name><surname>Lavista Ferres</surname><given-names>Juan M</given-names></name>
        <name><surname>Banerjee</surname><given-names>Arindam</given-names></name>
      </person-group>
      <article-title>TorchGeo: Deep learning with geospatial data</article-title>
      <source>Proceedings of the 30th International Conference on Advances in Geographic Information Systems</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1145/3557915.3560953</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Gomes2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gomes</surname><given-names>Carlos</given-names></name>
        <name><surname>Blumenstiel</surname><given-names>Benedikt</given-names></name>
        <name><surname>Almeida</surname><given-names>Joao Lucas de Sousa</given-names></name>
        <name><surname>Oliveira</surname><given-names>Pedro Henrique de</given-names></name>
        <name><surname>Fraccaro</surname><given-names>Paolo</given-names></name>
        <name><surname>Escofet</surname><given-names>Francesc Marti</given-names></name>
        <name><surname>Szwarcman</surname><given-names>Daniela</given-names></name>
        <name><surname>Simumba</surname><given-names>Naomi</given-names></name>
        <name><surname>Kienzler</surname><given-names>Romeo</given-names></name>
        <name><surname>Zadrozny</surname><given-names>Bianca</given-names></name>
      </person-group>
      <article-title>TerraTorch: The geospatial foundation models toolkit</article-title>
      <source>arXiv preprint arXiv:2503.20563</source>
      <year iso-8601-date="2025">2025</year>
      <uri>https://doi.org/10.48550/arXiv.2503.20563</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2503.20563</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Gramacki2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gramacki</surname><given-names>Piotr</given-names></name>
        <name><surname>Leśniara</surname><given-names>Kacper</given-names></name>
        <name><surname>Raczycki</surname><given-names>Kamil</given-names></name>
        <name><surname>Woźniak</surname><given-names>Szymon</given-names></name>
        <name><surname>Przymus</surname><given-names>Marcin</given-names></name>
        <name><surname>Szymański</surname><given-names>Piotr</given-names></name>
      </person-group>
      <article-title>SRAI: Towards standardization of geospatial AI</article-title>
      <source>arXiv [cs.LG]</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://doi.org/10.48550/arXiv.2310.13098</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.13098</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
