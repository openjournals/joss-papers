<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6187</article-id>
<article-id pub-id-type="doi">10.21105/joss.06187</article-id>
<title-group>
<article-title>Systems Neuro Browser (SNUB)</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6100-6084</contrib-id>
<name>
<surname>Weinreb</surname>
<given-names>Caleb</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8606-6518</contrib-id>
<name>
<surname>Osman</surname>
<given-names>Mohammed Abdal Monium</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5537-6476</contrib-id>
<name>
<surname>Jay</surname>
<given-names>Maya</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8068-3862</contrib-id>
<name>
<surname>Datta</surname>
<given-names>Sandeep Robert</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Neurobiology, Harvard Medical School, Boston,
Massachusetts, United States of America</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-03-24">
<day>24</day>
<month>3</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>95</issue>
<fpage>6187</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>neuroscience</kwd>
<kwd>animal behavior</kwd>
<kwd>graphical user interface</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>A core goal of neuroscience is to discover temporal patterns in
  behavior and neurophysiology. Though a variety of tools exist to
  characterize these relationships, there is still no substitute for
  direct inspection as a way to notice unexpected patterns and generate
  new hypotheses. To facilitate this process, we have developed the
  Systems Neuro Browser (SNUB), a graphical user interface for exploring
  time-series data. SNUB is a flexible, general-purpose tool that allows
  users to build a dashboard of synchronized data views, including
  neural recordings, behavioral videos, and annotations derived from
  these data.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Direct inspection of behavior and neurophysiology recordings is
  hard because the data are typically high-dimensional and come in a
  variety of modalities (such as raw video, pose tracking, spike trains,
  calcium traces, etc.) with different sampling rates and methods of
  visualization. SNUB lowers the activation energy for data exploration
  by integrating these data streams into a single easy-to-navigate
  interface. The main intended user is a researcher who has collected
  data and started to analyze it (e.g. in Python). They may already be
  generating static versions of the visualizations afforded by SNUB,
  such as aligned heatmaps and trace plots, and now would like a
  frictionless way to pan/zoom around these plots and keep all the data
  views linked together. Importantly, SNUB should be thought of as akin
  to a plotting library, rather than a data analysis tool.</p>
  <p>The interface is divided into synchronized windows that each show a
  different data stream. The linked data views allow users to quickly
  inspect the relationships between experimental phenomena, such as the
  behaviors that occur during a particular pattern of neural activity
  (<xref alt="[fig:screenshot]" rid="figU003Ascreenshot">[fig:screenshot]</xref>).</p>
  <fig>
    <caption><p>Screenshot from
    SNUB.<styled-content id="figU003Ascreenshot"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/docs/media/screenshot.png" />
  </fig>
  <p>We provide dedicated widgets and loading functions for exploring
  raw video, 3D animal pose, behavior annotations, electrophysiology
  recordings, and calcium imaging data—either as a raster or as a
  super-position of labeled regions of interest (ROIs). More broadly,
  SNUB can display any data that takes the form of a heatmap, scatter
  plot, video, or collection of named temporally-varying signals.</p>
  <p>In addition to the front-end GUI, we include a library of functions
  that ingest data (or paths to the data) and visualization parameters,
  and then organize these in a format that is quickly readable by the
  SNUB viewer. The following code, for example, creates a project with
  paired electrophysiology and video data.</p>
  <code language="python">snub.io.create_project(project_directory, duration=1800)
snub.io.add_video(project_directory, 'path/to/my_video.avi', name='IR_camera')
snub.io.add_spikeplot(project_directory, 'my_ephys_data', spike_data)</code>
  <p>We also provide a rudimentary tool for automatically generating
  SNUB datasets from Neurodata Without Borders (NWB) files, which
  contain raw and processed data from neuroscience recordings
  (<xref alt="Rübel et al., 2022" rid="ref-NWB" ref-type="bibr">Rübel et
  al., 2022</xref>). The data in NWB files are stored hierarchically,
  and each component of the hierarchy has a specific neurodata type that
  reflects the measurement modality (e.g, “Units” for spike trains,
  “ImageSeries” for video). Our conversion tool generates a SNUB display
  element for each supported neurodata type. Users can optionally
  restrict this process to a subset of the NWB hierarchy (e.g., include
  pose tracking while excluding electrophysiology, or include just a
  subset of electrophysiology measurements).</p>
  <p>SNUB is a flexible general-purpose tool that complements more
  specialized packages such as rastermap
  (<xref alt="Stringer et al., 2023" rid="ref-Stringer2023.07.25.550571" ref-type="bibr">Stringer
  et al., 2023</xref>) and Bento
  (<xref alt="Segalin et al., 2021" rid="ref-bento" ref-type="bibr">Segalin
  et al., 2021</xref>). The rastermap interface, for example, is
  hard-coded for the display of neural activity rasters, ROIs and 2D
  embeddings of neural activity. Bento is hard-coded for the display of
  neural activity rasters, behavioral videos and behavioral annotations.
  SNUB can reproduce either of these configurations and is especially
  useful when one wishes to include additional types of data or more
  directly customize the way that data is rendered.</p>
  <p>The graphics in SNUB are powered by vispy
  (<xref alt="Campagnola et al., 2022" rid="ref-vispy" ref-type="bibr">Campagnola
  et al., 2022</xref>). SNUB includes wrappers for several
  dimensionality reduction methods, including rastermap
  (<xref alt="Stringer et al., 2023" rid="ref-Stringer2023.07.25.550571" ref-type="bibr">Stringer
  et al., 2023</xref>) for ordering raster plots and UMAP
  (<xref alt="McInnes et al., 2018" rid="ref-umap" ref-type="bibr">McInnes
  et al., 2018</xref>) for 2D scatter plots. Fast video loading is
  enabled by VidIO
  (<xref alt="Bohnslav, 2024" rid="ref-vidio" ref-type="bibr">Bohnslav,
  2024</xref>).</p>
  <p>The SNUB documentation includes a set of tutorials that make use of
  original data collected in the Datta lab between 2020 and 2022. All
  experimental procedures were approved by the Harvard Medical School
  Institutional Animal Care and Use Committee (Protocol Number 04930)
  and were performed in compliance with the ethical regulations of
  Harvard University as well as the Guide for Animal Care and Use of
  Laboratory Animals. Experimental protocols and processed data have
  been deposited on Zenodo
  (<xref alt="Weinreb et al., 2024" rid="ref-weinreb_2024_10578025" ref-type="bibr">Weinreb
  et al., 2024</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>CW is a Fellow of The Jane Coffin Childs Memorial Fund for Medical
  Research. SRD is supported by NIH grants U19NS113201, RF1AG073625,
  R01NS114020, the Brain Research Foundation, and the Simons
  Collaboration on the Global Brain. The SNUB app icon was adapted from
  a drawing contributed to scidraw by Luigi Petrucco
  (<xref alt="Petrucco, 2020" rid="ref-petrucco_2020_3925903" ref-type="bibr">Petrucco,
  2020</xref>).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-vispy">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Campagnola</surname><given-names>Luke</given-names></name>
        <name><surname>Larson</surname><given-names>Eric</given-names></name>
        <name><surname>Klein</surname><given-names>Almar</given-names></name>
        <name><surname>Hoese</surname><given-names>David</given-names></name>
        <name><surname>Siddharth</surname></name>
        <name><surname>Rossant</surname><given-names>Cyrille</given-names></name>
        <name><surname>Griffiths</surname><given-names>Adam</given-names></name>
        <name><surname>Rougier</surname><given-names>Nicolas P.</given-names></name>
        <name><surname>asnt</surname></name>
        <name><surname>Mühlbauer</surname><given-names>Kai</given-names></name>
        <name><surname>Taylor</surname><given-names>Alexander</given-names></name>
        <name><surname>MSS</surname></name>
        <name><surname>Lambert</surname><given-names>Talley</given-names></name>
        <name><surname>sylm21</surname></name>
        <name><surname>Champandard</surname><given-names>Alex J.</given-names></name>
        <name><surname>Hunter</surname><given-names>Max</given-names></name>
        <name><surname>Robitaille</surname><given-names>Thomas</given-names></name>
        <name><surname>Kaptan</surname><given-names>Mustafa Furkan</given-names></name>
        <name><surname>Andrade</surname><given-names>Elliott Sales de</given-names></name>
        <name><surname>Czajkowski</surname><given-names>Karl</given-names></name>
        <name><surname>Gaifas</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Bacchini</surname><given-names>Alessandro</given-names></name>
        <name><surname>Favelier</surname><given-names>Guillaume</given-names></name>
        <name><surname>Combrisson</surname><given-names>Etienne</given-names></name>
        <name><surname>ThenTech</surname></name>
        <name><surname>fschill</surname></name>
        <name><surname>Harfouche</surname><given-names>Mark</given-names></name>
        <name><surname>Aye</surname><given-names>Michael</given-names></name>
        <name><surname>Elteren</surname><given-names>Casper van</given-names></name>
        <name><surname>GESTES</surname><given-names>Cedric</given-names></name>
      </person-group>
      <article-title>Vispy/vispy: Version 0.11.0</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2022-07">2022</year><month>07</month>
      <uri>https://doi.org/10.5281/zenodo.6795163</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.6795163</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bento">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Segalin</surname><given-names>Cristina</given-names></name>
        <name><surname>Williams</surname><given-names>Jalani</given-names></name>
        <name><surname>Karigo</surname><given-names>Tomomi</given-names></name>
        <name><surname>Hui</surname><given-names>May</given-names></name>
        <name><surname>Zelikowsky</surname><given-names>Moriel</given-names></name>
        <name><surname>Sun</surname><given-names>Jennifer J</given-names></name>
        <name><surname>Perona</surname><given-names>Pietro</given-names></name>
        <name><surname>Anderson</surname><given-names>David J</given-names></name>
        <name><surname>Kennedy</surname><given-names>Ann</given-names></name>
      </person-group>
      <article-title>The mouse action recognition system (MARS) software pipeline for automated analysis of social behaviors in mice</article-title>
      <source>eLife</source>
      <person-group person-group-type="editor">
        <name><surname>Berman</surname><given-names>Gordon J</given-names></name>
        <name><surname>Wassum</surname><given-names>Kate M</given-names></name>
        <name><surname>Gal</surname><given-names>Asaf</given-names></name>
      </person-group>
      <publisher-name>eLife Sciences Publications, Ltd</publisher-name>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <volume>10</volume>
      <issn>2050-084X</issn>
      <uri>https://doi.org/10.7554/eLife.63720</uri>
      <pub-id pub-id-type="doi">10.7554/eLife.63720</pub-id>
      <fpage>e63720</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Stringer2023.07.25.550571">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stringer</surname><given-names>Carsen</given-names></name>
        <name><surname>Zhong</surname><given-names>Lin</given-names></name>
        <name><surname>Syeda</surname><given-names>Atika</given-names></name>
        <name><surname>Du</surname><given-names>Fengtong</given-names></name>
        <name><surname>Kesa</surname><given-names>Maria</given-names></name>
        <name><surname>Pachitariu</surname><given-names>Marius</given-names></name>
      </person-group>
      <article-title>Rastermap: A discovery method for neural population recordings</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.biorxiv.org/content/early/2023/08/07/2023.07.25.550571</uri>
      <pub-id pub-id-type="doi">10.1101/2023.07.25.550571</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-vidio">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bohnslav</surname><given-names>Jim</given-names></name>
      </person-group>
      <article-title>VidIO: Simple, performant video reading and writing in python</article-title>
      <year iso-8601-date="2024-03-11">2024</year><month>03</month><day>11</day>
      <uri>https://github.com/jbohnslav/vidio</uri>
    </element-citation>
  </ref>
  <ref id="ref-umap">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>McInnes</surname><given-names>Leland</given-names></name>
        <name><surname>Healy</surname><given-names>John</given-names></name>
        <name><surname>Saul</surname><given-names>Nathaniel</given-names></name>
        <name><surname>Großberger</surname><given-names>Lukas</given-names></name>
      </person-group>
      <article-title>UMAP: Uniform manifold approximation and projection</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>3</volume>
      <issue>29</issue>
      <uri>https://doi.org/10.21105/joss.00861</uri>
      <pub-id pub-id-type="doi">10.21105/joss.00861</pub-id>
      <fpage>861</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-petrucco_2020_3925903">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Petrucco</surname><given-names>Luigi</given-names></name>
      </person-group>
      <article-title>Mouse head schema</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2020-07">2020</year><month>07</month>
      <uri>https://doi.org/10.5281/zenodo.3925903</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3925903</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-NWB">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rübel</surname><given-names>Oliver</given-names></name>
        <name><surname>Tritt</surname><given-names>Andrew</given-names></name>
        <name><surname>Ly</surname><given-names>Ryan</given-names></name>
        <name><surname>Dichter</surname><given-names>Benjamin K</given-names></name>
        <name><surname>Ghosh</surname><given-names>Satrajit</given-names></name>
        <name><surname>Niu</surname><given-names>Lawrence</given-names></name>
        <name><surname>Baker</surname><given-names>Pamela</given-names></name>
        <name><surname>Soltesz</surname><given-names>Ivan</given-names></name>
        <name><surname>Ng</surname><given-names>Lydia</given-names></name>
        <name><surname>Svoboda</surname><given-names>Karel</given-names></name>
        <name><surname>Frank</surname><given-names>Loren</given-names></name>
        <name><surname>Bouchard</surname><given-names>Kristofer E</given-names></name>
      </person-group>
      <article-title>The neurodata without borders ecosystem for neurophysiological data science</article-title>
      <source>eLife</source>
      <person-group person-group-type="editor">
        <name><surname>Colgin</surname><given-names>Laura L</given-names></name>
        <name><surname>Jadhav</surname><given-names>Shantanu P</given-names></name>
      </person-group>
      <publisher-name>eLife Sciences Publications, Ltd</publisher-name>
      <year iso-8601-date="2022-10">2022</year><month>10</month>
      <volume>11</volume>
      <issn>2050-084X</issn>
      <uri>https://doi.org/10.7554/eLife.78362</uri>
      <pub-id pub-id-type="doi">10.7554/eLife.78362</pub-id>
      <fpage>e78362</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-weinreb_2024_10578025">
    <element-citation publication-type="dataset">
      <person-group person-group-type="author">
        <name><surname>Weinreb</surname><given-names>Caleb</given-names></name>
        <name><surname>Osman</surname><given-names>Mohammed Abdal Monium</given-names></name>
        <name><surname>Jay</surname><given-names>Maya</given-names></name>
        <name><surname>Datta</surname><given-names>Sandeep Robert</given-names></name>
      </person-group>
      <article-title>Systems neuro browser (SNUB) example datasets</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024-01">2024</year><month>01</month>
      <uri>https://doi.org/10.5281/zenodo.10578025</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.10578025</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
