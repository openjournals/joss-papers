<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8101</article-id>
<article-id pub-id-type="doi">10.21105/joss.08101</article-id>
<title-group>
<article-title>Lighter: Configuration-Driven Deep
Learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8397-5940</contrib-id>
<name>
<surname>Hadzic</surname>
<given-names>Ibrahim</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8043-2230</contrib-id>
<name>
<surname>Pai</surname>
<given-names>Suraj</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9249-8624</contrib-id>
<name>
<surname>Bressem</surname>
<given-names>Keno</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2466-4827</contrib-id>
<name>
<surname>Foldyna</surname>
<given-names>Borek</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2122-2003</contrib-id>
<name>
<surname>Aerts</surname>
<given-names>Hugo JWL</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Cardiovascular Imaging Research Center, Massachusetts
General Hospital, Harvard Medical School, United States of
America</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Radiology and Nuclear Medicine, CARIM &amp; GROW,
Maastricht University, The Netherlands</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Artificial Intelligence in Medicine (AIM) Program, Mass
General Brigham, Harvard Medical School, Harvard Institutes of Medicine,
United States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Department of Radiation Oncology, Brigham and Women’s
Hospital, Dana-Farber Cancer Institute, Harvard Medical School, United
States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Technical University of Munich, School of Medicine and
Health, Klinikum rechts der Isar, TUM University Hospital,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Department of Cardiovascular Radiology and Nuclear
Medicine, Technical University of Munich, School of Medicine and Health,
German Heart Center, TUM University Hospital, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-02-24">
<day>24</day>
<month>2</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>111</issue>
<fpage>8101</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>PyTorch</kwd>
<kwd>deep learning</kwd>
<kwd>configuration</kwd>
<kwd>framework</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Lighter is a configuration-driven deep learning (DL)
  <ext-link ext-link-type="uri" xlink:href="https://github.com/project-lighter/lighter">framework</ext-link>
  that separates experimental setup from code implementation. Models,
  datasets, and other components are defined through structured
  configuration files (configs). Configs serve as snapshots of the
  experiments, enhancing reproducibility while eliminating unstructured
  and repetitive scripts. Lighter uses (i) PyTorch Lightning
  (<xref alt="Falcon &amp; The PyTorch Lightning team, 2019" rid="ref-Falcon_PyTorch_Lightning_2019" ref-type="bibr">Falcon
  &amp; The PyTorch Lightning team, 2019</xref>) to implement a
  task-agnostic DL logic, and (ii)
  <ext-link ext-link-type="uri" xlink:href="https://docs.monai.io/en/stable/config_syntax.html#">MONAI
  Bundle configuration</ext-link>
  (<xref alt="Cardoso et al., 2022" rid="ref-Cardoso_MONAI_An_open-source_2022" ref-type="bibr">Cardoso
  et al., 2022</xref>) to manage experiments using YAML configs.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Lighter addresses several challenges in DL experimentation:</p>
  <list list-type="order">
    <list-item>
      <p><bold>Repetitive and Error-Prone Setups</bold>: DL typically
      involves significant boilerplate code for training loops, data
      loading, and metric calculations. The numerous hyperparameters and
      components across experiments can easily become complex and
      error-prone. Lighter abstracts these repetitive tasks and uses
      centralized configs for a clear, manageable experimental setup,
      reducing tedium and potential for errors.</p>
    </list-item>
    <list-item>
      <p><bold>Reproducibility and Collaboration</bold>: Inconsistent or
      complex codebases hinder collaboration and experiment
      reproduction. Lighter’s self-documenting configs offer clear,
      structured snapshots of each experiment. This greatly improves
      reproducibility and simplifies how teams share and reuse
      setups.</p>
    </list-item>
    <list-item>
      <p><bold>Pace of Research Iteration</bold>: The cumulative effect
      of these challenges inherently slows down the research cycle.
      Lighter streamlines the entire experimental process, allowing
      researchers to focus on core hypotheses and iterate on ideas
      efficiently.</p>
    </list-item>
  </list>
</sec>
<sec id="state-of-the-field">
  <title>State of the Field</title>
  <p>Config-driven frameworks like Ludwig
  (<xref alt="Molino et al., 2019" rid="ref-Ludwig" ref-type="bibr">Molino
  et al., 2019</xref>), Quadra
  (<xref alt="Mammana et al., 2025" rid="ref-Quadra" ref-type="bibr">Mammana
  et al., 2025</xref>), and GaNDLF
  (<xref alt="Pati et al., 2023" rid="ref-Gandlf" ref-type="bibr">Pati
  et al., 2023</xref>) offer high level of abstraction by providing
  predefined structures and pipelines. While this approach simplifies
  usage, it limits flexibility to modify the pipeline or extend
  components, often requiring direct source code changes. Lighter takes
  a different approach by providing medium-level abstraction. It
  implements a flexible pipeline that maintains direct compatibility
  with standard PyTorch components (models, datasets, optimizers). The
  pipeline itself is modifiable to any task via
  <xref alt="adapters" rid="adapters">adapters</xref>, while custom code
  is
  <xref alt="importable via config" rid="project-specific-modules">importable
  via config</xref> without source code modifications.</p>
</sec>
<sec id="design">
  <title>Design</title>
  <p>Lighter is built upon three fundamental components
  (<xref alt="[fig:overview_all]" rid="figU003Aoverview_all">[fig:overview_all]</xref>):</p>
  <list list-type="order">
    <list-item>
      <p><bold><monospace>Config</monospace></bold>: serves as the
      primary interface for interacting with Lighter. It parses and
      validates YAML configs that define all components, creating a
      self-documenting record of each experiment.</p>
    </list-item>
    <list-item>
      <p><bold><monospace>System</monospace></bold>: encapsulates the
      components (model, optimizer, scheduler, loss function, metrics,
      and dataloaders) and connects them into a pipeline that can be
      customized through
      <xref alt="adapters" rid="adapters">adapters</xref>
      (<xref alt="[fig:overview_system]" rid="figU003Aoverview_system">[fig:overview_system]</xref>).</p>
    </list-item>
    <list-item>
      <p><bold><monospace>Trainer</monospace></bold>: PyTorch
      Lightning’s <monospace>Trainer</monospace> handles aspects like
      distributed or mixed-precision training and checkpoint management.
      Lighter uses it to execute the protocol defined by the
      <monospace>System</monospace>.</p>
    </list-item>
  </list>
  <fig>
    <caption><p><bold>Lighter Overview.</bold>
    <monospace>Config</monospace> leverages MONAI’s
    <monospace>ConfigParser</monospace> for parsing the user-defined
    YAML configs, and its features are used by Runner to instantiate the
    <monospace>System</monospace> and <monospace>Trainer</monospace>.
    <monospace>Trainer</monospace> is used directly from PyTorch
    Lightning, whereas <monospace>System</monospace> inherits from
    <monospace>LightningModule</monospace>, ensuring its compatibility
    with <monospace>Trainer</monospace> while implementing a logic
    generalizable to any task or type of data. Finally,
    <monospace>Runner</monospace> runs the paired
    <monospace>Trainer</monospace> and <monospace>System</monospace> for
    a particular stage (e.g., fit or
    test).<styled-content id="figU003Aoverview_all"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="overview_all.png" />
  </fig>
  <fig>
    <caption><p><bold>Flowchart of the
    <monospace>lighter.System</monospace>.</bold> A
    <monospace>batch</monospace> from the
    <monospace>DataLoader</monospace> is processed by
    <monospace>BatchAdapter</monospace> to extract
    <monospace>input</monospace>, <monospace>target</monospace>
    (optional), and <monospace>identifier</monospace> (optional). The
    <monospace>Model</monospace> generates <monospace>pred</monospace>
    (predictions) from the <monospace>input</monospace>.
    <monospace>CriterionAdapter</monospace> and
    <monospace>MetricsAdapter</monospace> compute loss and metrics,
    respectively, by applying optional transformations and routing
    arguments for the loss and metric functions. Results, including
    loss, metrics, and other data prepared for logging by the
    <monospace>LoggingAdapter</monospace> are returned to the
    <monospace>Trainer</monospace>.<styled-content id="figU003Aoverview_system"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="overview_system.png" />
  </fig>
  <sec id="adaptability-through-modular-design">
    <title>Adaptability Through Modular Design</title>
    <sec id="adapters">
      <title>Adapters</title>
      <p>If we consider all possible DL tasks, we will find it
      challenging to implement a single pipeline that supports all.
      Instead, frameworks often implement per-task pipelines (e.g.,
      segmentation, classification, etc.). By contrast, Lighter
      implements a unified pipeline modifiable via <italic>adapter
      classes</italic>. In software design, <italic>adapter design
      pattern</italic> enables components with incompatible interfaces
      to work together by <italic>bridging</italic> them using an
      adapter class. In Lighter, these bridges
      (<xref alt="[fig:overview_system]" rid="figU003Aoverview_system">[fig:overview_system]</xref>)
      specify how components should interact across data types and
      tasks. For example, a model’s output will differ based on the task
      (e.g., segmentation, regression), and the adapter will specify how
      to pass them on to the next component (e.g., criterion or
      metrics). This design allows Lighter to handle any task without
      requiring changes to the source code.</p>
      <code language="yaml"># Example of an adapter transforming and routing data to the loss function
adapters:
    train:
        criterion:
            _target_: lighter.adapters.CriterionAdapter
            pred_transforms:   # Apply sigmoid activation to predictions
                _target_: torch.sigmoid
            pred_argument: 0   # Pass 'pred' to criterion's first arg
            target_argument: 1 # Pass 'target' to criterion's second arg</code>
    </sec>
    <sec id="project-specific-modules">
      <title>Project-specific modules</title>
      <p>Using custom components does not require modifying the
      framework. Instead, they can be defined within a <italic>project
      folder</italic> like:</p>
      <preformat>joss_project
├── __init__.py
└── models/
    ├── __init__.py
    └── mlp.py</preformat>
      <p>By specifying the project path in the config, it is imported as
      a module whose components can be referenced in the config:</p>
      <code language="yaml">project: /path/to/joss_project  # Path to the directory above
system:
    model:
        _target_: project.models.mlp.MLP  # Reference to the custom model
        input_size: 784
        num_classes: 10</code>
    </sec>
  </sec>
</sec>
<sec id="research-contributions-that-use-lighter">
  <title>Research Contributions That Use Lighter</title>
  <list list-type="bullet">
    <list-item>
      <p>Foundation model for cancer imaging biomarkers
      (<xref alt="Pai et al., 2024" rid="ref-Pai2024" ref-type="bibr">Pai
      et al., 2024</xref>)</p>
    </list-item>
    <list-item>
      <p>Vision Foundation Models for Computed Tomography
      (<xref alt="Pai et al., 2025" rid="ref-Pai2025" ref-type="bibr">Pai
      et al., 2025</xref>)</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>We thank John Zielke for the adapter design pattern idea. We thank
  Wenqi Li, Nic Ma, Yun Liu, and Eric Kerfoot for their continuous
  support with MONAI Bundle.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Falcon_PyTorch_Lightning_2019">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Falcon</surname><given-names>William</given-names></name>
        <string-name>The PyTorch Lightning team</string-name>
      </person-group>
      <article-title>PyTorch Lightning</article-title>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <uri>https://github.com/Lightning-AI/lightning</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3828935</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Cardoso_MONAI_An_open-source_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cardoso</surname><given-names>M. Jorge</given-names></name>
        <name><surname>Li</surname><given-names>Wenqi</given-names></name>
        <name><surname>Brown</surname><given-names>Richard</given-names></name>
        <name><surname>Ma</surname><given-names>Nic</given-names></name>
        <name><surname>Kerfoot</surname><given-names>Eric</given-names></name>
        <name><surname>Wang</surname><given-names>Yiheng</given-names></name>
        <name><surname>Murray</surname><given-names>Benjamin</given-names></name>
        <name><surname>Myronenko</surname><given-names>Andriy</given-names></name>
        <name><surname>Zhao</surname><given-names>Can</given-names></name>
        <name><surname>Yang</surname><given-names>Dong</given-names></name>
        <name><surname>Nath</surname><given-names>Vishwesh</given-names></name>
        <name><surname>He</surname><given-names>Yufan</given-names></name>
        <name><surname>Xu</surname><given-names>Ziyue</given-names></name>
        <name><surname>Hatamizadeh</surname><given-names>Ali</given-names></name>
        <name><surname>Zhu</surname><given-names>Wentao</given-names></name>
        <name><surname>Liu</surname><given-names>Yun</given-names></name>
        <name><surname>Zheng</surname><given-names>Mingxin</given-names></name>
        <name><surname>Tang</surname><given-names>Yucheng</given-names></name>
        <name><surname>Yang</surname><given-names>Isaac</given-names></name>
        <name><surname>Zephyr</surname><given-names>Michael</given-names></name>
        <name><surname>Hashemian</surname><given-names>Behrooz</given-names></name>
        <name><surname>Alle</surname><given-names>Sachidanand</given-names></name>
        <name><surname>Zalbagi Darestani</surname><given-names>Mohammad</given-names></name>
        <name><surname>Budd</surname><given-names>Charlie</given-names></name>
        <name><surname>Modat</surname><given-names>Marc</given-names></name>
        <name><surname>Vercauteren</surname><given-names>Tom</given-names></name>
        <name><surname>Wang</surname><given-names>Guotai</given-names></name>
        <name><surname>Li</surname><given-names>Yiwen</given-names></name>
        <name><surname>Hu</surname><given-names>Yipeng</given-names></name>
        <name><surname>Fu</surname><given-names>Yunguan</given-names></name>
        <name><surname>Gorman</surname><given-names>Benjamin</given-names></name>
        <name><surname>Johnson</surname><given-names>Hans</given-names></name>
        <name><surname>Genereaux</surname><given-names>Brad</given-names></name>
        <name><surname>Erdal</surname><given-names>Barbaros S.</given-names></name>
        <name><surname>Gupta</surname><given-names>Vikash</given-names></name>
        <name><surname>Diaz-Pinto</surname><given-names>Andres</given-names></name>
        <name><surname>Dourson</surname><given-names>Andre</given-names></name>
        <name><surname>Maier-Hein</surname><given-names>Lena</given-names></name>
        <name><surname>Jaeger</surname><given-names>Paul F.</given-names></name>
        <name><surname>Baumgartner</surname><given-names>Michael</given-names></name>
        <name><surname>Kalpathy-Cramer</surname><given-names>Jayashree</given-names></name>
        <name><surname>Flores</surname><given-names>Mona</given-names></name>
        <name><surname>Kirby</surname><given-names>Justin</given-names></name>
        <name><surname>Cooper</surname><given-names>Lee A. D.</given-names></name>
        <name><surname>Roth</surname><given-names>Holger R.</given-names></name>
        <name><surname>Xu</surname><given-names>Daguang</given-names></name>
        <name><surname>Bericat</surname><given-names>David</given-names></name>
        <name><surname>Floca</surname><given-names>Ralf</given-names></name>
        <name><surname>Zhou</surname><given-names>S. Kevin</given-names></name>
        <name><surname>Shuaib</surname><given-names>Haris</given-names></name>
        <name><surname>Farahani</surname><given-names>Keyvan</given-names></name>
        <name><surname>Maier-Hein</surname><given-names>Klaus H.</given-names></name>
        <name><surname>Aylward</surname><given-names>Stephen</given-names></name>
        <name><surname>Dogra</surname><given-names>Prerna</given-names></name>
        <name><surname>Ourselin</surname><given-names>Sebastien</given-names></name>
        <name><surname>Feng</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>MONAI: An open-source framework for deep learning in healthcare</article-title>
      <year iso-8601-date="2022-11">2022</year><month>11</month>
      <pub-id pub-id-type="doi">10.48550/arXiv.2211.02701</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Pai2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pai</surname><given-names>Suraj</given-names></name>
        <name><surname>Bontempi</surname><given-names>Dennis</given-names></name>
        <name><surname>Hadzic</surname><given-names>Ibrahim</given-names></name>
        <name><surname>Prudente</surname><given-names>Vasco</given-names></name>
        <name><surname>Sokač</surname><given-names>Mateo</given-names></name>
        <name><surname>Chaunzwa</surname><given-names>Tafadzwa L</given-names></name>
        <name><surname>Bernatz</surname><given-names>Simon</given-names></name>
        <name><surname>Hosny</surname><given-names>Ahmed</given-names></name>
        <name><surname>Mak</surname><given-names>Raymond H</given-names></name>
        <name><surname>Birkbak</surname><given-names>Nicolai J</given-names></name>
        <name><surname>Aerts</surname><given-names>Hugo J W L</given-names></name>
      </person-group>
      <article-title>Foundation model for cancer imaging biomarkers</article-title>
      <source>Nat. Mach. Intell.</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2024-03">2024</year><month>03</month>
      <volume>6</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1038/s42256-024-00807-9</pub-id>
      <fpage>354</fpage>
      <lpage>367</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Pai2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pai</surname><given-names>Suraj</given-names></name>
        <name><surname>Hadzic</surname><given-names>Ibrahim</given-names></name>
        <name><surname>Bontempi</surname><given-names>Dennis</given-names></name>
        <name><surname>Bressem</surname><given-names>Keno</given-names></name>
        <name><surname>Kann</surname><given-names>Benjamin H</given-names></name>
        <name><surname>Fedorov</surname><given-names>Andriy</given-names></name>
        <name><surname>Mak</surname><given-names>Raymond H</given-names></name>
        <name><surname>Aerts</surname><given-names>Hugo J W L</given-names></name>
      </person-group>
      <article-title>Vision foundation models for computed tomography</article-title>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2501.09001</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Ludwig">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Molino</surname><given-names>Piero</given-names></name>
        <name><surname>Dudin</surname><given-names>Yaroslav</given-names></name>
        <name><surname>Miryala</surname><given-names>Sai Sumanth</given-names></name>
      </person-group>
      <article-title>Ludwig: A type-based declarative deep learning toolbox</article-title>
      <source>CoRR</source>
      <year iso-8601-date="2019">2019</year>
      <volume>abs/1909.07930</volume>
      <uri>http://arxiv.org/abs/1909.07930</uri>
    </element-citation>
  </ref>
  <ref id="ref-Quadra">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Mammana</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Malli</surname><given-names>Refik Can</given-names></name>
        <name><surname>Polidori</surname><given-names>Alessandro</given-names></name>
        <name><surname>ebernatene</surname></name>
      </person-group>
      <article-title>Orobix/quadra</article-title>
      <year iso-8601-date="2025-05-20">2025</year><month>05</month><day>20</day>
      <uri>https://github.com/orobix/quadra</uri>
    </element-citation>
  </ref>
  <ref id="ref-Gandlf">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pati</surname><given-names>Sarthak</given-names></name>
        <name><surname>Thakur</surname><given-names>Siddhesh P.</given-names></name>
        <name><surname>Hamamcı</surname><given-names>İbrahim Ethem</given-names></name>
        <name><surname>Baid</surname><given-names>Ujjwal</given-names></name>
        <name><surname>Baheti</surname><given-names>Bhakti</given-names></name>
        <name><surname>Bhalerao</surname><given-names>Megh</given-names></name>
        <name><surname>Güley</surname><given-names>Orhun</given-names></name>
        <name><surname>Mouchtaris</surname><given-names>Sofia</given-names></name>
        <name><surname>Lang</surname><given-names>David</given-names></name>
        <name><surname>Thermos</surname><given-names>Spyridon</given-names></name>
        <name><surname>Gotkowski</surname><given-names>Karol</given-names></name>
        <name><surname>González</surname><given-names>Camila</given-names></name>
        <name><surname>Grenko</surname><given-names>Caleb</given-names></name>
        <name><surname>Getka</surname><given-names>Alexander</given-names></name>
        <name><surname>Edwards</surname><given-names>Brandon</given-names></name>
        <name><surname>Sheller</surname><given-names>Micah</given-names></name>
        <name><surname>Wu</surname><given-names>Junwen</given-names></name>
        <name><surname>Karkada</surname><given-names>Deepthi</given-names></name>
        <name><surname>Panchumarthy</surname><given-names>Ravi</given-names></name>
        <name><surname>Ahluwalia</surname><given-names>Vinayak</given-names></name>
        <name><surname>Zou</surname><given-names>Chunrui</given-names></name>
        <name><surname>Bashyam</surname><given-names>Vishnu</given-names></name>
        <name><surname>Li</surname><given-names>Yuemeng</given-names></name>
        <name><surname>Haghighi</surname><given-names>Babak</given-names></name>
        <name><surname>Chitalia</surname><given-names>Rhea</given-names></name>
        <name><surname>Abousamra</surname><given-names>Shahira</given-names></name>
        <name><surname>Kurc</surname><given-names>Tahsin M.</given-names></name>
        <name><surname>Gastounioti</surname><given-names>Aimilia</given-names></name>
        <name><surname>Er</surname><given-names>Sezgin</given-names></name>
        <name><surname>Bergman</surname><given-names>Mark</given-names></name>
        <name><surname>Saltz</surname><given-names>Joel H.</given-names></name>
        <name><surname>Fan</surname><given-names>Yong</given-names></name>
        <name><surname>Shah</surname><given-names>Prashant</given-names></name>
        <name><surname>Mukhopadhyay</surname><given-names>Anirban</given-names></name>
        <name><surname>Tsaftaris</surname><given-names>Sotirios A.</given-names></name>
        <name><surname>Menze</surname><given-names>Bjoern</given-names></name>
        <name><surname>Davatzikos</surname><given-names>Christos</given-names></name>
        <name><surname>Kontos</surname><given-names>Despina</given-names></name>
        <name><surname>Karargyris</surname><given-names>Alexandros</given-names></name>
        <name><surname>Umeton</surname><given-names>Renato</given-names></name>
        <name><surname>Mattson</surname><given-names>Peter</given-names></name>
        <name><surname>Bakas</surname><given-names>Spyridon</given-names></name>
      </person-group>
      <article-title>GaNDLF: The generally nuanced deep learning framework for scalable end-to-end clinical workflows</article-title>
      <source>Communications Engineering</source>
      <year iso-8601-date="2023-05-16">2023</year><month>05</month><day>16</day>
      <volume>2</volume>
      <issue>1</issue>
      <issn>2731-3395</issn>
      <uri>https://doi.org/10.1038/s44172-023-00066-3</uri>
      <pub-id pub-id-type="doi">10.1038/s44172-023-00066-3</pub-id>
      <fpage>23</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
