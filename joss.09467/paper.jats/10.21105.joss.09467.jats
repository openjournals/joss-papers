<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9467</article-id>
<article-id pub-id-type="doi">10.21105/joss.09467</article-id>
<title-group>
<article-title>JSOSolvers.jl: Unconstrained and bound-constrained
optimization solvers</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7729-2513</contrib-id>
<name>
<surname>Migot</surname>
<given-names>Tangi</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5482-6831</contrib-id>
<name>
<surname>Monnet</surname>
<given-names>Dominique</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8017-7687</contrib-id>
<name>
<surname>Orban</surname>
<given-names>Dominique</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4451-281X</contrib-id>
<name>
<surname>Siqueira</surname>
<given-names>Abel Soares</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>GERAD and Department of Mathematics and Industrial
Engineering, Polytechnique Montréal, QC, Canada.</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Netherlands eScience Center, Amsterdam,
Netherlands</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Univ Rennes, INSA Rennes, CNRS, IRMAR - UMR 6625, Rennes,
France</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-10-18">
<day>18</day>
<month>10</month>
<year>2025</year>
</pub-date>
<volume>11</volume>
<issue>117</issue>
<fpage>9467</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>nonlinear optimization</kwd>
<kwd>numerical optimization</kwd>
<kwd>large-scale optimization</kwd>
<kwd>unconstrained optimization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>JSOSolvers.jl</monospace> is a collection of Julia
  (<xref alt="Bezanson et al., 2017" rid="ref-bezanson2017julia" ref-type="bibr">Bezanson
  et al., 2017</xref>) optimization solvers for nonlinear, potentially
  nonconvex, continuous optimization problems that are unconstrained or
  bound-constrained:
  <named-content id="eqU003Anlp" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
      \underset{x \in \mathbb{R}^n}{\text{minimize}} \ f(x) \quad \text{subject to} \quad \ell \leq x \leq u,]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:munder><mml:mtext mathvariant="normal">minimize</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:munder><mml:mspace width="0.222em"></mml:mspace><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mspace width="1.0em"></mml:mspace><mml:mtext mathvariant="normal">subject to</mml:mtext><mml:mspace width="1.0em"></mml:mspace><mml:mo>ℓ</mml:mo><mml:mo>≤</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></named-content>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[f:\mathbb{R}^n \rightarrow \mathbb{R}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mi>ℝ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  is a continuously differentiable function, with
  <inline-formula><alternatives>
  <tex-math><![CDATA[\ell \in \left(\mathbb{R} \cup \{-\infty\} \right)^n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>ℓ</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>ℝ</mml:mi><mml:mo>∪</mml:mo><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mi>−</mml:mi><mml:mi>∞</mml:mi><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>,
  and <inline-formula><alternatives>
  <tex-math><![CDATA[u \in \left(\mathbb{R} \cup \{+\infty\} \right)^n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>ℝ</mml:mi><mml:mo>∪</mml:mo><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mi>+</mml:mi><mml:mi>∞</mml:mi><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.
  The algorithms implemented here are iterative methods that aim to
  compute a stationary point of <xref alt="1" rid="eqU003Anlp">1</xref>
  using first and, if possible, second-order derivatives.</p>
  <p>Our initial motivation for considering
  <xref alt="1" rid="eqU003Anlp">1</xref> and developing
  <monospace>JSOSolvers.jl</monospace> is to solve large-scale
  unconstrained and bound-constrained problems such as parameter
  estimation in inverse problems, design optimization in engineering,
  and regularized machine learning models, and use these solvers to
  solve subproblems of penalty algorithms, such as
  <monospace>Percival.jl</monospace>
  (<xref alt="Antunes dos Santos et al., 2026" rid="ref-Percival_jl" ref-type="bibr">Antunes
  dos Santos et al., 2026</xref>) or
  <monospace>FletcherPenaltySolver.jl</monospace>
  (<xref alt="Migot et al., 2025" rid="ref-FletcherPenaltySolver_jl" ref-type="bibr">Migot
  et al., 2025</xref>), for constrained nonlinear continuous
  optimization problems. In many of these problems, explicitly storing
  Hessian matrices is either computationally prohibitive or impractical.
  The solvers in <monospace>JSOSolvers.jl</monospace> adopt a
  matrix-free approach, where standard optimization methods are
  implemented without forming derivative matrices explicitly. This
  strategy enables the solution of large-scale problems even when
  function and gradient evaluations are expensive.</p>
  <p>The library includes TRON, a trust-region Newton method for
  bound-constrained problems following the classical formulation of Lin
  &amp; Moré
  (<xref alt="1999" rid="ref-tron" ref-type="bibr">1999</xref>), TRUNK,
  a factorization-free trust-region Newton method based on the truncated
  conjugate gradient method, as described by Conn et al.
  (<xref alt="2000" rid="ref-conn2000trust" ref-type="bibr">2000</xref>),
  an implementation of L-BFGS, a limited-memory quasi-Newton method
  using a line search globalization strategy, and FOMO, a first-order
  method based on quadratic regularization designed for unconstrained
  optimization. FOMO is an extension of a quadratic regularization
  method described by Aravkin et al.
  (<xref alt="2022" rid="ref-aravkin2022proximal" ref-type="bibr">2022</xref>),
  and called R2 in <monospace>JSOSolvers.jl</monospace>. Unlike textbook
  implementations, our solvers introduce several design differences.
  TRON operates in a factorization-free mode, while the original Fortran
  TRON requires an explicitly formed Hessian. TRUNK departs from the
  Conn–Gould–Toint formulation by supporting a non-monotone mode and
  multiple subproblem solvers (CG, CR, MINRES, etc.). Our L-BFGS
  implementation uses a simplified line-search strategy that avoids the
  standard Wolfe conditions while maintaining robust convergence in
  practice.</p>
  <p>A nonlinear least-squares problem is a special case of
  <xref alt="1" rid="eqU003Anlp">1</xref>, where
  <inline-formula><alternatives>
  <tex-math><![CDATA[f(x)=\frac{1}{2}\|F(x)\|^2_2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:msubsup><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>
  and the residual <inline-formula><alternatives>
  <tex-math><![CDATA[F:\mathbb{R}^n \rightarrow \mathbb{R}^m]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>F</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
  is continuously differentiable, which appears in many applications,
  including inverse problems in imaging, geophysics, and machine
  learning. While it is possible to solve the problem using only the
  objective, knowing <inline-formula><alternatives>
  <tex-math><![CDATA[F]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>F</mml:mi></mml:math></alternatives></inline-formula>
  independently allows the development of more efficient methods.
  Specialized variants of TRON and TRUNK, called TRON-NLS and TRUNK-NLS,
  leverage the structure of residual models to improve performance and
  scalability.</p>
  <p>A key strength of <monospace>JSOSolvers.jl</monospace> lies in its
  efficiency and flexibility. The solvers support fully in-place
  execution, allowing repeated solves without additional memory
  allocation, which is particularly beneficial in high-performance and
  GPU computing environments where memory management is critical. The
  solvers support any floating-point type, including extended and
  multi-precision types such as BigFloat, DoubleFloats or QuadMath.
  Moreover, TRUNK, TRUNK-NLS, and FOMO support GPU arrays, broadening
  the range of hardware where the package can be effectively deployed,
  for instance when used together with
  <monospace>ExaModels.jl</monospace>
  (<xref alt="Shin et al., 2024" rid="ref-shin2024accelerating" ref-type="bibr">Shin
  et al., 2024</xref>). The package documentation and
  <ext-link ext-link-type="uri" xlink:href="https://jso.dev/tutorials">https://jso.dev/tutorials</ext-link>
  provide examples illustrating the use of different floating-point
  systems. Furthermore, the solvers expose in-place function variants,
  allowing multiple optimization problems with identical dimensions and
  data types to be solved efficiently without reallocations.</p>
  <p><monospace>JSOSolvers.jl</monospace> is built upon the
  JuliaSmoothOptimizers (JSO) tools
  <xref ref-type="fn" rid="fn1">1</xref>. JSO is an academic
  organization containing a collection of Julia packages for nonlinear
  optimization software development, testing, and benchmarking. It
  provides tools for building models, accessing problem repositories,
  and solving subproblems. Solvers in
  <monospace>JSOSolvers.jl</monospace> take as input an
  <monospace>AbstractNLPModel</monospace>, JSO’s general model API
  defined in <monospace>NLPModels.jl</monospace>
  (<xref alt="Orban et al., 2026a" rid="ref-NLPModels_jl" ref-type="bibr">Orban
  et al., 2026a</xref>), a flexible data type to evaluate objective and
  constraints, their derivatives, and to provide any information that a
  solver might request from a model. The user can hand-code derivatives,
  use automatic differentiation, or use JSO-interfaces to classical
  mathematical optimization modeling languages such as AMPL
  (<xref alt="Fourer et al., 1990" rid="ref-fourer2003ampl" ref-type="bibr">Fourer
  et al., 1990</xref>), CUTEst
  (<xref alt="Gould et al., 2015" rid="ref-cutest" ref-type="bibr">Gould
  et al., 2015</xref>), or JuMP
  (<xref alt="Dunning et al., 2017" rid="ref-jump" ref-type="bibr">Dunning
  et al., 2017</xref>). The solvers rely heavily on iterative linear
  algebra methods from <monospace>Krylov.jl</monospace>
  (<xref alt="Montoison &amp; Orban, 2023" rid="ref-Krylov_jl" ref-type="bibr">Montoison
  &amp; Orban, 2023</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Julia’s JIT compiler is attractive for the design of efficient
  scientific computing software, and, in particular, mathematical
  optimization
  (<xref alt="Lubin &amp; Dunning, 2015" rid="ref-lubin2015computing" ref-type="bibr">Lubin
  &amp; Dunning, 2015</xref>), and has become a natural choice for
  developing new solvers.</p>
  <p>While several options exist to solve
  <xref alt="1" rid="eqU003Anlp">1</xref> in Julia, many rely on
  wrappers to solvers implemented in low-level compiled languages. For
  example, if <xref alt="1" rid="eqU003Anlp">1</xref> is modeled using
  JuMP
  (<xref alt="Dunning et al., 2017" rid="ref-jump" ref-type="bibr">Dunning
  et al., 2017</xref>), it can be passed to solvers like IPOPT
  (<xref alt="Wächter &amp; Biegler, 2006" rid="ref-wachter2006implementation" ref-type="bibr">Wächter
  &amp; Biegler, 2006</xref>) or Artelys Knitro
  (<xref alt="Byrd et al., 2006" rid="ref-byrd2006k" ref-type="bibr">Byrd
  et al., 2006</xref>) via Julia’s native C and Fortran
  interoperability. However, these interfaces often lack flexibility
  with respect to data types and numerical precision. In contrast,
  solvers written in pure Julia can operate seamlessly with a variety of
  arithmetic types or even GPU array types. This capability is
  increasingly important as extended-precision arithmetic becomes more
  accessible through packages such as GNU MPFR, shipped with Julia. Such
  flexibility enables high-precision computing when numerical accuracy
  is paramount.</p>
  <p>Several alternatives to <monospace>JSOSolvers.jl</monospace> are
  available within and outside the Julia ecosystem.
  <monospace>Optim.jl</monospace>
  (<xref alt="Mogensen &amp; Riseth, 2018" rid="ref-mogensen2018optim" ref-type="bibr">Mogensen
  &amp; Riseth, 2018</xref>) is a general-purpose optimization library
  in pure Julia, suitable for small to medium-scale problems, but it
  lacks in-place execution and GPU support.
  <monospace>NLopt.jl</monospace>
  (<xref alt="Johnson, 2007" rid="ref-NLopt" ref-type="bibr">Johnson,
  2007</xref>) provides access to a broad collection of optimization
  algorithms via a C library but does not support matrix-free methods or
  extended precision. <monospace>AdaptiveRegularization.jl</monospace>
  (<xref alt="Dussault et al., 2024" rid="ref-AdaptiveRegularization_jl" ref-type="bibr">Dussault
  et al., 2024</xref>) offers a matrix-free, multi-precision solver for
  unconstrained problems and is closely aligned with the design
  philosophy of <monospace>JSOSolvers.jl</monospace>. Ipopt
  (<xref alt="Wächter &amp; Biegler, 2006" rid="ref-wachter2006implementation" ref-type="bibr">Wächter
  &amp; Biegler, 2006</xref>), via <monospace>Ipopt.jl</monospace>, is a
  widely used and efficient solver, but requires explicit derivatives
  and is limited to CPU execution. GALAHAD
  (<xref alt="Fowkes &amp; Gould, 2023" rid="ref-galahad" ref-type="bibr">Fowkes
  &amp; Gould, 2023</xref>), a Fortran-based suite for large-scale
  problems, is accessible through experimental Julia wrappers, yet lacks
  native composability. Commercial solvers such as Artelys Knitro
  (<xref alt="Byrd et al., 2006" rid="ref-byrd2006k" ref-type="bibr">Byrd
  et al., 2006</xref>) provide robust algorithms but remain constrained
  by licensing and limited Julia interoperability.
  <monospace>Optimization.jl</monospace> is a wrapper to existing
  optimization packages.</p>
  <sec id="benchmarking">
    <title>Benchmarking</title>
    <p><monospace>JSOSolvers.jl</monospace> can solve large-scale
    problems and can be benchmarked easily against other JSO-compliant
    solvers using <monospace>SolverBenchmark.jl</monospace>
    (<xref alt="Orban et al., 2026b" rid="ref-SolverBenchmark_jl" ref-type="bibr">Orban
    et al., 2026b</xref>). We include below performance profiles
    (<xref alt="Dolan &amp; Moré, 2002" rid="ref-dolan2002benchmarking" ref-type="bibr">Dolan
    &amp; Moré, 2002</xref>) with respect to elapsed time of
    <monospace>JSOSolvers.jl</monospace> solvers against Ipopt on all
    the 291 unconstrained problems from the CUTEst collection
    (<xref alt="Gould et al., 2015" rid="ref-cutest" ref-type="bibr">Gould
    et al., 2015</xref>), whose dimensions range from 2 up to 192,627
    variables.<xref ref-type="fn" rid="fn2">2</xref> LBFGS uses only
    first-order information, while TRON and TRUNK use Hessian-vector
    products and Ipopt uses the Hessian as a matrix. Without explaining
    performance profiles in full detail, the plot shows that Ipopt is
    fastest on 42 problems (15%), TRON on 9 (3%), TRUNK on 64 (21%), and
    L-BFGS on 176 (60%). Nearly all problems were solved within the
    20-minute limit: TRON solved 272 (93%), Ipopt 270, TRUNK 269, and
    L-BFGS 267.</p>
    <p>Overall, these results are encouraging. Although Ipopt is a
    mature and highly optimized solver, TRUNK and L-BFGS achieve
    comparable problem coverage while being significantly faster on many
    instances. This suggests that the algorithms implemented here are
    competitive for large-scale problems. We also expect further gains
    as we continue refining algorithmic hyperparameters, which is one of
    the project’s short-term development goals. A complementary
    benchmark for bound-constrained problems is available in the package
    documentation.</p>
    <fig>
      <caption><p>Unconstrained solvers on CUTEst with respect to the
      elapsed time.</p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="2025-09-06_ipopt_lbfgs_trunk_tron_cutest_Float64_0_291_time_pp.pdf" />
    </fig>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Dominique Orban is partially supported by an NSERC Discovery
  Grant.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-bezanson2017julia">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
      </person-group>
      <article-title>Julia: A Fresh Approach to Numerical Computing</article-title>
      <source>SIAM Review</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>59</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
  <ref id="ref-shin2024accelerating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Shin</surname><given-names>Sungho</given-names></name>
        <name><surname>Anitescu</surname><given-names>Mihai</given-names></name>
        <name><surname>Pacaud</surname><given-names>François</given-names></name>
      </person-group>
      <article-title>Accelerating optimal power flow with GPUs: SIMD abstraction of nonlinear programs and condensed-space interior-point methods</article-title>
      <source>Electric Power Systems Research</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>236</volume>
      <pub-id pub-id-type="doi">10.1016/j.epsr.2024.110651</pub-id>
      <fpage>110651</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-aravkin2022proximal">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Aravkin</surname><given-names>Aleksandr Y</given-names></name>
        <name><surname>Baraldi</surname><given-names>Robert</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>A Proximal Quasi-Newton Trust-Region Method for Nonsmooth Regularized Optimization</article-title>
      <source>SIAM Journal on Optimization</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>32</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/21m1409536</pub-id>
      <fpage>900</fpage>
      <lpage>929</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Percival_jl">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Antunes dos Santos</surname><given-names>Egmara</given-names></name>
        <name><surname>Migot</surname><given-names>Tangi</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>Soares Siqueira</surname><given-names>Abel</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>Percival.jl: An augmented Lagrangian method</article-title>
      <year iso-8601-date="2026">2026</year>
      <uri>https://github.com/JuliaSmoothOptimizers/Percival.jl</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.3969045</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-FletcherPenaltySolver_jl">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Migot</surname><given-names>Tangi</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>Soares Siqueira</surname><given-names>Abel</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>FletcherPenaltySolver.jl: Fletcher’s penalty method for nonlinear optimization models</article-title>
      <year iso-8601-date="2025">2025</year>
      <uri>https://github.com/JuliaSmoothOptimizers/FletcherPenaltySolver.jl</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.7153563</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-NLPModels_jl">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>Soares Siqueira</surname><given-names>Abel</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>NLPModels.jl: Data structures for optimization models</article-title>
      <year iso-8601-date="2026">2026</year>
      <uri>https://github.com/JuliaSmoothOptimizers/NLPModels.jl</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.2558626</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jump">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dunning</surname><given-names>Iain</given-names></name>
        <name><surname>Huchette</surname><given-names>Joey</given-names></name>
        <name><surname>Lubin</surname><given-names>Miles</given-names></name>
      </person-group>
      <article-title>JuMP: A Modeling Language for Mathematical Optimization</article-title>
      <source>SIAM Review</source>
      <year iso-8601-date="2017">2017</year>
      <volume>59</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/15M1020575</pub-id>
      <fpage>295</fpage>
      <lpage>320</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fourer2003ampl">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fourer</surname><given-names>Robert</given-names></name>
        <name><surname>Gay</surname><given-names>David M.</given-names></name>
        <name><surname>Kernighan</surname><given-names>Brian W.</given-names></name>
      </person-group>
      <article-title>A Modeling Language for Mathematical Programming</article-title>
      <source>Management Science</source>
      <year iso-8601-date="1990">1990</year>
      <volume>36</volume>
      <issue>5</issue>
      <isbn>0-534-38809-4</isbn>
      <pub-id pub-id-type="doi">10.1287/mnsc.36.5.519</pub-id>
      <fpage>519</fpage>
      <lpage>554</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cutest">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gould</surname><given-names>Nicholas I.</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>Toint</surname><given-names>Philippe L.</given-names></name>
      </person-group>
      <article-title>CUTEst: A Constrained and Unconstrained Testing Environment with safe threads for mathematical optimization</article-title>
      <source>Computational Optimization and Applications</source>
      <year iso-8601-date="2015">2015</year>
      <volume>60</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1007/s10589-014-9687-3</pub-id>
      <fpage>545</fpage>
      <lpage>557</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tron">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lin</surname><given-names>Chih-Jen</given-names></name>
        <name><surname>Moré</surname><given-names>Jorge J.</given-names></name>
      </person-group>
      <article-title>Newton’s Method for Large Bound-Constrained Optimization Problems</article-title>
      <source>SIAM Journal on Optimization</source>
      <publisher-name>Society for Industrial &amp; Applied Mathematics (SIAM)</publisher-name>
      <year iso-8601-date="1999-01">1999</year><month>01</month>
      <volume>9</volume>
      <issue>4</issue>
      <issn>1095-7189</issn>
      <uri>http://dx.doi.org/10.1137/S1052623498345075</uri>
      <pub-id pub-id-type="doi">10.1137/s1052623498345075</pub-id>
      <fpage>1100</fpage>
      <lpage>1127</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Krylov_jl">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Montoison</surname><given-names>Alexis</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>Krylov.jl: A Julia basket of hand-picked Krylov methods</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2023-09">2023</year><month>09</month>
      <volume>8</volume>
      <issue>89</issue>
      <uri>https://joss.theoj.org/papers/10.21105/joss.05187</uri>
      <pub-id pub-id-type="doi">10.21105/joss.05187</pub-id>
      <fpage>5187</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-lubin2015computing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lubin</surname><given-names>Miles</given-names></name>
        <name><surname>Dunning</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Computing in Operations Research Using Julia</article-title>
      <source>INFORMS Journal on Computing</source>
      <publisher-name>INFORMS</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>27</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1287/ijoc.2014.0623</pub-id>
      <fpage>238</fpage>
      <lpage>248</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mogensen2018optim">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mogensen</surname><given-names>Patrick Kofod</given-names></name>
        <name><surname>Riseth</surname><given-names>Asbjørn Nilsen</given-names></name>
      </person-group>
      <article-title>Optim: A mathematical optimization package for Julia</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2018">2018</year>
      <volume>3</volume>
      <issue>24</issue>
      <pub-id pub-id-type="doi">10.21105/joss.00615</pub-id>
      <fpage>615</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-AdaptiveRegularization_jl">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Dussault</surname><given-names>Jean-Pierre</given-names></name>
        <name><surname>Goyette</surname><given-names>Samuel</given-names></name>
        <name><surname>Migot</surname><given-names>Tangi</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>AdaptiveRegularization.jl: A unified efficient implementation of trust-region type algorithms for unconstrained optimization</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://github.com/JuliaSmoothOptimizers/AdaptiveRegularization.jl</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.10434673</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-SolverBenchmark_jl">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
        <name><surname>Soares Siqueira</surname><given-names>Abel</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>SolverBenchmark.jl: Benchmark tools for solvers</article-title>
      <year iso-8601-date="2026">2026</year>
      <uri>https://github.com/JuliaSmoothOptimizers/SolverBenchmark.jl</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.2581661</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dolan2002benchmarking">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dolan</surname><given-names>Elizabeth D</given-names></name>
        <name><surname>Moré</surname><given-names>Jorge J</given-names></name>
      </person-group>
      <article-title>Benchmarking optimization software with performance profiles</article-title>
      <source>Mathematical programming</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <volume>91</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1007/s101070100263</pub-id>
      <fpage>201</fpage>
      <lpage>213</lpage>
    </element-citation>
  </ref>
  <ref id="ref-conn2000trust">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Conn</surname><given-names>Andrew R.</given-names></name>
        <name><surname>Gould</surname><given-names>Nicholas I. M.</given-names></name>
        <name><surname>Toint</surname><given-names>Philippe L.</given-names></name>
      </person-group>
      <source>Trust Region Methods</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2000">2000</year>
      <pub-id pub-id-type="doi">10.1137/1.9780898719857</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-NLopt">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Johnson</surname><given-names>Steven G.</given-names></name>
      </person-group>
      <article-title>The NLopt nonlinear-optimization package</article-title>
      <publisher-name>https://github.com/stevengj/nlopt</publisher-name>
      <year iso-8601-date="2007">2007</year>
    </element-citation>
  </ref>
  <ref id="ref-byrd2006k">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Byrd</surname><given-names>Richard H</given-names></name>
        <name><surname>Nocedal</surname><given-names>Jorge</given-names></name>
        <name><surname>Waltz</surname><given-names>Richard A</given-names></name>
      </person-group>
      <article-title>: An Integrated Package for Nonlinear Optimization</article-title>
      <source>Large-Scale Nonlinear Optimization</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2006">2006</year>
      <pub-id pub-id-type="doi">10.1007/0-387-30065-1_4</pub-id>
      <fpage>35</fpage>
      <lpage>59</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wachter2006implementation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wächter</surname><given-names>Andreas</given-names></name>
        <name><surname>Biegler</surname><given-names>Lorenz T.</given-names></name>
      </person-group>
      <article-title>On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming</article-title>
      <source>Mathematical Programming</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2006">2006</year>
      <volume>106</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1007/s10107-004-0559-y</pub-id>
      <fpage>25</fpage>
      <lpage>57</lpage>
    </element-citation>
  </ref>
  <ref id="ref-galahad">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fowkes</surname><given-names>Jaroslav M.</given-names></name>
        <name><surname>Gould</surname><given-names>Nicholas I. M.</given-names></name>
      </person-group>
      <article-title>GALAHAD 4.0: An open source library of Fortran packages with C and Matlab interfaces for continuous optimization</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2023-07">2023</year><month>07</month>
      <volume>8</volume>
      <issue>87</issue>
      <issn>2475-9066</issn>
      <uri>http://dx.doi.org/10.21105/joss.04882</uri>
      <pub-id pub-id-type="doi">10.21105/joss.04882</pub-id>
      <fpage>4882</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>JuliaSmoothOptimizers https://jso.dev/</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>Benchmarks were run sequentially on a CPU-only
    machine. The hardware configuration was an Intel Core i7-class
    processor with approximately 16 GB of RAM running Linux. Timings are
    intended for relative comparison only.</p>
  </fn>
</fn-group>
</back>
</article>
