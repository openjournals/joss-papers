<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9144</article-id>
<article-id pub-id-type="doi">10.21105/joss.09144</article-id>
<title-group>
<article-title>Plaquette: An Object-Oriented Framework for Embedded
Signal Processing in Interactive Media</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6621-6427</contrib-id>
<name>
<surname>Audry</surname>
<given-names>Sofian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0004-8587-9508</contrib-id>
<name>
<surname>Fredericks</surname>
<given-names>Thomas Ouellet</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Université du Québec à Montréal, Canada</institution>
<institution-id institution-id-type="ROR">002rjbv21</institution-id>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Collège Montmorency, Canada</institution>
<institution-id institution-id-type="ROR">05kqg2j33</institution-id>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-09-30">
<day>30</day>
<month>9</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>115</issue>
<fpage>9144</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Arduino</kwd>
<kwd>C++</kwd>
<kwd>Creative Coding</kwd>
<kwd>Dataflow</kwd>
<kwd>Embedded Systems</kwd>
<kwd>Interactive Media</kwd>
<kwd>Signal Processing</kwd>
<kwd>Physical Computing</kwd>
<kwd>Research-Creation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><italic>Plaquette</italic> is an object-oriented C++ framework for
  interactive media on embedded systems, supporting a wide range of
  platforms including AVR, ARM, ESP32, SAMD, and STM32. It provides a
  signal-centric architecture and a suite of modular abstractions
  (oscillators, filters, units, and scheduling engines) that simplify
  the design of time-based behaviors. Its expressive syntax allows fast
  prototyping with multiple sensors, actuators, and real-time processes,
  enabling researchers as well as creative practitioners to experiment
  with and design complex physical computing systems.</p>
  <p>Beyond its technical contributions, <italic>Plaquette</italic>
  serves as a bridge between scientific research and creative practice.
  Its application to interdisciplinary projects involving affective
  biofeedback and robotic behaviors demonstrates how the framework’s
  flexible and robust infrastructure supports creativity and
  experimentation across interactive media.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p><italic>Plaquette</italic> is designed for research—specifically,
  practice-based research
  (<xref alt="Candy &amp; Edmonds, 2018" rid="ref-Candy2018-PracticeBased" ref-type="bibr">Candy
  &amp; Edmonds, 2018</xref>) and research-creation
  (<xref alt="Loveless, 2019" rid="ref-Loveless2019-How" ref-type="bibr">Loveless,
  2019</xref>)—in embedded interactive media, with applications ranging
  from affective computing and digital lutherie to robotic art,
  interactive installation, connected objects, and performance. The
  <ext-link ext-link-type="uri" xlink:href="https://arduino.cc">Arduino</ext-link>
  (<xref alt="Banzi &amp; Shiloh, 2022" rid="ref-Banzi2022-Getting" ref-type="bibr">Banzi
  &amp; Shiloh, 2022</xref>) open-source platform for physical computing
  anchors a large and active ecosystem; it remains the go-to environment
  for artists, makers, and researchers working with embedded interactive
  media. Its accessibility, community, libraries, and hardware options
  have made it the most popular microcontroller platform worldwide. Yet,
  Arduino’s core library is not optimized for real-time signal
  processing: it lacks an object-oriented design, provides limited
  abstractions for managing concurrent events, and often requires
  manipulating raw numerical values, making interaction design
  unintuitive and hindering expressive experimentation.</p>
  <p>In contrast, dataflow software popular within scientific and
  creative communities working with real-time media (such as Pure Data,
  Max, and TouchDesigner) provide powerful models for composing with
  signals, but are too memory- and CPU-intensive to run on constrained
  hardware. Similarly, scientific tools such as Python’s NumPy/SciPy,
  Matlab, or R, offer rich signal analysis tools, but are not designed
  for real-time processing on embedded devices.</p>
  <p>Several Arduino libraries specialize in particular aspects of
  real-time signal processing such as filtering (e.g.,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/arduinofft/">arduinoFFT</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/datatome/">DataTome</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/fir-filter/">FIR-filter</ext-link>),
  generating waveforms (e.g.,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/functiongenerator/">FunctionGenerator</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/syncwaveformslib/">SyncWaveformsLib</ext-link>),
  or timing (e.g.,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/arduino-timer/">arduino-timer</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/chrono/">Chrono</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/softtimer/">SoftTimer</ext-link>).
  While these tools are effective within their domains, they address
  isolated functionalities and do not share a common programming model.
  Finally, Arduino’s hardware timers provide precise low-level control
  but require complex configuration of prescalers, registers, and
  interrupt handlers. These limitations of existing Arduino libraries
  and hardware timers hamper creative expression and
  experimentation.</p>
  <p><italic>Plaquette</italic> addresses these gaps by bringing the
  expressive power of dataflow signal-based programming into a
  lightweight object-oriented framework optimized for microcontrollers
  (i.e., requiring minimal CPU and memory usage). It enables intuitive
  handling of signals, providing efficient implementations of core data
  processing functions such as peak detection, normalization, scaling,
  and smoothing (low-pass), all under a unified framework. This enables
  researchers in art and science to focus on experimentation and
  expressivity while ensuring accurate and reliable real-time
  performance on resource-constrained platforms. Additional
  functionalities that expand on Plaquette’s core, such as advanced data
  filtering and event management, can be implemented as external
  Plaquette libraries.</p>
  <p>The framework provides a strong foundation for workshop-based
  research-creation projects, where participants often have diverse
  levels of technical skills. Its accessibility ensures that beginners
  can quickly grasp and apply core concepts, while its efficient,
  expressive, and extensible architecture supports the needs of advanced
  users. This makes it particularly well-suited for collaborative
  prototyping in media arts, design, and human-computer interaction,
  where embodied and situated practices require adaptable tools.</p>
  <p><italic>Plaquette</italic> has already supported a number of public
  research projects. It was used to improve real-time physiological
  signal processing as part of the
  <ext-link ext-link-type="uri" xlink:href="https://docs.arduino.cc/libraries/biodata/">BioData</ext-link>
  library for affective biofeedback, supporting creative applications in
  music and performance
  (<xref alt="Gee, 2023" rid="ref-Gee2023-BioSynth" ref-type="bibr">Gee,
  2023</xref>), and in studies of electrodermal activity
  (<xref alt="Hagler et al., 2022" rid="ref-Hagler2022-Flexible" ref-type="bibr">Hagler
  et al., 2022</xref>). It was integrated at the core of the
  <ext-link ext-link-type="uri" xlink:href="https://misbkit.ensadlab.fr">MisBKit</ext-link>,
  a robotic kit enabling research on object behaviors
  (<xref alt="Bianchini et al., 2015" rid="ref-Bianchini2015-Misbehavioral" ref-type="bibr">Bianchini
  et al., 2015</xref>). It was also employed for signal processing and
  robotic expression in <italic>Morphosis</italic>, an installation
  featuring three spheroid robots that learn in real-time using
  reinforcement learning
  (<xref alt="Audry et al., 2020" rid="ref-Audry2020-Behaviour" ref-type="bibr">Audry
  et al., 2020</xref>;
  <xref alt="Audry, 2023" rid="ref-Audry2023-Choreomata" ref-type="bibr">Audry,
  2023</xref>). These examples illustrate the framework’s role not only
  as a technical tool but also as a catalyst for interdisciplinary
  research.</p>
</sec>
<sec id="functionality-and-design-overview">
  <title>Functionality and Design Overview</title>
  <p>The core of <italic>Plaquette</italic> is organized around two
  interdependent abstractions called <italic>units</italic> and
  <italic>engines</italic> that provide a coherent structure for
  building complex, real-time interactive systems on microcontrollers.
  <italic>Units</italic> are modular building blocks that encapsulate
  behaviors such as sensing, generating, filtering, or actuating.
  <italic>Engines</italic> operate as conductors, managing
  initialization and timing of units so that they execute consistently
  without blocking or interruptions.</p>
  <p>All units implement a unified interface consisting of a single
  input and a single output function. This design makes it possible to
  chain units together in a dataflow-like manner using a special
  operator (<monospace>&gt;&gt;</monospace>), where the output of one
  unit is sent as input to another. This signal-centric approach allows
  developers to work with flows of information rather than low-level
  procedural code.</p>
  <p>The framework includes a set of core unit types:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Base units</bold>: basic analog and binary inputs and
      outputs</p>
    </list-item>
    <list-item>
      <p><bold>Generators</bold>: generative source signals such as
      square, triangle, and sine waves, as well as ramps</p>
    </list-item>
    <list-item>
      <p><bold>Timing units</bold>: scheduling and temporal control
      units such as timers and metronomes</p>
    </list-item>
    <list-item>
      <p><bold>Filters</bold>: real-time signal transformations such as
      min-max scaling, normalizing, and detecting peaks</p>
    </list-item>
    <list-item>
      <p><bold>Fields</bold>: spatial functions sampled at fractional
      positions to plot, shape, or transform signals across space</p>
    </list-item>
  </list>
  <p>Engines and units have a low memory footprint, with static
  allocation at compile time that prevents dynamic allocation and
  fragmentation. In particular, signal-processing units such as min-max
  scaling and normalization use exponential moving averages rather than
  circular buffers, ensuring low and predictable memory usage.</p>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>The following program chains an analog input through a min-max
  scaling filter to bring it to full range, then uses the input value to
  influence the period of oscillation of an LED using a sine wave.</p>
  <code language="c++">  #include &lt;Plaquette.h&gt;

  AnalogIn input{A0};        // analog input on pin A0
  AnalogOut led{9};          // PWM-controlled LED on pin 9
  MinMaxScaler scaler{};     // min-max scaler
  Wave oscillator{SINE};     // sine wave

  void begin() {}

  void step() {
    input &gt;&gt; scaler;         // rescale input to full range [0, 1]
    oscillator.period(scaler.mapTo(1, 10)); // set period from 1 to 10 seconds
    oscillator &gt;&gt; led;       // send oscillator value to LED
  }</code>
  <p>This program reacts to peaks in the incoming signal by triggering a
  sudden movement (ramp) in a servo motor. The peak detector triggers in
  response to outliers after signal normalization, using an event
  callback to start the ramp. The normalization is calibrated over a
  sliding time window, smoothly re-calibrating itself in response to
  changes in the input signal over time.</p>
  <code language="c++">  #include &lt;Plaquette.h&gt;

  AnalogIn input{A0};            // analog input on pin A0
  ServoOut servo{9};             // servomotor connected on pin 9
  Normalizer normalizer{0, 1};   // normalizes to N(0, 1)
  PeakDetector peak{1.5};        // detects outliers at 1.5 times stddev
  Ramp ramp{2.0};                // ramp with 2 seconds duration

  void begin() {
    normalizer.timeWindow(60);   // 60 seconds calibration sliding time window
    peak.onBang([](){ ramp.start(); }); // on peak detection: restart ramp
  }

  void step() {
    input &gt;&gt; normalizer &gt;&gt; peak; // chain-process input signal
    ramp &gt;&gt; servo;               // send ramp value to servo motor
  }</code>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was partially supported by the Natural Sciences and
  Engineering Research Council of Canada, the Social Sciences and
  Humanities Research Council of Canada, the Fonds de Recherche du
  Québec — Société et Culture, the Canada Council for the Arts, MITACS,
  and the Society for Arts and Technology. We thank our collaborators
  and colleagues for supporting the project, in particular Luana
  Belinsky, Marianne Fournier, Erin Gee, Matthew Loewen, and Chris
  Salter.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Audry2020-Behaviour">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Audry</surname><given-names>Sofian</given-names></name>
        <name><surname>Dumont-Gagné</surname><given-names>Rosalie</given-names></name>
        <name><surname>Scurto</surname><given-names>Hugo</given-names></name>
      </person-group>
      <article-title>Behaviour aesthetics of reinforcement learning in a robotic art installation</article-title>
      <source>4th NeurIPS workshop on machine learning for creativity and design</source>
      <publisher-loc>Vancouver, Canada</publisher-loc>
      <year iso-8601-date="2020-12">2020</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2021-01-29">2021</year><month>01</month><day>29</day></date-in-citation>
      <uri>https://hal.archives-ouvertes.fr/hal-03100907</uri>
    </element-citation>
  </ref>
  <ref id="ref-Audry2023-Choreomata">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Audry</surname><given-names>Sofian</given-names></name>
      </person-group>
      <article-title>Choreomata</article-title>
      <source>Choreomata</source>
      <publisher-name>Chapman and Hall/CRC</publisher-name>
      <publisher-loc>Boca Raton</publisher-loc>
      <year iso-8601-date="2023-12-04">2023</year><month>12</month><day>04</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-10-01">2025</year><month>10</month><day>01</day></date-in-citation>
      <edition>1</edition>
      <isbn>978-1-003-31233-8</isbn>
      <uri>https://www.taylorfrancis.com/books/9781003312338/chapters/10.1201/9781003312338-16</uri>
      <pub-id pub-id-type="doi">10.1201/9781003312338-16</pub-id>
      <fpage>283</fpage>
      <lpage>307</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Banzi2022-Getting">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Banzi</surname><given-names>Massimo</given-names></name>
        <name><surname>Shiloh</surname><given-names>Michael</given-names></name>
      </person-group>
      <source>Getting started with Arduino: The open source electronics prototyping platform</source>
      <publisher-name>Make Community, LLC</publisher-name>
      <publisher-loc>Sebastopol</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <isbn>978-1-68045-693-6</isbn>
    </element-citation>
  </ref>
  <ref id="ref-Bianchini2015-Misbehavioral">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Bianchini</surname><given-names>Samuel</given-names></name>
        <name><surname>Bourganel</surname><given-names>Rémy</given-names></name>
        <name><surname>Quinz</surname><given-names>Emanuele</given-names></name>
        <name><surname>Levillain</surname><given-names>Florent</given-names></name>
        <name><surname>Zibetti</surname><given-names>Elisabetta</given-names></name>
      </person-group>
      <article-title>MisBehavioral objects</article-title>
      <source>Empowering users through design: Interdisciplinary studies and combined approaches for technological products and services</source>
      <person-group person-group-type="editor">
        <name><surname>Bihanic</surname><given-names>David</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2015">2015</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-09-26">2025</year><month>09</month><day>26</day></date-in-citation>
      <isbn>978-3-319-13018-7</isbn>
      <uri>https://doi.org/10.1007/978-3-319-13018-7_8</uri>
      <pub-id pub-id-type="doi">10.1007/978-3-319-13018-7_8</pub-id>
      <fpage>129</fpage>
      <lpage>152</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Candy2018-PracticeBased">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Candy</surname><given-names>Linda</given-names></name>
        <name><surname>Edmonds</surname><given-names>Ernest</given-names></name>
      </person-group>
      <article-title>Practice-based research in the creative arts: Foundations and futures from the front line</article-title>
      <source>Leonardo</source>
      <publisher-name>[Leonardo, The MIT Press]</publisher-name>
      <year iso-8601-date="2018-02">2018</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-10-01">2025</year><month>10</month><day>01</day></date-in-citation>
      <volume>51</volume>
      <issue>1, 1</issue>
      <issn>0024-094X</issn>
      <uri>https://direct.mit.edu/leon/article/51/1/63-69/46472</uri>
      <pub-id pub-id-type="doi">10.1162/LEON_a_01471</pub-id>
      <fpage>63</fpage>
      <lpage>69</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Gee2023-BioSynth">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gee</surname><given-names>Erin M.</given-names></name>
      </person-group>
      <article-title>The BioSynth—an affective biofeedback device grounded in feminist thought</article-title>
      <year iso-8601-date="2023">2023</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-09-07">2025</year><month>09</month><day>07</day></date-in-citation>
      <issn>2220-4806</issn>
      <uri>https://www.nime.org/proc/nime2023_66/index.html</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.11189254</pub-id>
      <fpage>479</fpage>
      <lpage>485</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hagler2022-Flexible">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hagler</surname><given-names>Jo’Elen</given-names></name>
        <name><surname>Kim</surname><given-names>ChiHyeong</given-names></name>
        <name><surname>Kateb</surname><given-names>Pierre</given-names></name>
        <name><surname>Yeu</surname><given-names>JeeYeon</given-names></name>
        <name><surname>Gagnon-Lafrenais</surname><given-names>Noémy</given-names></name>
        <name><surname>Gee</surname><given-names>Erin</given-names></name>
        <name><surname>Audry</surname><given-names>Sofian</given-names></name>
        <name><surname>Cicoira</surname><given-names>Fabio</given-names></name>
      </person-group>
      <article-title>Flexible and stretchable printed conducting polymer devices for electrodermal activity measurements</article-title>
      <source>Flexible and Printed Electronics</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2022-02">2022</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-08-14">2022</year><month>08</month><day>14</day></date-in-citation>
      <volume>7</volume>
      <issue>1</issue>
      <issn>2058-8585</issn>
      <uri>https://doi.org/10.1088/2058-8585/ac4d0f</uri>
      <pub-id pub-id-type="doi">10.1088/2058-8585/ac4d0f</pub-id>
      <fpage>014008</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Loveless2019-How">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Loveless</surname><given-names>Natalie</given-names></name>
      </person-group>
      <source>How to make art at the end of the world: A manifesto for research-creation</source>
      <publisher-name>Duke University Press</publisher-name>
      <publisher-loc>Durham</publisher-loc>
      <year iso-8601-date="2019">2019</year>
      <isbn>978-1-4780-0464-6</isbn>
      <pub-id pub-id-type="doi">10.1215/9781478004646</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
