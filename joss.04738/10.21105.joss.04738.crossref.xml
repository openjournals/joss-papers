<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20221111T112523-ee7149a13bd8658dc7861a333b29c535b1b7f5c7</doi_batch_id>
    <timestamp>20221111112523</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>11</month>
          <year>2022</year>
        </publication_date>
        <journal_volume>
          <volume>7</volume>
        </journal_volume>
        <issue>79</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>py2lispIDyOM: A Python package for the information
dynamics of music (IDyOM) model</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Xinyi</given_name>
            <surname>Guan</surname>
            <ORCID>https://orcid.org/0000-0002-4570-906X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Zeng</given_name>
            <surname>Ren</surname>
            <ORCID>https://orcid.org/0000-0002-9097-2633</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Claire</given_name>
            <surname>Pelofi</surname>
            <ORCID>https://orcid.org/0000-0001-5960-8174</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>11</month>
          <day>11</day>
          <year>2022</year>
        </publication_date>
        <pages>
          <first_page>4738</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.04738</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.7272236</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/4738</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.04738</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.04738</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.04738.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="PearceWiggins2006">
            <article_title>Expectation in melody: The influence of
context and learning</article_title>
            <author>Pearce</author>
            <journal_title>Music Perception</journal_title>
            <issue>5</issue>
            <volume>23</volume>
            <doi>10.1525/mp.2006.23.5.377</doi>
            <cYear>2006</cYear>
            <unstructured_citation>Pearce, M. T., &amp; Wiggins, G. A.
(2006). Expectation in melody: The influence of context and learning.
Music Perception, 23(5), 377–405.
https://doi.org/10.1525/mp.2006.23.5.377</unstructured_citation>
          </citation>
          <citation key="Margulis2005">
            <article_title>A model of melodic
expectation</article_title>
            <author>Margulis</author>
            <journal_title>Music Perception</journal_title>
            <issue>4</issue>
            <volume>22</volume>
            <doi>10.1525/mp.2005.22.4.663</doi>
            <cYear>2005</cYear>
            <unstructured_citation>Margulis, E. H. (2005). A model of
melodic expectation. Music Perception, 22(4), 663–714.
https://doi.org/10.1525/mp.2005.22.4.663</unstructured_citation>
          </citation>
          <citation key="Morgan2019">
            <article_title>Statistical learning and gestalt-like
principles predict melodic expectations</article_title>
            <author>Morgan</author>
            <journal_title>Cognition</journal_title>
            <volume>189</volume>
            <doi>10.1016/j.cognition.2018.12.015</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Morgan, E., Fogel, A., Nair, A.,
&amp; Patel, A. D. (2019). Statistical learning and gestalt-like
principles predict melodic expectations. Cognition, 189, 23–34.
https://doi.org/10.1016/j.cognition.2018.12.015</unstructured_citation>
          </citation>
          <citation key="Bigand2006">
            <article_title>Are we “experienced listeners”? A review of
the musical capacities that do not depend on formal musical
training</article_title>
            <author>Bigand</author>
            <journal_title>Cognition</journal_title>
            <issue>1</issue>
            <volume>100</volume>
            <doi>10.1016/j.cognition.2005.11.007</doi>
            <cYear>2006</cYear>
            <unstructured_citation>Bigand, E., &amp; Poulin-Charronnat,
B. (2006). Are we “experienced listeners”? A review of the musical
capacities that do not depend on formal musical training. Cognition,
100(1), 100–130.
https://doi.org/10.1016/j.cognition.2005.11.007</unstructured_citation>
          </citation>
          <citation key="Eerola2009">
            <article_title>Expectancy in sami yoiks revisited: The role
of data-driven and schema-driven knowledge in the formation of melodic
expectations</article_title>
            <author>Eerola</author>
            <journal_title>Musicae Scientiae</journal_title>
            <issue>2</issue>
            <volume>13</volume>
            <doi>10.1177/102986490901300203</doi>
            <cYear>2009</cYear>
            <unstructured_citation>Eerola, T., Louhivuori, J., &amp;
Lebaka, E. (2009). Expectancy in sami yoiks revisited: The role of
data-driven and schema-driven knowledge in the formation of melodic
expectations. Musicae Scientiae, 13(2), 231–272.
https://doi.org/10.1177/102986490901300203</unstructured_citation>
          </citation>
          <citation key="Rohrmeier2011">
            <article_title>Incidental and online learning of melodic
structure</article_title>
            <author>Rohrmeier</author>
            <journal_title>Consciousness and cognition</journal_title>
            <issue>2</issue>
            <volume>20</volume>
            <doi>10.1016/j.concog.2010.07.004</doi>
            <cYear>2011</cYear>
            <unstructured_citation>Rohrmeier, M., Rebuschat, P., &amp;
Cross, I. (2011). Incidental and online learning of melodic structure.
Consciousness and Cognition, 20(2), 214–222.
https://doi.org/10.1016/j.concog.2010.07.004</unstructured_citation>
          </citation>
          <citation key="PearceWiggins2012">
            <article_title>Auditory expectation: The information
dynamics of music perception and cognition</article_title>
            <author>Pearce</author>
            <journal_title>Topics in cognitive science</journal_title>
            <issue>4</issue>
            <volume>4</volume>
            <doi>10.1111/j.1756-8765.2012.01214.x</doi>
            <cYear>2012</cYear>
            <unstructured_citation>Pearce, M. T., &amp; Wiggins, G. A.
(2012). Auditory expectation: The information dynamics of music
perception and cognition. Topics in Cognitive Science, 4(4), 625–652.
https://doi.org/10.1111/j.1756-8765.2012.01214.x</unstructured_citation>
          </citation>
          <citation key="Di2020">
            <article_title>Cortical encoding of melodic expectations in
human temporal cortex</article_title>
            <author>Di Liberto</author>
            <journal_title>Elife</journal_title>
            <volume>9</volume>
            <doi>10.7554/eLife.51784</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Di Liberto, G. M., Pelofi, C.,
Bianco, R., Patel, P., Mehta, A. D., Herrero, J. L., Cheveigné, A. de,
Shamma, S., &amp; Mesgarani, N. (2020). Cortical encoding of melodic
expectations in human temporal cortex. Elife, 9, e51784.
https://doi.org/10.7554/eLife.51784</unstructured_citation>
          </citation>
          <citation key="Politimou2021">
            <article_title>Melodic expectations in 5-and 6-year-old
children</article_title>
            <author>Politimou</author>
            <journal_title>Journal of Experimental Child
Psychology</journal_title>
            <volume>203</volume>
            <doi>10.1016/j.jecp.2020.105020</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Politimou, N., Douglass-Kirk, P.,
Pearce, M., Stewart, L., &amp; Franco, F. (2021). Melodic expectations
in 5-and 6-year-old children. Journal of Experimental Child Psychology,
203, 105020.
https://doi.org/10.1016/j.jecp.2020.105020</unstructured_citation>
          </citation>
          <citation key="Pearce2005">
            <article_title>The construction and evaluation of
statistical models of melodic structure in music perception and
composition</article_title>
            <author>Pearce</author>
            <cYear>2005</cYear>
            <unstructured_citation>Pearce, M. T. (2005). The
construction and evaluation of statistical models of melodic structure
in music perception and composition [PhD thesis, City University
London].
https://openaccess.city.ac.uk/id/eprint/8459/</unstructured_citation>
          </citation>
          <citation key="Pearce2018">
            <article_title>Statistical learning and probabilistic
prediction in music cognition: Mechanisms of stylistic
enculturation</article_title>
            <author>Pearce</author>
            <journal_title>Annals of the New York Academy of
Sciences</journal_title>
            <issue>1</issue>
            <volume>1423</volume>
            <doi>10.1111/nyas.13654</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Pearce, M. T. (2018). Statistical
learning and probabilistic prediction in music cognition: Mechanisms of
stylistic enculturation. Annals of the New York Academy of Sciences,
1423(1), 378–395.
https://doi.org/10.1111/nyas.13654</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
