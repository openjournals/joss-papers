<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6873</article-id>
<article-id pub-id-type="doi">10.21105/joss.06873</article-id>
<title-group>
<article-title>ICAT: The Interactive Corpus Analysis
Tool</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5036-5433</contrib-id>
<name>
<surname>Martindale</surname>
<given-names>Nathan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4320-5818</contrib-id>
<name>
<surname>Stewart</surname>
<given-names>Scott L.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Oak Ridge National Laboratory</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-11-01">
<day>1</day>
<month>11</month>
<year>2023</year>
</pub-date>
<volume>10</volume>
<issue>110</issue>
<fpage>6873</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Machine Learning</kwd>
<kwd>HCI</kwd>
<kwd>Visual Analytics</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The Interactive Corpus Analysis Tool (ICAT) is a Python library for
  creating dashboards to explore textual datasets and build simple
  binary classification models to help filter through them and focus on
  entries of interest. This tool uses a form of interactive machine
  learning (IML), a paradigm of “machine teaching”
  (<xref alt="Simard et al., 2017" rid="ref-simardMachineTeachingNew2017" ref-type="bibr">Simard
  et al., 2017</xref>) that sits at the intersection of the fields of
  human computer interaction (HCI), visual analytics, and machine
  learning. The intent of ICAT is to allow subject matter experts (SME)
  with limited to no experience in machine learning to benefit from an
  iterative human-in-the-loop (HITL) approach to building their own
  model without needing to understand the details of the underlying
  algorithm. This interactivity is achieved by allowing the user to
  create features, label data points, and visually manipulate a
  representation of the features to manually cluster and investigate
  data, while a model is trained on the fly based on these actions. ICAT
  is built on top of the Panel
  (<xref alt="Holoviz, 2018" rid="ref-panelholoviz" ref-type="bibr">Holoviz,
  2018</xref>) library, using a combination of Vega, a custom IPyWidget
  using D3, and ipyvuetify, and is intended to be used inside of a
  Jupyter environment.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Machine teaching promises to democratize machine learning
  algorithms and grant non-machine-learning experts the ability to
  train, manipulate, and work with models themselves
  (<xref alt="Simard et al., 2017" rid="ref-simardMachineTeachingNew2017" ref-type="bibr">Simard
  et al., 2017</xref>). Traditionally, the process for an SME to obtain
  a model that aids in their data analysis is a time consuming iterative
  loop: they must first communicate their problem space and data to a
  machine learning expert, who experiments and trains a model for the
  SME, who then tests it and finds any issues or insufficiently learned
  concepts, which must then be communicated back to the ML expert, and
  the iterative loop continues as such. Ideally, an effective HITL
  training process involves the SME more directly in the training
  process, dramatically speeding up this iteration loop and benefiting
  from the SME’s implicit knowledge and experience. IML seeks to provide
  this process through mechanisms such as feature selection (interactive
  featuring) and model steering (interactive labeling)
  (<xref alt="Dudley &amp; Kristensson, 2018" rid="ref-dudleyReviewUserInterface2018" ref-type="bibr">Dudley
  &amp; Kristensson, 2018</xref>).</p>
  <p>This is a challenging space for a number of reasons. The efficacy
  of an IML system heavily revolves around the design of the interface
  itself, in addition to the underlying machine learning models and the
  many considerations they entail. Thus, incorporating effective user
  experience design principles and understanding the mental models of
  the users as they explore and use the interface is crucial. Both
  quantitative and qualitative metrics must include the human element,
  so any research seeking to demonstrate a measured value-add or
  efficacy of an IML interface must incorporate user studies
  (<xref alt="Lai et al., 2023" rid="ref-laiScienceHumanAIDecision2023" ref-type="bibr">Lai
  et al., 2023</xref>). A positive user experience additionally
  constrains algorithmic design in terms of speed and efficiency–an
  underlying model that takes minutes to train is frustrating to
  interact with
  (<xref alt="Fails &amp; Olsen, 2003" rid="ref-failsInteractiveMachineLearning" ref-type="bibr">Fails
  &amp; Olsen, 2003</xref>). Care must be taken not to treat the user
  like a mechanical turk or mindless oracle for the model to endlessly
  query Cakmak et al.
  (<xref alt="2010" rid="ref-cakmakDesigningInteractionsRobot2010" ref-type="bibr">2010</xref>).</p>
  <p>Despite these challenges, there is tremendous potential for IML to
  empower SMEs and allow them to benefit from the value of machine
  learning in their work. For the field to grow and realize this
  potential, a great deal more research and work are required. Our work
  draws heavily on the IML interface concepts proposed by Suh et al.
  (<xref alt="2019" rid="ref-suhAnchorVizFacilitatingSemantic2019" ref-type="bibr">2019</xref>),
  and as of this writing there is no other open source package
  implementing their visuals or overall interface. ICAT seeks to fill
  this gap to allow other researchers to explore, build on, and compare
  against the concepts discussed below to further the state of the
  field.</p>
</sec>
<sec id="interface-concepts">
  <title>Interface Concepts</title>
  <p>The ICAT workflow trains a simple binary classification model to
  separate “uninteresting” from “interesting” entries in an initially
  unlabeled dataset. “Interesting” here is intentionally vague to refer
  to whatever classification signal a user is implicitly or explicitly
  attempting to extract. The primary use case for this is for ICAT to
  help filter a large collection of text objects to some smaller target
  subset of interest that is easier to manually review.</p>
  <p>ICAT implements both interactive featuring and interactive
  labeling. Interactive featuring allows the user to create or influence
  the feature columns that the underlying model uses for training and
  predicting. In ICAT this is done through “concept anchors,” or
  functions that return some value, nominally between 0 and 1, to
  represent a strength or “pull” on a provided input. An example anchor
  type included with ICAT is a dictionary or keyword anchor, where the
  feature value is a bag of words or count of the number of occurences
  of each keyword the user provides to that anchor. Interactive labeling
  is done by allowing the user to manually specify or change a label
  (uninteresting or interesting) for any text entry. All labeled rows
  are used as the training dataset for the underlying model. Once the
  model is “seeded,” or given some minimum number of labels to train on,
  it begins to predict on the full dataset, and the visualizations in
  the dashboard are colored to reflect the interesting/uninteresting
  prediction for each entry.</p>
  <p>Anchors are visualized with the AnchorViz ring
  (<xref alt="Suh et al., 2019" rid="ref-suhAnchorVizFacilitatingSemantic2019" ref-type="bibr">Suh
  et al., 2019</xref>), which are shown below in
  <xref alt="[fig:dashboard]" rid="figU003Adashboard">[fig:dashboard]</xref>(a).
  The visual representation of anchors are draggable points around the
  circumference of the ring, with the entries from a sample of the data
  rendered as the smaller points inside. Anchors pull points toward them
  based on the strength of influence or the magnitude of the feature
  value on each point. As the user drags the anchors around, the
  associated points then similarly move according to these varying
  attraction strengths, and this helps visually determine the overlap
  between anchors and which points are or are not represented well by
  the current feature set. This ability to manually position the anchors
  and their correpsonding points allows for various strategies for
  manually clustering the data, such as using anchors to pull away any
  distractors or known incorrect keywords from the interesting set, and
  so on.</p>
  <fig>
    <caption><p>An example of a rendered dashboard from ICAT. Throughout
    the dashboard, blue points and text indicate uninteresting, orange
    indicate interesting. (a) The AnchorViz ring. (b) The data manager,
    explorer, and labeling tool. (c) The anchor list/feature editing
    section.<styled-content id="figU003Adashboard"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="icat_labeled.png" />
  </fig>
  <p>The dashboard also includes a data manager, shown in
  <xref alt="[fig:dashboard]" rid="figU003Adashboard">[fig:dashboard]</xref>(b),
  with tables containing various subsets of the data to make it easier
  to scroll through and explore the text. The data tabs have five
  filters that can be applied to the data. These include showing only
  the current sample of points in the AnchorViz display, showing all
  points that have been labeled, showing all points the model has
  predicted are interesting, or showing the result of the user
  lasso-selecting arbitrary points in the visualization. The tables also
  include a set of actions per row, allowing the user to apply labels to
  the points, create example anchors (by default adding a new
  <monospace>TFIDFAnchor</monospace> with the chosen row as the
  similarity target), and add them to the current sample if they are not
  already included.</p>
  <p>Below the AnchorViz ring is the anchor list, shown in
  <xref alt="[fig:dashboard]" rid="figU003Adashboard">[fig:dashboard]</xref>(c).
  The anchor list contains all of the current anchors, statistics about
  the number of points they cover and their classification breakdown,
  and the associated controls for modifying their parameters. Every
  anchor type can have a customized set of controls to display when a
  corresponding anchor row is expanded in the anchor list. This can
  consist of any combination of ipyvuetify
  (<xref alt="Widgetti, 2019" rid="ref-ipyvuetify" ref-type="bibr">Widgetti,
  2019</xref>) elements stored in the <monospace>.widget</monospace>
  instance of the anchor. An anchor type is effectively a wrapper around
  a function that computes a feature value, and ICAT can support
  dynamically adding new anchor types to the interface for any class
  inheriting from <monospace>icat.anchors.Anchor</monospace>.</p>
  <p>As discussed earlier, an important concept for a tool that trains a
  model on the fly based on user interaction is to respond and train
  quickly
  (<xref alt="Fails &amp; Olsen, 2003" rid="ref-failsInteractiveMachineLearning" ref-type="bibr">Fails
  &amp; Olsen, 2003</xref>). <italic>Interactive featuring</italic>
  means that a single user action could change the feature values for
  the entire training dataset, which requires retraining the underlying
  model from scratch. Since all features and labels are user provided,
  the overall volume and necessary complexity is relatively low, and by
  default ICAT uses scikit-learn’s
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikit-learn" ref-type="bibr">Pedregosa
  et al., 2011</xref>) logistic regression algorithm. This results in a
  training time of a few seconds on most modern laptop hardware with
  datasets smaller than 50,000 entries when using the default anchor
  types that come with ICAT.</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>The authors would like to acknowledge the US Department of Energy,
  National Nuclear Security Administration’s Office of Defense Nuclear
  Nonproliferation Research and Development (NA-22) for supporting this
  work.</p>
  <p>This manuscript has been authored by UT-Battelle, LLC, under
  contract DE-AC05-00OR22725 with the US Department of Energy (DOE). The
  US government retains and the publisher, by accepting the article for
  publication, acknowledges that the US government retains a
  nonexclusive, paid-up, irrevocable, worldwide license to publish or
  reproduce the published form of this manuscript, or allow others to do
  so, for US government purposes. DOE will provide public access to
  these results of federally sponsored research in accordance with the
  DOE Public Access Plan
  (<ext-link ext-link-type="uri" xlink:href="http://energy.gov/downloads/doe-public-access-plan">http://energy.gov/downloads/doe-public-access-plan</ext-link>).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-simardMachineTeachingNew2017">
    <element-citation publication-type="manuscript">
      <person-group person-group-type="author">
        <name><surname>Simard</surname><given-names>Patrice Y.</given-names></name>
        <name><surname>Amershi</surname><given-names>Saleema</given-names></name>
        <name><surname>Chickering</surname><given-names>David M.</given-names></name>
        <name><surname>Pelton</surname><given-names>Alicia Edelman</given-names></name>
        <name><surname>Ghorashi</surname><given-names>Soroush</given-names></name>
        <name><surname>Meek</surname><given-names>Christopher</given-names></name>
        <name><surname>Ramos</surname><given-names>Gonzalo</given-names></name>
        <name><surname>Suh</surname><given-names>Jina</given-names></name>
        <name><surname>Verwey</surname><given-names>Johan</given-names></name>
        <name><surname>Wang</surname><given-names>Mo</given-names></name>
        <name><surname>Wernsing</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Machine Teaching: A New Paradigm for Building Machine Learning Systems</article-title>
      <year iso-8601-date="2017-08-10">2017</year><month>08</month><day>10</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-04-13">2022</year><month>04</month><day>13</day></date-in-citation>
      <uri>http://arxiv.org/abs/1707.06742</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1707.06742</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dudleyReviewUserInterface2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dudley</surname><given-names>John J.</given-names></name>
        <name><surname>Kristensson</surname><given-names>Per Ola</given-names></name>
      </person-group>
      <article-title>A Review of User Interface Design for Interactive Machine Learning</article-title>
      <source>ACM Transactions on Interactive Intelligent Systems</source>
      <year iso-8601-date="2018-06-13">2018</year><month>06</month><day>13</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-04-14">2022</year><month>04</month><day>14</day></date-in-citation>
      <volume>8</volume>
      <issue>2</issue>
      <issn>2160-6455</issn>
      <uri>https://doi.org/10.1145/3185517</uri>
      <pub-id pub-id-type="doi">10.1145/3185517</pub-id>
      <fpage>8:1</fpage>
      <lpage>8:37</lpage>
    </element-citation>
  </ref>
  <ref id="ref-laiScienceHumanAIDecision2023">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lai</surname><given-names>Vivian</given-names></name>
        <name><surname>Chen</surname><given-names>Chacha</given-names></name>
        <name><surname>Smith-Renner</surname><given-names>Alison</given-names></name>
        <name><surname>Liao</surname><given-names>Q. Vera</given-names></name>
        <name><surname>Tan</surname><given-names>Chenhao</given-names></name>
      </person-group>
      <article-title>Towards a Science of Human-AI Decision Making: An Overview of Design Space in Empirical Human-Subject Studies</article-title>
      <source>2023 ACM Conference on Fairness, Accountability, and Transparency</source>
      <publisher-name>ACM</publisher-name>
      <publisher-loc>Chicago IL USA</publisher-loc>
      <year iso-8601-date="2023-06-12">2023</year><month>06</month><day>12</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-06-22">2023</year><month>06</month><day>22</day></date-in-citation>
      <isbn>9798400701924</isbn>
      <uri>https://dl.acm.org/doi/10.1145/3593013.3594087</uri>
      <pub-id pub-id-type="doi">10.1145/3593013.3594087</pub-id>
      <fpage>1369</fpage>
      <lpage>1385</lpage>
    </element-citation>
  </ref>
  <ref id="ref-amershiPowerPeopleRole2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Amershi</surname><given-names>Saleema</given-names></name>
        <name><surname>Cakmak</surname><given-names>Maya</given-names></name>
        <name><surname>Knox</surname><given-names>William Bradley</given-names></name>
        <name><surname>Kulesza</surname><given-names>Todd</given-names></name>
      </person-group>
      <article-title>Power to the People: The Role of Humans in Interactive Machine Learning</article-title>
      <source>AI Magazine</source>
      <year iso-8601-date="2014-12-22">2014</year><month>12</month><day>22</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-04-14">2022</year><month>04</month><day>14</day></date-in-citation>
      <volume>35</volume>
      <issue>4, 4</issue>
      <issn>2371-9621</issn>
      <uri>https://ojs.aaai.org/index.php/aimagazine/article/view/2513</uri>
      <pub-id pub-id-type="doi">10.1609/aimag.v35i4.2513</pub-id>
      <fpage>105</fpage>
      <lpage>120</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cakmakDesigningInteractionsRobot2010">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cakmak</surname><given-names>Maya</given-names></name>
        <name><surname>Chao</surname><given-names>Crystal</given-names></name>
        <name><surname>Thomaz</surname><given-names>Andrea L.</given-names></name>
      </person-group>
      <article-title>Designing Interactions for Robot Active Learners</article-title>
      <source>IEEE Transactions on Autonomous Mental Development</source>
      <year iso-8601-date="2010-06">2010</year><month>06</month>
      <volume>2</volume>
      <issue>2</issue>
      <issn>1943-0612</issn>
      <pub-id pub-id-type="doi">10.1109/TAMD.2010.2051030</pub-id>
      <fpage>108</fpage>
      <lpage>118</lpage>
    </element-citation>
  </ref>
  <ref id="ref-suhAnchorVizFacilitatingSemantic2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Suh</surname><given-names>Jina</given-names></name>
        <name><surname>Ghorashi</surname><given-names>Soroush</given-names></name>
        <name><surname>Ramos</surname><given-names>Gonzalo</given-names></name>
        <name><surname>Chen</surname><given-names>Nan-Chen</given-names></name>
        <name><surname>Drucker</surname><given-names>Steven</given-names></name>
        <name><surname>Verwey</surname><given-names>Johan</given-names></name>
        <name><surname>Simard</surname><given-names>Patrice</given-names></name>
      </person-group>
      <article-title>AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning</article-title>
      <source>ACM Transactions on Interactive Intelligent Systems</source>
      <year iso-8601-date="2019-08-09">2019</year><month>08</month><day>09</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-04-13">2022</year><month>04</month><day>13</day></date-in-citation>
      <volume>10</volume>
      <issue>1</issue>
      <issn>2160-6455</issn>
      <uri>https://doi.org/10.1145/3241379</uri>
      <pub-id pub-id-type="doi">10.1145/3241379</pub-id>
      <fpage>7:1</fpage>
      <lpage>7:38</lpage>
    </element-citation>
  </ref>
  <ref id="ref-panelholoviz">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Holoviz</surname></name>
      </person-group>
      <article-title>Panel: The powerful data exploration &amp; web app framework for python</article-title>
      <publisher-name>https://panel.holoviz.org/</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.3706648</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ipyvuetify">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Widgetti</surname></name>
      </person-group>
      <article-title>Ipyvuetify: Jupyter widgets based on vuetify UI components</article-title>
      <publisher-name>https://github.com/widgetti/ipyvuetify</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-scikit-learn">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
        <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
        <name><surname>Gramfort</surname><given-names>A.</given-names></name>
        <name><surname>Michel</surname><given-names>V.</given-names></name>
        <name><surname>Thirion</surname><given-names>B.</given-names></name>
        <name><surname>Grisel</surname><given-names>O.</given-names></name>
        <name><surname>Blondel</surname><given-names>M.</given-names></name>
        <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
        <name><surname>Weiss</surname><given-names>R.</given-names></name>
        <name><surname>Dubourg</surname><given-names>V.</given-names></name>
        <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
        <name><surname>Passos</surname><given-names>A.</given-names></name>
        <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
        <name><surname>Brucher</surname><given-names>M.</given-names></name>
        <name><surname>Perrot</surname><given-names>M.</given-names></name>
        <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
      </person-group>
      <article-title>Scikit-learn: Machine learning in Python</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2011">2011</year>
      <volume>12</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1201.0490</pub-id>
      <fpage>2825</fpage>
      <lpage>2830</lpage>
    </element-citation>
  </ref>
  <ref id="ref-failsInteractiveMachineLearning">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Fails</surname><given-names>Jerry Alan</given-names></name>
        <name><surname>Olsen</surname><given-names>Dan R.</given-names></name>
      </person-group>
      <article-title>Interactive machine learning</article-title>
      <source>Proceedings of the 8th international conference on intelligent user interfaces</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2003">2003</year>
      <isbn>1581135866</isbn>
      <uri>https://doi.org/10.1145/604045.604056</uri>
      <pub-id pub-id-type="doi">10.1145/604045.604056</pub-id>
      <fpage>39</fpage>
      <lpage>45</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
