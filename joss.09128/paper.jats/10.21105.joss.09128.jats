<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9128</article-id>
<article-id pub-id-type="doi">10.21105/joss.09128</article-id>
<title-group>
<article-title>Shekar: A Python Toolkit for Persian Natural Language
Processing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3741-3979</contrib-id>
<name>
<surname>Amirivojdan</surname>
<given-names>Ahmad</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University of Tennessee, Knoxville, United
States</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-08-23">
<day>23</day>
<month>8</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>9128</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Natural Language Processing</kwd>
<kwd>Persian Language</kwd>
<kwd>Text Processing</kwd>
<kwd>Computational Linguistics</kwd>
<kwd>Open Source Software</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Shekar is an open-source Python toolkit for Persian natural
  language processing (NLP). It provides a modular, efficient, and
  easy-to-use framework for tasks such as text preprocessing,
  tokenization, stemming, lemmatization, part-of-speech (POS) tagging,
  named entity recognition (NER), keyword extraction, embeddings, spell
  checking, and visualization. Its composable pipeline design supports
  reproducible workflows that scale effectively from basic text
  processing to large-scale corpus analysis.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Persian natural language processing has expanded rapidly over the
  past decade, supporting applications in digital humanities, social
  media analysis, conversational systems, and language modeling.
  Accordingly, there has been substantial progress in developing tools
  for Persian language processing. Libraries such as
  <ext-link ext-link-type="uri" xlink:href="https://github.com/roshan-research/hazm">Hazm</ext-link>,
  Parsivar
  (<xref alt="Mohtaj et al., 2018" rid="ref-mohtaj2018parsivar" ref-type="bibr">Mohtaj
  et al., 2018</xref>), and DadmaTools
  (<xref alt="Jafari et al., 2025" rid="ref-jafari2025dadmatools" ref-type="bibr">Jafari
  et al., 2025</xref>) provide essential functionalities including
  normalization, tokenization, and part-of-speech tagging. While these
  tools are valuable, they often come with limitations that restrict
  flexibility, extensibility, and efficient deployment in diverse
  settings.</p>
  <p>Common challenges include:</p>
  <list list-type="bullet">
    <list-item>
      <p>Limited modularity, making it difficult to adapt components or
      extend functionality.</p>
    </list-item>
    <list-item>
      <p>Tight coupling between processing stages, which hinders the
      creation of custom workflows.</p>
    </list-item>
    <list-item>
      <p>Heavy dependencies and large transformer models that require
      GPUs or specialized hardware for reasonable performance.</p>
    </list-item>
    <list-item>
      <p>Irregular updates and delayed issue resolution, which affect
      long-term maintainability.</p>
    </list-item>
  </list>
  <p>Shekar was developed to address these challenges by offering a
  lightweight, modular, and extensible toolkit for Persian natural
  language processing. It adopts a clean and composable pipeline
  architecture, allowing users to build workflows from independently
  configurable components. This modular approach is especially effective
  for handling the complexities of Persian script, including
  inconsistent diacritics, spacing conventions, and the blend of formal
  and colloquial writing styles. It also supports practical applications
  such as OCR post-processing, social media text normalization, and data
  preparation for training language models.</p>
  <p>A key distinction of Shekar is its focus on algorithmic efficiency
  and accessibility. The toolkit combines optimized preprocessing
  algorithms with lightweight, quantized transformer models, making it
  practical for low-resource devices as well as diverse environments
  ranging from research laboratories to production systems with limited
  computational capacity.</p>
  <p>By emphasizing simplicity, performance, and modular design, Shekar
  fills a critical gap in the Persian NLP ecosystem. It offers a
  practical and user-friendly toolkit that supports both rapid
  experimentation and robust deployment across a wide range of use
  cases.</p>
</sec>
<sec id="main-components">
  <title>Main Components</title>
  <p>Shekar provides a set of key functionalities covering essential
  tasks in Persian natural language processing. Each functionality is
  implemented as an independent component that can be combined into
  customizable pipelines.</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Preprocessing</bold> Provides text normalization tools to
      handle Persian-specific challenges such as inconsistent diacritics
      and spacing rules. The normalization steps follow the orthographic
      and typographic guidelines defined by
      <ext-link ext-link-type="uri" xlink:href="https://apll.ir/">The
      Academy of Persian Language and Literature</ext-link> and include
      filters for punctuation, digits, emojis, non-Persian characters,
      and corrections for spacing and script variants.</p>
    </list-item>
    <list-item>
      <p><bold>Tokenization</bold> Offers word-level, sentence-level,
      and SentencePiece
      (<xref alt="Kudo &amp; Richardson, 2018" rid="ref-kudo2018sentencepiece" ref-type="bibr">Kudo
      &amp; Richardson, 2018</xref>) tokenizers built specifically for
      Persian text. These tokenizers use Unicode-aware rules to handle
      zero-width non-joiners, punctuation boundaries, and other
      language-specific edge cases.</p>
    </list-item>
    <list-item>
      <p><bold>Morphological Analysis</bold> Includes stemming,
      lemmatization, inflection, and verb conjugation tools. The stemmer
      applies rule-based suffix removal, while the lemmatizer combines
      vocabulary lookups with morphological rules to generate accurate
      base forms. The inflector and verb conjugator support the
      generation of correct word forms and verb tenses for diverse
      linguistic applications.</p>
    </list-item>
    <list-item>
      <p><bold>Part-of-Speech (POS) Tagging</bold> Provides lightweight
      transformer-based models for assigning POS tags to tokens using
      the
      <ext-link ext-link-type="uri" xlink:href="https://universaldependencies.org/u/pos/index.html">Universal
      Dependencies</ext-link> tagging scheme. The models are based on a
      pretrained ALBERT model
      (<xref alt="Lan et al., 2019" rid="ref-lan2019albert" ref-type="bibr">Lan
      et al., 2019</xref>) trained on the large-scale Naab corpus
      (<xref alt="Sabouri et al., 2022" rid="ref-sabouri2022naab" ref-type="bibr">Sabouri
      et al., 2022</xref>) and fine-tuned on The Persian Universal
      Dependency Treebank (PerUDT)
      (<xref alt="Rasooli et al., 2020" rid="ref-rasooli2020persian" ref-type="bibr">Rasooli
      et al., 2020</xref>) for accurate and efficient POS tagging.</p>
    </list-item>
    <list-item>
      <p><bold>Named Entity Recognition (NER)</bold> Offers models
      trained on the publicly available
      <ext-link ext-link-type="uri" xlink:href="https://github.com/Text-Mining/Persian-NER">Persian
      NER dataset</ext-link> and fine-tuned from the same pretrained
      ALBERT model used for POS tagging. These models identify entities
      such as persons, locations, organizations, and dates in Persian
      text with high accuracy.</p>
    </list-item>
    <list-item>
      <p><bold>Keyword Extraction</bold> Implements algorithms for
      identifying the most informative terms and phrases within a text.
      The default implementation uses the RAKE (Rapid Automatic Keyword
      Extraction) algorithm
      (<xref alt="Rose et al., 2010" rid="ref-rose2010automatic" ref-type="bibr">Rose
      et al., 2010</xref>) for efficient and unsupervised keyword
      extraction.</p>
    </list-item>
    <list-item>
      <p><bold>Embeddings</bold> Supports both static embeddings
      (FastText) and contextual embeddings (ALBERT-based) for
      representing words and sentences as numerical vectors.</p>
    </list-item>
    <list-item>
      <p><bold>Sentiment and Toxicity Detection</bold> The Sentiment
      Analysis module features an ALBERT-based transformer model trained
      on the Snapfood dataset
      (<xref alt="Farahani et al., 2021" rid="ref-farahani2021parsbert" ref-type="bibr">Farahani
      et al., 2021</xref>) to classify Persian text as positive or
      negative. The Toxicity Detection module includes an offensive
      language classifier based on Logistic Regression trained on
      character-level TF-IDF features using the Naseza dataset
      (<xref alt="Amirivojdan, 2025" rid="ref-amirivojdan_2025_naseza" ref-type="bibr">Amirivojdan,
      2025</xref>). Together, they provide efficient and accurate tools
      for sentiment understanding and content moderation in Persian
      text.</p>
    </list-item>
    <list-item>
      <p><bold>Spell Checking</bold> Identifies and corrects common
      spelling errors and spacing mistakes in Persian text. The spell
      checker uses a frequency-based approach built on a combined
      dictionary constructed from Persian generative lexicon dataset
      (<xref alt="Eslami et al., 2004" rid="ref-eslami2004persian" ref-type="bibr">Eslami
      et al., 2004</xref>) and unique words extracted from the Naab
      dataset
      (<xref alt="Sabouri et al., 2022" rid="ref-sabouri2022naab" ref-type="bibr">Sabouri
      et al., 2022</xref>), cross-checked against the Moein and Dehkhoda
      dictionaries for improved accuracy and coverage.</p>
    </list-item>
    <list-item>
      <p><bold>Visualization</bold></p>
    </list-item>
  </list>
  <p>Includes a WordCloud class offering an easy way to create visually
  rich Persian word clouds. It supports reshaping and right-to-left
  rendering, Persian fonts, color maps, and custom shape masks for
  accurate and elegant visualization of word frequencies.</p>
  <fig>
    <caption><p>Word cloud visualization of selected words from
    Ferdowsi’s Persian epic, the <italic>Shahnameh</italic>, arranged
    within the outline of Iran.
    <styled-content id="figU003Afig1"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="wordcloud_example.png" />
  </fig>
</sec>
<sec id="efficiency-and-reliability">
  <title>Efficiency and Reliability</title>
  <p>Shekar is designed with both performance and robustness in mind.
  All models are 8-bit integer quantized, exported to ONNX format, and
  executed using onnxruntime to minimize dependencies and enable
  efficient CPU inference on a wide range of hardware, including
  low-resource systems.</p>
  <p>The codebase is extensively tested across macOS, Linux, and Windows
  environments, with continuous integration workflows ensuring
  consistent behavior on all platforms. Unit tests cover more than 95
  percent of the codebase, helping maintain reliability and stability as
  the toolkit evolves.</p>
</sec>
<sec id="availability">
  <title>Availability</title>
  <p>Shekar is distributed as a Python package on
  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/shekar">PyPI</ext-link>
  under the MIT License, with full source code, test suite,
  documentations, pre-trained models, example scripts, and Jupyter
  notebooks available on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/amirivojdan/shekar">https://github.com/amirivojdan/shekar</ext-link>.</p>
</sec>
<sec id="acknowledgement">
  <title>Acknowledgement</title>
  <p>The author sincerely thanks Dr. Shaghayegh Yaraghi and Siavash
  Alizadeh for their continued support, which provided encouragement
  throughout the development of this work.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-jafari2025dadmatools">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Jafari</surname><given-names>Sadegh</given-names></name>
        <name><surname>Farsi</surname><given-names>Farhan</given-names></name>
        <name><surname>Ebrahimi</surname><given-names>Navid</given-names></name>
        <name><surname>Sajadi</surname><given-names>Mohamad Bagher</given-names></name>
        <name><surname>Eetemadi</surname><given-names>Sauleh</given-names></name>
      </person-group>
      <article-title>DadmaTools V2: An adapter-based natural language processing toolkit for the Persian language</article-title>
      <source>Proceedings of the 1st workshop on NLP for languages using arabic script</source>
      <year iso-8601-date="2025">2025</year>
      <fpage>37</fpage>
      <lpage>43</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mohtaj2018parsivar">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mohtaj</surname><given-names>Salar</given-names></name>
        <name><surname>Roshanfekr</surname><given-names>Behnam</given-names></name>
        <name><surname>Zafarian</surname><given-names>Atefeh</given-names></name>
        <name><surname>Asghari</surname><given-names>Habibollah</given-names></name>
      </person-group>
      <article-title>Parsivar: A language processing toolkit for Persian</article-title>
      <source>Proceedings of the eleventh international conference on language resources and evaluation (lrec 2018)</source>
      <year iso-8601-date="2018">2018</year>
    </element-citation>
  </ref>
  <ref id="ref-sabouri2022naab">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sabouri</surname><given-names>Sadra</given-names></name>
        <name><surname>Rahmati</surname><given-names>Elnaz</given-names></name>
        <name><surname>Gooran</surname><given-names>Soroush</given-names></name>
        <name><surname>Sameti</surname><given-names>Hossein</given-names></name>
      </person-group>
      <article-title>Naab: A ready-to-use plug-and-play corpus for Farsi</article-title>
      <source>arXiv preprint arXiv:2208.13486</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.22034/jaiai.2024.480062.1016</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-eslami2004persian">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Eslami</surname><given-names>Moharam</given-names></name>
        <name><surname>Atashgah</surname><given-names>M Sharifi</given-names></name>
        <name><surname>Alizadeh</surname><given-names>LS</given-names></name>
        <name><surname>Zandi</surname><given-names>T</given-names></name>
      </person-group>
      <article-title>Persian generative lexicon</article-title>
      <source>The first workshop on persian language and computer. Tehran, iran</source>
      <year iso-8601-date="2004">2004</year>
    </element-citation>
  </ref>
  <ref id="ref-kudo2018sentencepiece">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kudo</surname><given-names>Taku</given-names></name>
        <name><surname>Richardson</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</article-title>
      <source>arXiv preprint arXiv:1808.06226</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1808.06226</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-rasooli2020persian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rasooli</surname><given-names>Mohammad Sadegh</given-names></name>
        <name><surname>Safari</surname><given-names>Pegah</given-names></name>
        <name><surname>Moloodi</surname><given-names>Amirsaeid</given-names></name>
        <name><surname>Nourian</surname><given-names>Alireza</given-names></name>
      </person-group>
      <article-title>The Persian dependency treebank made universal</article-title>
      <source>arXiv preprint arXiv:2009.10205</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2009.10205</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lan2019albert">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lan</surname><given-names>Zhenzhong</given-names></name>
        <name><surname>Chen</surname><given-names>Mingda</given-names></name>
        <name><surname>Goodman</surname><given-names>Sebastian</given-names></name>
        <name><surname>Gimpel</surname><given-names>Kevin</given-names></name>
        <name><surname>Sharma</surname><given-names>Piyush</given-names></name>
        <name><surname>Soricut</surname><given-names>Radu</given-names></name>
      </person-group>
      <article-title>ALBERT: A lite BERT for self-supervised learning of language representations</article-title>
      <source>arXiv preprint arXiv:1909.11942</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1909.11942</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-rose2010automatic">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rose</surname><given-names>Stuart</given-names></name>
        <name><surname>Engel</surname><given-names>Dave</given-names></name>
        <name><surname>Cramer</surname><given-names>Nick</given-names></name>
        <name><surname>Cowley</surname><given-names>Wendy</given-names></name>
      </person-group>
      <article-title>Automatic keyword extraction from individual documents</article-title>
      <source>Text mining: applications and theory</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <pub-id pub-id-type="doi">10.1002/9780470689646.ch1</pub-id>
      <fpage>1</fpage>
      <lpage>20</lpage>
    </element-citation>
  </ref>
  <ref id="ref-farahani2021parsbert">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Farahani</surname><given-names>Mehrdad</given-names></name>
        <name><surname>Gharachorloo</surname><given-names>Mohammad</given-names></name>
        <name><surname>Farahani</surname><given-names>Marzieh</given-names></name>
        <name><surname>Manthouri</surname><given-names>Mohammad</given-names></name>
      </person-group>
      <article-title>Parsbert: Transformer-based model for Persian language understanding</article-title>
      <source>Neural Processing Letters</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>53</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1007/s11063-021-10528-4</pub-id>
      <fpage>3831</fpage>
      <lpage>3847</lpage>
    </element-citation>
  </ref>
  <ref id="ref-amirivojdan_2025_naseza">
    <element-citation publication-type="dataset">
      <person-group person-group-type="author">
        <name><surname>Amirivojdan</surname><given-names>Ahmad</given-names></name>
      </person-group>
      <article-title>Naseza: A large-scale dataset for Persian hate speech and offensive language detection</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <uri>https://doi.org/10.5281/zenodo.17355123</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.17355123</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
