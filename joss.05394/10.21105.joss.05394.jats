<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5394</article-id>
<article-id pub-id-type="doi">10.21105/joss.05394</article-id>
<title-group>
<article-title>DeepOF: a Python package for supervised and unsupervised
pattern recognition in mice motion tracking data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5484-6744</contrib-id>
<name>
<surname>Miranda</surname>
<given-names>Lucas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2909-2976</contrib-id>
<name>
<surname>Bordes</surname>
<given-names>Joeri</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2208-209X</contrib-id>
<name>
<surname>Pütz</surname>
<given-names>Benno</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3788-2268</contrib-id>
<name>
<surname>Schmidt</surname>
<given-names>Mathias V</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0719-101X</contrib-id>
<name>
<surname>Müller-Myhsok</surname>
<given-names>Bertram</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Research Group Statistical Genetics, Max Planck Institute
of Psychiatry, Munich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Research Group Neurobiology of Stress Resilience, Max
Planck Institute of Psychiatry, Munich, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-04-04">
<day>4</day>
<month>4</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>86</issue>
<fpage>5394</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>biology</kwd>
<kwd>neuroscience</kwd>
<kwd>behavioral annotation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>DeepOF (Deep Open Field) is a Python package that provides a suite
  of tools for analyzing behavior in freely-moving rodents.
  Specifically, it focuses on postprocessing time-series data extracted
  from videos using
  <ext-link ext-link-type="uri" xlink:href="http://www.mackenziemathislab.org/deeplabcut#:~:text=DeepLabCut%E2%84%A2%20is%20an%20efficient,typically%2050%2D200%20frames">DeepLabCut</ext-link>
  (<xref alt="Mathis et al., 2018" rid="ref-Mathis2018DeepLabCutU003ALearning" ref-type="bibr">Mathis
  et al., 2018</xref>). The software encompasses a diverse set of
  capabilities, such as:</p>
  <list list-type="bullet">
    <list-item>
      <p>Loading DeepLabCut data into custom objects and incorporating
      metadata related to experimental design.</p>
    </list-item>
    <list-item>
      <p>Processing data, including smoothing, imputation, and feature
      extraction.</p>
    </list-item>
    <list-item>
      <p>Annotating behavioral motifs in a supervised manner, such as
      recognizing huddling and climbing, and detecting fundamental
      social interactions between animals.</p>
    </list-item>
    <list-item>
      <p>Embedding motion tracking data in an unsupervised manner using
      neural network models, which also facilitate end-to-end deep
      clustering.</p>
    </list-item>
    <list-item>
      <p>Conducting post-hoc analysis of results and visualization to
      compare patterns across animals under different experimental
      conditions.</p>
    </list-item>
  </list>
  <p>The package is designed to work with various types of DeepLabCut
  input (single and multi-animal projects), includes comprehensive
  documentation, and offers interactive tutorials. Although many of its
  primary functionalities (particularly the supervised annotation
  pipeline) were developed with top-down mice videos in mind, tagged
  with a specific set of labels, most essential functions operate
  without constraints. As demonstrated in the accompanying scientific
  application paper
  (<xref alt="Bordes et al., 2022" rid="ref-Bordes2022.06.23.497350" ref-type="bibr">Bordes
  et al., 2022</xref>), DeepOF has the potential to enable systematic
  and thorough behavioral assessments in a wide range of preclinical
  research settings.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The field of behavioral research has experienced significant
  advancements in recent years, particularly in the quantification and
  analysis of animal behavior. Historically, behavioral quantification
  relied heavily on tests that were designed with either one or a few
  readouts in mind. However, the advent of deep learning for computer
  vision and the development of packages such as DeepLabCut, which
  enable pose estimation without the need for physical markers, have
  rapidly expanded the possibilities for non-invasive animal tracking
  (<xref alt="Mathis et al., 2020" rid="ref-Mathis2020APerspectives" ref-type="bibr">Mathis
  et al., 2020</xref>).</p>
  <p>By transforming raw video footage into time series data of tracked
  body parts, these approaches have paved the way for the development of
  software packages capable of automatically annotating behavior
  following a plethora of different approaches, increasing the number of
  patterns that can be studied per experiment with little burden on the
  experimenters.</p>
  <p>For example, several tools offer options to detect predefined
  behaviors using supervised machine learning. Along these lines,
  programs like SimBA
  (<xref alt="Nilsson et al., 2020" rid="ref-Nilsson2020.04.19.049452" ref-type="bibr">Nilsson
  et al., 2020</xref>), MARS
  (<xref alt="Segalin et al., 2021" rid="ref-MARS2021" ref-type="bibr">Segalin
  et al., 2021</xref>), or TREBA
  (<xref alt="Sun et al., 2021" rid="ref-sun2021task" ref-type="bibr">Sun
  et al., 2021</xref>), allow users to label a set of behaviors and
  train classifiers to detect them in new videos. They employ different
  labelling schemes which require different amounts of user input, and
  offer high flexibility in terms of the number of behaviors that can be
  detected. On the other hand, packages such as B-SOiD
  (<xref alt="Hsu &amp; Yttri, 2021" rid="ref-Hsu2021" ref-type="bibr">Hsu
  &amp; Yttri, 2021</xref>), VAME
  (<xref alt="Luxem et al., 2022" rid="ref-Luxem2022IdentifyingMotion" ref-type="bibr">Luxem
  et al., 2022</xref>), and Keypoint-MoSeq
  (<xref alt="Weinreb et al., 2023" rid="ref-Weinreb2023.03.16.532307" ref-type="bibr">Weinreb
  et al., 2023</xref>), aim for a more exploratory approach that does
  not require user labelling, but instead relies on unsupervised
  learning to segment time series into different behaviors. These
  packages are particularly useful when the user is interested in
  detecting novel behaviors, or when the number of behaviors is too
  large to be annotated manually. Moreover, some approaches have been
  developed to combine the best of both worlds, such as the the A-SOiD
  active learning framework
  (<xref alt="Schweihoff et al., 2022" rid="ref-Schweihoff2022.11.04.515138" ref-type="bibr">Schweihoff
  et al., 2022</xref>), and the semi-supervised DAART
  (<xref alt="Whiteway et al., 2021" rid="ref-Whiteway2021.06.16.448685" ref-type="bibr">Whiteway
  et al., 2021</xref>). While a thorough discussion on the advantages
  and disadvantages of each package is beyond the scope of this paper,
  further information can be found in this recent review
  (<xref alt="Bordes et al., 2023" rid="ref-Bordes2023" ref-type="bibr">Bordes
  et al., 2023</xref>).</p>
  <p>In contrast to other available options, DeepOF offers both
  supervised and unsupervised annotation pipelines, that allow
  researchers to test hypotheses regarding experimental conditions such
  as stress, gene mutations, and sex, in a flexible way
  (<xref alt="[fig:intro]" rid="figU003Aintro">[fig:intro]</xref>).</p>
  <fig>
    <caption><p>Scheme representing DeepOF workflow. Upon creating a
    project, DLC data can be loaded and preprocessed before annotating
    it with either a supervised pipeline (which uses a set of
    pre-trained models and rule-based annotators) or an unsupervised
    pipeline, which relies on custom deep clustering algorithms.
    Patterns retrieved with either pipeline can be passed to downstream
    post-hoc analysis tools and visualization
    functions.<styled-content id="figU003Aintro"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/bb246560608c6c9db43a35c6b8bead329da55f2f.png" />
  </fig>
  <p>The included supervised pipeline uses a series of rule-based
  annotators and pre-trained machine learning classifiers to detect when
  each animal is displaying a set of pre-defined behavioral motifs. The
  unsupervised workflow uses state-of-the-art deep clustering models to
  extract novel motifs without prior definition. DeepOF then provides an
  interpretability pipeline to explore what these retrieved clusters are
  in terms of behavior, which uses both Shapley Additive Explanations
  (SHAP)
  (<xref alt="Goodwin et al., 2022" rid="ref-Goodwin2022" ref-type="bibr">Goodwin
  et al., 2022</xref>) and direct mappings from clusters to video.
  Moreover, regardless of whether the user chose the supervised
  annotation pipeline, the unsupervised one, or both, DeepOF provides an
  extensive set of post-hoc analysis and visualization tools.</p>
  <p>When it comes to comparing it to other individual packages that use
  supervised and unsupervised annotation, DeepOF stands out in several
  ways. First of all, it is the first package, to the best of our
  knowledge, to offer both options. Second, the supervised pipeline in
  DeepOF follows an opinionated philosophy, in the sense that it
  provides a set of pre-trained models that cannot be customized, but do
  not require user labels. This trades flexibility for ease of use,
  aiming at being a quick exploratory tool that can provide information
  on key individual and social behaviors with just a few commands.
  Furthermore, when it comes to the unsupervised pipeline, DeepOF
  provides three custom deep clustering algorithms capable of segmenting
  the behavioral time series, as well as the aforementioned built-in
  interpretability pipeline. If a user runs both pipelines, supervised
  annotations can be incorporated into this interpretability pipeline in
  quite a unique way, to detect associations between supervised and
  unsupervised patterns.</p>
  <p>All in all, DeepOF is a comprehensive, end-to-end tool designed to
  transform DeepLabCut output into relatively quick, exploratory
  insights on behavioral shifts between experimental conditions, and
  pinpoint which behaviors are driving them.</p>
</sec>
<sec id="related-literature">
  <title>Related literature</title>
  <p>The DeepOF package has been used to characterize differences in
  behavior associated with Chronic Social Defeat Stress (CSDS) in mice,
  as presented in our preprint (currently in revision at the time of
  writing
  (<xref alt="Bordes et al., 2022" rid="ref-Bordes2022.06.23.497350" ref-type="bibr">Bordes
  et al., 2022</xref>)). There are several other ongoing projects
  involving the software, although none of them are published to this
  date.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge contributions from Felix Agakov and Karsten
  Borgwardt.</p>
</sec>
<sec id="funding">
  <title>Funding</title>
  <p>This project has received funding from the European Union’s
  Framework Programme for Research and Innovation Horizon 2020
  (2014-2020) under the Marie Skłodowska-Curie Grant Agreement
  No. 813533-MSCA-ITN-2018.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Mathis2018DeepLabCutU003ALearning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mathis</surname><given-names>Alexander</given-names></name>
        <name><surname>Mamidanna</surname><given-names>Pranav</given-names></name>
        <name><surname>Cury</surname><given-names>Kevin M.</given-names></name>
        <name><surname>Abe</surname><given-names>Taiga</given-names></name>
        <name><surname>Murthy</surname><given-names>Venkatesh N.</given-names></name>
        <name><surname>Mathis</surname><given-names>Mackenzie Weygandt</given-names></name>
        <name><surname>Bethge</surname><given-names>Matthias</given-names></name>
      </person-group>
      <article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title>
      <source>Nature Neuroscience 2018 21:9</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2018-08">2018</year><month>08</month>
      <volume>21</volume>
      <issue>9</issue>
      <issn>1546-1726</issn>
      <uri>https://www.nature.com/articles/s41593-018-0209-y</uri>
      <pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id>
      <pub-id pub-id-type="pmid">30127430</pub-id>
      <fpage>1281</fpage>
      <lpage>1289</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Mathis2020APerspectives">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mathis</surname><given-names>Alexander</given-names></name>
        <name><surname>Schneider</surname><given-names>Steffen</given-names></name>
        <name><surname>Lauer</surname><given-names>Jessy</given-names></name>
        <name><surname>Mathis</surname><given-names>Mackenzie Weygandt</given-names></name>
      </person-group>
      <article-title>A Primer on Motion Capture with Deep Learning: Principles, Pitfalls, and Perspectives</article-title>
      <source>Neuron</source>
      <publisher-name>Cell Press</publisher-name>
      <year iso-8601-date="2020-10">2020</year><month>10</month>
      <volume>108</volume>
      <issue>1</issue>
      <uri>http://www.cell.com/article/S0896627320307170/fulltext http://www.cell.com/article/S0896627320307170/abstract https://www.cell.com/neuron/abstract/S0896-6273(20)30717-0</uri>
      <pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.017</pub-id>
      <pub-id pub-id-type="pmid">33058765</pub-id>
      <fpage>44</fpage>
      <lpage>65</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Luxem2022IdentifyingMotion">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Luxem</surname><given-names>Kevin</given-names></name>
        <name><surname>Mocellin</surname><given-names>Petra</given-names></name>
        <name><surname>Fuhrmann</surname><given-names>Falko</given-names></name>
        <name><surname>Kürsch</surname><given-names>Johannes</given-names></name>
        <name><surname>Miller</surname><given-names>Stephanie R.</given-names></name>
        <name><surname>Palop</surname><given-names>Jorge J.</given-names></name>
        <name><surname>Remy</surname><given-names>Stefan</given-names></name>
        <name><surname>Bauer</surname><given-names>Pavol</given-names></name>
      </person-group>
      <article-title>Identifying behavioral structure from deep variational embeddings of animal motion</article-title>
      <source>Communications Biology 2022 5:1</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2022-11">2022</year><month>11</month>
      <volume>5</volume>
      <issue>1</issue>
      <issn>2399-3642</issn>
      <uri>https://www.nature.com/articles/s42003-022-04080-7</uri>
      <pub-id pub-id-type="doi">10.1038/s42003-022-04080-7</pub-id>
      <pub-id pub-id-type="pmid">36400882</pub-id>
      <fpage>1</fpage>
      <lpage>15</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Nilsson2020.04.19.049452">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nilsson</surname><given-names>Simon RO</given-names></name>
        <name><surname>Goodwin</surname><given-names>Nastacia L.</given-names></name>
        <name><surname>Choong</surname><given-names>Jia Jie</given-names></name>
        <name><surname>Hwang</surname><given-names>Sophia</given-names></name>
        <name><surname>Wright</surname><given-names>Hayden R</given-names></name>
        <name><surname>Norville</surname><given-names>Zane C</given-names></name>
        <name><surname>Tong</surname><given-names>Xiaoyu</given-names></name>
        <name><surname>Lin</surname><given-names>Dayu</given-names></name>
        <name><surname>Bentzley</surname><given-names>Brandon S.</given-names></name>
        <name><surname>Eshel</surname><given-names>Neir</given-names></name>
        <name><surname>McLaughlin</surname><given-names>Ryan J</given-names></name>
        <name><surname>Golden</surname><given-names>Sam A.</given-names></name>
      </person-group>
      <article-title>Simple Behavioral Analysis (SimBA)  an open source toolkit for computer classification of complex social behaviors in experimental animals</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://www.biorxiv.org/content/early/2020/04/21/2020.04.19.049452</uri>
      <pub-id pub-id-type="doi">10.1101/2020.04.19.049452</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Bordes2022.06.23.497350">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bordes</surname><given-names>Joeri</given-names></name>
        <name><surname>Miranda</surname><given-names>Lucas</given-names></name>
        <name><surname>Reinhardt</surname><given-names>Maya</given-names></name>
        <name><surname>Brix</surname><given-names>Lea Maria</given-names></name>
        <name><surname>Doeselaar</surname><given-names>Lotte van</given-names></name>
        <name><surname>Engelhardt</surname><given-names>Clara</given-names></name>
        <name><surname>Pütz</surname><given-names>Benno</given-names></name>
        <name><surname>Agakov</surname><given-names>Felix</given-names></name>
        <name><surname>Müller-Myhsok</surname><given-names>Bertram</given-names></name>
        <name><surname>Schmidt</surname><given-names>Mathias V.</given-names></name>
      </person-group>
      <article-title>Automatically annotated motion tracking identifies a distinct social behavioral profile following chronic social defeat stress</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://www.biorxiv.org/content/early/2022/06/26/2022.06.23.497350</uri>
      <pub-id pub-id-type="doi">10.1101/2022.06.23.497350</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Goodwin2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Goodwin</surname><given-names>Nastacia L.</given-names></name>
        <name><surname>Nilsson</surname><given-names>Simon R. O.</given-names></name>
        <name><surname>Choong</surname><given-names>Jia Jie</given-names></name>
        <name><surname>Golden</surname><given-names>Sam A.</given-names></name>
      </person-group>
      <article-title>Toward the explainability, transparency, and universality of machine learning for behavioral classification in neuroscience</article-title>
      <source>Current Opinion in Neurobiology</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2022-04">2022</year><month>04</month>
      <volume>73</volume>
      <uri>https://doi.org/10.1016/j.conb.2022.102544</uri>
      <pub-id pub-id-type="doi">10.1016/j.conb.2022.102544</pub-id>
      <fpage>102544</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-sun2021task">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Sun</surname><given-names>Jennifer J.</given-names></name>
        <name><surname>Kennedy</surname><given-names>Ann</given-names></name>
        <name><surname>Zhan</surname><given-names>Eric</given-names></name>
        <name><surname>Anderson</surname><given-names>David J.</given-names></name>
        <name><surname>Yue</surname><given-names>Yisong</given-names></name>
        <name><surname>Perona</surname><given-names>Pietro</given-names></name>
      </person-group>
      <article-title>Task Programming: Learning Data Efficient Behavior Representations</article-title>
      <source>2021 IEEE/CVF conference on computer vision and pattern recognition (CVPR)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2021-06">2021</year><month>06</month>
      <uri>https://doi.org/10.1109/cvpr46437.2021.00290</uri>
      <pub-id pub-id-type="doi">10.1109/cvpr46437.2021.00290</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-MARS2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Segalin</surname><given-names>Cristina</given-names></name>
        <name><surname>Williams</surname><given-names>Jalani</given-names></name>
        <name><surname>Karigo</surname><given-names>Tomomi</given-names></name>
        <name><surname>Hui</surname><given-names>May</given-names></name>
        <name><surname>Zelikowsky</surname><given-names>Moriel</given-names></name>
        <name><surname>Sun</surname><given-names>Jennifer J</given-names></name>
        <name><surname>Perona</surname><given-names>Pietro</given-names></name>
        <name><surname>Anderson</surname><given-names>David J</given-names></name>
        <name><surname>Kennedy</surname><given-names>Ann</given-names></name>
      </person-group>
      <article-title>The Mouse Action Recognition System (MARS) software pipeline for automated analysis of social behaviors in mice</article-title>
      <source>eLife</source>
      <person-group person-group-type="editor">
        <name><surname>Berman</surname><given-names>Gordon J</given-names></name>
        <name><surname>Wassum</surname><given-names>Kate M</given-names></name>
        <name><surname>Gal</surname><given-names>Asaf</given-names></name>
      </person-group>
      <publisher-name>eLife Sciences Publications, Ltd</publisher-name>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <volume>10</volume>
      <issn>2050-084X</issn>
      <uri>https://doi.org/10.7554/eLife.63720</uri>
      <pub-id pub-id-type="doi">10.7554/eLife.63720</pub-id>
      <fpage>e63720</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hsu2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hsu</surname><given-names>Alexander I.</given-names></name>
        <name><surname>Yttri</surname><given-names>Eric A.</given-names></name>
      </person-group>
      <article-title>B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors</article-title>
      <source>Nature Communications</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2021-08">2021</year><month>08</month>
      <volume>12</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1038/s41467-021-25420-x</uri>
      <pub-id pub-id-type="doi">10.1038/s41467-021-25420-x</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Weinreb2023.03.16.532307">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weinreb</surname><given-names>Caleb</given-names></name>
        <name><surname>Osman</surname><given-names>Mohammed Abdal Monium</given-names></name>
        <name><surname>Zhang</surname><given-names>Libby</given-names></name>
        <name><surname>Lin</surname><given-names>Sherry</given-names></name>
        <name><surname>Pearl</surname><given-names>Jonah</given-names></name>
        <name><surname>Annapragada</surname><given-names>Sidharth</given-names></name>
        <name><surname>Conlin</surname><given-names>Eli</given-names></name>
        <name><surname>Gillis</surname><given-names>Winthrop F.</given-names></name>
        <name><surname>Jay</surname><given-names>Maya</given-names></name>
        <name><surname>Ye</surname><given-names>Shaokai</given-names></name>
        <name><surname>Mathis</surname><given-names>Alexander</given-names></name>
        <name><surname>Mathis</surname><given-names>Mackenzie Weygandt</given-names></name>
        <name><surname>Pereira</surname><given-names>Talmo</given-names></name>
        <name><surname>Linderman</surname><given-names>Scott W.</given-names></name>
        <name><surname>Datta</surname><given-names>Sandeep Robert</given-names></name>
      </person-group>
      <article-title>Keypoint-MoSeq: parsing behavior by linking point tracking to pose dynamics</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.biorxiv.org/content/early/2023/03/17/2023.03.16.532307</uri>
      <pub-id pub-id-type="doi">10.1101/2023.03.16.532307</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Whiteway2021.06.16.448685">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Whiteway</surname><given-names>Matthew R</given-names></name>
        <name><surname>Schaffer</surname><given-names>Evan S</given-names></name>
        <name><surname>Wu</surname><given-names>Anqi</given-names></name>
        <name><surname>Buchanan</surname><given-names>E Kelly</given-names></name>
        <name><surname>Onder</surname><given-names>Omer F</given-names></name>
        <name><surname>Mishra</surname><given-names>Neeli</given-names></name>
        <name><surname>Paninski</surname><given-names>Liam</given-names></name>
      </person-group>
      <article-title>Semi-supervised sequence modeling for improved behavioral segmentation</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://www.biorxiv.org/content/early/2021/06/17/2021.06.16.448685</uri>
      <pub-id pub-id-type="doi">10.1101/2021.06.16.448685</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Bordes2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bordes</surname><given-names>Joeri</given-names></name>
        <name><surname>Miranda</surname><given-names>Lucas</given-names></name>
        <name><surname>Müller-Myhsok</surname><given-names>Bertram</given-names></name>
        <name><surname>Schmidt</surname><given-names>Mathias V.</given-names></name>
      </person-group>
      <article-title>Advancing social behavioral neuroscience by integrating ethology and comparative psychology methods through machine learning</article-title>
      <source>Neuroscience &amp; Biobehavioral Reviews</source>
      <publisher-name>Pergamon</publisher-name>
      <year iso-8601-date="2023-08">2023</year><month>08</month>
      <volume>151</volume>
      <issn>0149-7634</issn>
      <pub-id pub-id-type="doi">10.1016/J.NEUBIOREV.2023.105243</pub-id>
      <fpage>105243</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Schweihoff2022.11.04.515138">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schweihoff</surname><given-names>Jens F.</given-names></name>
        <name><surname>Hsu</surname><given-names>Alexander I.</given-names></name>
        <name><surname>Schwarz</surname><given-names>Martin K.</given-names></name>
        <name><surname>Yttri</surname><given-names>Eric A.</given-names></name>
      </person-group>
      <article-title>A-SOiD, an active learning platform for expert-guided, data efficient discovery of behavior</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://www.biorxiv.org/content/early/2022/11/08/2022.11.04.515138</uri>
      <pub-id pub-id-type="doi">10.1101/2022.11.04.515138</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
