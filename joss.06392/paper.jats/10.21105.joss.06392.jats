<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6392</article-id>
<article-id pub-id-type="doi">10.21105/joss.06392</article-id>
<title-group>
<article-title>‘StreamPoseML’ An End-to-End Open-Source Web Application
and Python Toolkit for Real-Time Video Pose Classification and Machine
Learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3694-763X</contrib-id>
<name>
<surname>Trajkova</surname>
<given-names>Milka</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0157-7744</contrib-id>
<name>
<surname>Green</surname>
<given-names>Nathaniel</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9260-0366</contrib-id>
<name>
<surname>Shinohara</surname>
<given-names>Minoru</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>School of Literature, Media, and Communication, Georgia
Institute of Technology, Atlanta, GA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Independent Researcher, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>School of Biological Sciences, Georgia Institute of
Technology, Atlanta, GA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Wallace H. Coulter Department of School of Biomedical
Engineering, Georgia Institute of Technology and Emory University,
Atlanta, GA, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-12-01">
<day>1</day>
<month>12</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>104</issue>
<fpage>6392</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Movement AI classification</kwd>
<kwd>Media Pipe</kwd>
<kwd>Python</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>With the ubiquity of video content in various sectors, from
  surveillance to entertainment to education, the demand for effective
  video analytics has never been greater - video data are being produced
  and consumed at an unprecedented rate, leading to an increased need
  for end-to-end research tools to integrate, manage, and utilize this
  massive influx of information. Classifying videos using machine
  learning often involves a series of data processing steps – data
  collection, annotation, pre-processing, model training, and
  deployment. These tasks require different tools and skill sets, making
  the process fragmented, time-consuming, and complex. Currently, many
  open-source machine learning pipelines require users to manually
  integrate different tools and libraries, which can be time-consuming
  and error-prone. There is a significant need for tools that can
  automatically develop an end-to-end machine learning pipeline,
  especially for human motion classification. A unified platform that
  can handle multiple stages in the machine learning pipeline will
  greatly streamline the workflow, saving time, reducing complexity, and
  lowering the barrier to entry for practitioners without extensive
  machine learning expertise. Our proposed web application and Python
  toolkit, “StreamPoseML” is an open-source, end-to-end toolkit for
  creating real-time, video-based classification experiments based on
  labeled data and body keypoint/pose estimation of human movements. It
  provides the capability of dataset generation, pre-processing, model
  building and training, as well as deployment in a real-time
  environment. Users will be able to monitor and adjust their models on
  the fly in the backend and test their models using a front-end UI. To
  illustrate its use, we provide an examples of on-going research on
  designing a real-time trial-to-trial movement classification for older
  adults undergoing Adapted Tango dance therapy.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The lack of tools available for open-source end-to-end machine
  learning pipelines, particularly for motion classification, is a
  recognized challenge in the field
  (<xref alt="Orhei et al., 2021" rid="ref-orhei2021end" ref-type="bibr">Orhei
  et al., 2021</xref>). The typical ten stages of an end-to-end video
  classification pipeline are listed below:</p>
  <list list-type="order">
    <list-item>
      <p>Collect video data</p>
    </list-item>
    <list-item>
      <p>Label video data</p>
    </list-item>
    <list-item>
      <p>Generate pose keypoints from video</p>
    </list-item>
    <list-item>
      <p>Compute features</p>
    </list-item>
    <list-item>
      <p>Merge annotations/labels with keypoints/features into a
      dataset</p>
    </list-item>
    <list-item>
      <p>Train a model</p>
    </list-item>
    <list-item>
      <p>Run experiments</p>
    </list-item>
    <list-item>
      <p>Deploy the trained the model</p>
    </list-item>
  </list>
  <p>And in our specific use cases:</p>
  <list list-type="order">
    <list-item>
      <label>9.</label>
      <p>Classify real-time video captured via the web or some other
      input source</p>
    </list-item>
    <list-item>
      <label>10.</label>
      <p>Actuate or send results outside the application (e.g., to a
      Bluetooth Device)</p>
    </list-item>
  </list>
  <p>While there are various individual tools and paid platforms
  available for each stage of the machine learning workflow, such as
  video annotation, e.g., Dataloop, LabelBox; data management and
  pre-processing, e.g., Postgres, SPSS; or unified machine learning
  services, such as Google Cloud, AWS SageMaker, Microsoft Azure, IBM
  Watson, and Databricks among others, there is a lack of an open-source
  integrated solution that streamlines those stages in an easy-to-used
  single pipeline. Motion assessment classification is iterative in
  nature, which involves going back and forth between stages for
  validating the detected body keypoints, features, and model
  performance quality.</p>
  <p>Recent initiatives have introduced open-source tools like Google’s
  Teachable Machine
  (<xref alt="Google, 2024" rid="ref-teachablemachine" ref-type="bibr">Google,
  2024</xref>), a web-based platform for developing basic machine
  learning models. This tool is user-friendly and easily accessible, yet
  it comes with a number of limitations. Its primary drawback is the
  limited customization and control it offers; users cannot alter the
  underlying features, algorithms, or hyperparameters, restricting
  advanced usage and complex project development. Additionally, data
  privacy is a concern since user data is uploaded to Google’s servers,
  posing potential risks for breaches in sensitive and identifiable
  information. Scalability is another issue, as it is designed as an
  educational platform for machine learning that is limited in
  processing capacity for large datasets and tuning models for
  real-world applications. The dependency on a stable internet
  connection, limited data processing capabilities, lack of integration
  with other tools and platforms, performance issues with large models,
  and no control over the training environment further underline its
  limitations for professional use. Thus, while the Teachable Machine is
  excellent for introductory purposes, its constraints render it less
  viable for advanced applications for developing models in complex
  scenarios.</p>
  <p>We identified several frameworks and toolkits in the literature,
  each allowing advanced applications for data handling and analysis
  workflows, machine learning frameworks, documentation of experiments,
  and optimizing hyperparameters
  (<xref alt="Alberti et al., 2018" rid="ref-alberti2018deepdiva" ref-type="bibr">Alberti
  et al., 2018</xref>;
  <xref alt="Gould, 2012" rid="ref-gould2012darwin" ref-type="bibr">Gould,
  2012</xref>;
  <xref alt="Hall et al., 2009" rid="ref-hall2009weka" ref-type="bibr">Hall
  et al., 2009</xref>;
  <xref alt="Holmes et al., 1994" rid="ref-holmes1994weka" ref-type="bibr">Holmes
  et al., 1994</xref>;
  <xref alt="Kiefer et al., 2013" rid="ref-kiefer2013emzed" ref-type="bibr">Kiefer
  et al., 2013</xref>;
  <xref alt="Orhei et al., 2021" rid="ref-orhei2021end" ref-type="bibr">Orhei
  et al., 2021</xref>;
  <xref alt="Schindelin et al., 2012" rid="ref-schindelin2012fiji" ref-type="bibr">Schindelin
  et al., 2012</xref>;
  <xref alt="Tokui et al., 2019" rid="ref-tokui2019chainer" ref-type="bibr">Tokui
  et al., 2019</xref>;
  <xref alt="Williams &amp; others, 2009" rid="ref-williams2009rattle" ref-type="bibr">Williams
  &amp; others, 2009</xref>). However, these toolkits do not address the
  complete pipeline comprehensively with the ability to 1) include pose
  estimation integration, 2) compute features and include them in a
  dataset, 3) present the results via a web application, and 4) actuate
  or send out the result to a subsequent tool via Bluetooth. These steps
  present a crucial point for the integration of video data, human pose
  estimation, and deployment for research activities, particularly for
  the bioinformatics and rehabilitation domains.</p>
  <p>Our proposed solution fills this crucial gap. Not only will our
  toolkit allow users to build and train models in real time, it is also
  capable of data generation, allowing users to create diverse and
  robust datasets for their specific needs. This end-to-end approach
  will enable users to iterate more rapidly on their models, experiment
  with different configurations, and calibrate the pipelines
  interactively in real-time. The StreamPoseML toolkit also makes the
  system portable within Python environments via
  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/stream-pose-ml/">installation
  with pip</ext-link> (steps 3-7 above) and a local-first web
  application with Docker containers (steps 8-10 above).</p>
  <p>The flexibility and accessibility of our proposed platform provide
  solutions for a wide range of users, from industry professionals
  seeking to improve their business operations to academic researchers
  conducting cutting-edge studies and educators teaching the next
  generation of data scientists on human movement assessment. This
  toolkit will accelerate research by providing a robust and flexible
  platform to experiment and innovate.</p>
</sec>
<sec id="use-case">
  <title>Use Case</title>
  <p>We currently use the tool for an ongoing research project that
  involves the creation of real-time feedback for adapted tango dance
  therapy for older adults with and without Parkinson’s disease.</p>
  <p>Currently, motor training for rehabilitation therapy or skill
  improvement often requires an on-site therapist or instructor who
  makes a trial-to-trial visual assessment and provides verbal feedback
  or manual intervention, which is costly and limits access to care. The
  first use case utilizes StreamPoseML to train a classification model
  to identify and provide real-time feedback when instructed backward
  Tango walking is performed successfully by older adults who may or may
  not have Parkinson’s Disease. We identify each movement execution on a
  trial-to-trial basis utilizing markerless motion capture with a
  standard video camera, such as a webcam. Our pipeline provides an
  important step toward users conducting on-demand movement testing in
  their homes through objective and automated assessments and feedback
  made by artificial intelligence models.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge the assistance of Koki Asahina (Georgia Institute of
  Technology) in preparing the source data and constructive comments of
  Dr. Hyeokhyen Kwon (Emory University) on the draft. This study was
  partially supported by the McCamish Parkinson’s Disease Innovation
  Program at Georgia Tech and Emory University.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-tokui2019chainer">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Tokui</surname><given-names>Seiya</given-names></name>
        <name><surname>Okuta</surname><given-names>Ryosuke</given-names></name>
        <name><surname>Akiba</surname><given-names>Takuya</given-names></name>
        <name><surname>Niitani</surname><given-names>Yusuke</given-names></name>
        <name><surname>Ogawa</surname><given-names>Toru</given-names></name>
        <name><surname>Saito</surname><given-names>Shunta</given-names></name>
        <name><surname>Suzuki</surname><given-names>Shuji</given-names></name>
        <name><surname>Uenishi</surname><given-names>Kota</given-names></name>
        <name><surname>Vogel</surname><given-names>Brian</given-names></name>
        <name><surname>Yamazaki Vincent</surname><given-names>Hiroyuki</given-names></name>
      </person-group>
      <article-title>Chainer: A deep learning framework for accelerating the research cycle</article-title>
      <source>Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</source>
      <year iso-8601-date="2019">2019</year>
      <fpage>2002</fpage>
      <lpage>2011</lpage>
    </element-citation>
  </ref>
  <ref id="ref-holmes1994weka">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Holmes</surname><given-names>Geoffrey</given-names></name>
        <name><surname>Donkin</surname><given-names>Andrew</given-names></name>
        <name><surname>Witten</surname><given-names>Ian H</given-names></name>
      </person-group>
      <article-title>Weka: A machine learning workbench</article-title>
      <source>Proceedings of ANZIIS’94-australian new zealnd intelligent information systems conference</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="1994">1994</year>
      <fpage>357</fpage>
      <lpage>361</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hall2009weka">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hall</surname><given-names>Mark</given-names></name>
        <name><surname>Frank</surname><given-names>Eibe</given-names></name>
        <name><surname>Holmes</surname><given-names>Geoffrey</given-names></name>
        <name><surname>Pfahringer</surname><given-names>Bernhard</given-names></name>
        <name><surname>Reutemann</surname><given-names>Peter</given-names></name>
        <name><surname>Witten</surname><given-names>Ian H</given-names></name>
      </person-group>
      <article-title>The WEKA data mining software: An update</article-title>
      <source>ACM SIGKDD explorations newsletter</source>
      <publisher-name>ACM New York, NY, USA</publisher-name>
      <year iso-8601-date="2009">2009</year>
      <volume>11</volume>
      <issue>1</issue>
      <fpage>10</fpage>
      <lpage>18</lpage>
    </element-citation>
  </ref>
  <ref id="ref-williams2009rattle">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Williams</surname><given-names>Graham</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Rattle: A data mining GUI for r</article-title>
      <publisher-name>Copenhagen Business School Press</publisher-name>
      <year iso-8601-date="2009">2009</year>
    </element-citation>
  </ref>
  <ref id="ref-gould2012darwin">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gould</surname><given-names>Stephen</given-names></name>
      </person-group>
      <article-title>DARWIN: A framework for machine learning and computer vision research and development</article-title>
      <source>The Journal of Machine Learning Research</source>
      <publisher-name>JMLR. org</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>13</volume>
      <issue>1</issue>
      <fpage>3533</fpage>
      <lpage>3537</lpage>
    </element-citation>
  </ref>
  <ref id="ref-schindelin2012fiji">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schindelin</surname><given-names>Johannes</given-names></name>
        <name><surname>Arganda-Carreras</surname><given-names>Ignacio</given-names></name>
        <name><surname>Frise</surname><given-names>Erwin</given-names></name>
        <name><surname>Kaynig</surname><given-names>Verena</given-names></name>
        <name><surname>Longair</surname><given-names>Mark</given-names></name>
        <name><surname>Pietzsch</surname><given-names>Tobias</given-names></name>
        <name><surname>Preibisch</surname><given-names>Stephan</given-names></name>
        <name><surname>Rueden</surname><given-names>Curtis</given-names></name>
        <name><surname>Saalfeld</surname><given-names>Stephan</given-names></name>
        <name><surname>Schmid</surname><given-names>Benjamin</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Fiji: An open-source platform for biological-image analysis</article-title>
      <source>Nature methods</source>
      <publisher-name>Nature Publishing Group US New York</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>9</volume>
      <issue>7</issue>
      <fpage>676</fpage>
      <lpage>682</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kiefer2013emzed">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kiefer</surname><given-names>Patrick</given-names></name>
        <name><surname>Schmitt</surname><given-names>Uwe</given-names></name>
        <name><surname>Vorholt</surname><given-names>Julia A</given-names></name>
      </person-group>
      <article-title>eMZed: An open source framework in python for rapid and interactive development of LC/MS data analysis workflows</article-title>
      <source>Bioinformatics</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <volume>29</volume>
      <issue>7</issue>
      <fpage>963</fpage>
      <lpage>964</lpage>
    </element-citation>
  </ref>
  <ref id="ref-alberti2018deepdiva">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Alberti</surname><given-names>Michele</given-names></name>
        <name><surname>Pondenkandath</surname><given-names>Vinaychandran</given-names></name>
        <name><surname>Würsch</surname><given-names>Marcel</given-names></name>
        <name><surname>Ingold</surname><given-names>Rolf</given-names></name>
        <name><surname>Liwicki</surname><given-names>Marcus</given-names></name>
      </person-group>
      <article-title>Deepdiva: A highly-functional python framework for reproducible experiments</article-title>
      <source>2018 16th international conference on frontiers in handwriting recognition (ICFHR)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <fpage>423</fpage>
      <lpage>428</lpage>
    </element-citation>
  </ref>
  <ref id="ref-orhei2021end">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Orhei</surname><given-names>Ciprian</given-names></name>
        <name><surname>Vert</surname><given-names>Silviu</given-names></name>
        <name><surname>Mocofan</surname><given-names>Muguras</given-names></name>
        <name><surname>Vasiu</surname><given-names>Radu</given-names></name>
      </person-group>
      <article-title>End-to-end computer vision framework: An open-source platform for research and education</article-title>
      <source>Sensors</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>21</volume>
      <issue>11</issue>
      <fpage>3691</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-teachablemachine">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Google</string-name>
      </person-group>
      <article-title>Teachable machine: A web-based tool for creating machine learning models</article-title>
      <publisher-name>https://teachablemachine.withgoogle.com/</publisher-name>
      <year iso-8601-date="2024">2024</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
