<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6186</article-id>
<article-id pub-id-type="doi">10.21105/joss.06186</article-id>
<title-group>
<article-title>Arabica: A Python package for exploratory analysis of
text data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2513-8981</contrib-id>
<name>
<surname>Koráb</surname>
<given-names>Petr</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8060-0086</contrib-id>
<name>
<surname>Poměnková</surname>
<given-names>Jitka</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Zeppelin University in Friedrichshafen,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Brno University of Technology, Department of Radio
Electronics, Czech Republic</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-08-25">
<day>25</day>
<month>8</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>97</issue>
<fpage>6186</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>text mining</kwd>
<kwd>exploratory data analysis</kwd>
<kwd>sentiment analysis</kwd>
<kwd>data visualization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Research meta-data is typically recorded as a time series with
  dimensions of cross-sections (e.g., article title, journal, volume,
  issue, author’s names, and affiliations) and time (e.g., publication
  date). Meta-datasets provide valuable insights into the research
  trends in a particular field of science. Meta-analysis (a group of
  methods to analyze research meta-data) currently does not implement
  text analytics in either programming language. This package aims to
  fill that need. Arabica offers descriptive analytics, visualization,
  sentiment classification, and structural break analysis for
  exploratory analysis of research meta-datasets in easy-to-use Python
  implementation.</p>
  <p>The package operates on three main modules: (1) descriptive and
  time-series n-gram analysis provides a frequency summarization of the
  key topics in the meta-dataset, (2) visualization module displays
  key-term frequencies in a heatmap, line plot, and word cloud, (3)
  sentiment and structural breakpoint analysis evaluates sentiment from
  research article titles and identifies turning points in the sentiment
  of published research. It uses VADER
  (<xref alt="Hutto &amp; Gilbert, 2014" rid="ref-HuttoU003A2014" ref-type="bibr">Hutto
  &amp; Gilbert, 2014</xref>) and FinVADER
  (<xref alt="Koráb, 2023" rid="ref-finvaderU003A2023" ref-type="bibr">Koráb,
  2023</xref>), the updated model with financial lexicons, to classify
  sentiment. Clustering-based Fisher-Jenks algorithm
  (<xref alt="Jenks, 1977" rid="ref-JenksU003A1977" ref-type="bibr">Jenks,
  1977</xref>) finds break points in the data.</p>
  <p>It provides standard cleaning operations for lower-casing,
  punctuation, numbers, and stopword removal. It allows removing more
  sets of stopwords from the NLTK corpus at once to clean datasets
  collected in multilingual regions.</p>
  <p>As an example, the package helps analyze trends in economic
  research published in the leading economic journals (Econometrica,
  Journal of Political Economy, American Economic Review, Quarterly
  Journal of Economics, and Review of Economic Studies) from 1990 -
  2017. The meta-data is collected from Constellate.org.</p>
  <p>A word cloud in Figure 1 displays the most frequent bigrams (two
  consecutive words) representing concepts, theories, and models that
  were central to researchers’ attention throughout the period. A
  heatmap in Figure 2 adds a time dimension and plots the most frequent
  terms with yearly frequency. The line plot in Figure 3 displays the
  most frequent concepts in an alternative form for a shorter period,
  and Figure 4 shows aggregated sentiment with two turning points (the
  2007 - 2009 financial crisis and the end of the Great Moderation
  period in economics in 1999).</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/word_cloud.png">
    <alt-text>Figure 1.</alt-text>
  </inline-graphic>
  <ext-link ext-link-type="uri" xlink:href="word_cloud.png">Figure 1.
  Word cloud.</ext-link></p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/heatmap.png">
    <alt-text>Figure 2.</alt-text>
  </inline-graphic>
  <ext-link ext-link-type="uri" xlink:href="heatmap.png">Figure 2.
  Heatmap.</ext-link></p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/line_plot.png">
    <alt-text>Figure 3.</alt-text>
  </inline-graphic>
  <ext-link ext-link-type="uri" xlink:href="line_plot.png">Figure 3.
  Line plot.</ext-link></p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/sentiment_and_breakpoint_analysis.png">
    <alt-text>Figure 4.</alt-text>
  </inline-graphic>
  <ext-link ext-link-type="uri" xlink:href="sentiment_and_breakpoint_analysis.png">Figure
  4. Sentiment and breakpoint analysis.</ext-link></p>
  <p>The package has more general use for exploratory analysis of
  time-series text datasets, mainly in social sciences. In business
  economics, it improves customer satisfaction measurement through
  product reviews analysis. In politology and behavioral economics, it
  enables detailed text mining of social media interactions. Similarly,
  in finance, it simplifies financial sentiment analysis of news
  headlines.</p>
  <p>Arabica is well-documented: its API reference and comprehensive
  tutorials can be found at https://arabica.readthedocs.io. For easy
  installation, the package is included in the Python Package Index. Its
  code repository and issue tracker are hosted on GitHub at
  https://github.com/PetrKorab/Arabica.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>With Arabica, it is possible to visualize and analyze textual data
  in novel ways. These are some of the package’s distinguishing
  features:</p>
  <p>• Unlike the current packages to perform meta-analysis
  (<xref alt="Balduzzi et al., 2023" rid="ref-BalduzziU003A2023" ref-type="bibr">Balduzzi
  et al., 2023</xref>;
  <xref alt="Mikolajewicz &amp; Komarova, 2019" rid="ref-MikolajewiczU003A2019" ref-type="bibr">Mikolajewicz
  &amp; Komarova, 2019</xref>;
  <xref alt="White, 2017" rid="ref-networkU003A2017" ref-type="bibr">White,
  2017</xref>), the package leverages text mining methods for in-depth
  analysis of research meta-data.</p>
  <p>• Existing text analysis packages, such as Texthero
  (<xref alt="Besomi, 2021" rid="ref-textheroU003A2021" ref-type="bibr">Besomi,
  2021</xref>) and TextBlob
  (<xref alt="Loria, 2021" rid="ref-textblobU003A2021" ref-type="bibr">Loria,
  2021</xref>) provide methods that explicitly focus on cross-sectional
  datasets and datasets without time variation. This perspective
  completely omits the time variability in text data. The time-series
  text approach provides additional insights into the qualitative
  changes in text datasets that are, as such, generated by human
  behavior. It involves the package’s extension of the word cloud graph
  and financial sentiment classification for time-series text
  analysis.</p>
  <p>• While some existing text-processing packages, e.g. Zerrouki
  (<xref alt="2022" rid="ref-pyarabicU003A2022" ref-type="bibr">2022</xref>),
  focus on a specific group of languages, Arabica offers text-mining
  methods for all Latin Alphabet languages, including the stopwords
  removal of 18 lists of stopwords included in the NLTK corpus of
  stopwords.</p>
</sec>
<sec id="dependencies">
  <title>Dependencies</title>
  <p>For most processing operations, Arabica uses data structures and
  methods from Numpy and Pandas
  (<xref alt="McKinney, 2013" rid="ref-McKinneyU003A2013" ref-type="bibr">McKinney,
  2013</xref>). It leverages NLTK for natural language processing
  (<xref alt="Loper &amp; Bird, 2002" rid="ref-LoperU003A2002" ref-type="bibr">Loper
  &amp; Bird, 2002</xref>) and Cleantext
  (<xref alt="Guidiva, 2021" rid="ref-cleantextU003A2021" ref-type="bibr">Guidiva,
  2021</xref>) for data pre-processing. It uses Plotnine
  (<xref alt="Wilkinson, 2005" rid="ref-WilkinsonU003A2005" ref-type="bibr">Wilkinson,
  2005</xref>) and Matplotlib
  (<xref alt="Hunter, 2007" rid="ref-HunterU003A2007" ref-type="bibr">Hunter,
  2007</xref>) for visualization. It also depends on VaderSentiment
  (<xref alt="Hutto &amp; Gilbert, 2014" rid="ref-HuttoU003A2014" ref-type="bibr">Hutto
  &amp; Gilbert, 2014</xref>), FinVADER
  (<xref alt="Koráb, 2023" rid="ref-finvaderU003A2023" ref-type="bibr">Koráb,
  2023</xref>), and Jenkspy
  (<xref alt="Viry, 2023" rid="ref-jenkspyU003A2023" ref-type="bibr">Viry,
  2023</xref>) to implement sentiment and breakpoint analysis of
  general-language and financial texts.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge contributions from Jarko Fidrmuc on empirical
  applications and the visualization design of the library.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-BalduzziU003A2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Balduzzi</surname><given-names>S.</given-names></name>
        <name><surname>Rücker</surname><given-names>G.</given-names></name>
        <name><surname>Nikolakopoulou</surname><given-names>A.</given-names></name>
        <name><surname>Papakonstantinou</surname><given-names>T.</given-names></name>
        <name><surname>Salanti</surname><given-names>G.</given-names></name>
        <name><surname>Efthimiou</surname><given-names>O.</given-names></name>
        <name><surname>Schwarzer</surname><given-names>G.</given-names></name>
      </person-group>
      <article-title>Netmeta: An r package for network meta-analysis using frequentist methods</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2023-03">2023</year><month>03</month>
      <volume>558</volume>
      <uri>https://www.jstatsoft.org/article/view/v106i02</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v106.i02</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-cleantextU003A2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Guidiva</surname><given-names>P.</given-names></name>
      </person-group>
      <article-title>Cleantext—an open-source python package to clean raw text data</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://pypi.org/project/cleantext</uri>
    </element-citation>
  </ref>
  <ref id="ref-finvaderU003A2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Koráb</surname><given-names>P.</given-names></name>
      </person-group>
      <article-title>FinVADER: VADER sentiment classifier updated with financial lexicons</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://pypi.org/project/finvader</uri>
    </element-citation>
  </ref>
  <ref id="ref-HunterU003A2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hunter</surname><given-names>J. D.</given-names></name>
      </person-group>
      <article-title>Matplotlib: A 2D graphics environment</article-title>
      <source>Computing in Science &amp; Engineering</source>
      <year iso-8601-date="2007-03">2007</year><month>03</month>
      <volume>9</volume>
      <uri>https://ieeexplore.ieee.org/document/4160265</uri>
      <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-HuttoU003A2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hutto</surname><given-names>C.</given-names></name>
        <name><surname>Gilbert</surname><given-names>E.</given-names></name>
      </person-group>
      <article-title>VADER: A parsimonious rule-based model for sentiment analysis of social media text</article-title>
      <source>Proceedings of the International AAAI Conference on Web and Social Media</source>
      <year iso-8601-date="2014-01">2014</year><month>01</month>
      <volume>8</volume>
      <uri>https://ojs.aaai.org/index.php/ICWSM/article/view/14550</uri>
      <pub-id pub-id-type="doi">10.1609/icwsm.v8i1.14550</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-JenksU003A1977">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Jenks</surname><given-names>G. F..</given-names></name>
      </person-group>
      <source>Optimal data classification for choropleth maps</source>
      <publisher-name>University of Kansas</publisher-name>
      <year iso-8601-date="1977">1977</year>
      <uri>https://openlibrary.org/books/OL22018775M/Optimal_data_classification_for_choropleth_maps</uri>
    </element-citation>
  </ref>
  <ref id="ref-jenkspyU003A2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Viry</surname><given-names>T.</given-names></name>
      </person-group>
      <article-title>Jenkspy- compute natural breaks Fisher-Jenks algorithm</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://pypi.org/project/jenkspy</uri>
    </element-citation>
  </ref>
  <ref id="ref-LoperU003A2002">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Loper</surname><given-names>E.</given-names></name>
        <name><surname>Bird</surname><given-names>S.</given-names></name>
      </person-group>
      <article-title>NLTK: The natural language toolkit</article-title>
      <source>ArXiv e-prints</source>
      <year iso-8601-date="2002-05">2002</year><month>05</month>
      <uri>https://arxiv.org/abs/cs/0205028</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.cs/0205028</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-McKinneyU003A2013">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>McKinney</surname><given-names>W.</given-names></name>
      </person-group>
      <source>Python for data analysis</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <uri>https://www.oreilly.com/library/view/python-for-data/9781491957653/</uri>
    </element-citation>
  </ref>
  <ref id="ref-MikolajewiczU003A2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mikolajewicz</surname><given-names>N.</given-names></name>
        <name><surname>Komarova</surname><given-names>S. V.</given-names></name>
      </person-group>
      <article-title>Meta-analytic methodology for basic research: A practical guide</article-title>
      <source>Frontiers in Physiology</source>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <volume>106</volume>
      <uri>https://www.frontiersin.org/articles/10.3389/fphys.2019.00203/full</uri>
      <pub-id pub-id-type="doi">10.3389/fphys.2019.00203</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-networkU003A2017">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>White</surname><given-names>I.</given-names></name>
      </person-group>
      <article-title>NETWORK: Stata module to perform network meta-analysis</article-title>
      <source>Boston College Department of Economics Statistical Software Components</source>
      <publisher-name>IDEAS/RePEc</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <uri>https://ideas.repec.org/c/boc/bocode/s458319.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-pyarabicU003A2022">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Zerrouki</surname><given-names>T.</given-names></name>
      </person-group>
      <article-title>PyArabic: A python package for arabic text.</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://pypi.org/project/PyArabic</uri>
      <pub-id pub-id-type="doi">10.21105/joss.04886</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-textheroU003A2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Besomi</surname><given-names>J.</given-names></name>
      </person-group>
      <article-title>Texthero — text preprocessing, representation and visualization from zero to hero.</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://pypi.org/project/texthero</uri>
    </element-citation>
  </ref>
  <ref id="ref-textblobU003A2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Loria</surname><given-names>S.</given-names></name>
      </person-group>
      <article-title>Textblob - simple, pythonic text processing. Sentiment analysis, part-of-speech tagging, noun phrase parsing, and more</article-title>
      <source>Python Package Index</source>
      <publisher-name>PyPI</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://pypi.org/project/textblob</uri>
    </element-citation>
  </ref>
  <ref id="ref-WilkinsonU003A2005">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Wilkinson</surname><given-names>L.</given-names></name>
      </person-group>
      <source>The grammar of graphics</source>
      <publisher-name>Princeton University Press</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <uri>https://link.springer.com/book/10.1007/0-387-28695-0</uri>
      <pub-id pub-id-type="doi">10.1007/0-387-28695-0</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
