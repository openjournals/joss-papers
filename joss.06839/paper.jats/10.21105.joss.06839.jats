<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6839</article-id>
<article-id pub-id-type="doi">10.21105/joss.06839</article-id>
<title-group>
<article-title>AutoRA: Automated Research Assistant for Closed-Loop
Empirical Research</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8896-639X</contrib-id>
<name>
<surname>Musslick</surname>
<given-names>Sebastian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Andrew</surname>
<given-names>Benjamin</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2016-5614</contrib-id>
<name>
<surname>Williams</surname>
<given-names>Chad C.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hewson</surname>
<given-names>Joshua T. S.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0009-7849-1923</contrib-id>
<name>
<surname>Li</surname>
<given-names>Sida</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Marinescu</surname>
<given-names>Ioana</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5264-0489</contrib-id>
<name>
<surname>Dubova</surname>
<given-names>Marina</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-1566-8245</contrib-id>
<name>
<surname>Dang</surname>
<given-names>George T.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3414-2838</contrib-id>
<name>
<surname>Strittmatter</surname>
<given-names>Younes</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6845-8657</contrib-id>
<name>
<surname>Holland</surname>
<given-names>John G.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Brown University, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Osnabrück University, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of Chicago, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Princeton University, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>University of Indiana, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-05-22">
<day>22</day>
<month>5</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>104</issue>
<fpage>6839</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>automated scientific discovery</kwd>
<kwd>symbolic regression</kwd>
<kwd>active learning</kwd>
<kwd>closed-loop behavioral science</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Automated Research Assistant (<monospace>autora</monospace>) is a
  Python package for automating and integrating empirical research
  processes, such as experimental design, data collection, and model
  discovery. With this package, users can define an empirical research
  problem and specify the methods they want to employ for solving it.
  <monospace>autora</monospace> is designed as a declarative language in
  that it provides a vocabulary and set of abstractions to describe and
  execute scientific processes and to integrate them into a closed-loop
  system for scientific discovery. The package interfaces with other
  tools for automating scientific practices, such as
  <monospace>scikit-learn</monospace> for model discovery,
  <monospace>sweetpea</monospace> and <monospace>sweetbean</monospace>
  for experimental design, <monospace>firebase_admin</monospace> for
  executing web-based experiments, and <monospace>autodoc</monospace>
  for documenting the empirical research process. While initially
  developed for the behavioral sciences, <monospace>autora</monospace>
  is designed as a general framework for closed-loop scientific
  discovery, with applications in other empirical disciplines. Use cases
  of <monospace>autora</monospace> include the execution of closed-loop
  empirical studies
  (<xref alt="Musslick et al., 2024" rid="ref-musslick2024" ref-type="bibr">Musslick
  et al., 2024</xref>), the benchmarking of scientific discovery
  algorithms
  (<xref alt="Hewson et al., 2023" rid="ref-hewson_bayesian_2023" ref-type="bibr">Hewson
  et al., 2023</xref>;
  <xref alt="Weinhardt et al., 2024" rid="ref-weinhardt2024computational" ref-type="bibr">Weinhardt
  et al., 2024</xref>), and the implementation of metascientific studies
  (<xref alt="Musslick et al., 2023" rid="ref-musslick_evaluation_2023" ref-type="bibr">Musslick
  et al., 2023</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The pace of empirical research is constrained by the rate at which
  scientists can alternate between the design and execution of
  experiments, on the one hand, and the derivation of scientific
  knowledge, on the other hand
  (<xref alt="Musslick et al., in press" rid="ref-musslick2024perspective" ref-type="bibr">Musslick
  et al., in press</xref>). However, attempts to increase this rate can
  compromise scientific rigor, leading to lower quality of formal
  modeling, insufficient documentation, and non-replicable findings.
  <monospace>autora</monospace> aims to surmount these limitations by
  formalizing the empirical research process and automating the
  generation, estimation, and empirical testing of scientific models. By
  providing a declarative language for empirical research,
  <monospace>autora</monospace> offers greater transparency and rigor in
  empirical research while accelerating scientific discovery. While
  existing scientific computing packages solve individual aspects of
  empirical research, there is no workflow mechanic for integrating them
  into a single pipeline, e.g., to enable closed-loop experiments.
  <monospace>autora</monospace> offers such a workflow mechanic,
  integrating Python packages for automating specific aspects of the
  empirical research process.</p>
  <fig>
    <caption><p>The <monospace>autora</monospace> framework illustrated
    for closed-loop behavioral research. (A) Exemplary
    <monospace>autora</monospace> workflow.
    <monospace>autora</monospace> implements components (colored boxes;
    see text) that can be integrated into a closed-loop discovery
    process. Workflows expressed in <monospace>autora</monospace> depend
    on modules for individual scientific tasks, such as designing
    behavioral experiments, executing those experiments, and analyzing
    collected data. (B) <monospace>autora</monospace>’s components
    acting on the state object. The state object maintains relevant
    scientific data, such as experimental conditions X, observations Y,
    and models, and can be modified by <monospace>autora</monospace>
    components. Here, the cycle begins with an experimentalist adding
    experimental conditions <inline-formula><alternatives>
    <tex-math><![CDATA[x_1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
    to the state. The experiment runner then executes the experiment and
    collects corresponding observations <inline-formula><alternatives>
    <tex-math><![CDATA[y_1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>.
    The cycle concludes with the theorist computing a model that relates
    <inline-formula><alternatives>
    <tex-math><![CDATA[x_1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
    to <inline-formula><alternatives>
    <tex-math><![CDATA[y_1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>.<styled-content id="figU003Aoverview"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figure.png" />
  </fig>
</sec>
<sec id="overview-and-components">
  <title>Overview and Components</title>
  <p>The <monospace>autora</monospace> framework implements and
  interfaces with components automating different phases of the
  empirical research process
  (<xref alt="[fig:overview]" rid="figU003Aoverview">[fig:overview]</xref>A).
  These components include <italic>experimentalists</italic> for
  automating experimental design, <italic>experiment runners</italic>
  for automating data collection, and <italic>theorists</italic> for
  automating scientific model discovery. To illustrate each component,
  we consider an exemplary behavioral research study
  (cf. <xref alt="[fig:overview]" rid="figU003Aoverview">[fig:overview]</xref>)
  that examines the probability of human participants detecting a visual
  stimulus as a function of its luminosity.</p>
  <p><italic>Experimentalist</italic> components take the role of a
  research design expert, determining the next iteration of experiments
  to be conducted. Experimentalists are functions that identify
  experimental conditions which can be subjected to measurement by
  experiment runners, such as different levels of stimulus luminosity.
  To determine these conditions, experimentalists may use information
  about candidate models obtained from theorist components, experimental
  conditions that have already been probed, or respective observations.
  The <monospace>autora</monospace> framework offers various
  experimentalist packages, each for determining new conditions based
  on, for example, novelty, prediction uncertainty, or model
  disagreement
  (<xref alt="Dubova et al., 2022" rid="ref-dubova_against_2022" ref-type="bibr">Dubova
  et al., 2022</xref>;
  <xref alt="Musslick et al., 2023" rid="ref-musslick_evaluation_2023" ref-type="bibr">Musslick
  et al., 2023</xref>).</p>
  <p><italic>Experiment runner</italic> components correspond to
  research technicians collecting data from an experiment. They are
  implemented as functions that accept experimental conditions as input
  (e.g., a <monospace>pandas</monospace> dataframe with columns
  representing different experimental variables) and produce collected
  observations as output (e.g., a <monospace>pandas</monospace>
  dataframe with columns representing different experimental variables
  along with corresponding measurements). <monospace>autora</monospace>
  (4.2.0) provides experiment runners for two types of automated data
  collection: real-world and synthetic. Real-world experiment runners
  include interfaces for collecting data in the real world. For example,
  the <monospace>autora</monospace> framework offers experiment runners
  for automating the data collection from web-based experiments for
  behavioral research studies
  (<xref alt="Musslick et al., 2024" rid="ref-musslick2024" ref-type="bibr">Musslick
  et al., 2024</xref>). In the behavioral experiment described above, an
  experiment runner may set up a web-based experiment that measures the
  probability of human participants detecting visual stimuli with
  varying luminosities. These runners interface with external components
  including recruitment platforms (e.g, Prolific; Palan &amp; Schitter
  (<xref alt="2018" rid="ref-palan_prolific_2018" ref-type="bibr">2018</xref>))
  for coordinating the recruitment of participants, databases (e.g.,
  Google Firestore) for storing collected observations, and web servers
  for hosting the experiments (e.g., Google Firebase). Synthetic
  experiment runners act as simulators for real-world experiments: they
  specify the data-generating process and collect observations from it.
  For example, <monospace>autora-synthetic</monospace> implements
  established models of human information processing (e.g, for
  perceptual discrimination) and conducts experiments on them. These
  synthetic experiments serve multiple purposes, such as testing and
  benchmarking <monospace>autora</monospace> components before applying
  them in the real-world
  (<xref alt="Musslick et al., 2024" rid="ref-musslick2024" ref-type="bibr">Musslick
  et al., 2024</xref>) or conducting computational metascience studies
  (<xref alt="Musslick et al., 2023" rid="ref-musslick_evaluation_2023" ref-type="bibr">Musslick
  et al., 2023</xref>).</p>
  <p><italic>Theorist</italic> components embody the role of a
  computational scientist, employing modeling techniques to find a model
  that best characterizes, predicts, and/or explains the study’s
  observations. Theorists may identify different types of scientific
  models (e.g., statistical, mathematical, or computational) implemented
  as <monospace>scikit-learn</monospace> estimators
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa2011scikit" ref-type="bibr">Pedregosa
  et al., 2011</xref>). In case of the behavioral research study, a
  model may correspond to a psychophysical law relating stimulus
  luminosity to the probability of detecting the stimulus.
  <monospace>autora</monospace> provides interfaces for various equation
  discovery methods that are implemented as
  <monospace>scikit-learn</monospace> estimators, such as deep symbolic
  regression
  (<xref alt="Landajuela et al., 2022" rid="ref-landajuela_unified_2022" ref-type="bibr">Landajuela
  et al., 2022</xref>;
  <xref alt="Petersen et al., 2021" rid="ref-petersen2021deep" ref-type="bibr">Petersen
  et al., 2021</xref>), <monospace>PySR</monospace>
  (<xref alt="Cranmer et al., 2020" rid="ref-cranmer_discovering_2020" ref-type="bibr">Cranmer
  et al., 2020</xref>), and the Bayesian Machine Scientist
  (<xref alt="Guimerà et al., 2020" rid="ref-guimera_bayesian_2020" ref-type="bibr">Guimerà
  et al., 2020</xref>;
  <xref alt="Hewson et al., 2023" rid="ref-hewson_bayesian_2023" ref-type="bibr">Hewson
  et al., 2023</xref>). Alternatively, a model may correspond to a
  fine-tuned large language model
  (<xref alt="Binz et al., 2024" rid="ref-binz2024centaur" ref-type="bibr">Binz
  et al., 2024</xref>), enabling its automated alignment with human
  behavior from web-based experiments. A model is generated by fitting
  experimental data. Accordingly, theorists take as input a
  <monospace>pandas</monospace> dataframe specifying experimental
  conditions (instances of experimental variables) along with
  corresponding observations to fit a respective model. The model can
  then be used to generate predictions, e.g., to inform the design of a
  subsequent experiment.</p>
</sec>
<sec id="design-principles-and-packaging">
  <title>Design Principles and Packaging</title>
  <p><monospace>autora</monospace> was designed as a general framework
  aimed at democratizing the automation of empirical research across the
  scientific community. Key design decisions were: 1) using a functional
  paradigm for the components and 2) splitting components across Python
  namespace packages.</p>
  <p>Each component is a function that operates on immutable “state
  objects” which represent data from an experiment
  (<xref alt="[fig:overview]" rid="figU003Aoverview">[fig:overview]</xref>B),
  such as proposed experimental conditions, corresponding observations
  (represented as a <monospace>pandas</monospace> dataframe), and
  scientific models (represented as a list of
  <monospace>scikit-learn</monospace> estimators). Data produced by each
  component can be seen as additions to the existing data stored in the
  state. Thus, each component <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  takes in existing data in a state <inline-formula><alternatives>
  <tex-math><![CDATA[S]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>S</mml:mi></mml:math></alternatives></inline-formula>,
  adds new data <inline-formula><alternatives>
  <tex-math><![CDATA[\Delta S]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
  and returns an updated state <inline-formula><alternatives>
  <tex-math><![CDATA[S']]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>S</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,</p>
  <p><disp-formula><alternatives>
  <tex-math><![CDATA[
  S' = C(S) = S + \Delta S.
  ]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>S</mml:mi><mml:mi>′</mml:mi><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>S</mml:mi><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>Accordingly, the components share their interface – every component
  loads data from and saves data to state objects, so they can be
  ordered arbitrarily, and adding a new component is as simple as
  implementing a new function or
  <monospace>scikit-learn</monospace>-compatible estimator and wrapping
  it with a utility function provided in
  <monospace>autora-core</monospace>. State immutability allows for easy
  parallelism and reproducibility (so long as the components themselves
  have no hidden state).</p>
  <p>The <monospace>autora</monospace> framework presumes that each
  component is distributed as a separate package but in a shared
  namespace, and that <monospace>autora-core</monospace> – which
  provides the state – has very few dependencies of its own. For users,
  separate packages minimize the time and storage required for an
  install of an <monospace>autora</monospace> project. For contributors,
  they reduce incidence of dependency conflicts (a common problem for
  projects with many dependencies) by reducing the likelihood that the
  library they need has an existing conflict in
  <monospace>autora</monospace>. It also allows contributors to
  independently develop and maintain modules, fostering ownership of and
  responsibility for their contributions. External contributors can
  request to have packages vetted and included as an optional dependency
  in the <monospace>autora</monospace> package.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The AutoRA framework is developed and maintained by members of the
  Autonomous Empirical Research Group. S. M., B. A., C. C. W., J. T. S.
  H., and Y. S. were supported by the Carney BRAINSTORM program at Brown
  University. S. M. also received support from Schmidt Science Fellows,
  in partnership with the Rhodes Trust. The development of auxiliary
  packages for AutoRA, such as <monospace>autodoc</monospace> or
  <monospace>autora-experiment-server</monospace>, is supported by the
  Virtual Institute for Scientific Software (VISS) as part of Schmidt
  Sciences, LLC. The AutoRA package was developed using computational
  resources and services at the Center for Computation and
  Visualization, Brown University.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-hewson_bayesian_2023">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hewson</surname><given-names>Joshua</given-names></name>
        <name><surname>Strittmatter</surname><given-names>Younes</given-names></name>
        <name><surname>Marinescu</surname><given-names>Ioana</given-names></name>
        <name><surname>Williams</surname><given-names>Chad</given-names></name>
        <name><surname>Musslick</surname><given-names>Sebastian</given-names></name>
      </person-group>
      <article-title>Bayesian machine scientist for model discovery in psychology</article-title>
      <source>NeurIPS 2023 AI for science workshop</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://openreview.net/forum?id=XHFfvzlQ1n</uri>
    </element-citation>
  </ref>
  <ref id="ref-musslick_evaluation_2023">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Musslick</surname><given-names>Sebastian</given-names></name>
        <name><surname>Hewson</surname><given-names>Joshua TS</given-names></name>
        <name><surname>Andrew</surname><given-names>Benjamin W</given-names></name>
        <name><surname>Strittmatter</surname><given-names>Younes</given-names></name>
        <name><surname>Williams</surname><given-names>Chad C</given-names></name>
        <name><surname>Dang</surname><given-names>George T</given-names></name>
        <name><surname>Dubova</surname><given-names>Marina</given-names></name>
        <name><surname>Holland</surname><given-names>John Gerrard</given-names></name>
      </person-group>
      <article-title>An evaluation of experimental sampling strategies for autonomous empirical research in cognitive science</article-title>
      <year iso-8601-date="2023">2023</year>
      <volume>45</volume>
      <fpage>1386</fpage>
      <lpage>1392</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dubova_against_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dubova</surname><given-names>Marina</given-names></name>
        <name><surname>Moskvichev</surname><given-names>Arseny</given-names></name>
        <name><surname>Zollman</surname><given-names>Kevin</given-names></name>
      </person-group>
      <article-title>Against theory-motivated experimentation in science</article-title>
      <source>MetaArXiv</source>
      <year iso-8601-date="2022">2022</year>
      <volume>24</volume>
      <pub-id pub-id-type="doi">10.31222/osf.io/ysv2u</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-palan_prolific_2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Palan</surname><given-names>Stefan</given-names></name>
        <name><surname>Schitter</surname><given-names>Christian</given-names></name>
      </person-group>
      <article-title>Prolific. Ac—A subject pool for online experiments</article-title>
      <source>Journal of Behavioral and Experimental Finance</source>
      <year iso-8601-date="2018">2018</year>
      <volume>17</volume>
      <issn>2214-6350</issn>
      <pub-id pub-id-type="doi">10.1016/j.jbef.2017.12.004</pub-id>
      <fpage>22</fpage>
      <lpage>27</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pedregosa2011scikit">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>Varoquaux</surname><given-names>Gaël</given-names></name>
        <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
        <name><surname>Michel</surname><given-names>Vincent</given-names></name>
        <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
        <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
        <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
        <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
        <name><surname>Weiss</surname><given-names>Ron</given-names></name>
        <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Scikit-learn: Machine learning in Python</article-title>
      <source>Journal of Machine Learning Research</source>
      <publisher-name>JMLR. org</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>12</volume>
      <fpage>2825</fpage>
      <lpage>2830</lpage>
    </element-citation>
  </ref>
  <ref id="ref-petersen2021deep">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Petersen</surname><given-names>Brenden K</given-names></name>
        <name><surname>Larma</surname><given-names>Mikel Landajuela</given-names></name>
        <name><surname>Mundhenk</surname><given-names>Terrell N.</given-names></name>
        <name><surname>Santiago</surname><given-names>Claudio Prata</given-names></name>
        <name><surname>Kim</surname><given-names>Soo Kyung</given-names></name>
        <name><surname>Kim</surname><given-names>Joanne Taery</given-names></name>
      </person-group>
      <article-title>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://openreview.net/forum?id=m5Qsh0kBQG</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.04871</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-binz2024centaur">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Binz</surname><given-names>Marcel</given-names></name>
        <name><surname>Akata</surname><given-names>Elif</given-names></name>
        <name><surname>Bethge</surname><given-names>Matthias</given-names></name>
        <name><surname>Brändle</surname><given-names>Franziska</given-names></name>
        <name><surname>Callaway</surname><given-names>Fred</given-names></name>
        <name><surname>Coda-Forno</surname><given-names>Julian</given-names></name>
        <name><surname>Dayan</surname><given-names>Peter</given-names></name>
        <name><surname>Demircan</surname><given-names>Can</given-names></name>
        <name><surname>Eckstein</surname><given-names>Maria K</given-names></name>
        <name><surname>Éltető</surname><given-names>Noémi</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Centaur: A foundation model of human cognition</article-title>
      <source>arXiv preprint arXiv:2410.20268</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2410.20268</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-weinhardt2024computational">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Weinhardt</surname><given-names>Daniel</given-names></name>
        <name><surname>Eckstein</surname><given-names>Maria K</given-names></name>
        <name><surname>Musslick</surname><given-names>Sebastian</given-names></name>
      </person-group>
      <article-title>Computational discovery of human reinforcement learning dynamics from choice behavior</article-title>
      <source>NeurIPS 2024 workshop on behavioral machine learning</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://openreview.net/forum?id=x2WDZrpgmB</uri>
    </element-citation>
  </ref>
  <ref id="ref-landajuela_unified_2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Landajuela</surname><given-names>Mikel</given-names></name>
        <name><surname>Lee</surname><given-names>Chak Shing</given-names></name>
        <name><surname>Yang</surname><given-names>Jiachen</given-names></name>
        <name><surname>Glatt</surname><given-names>Ruben</given-names></name>
        <name><surname>Santiago</surname><given-names>Claudio P</given-names></name>
        <name><surname>Aravena</surname><given-names>Ignacio</given-names></name>
        <name><surname>Mundhenk</surname><given-names>Terrell</given-names></name>
        <name><surname>Mulcahy</surname><given-names>Garrett</given-names></name>
        <name><surname>Petersen</surname><given-names>Brenden K</given-names></name>
      </person-group>
      <article-title>A unified framework for deep symbolic regression</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Koyejo</surname><given-names>S.</given-names></name>
        <name><surname>Mohamed</surname><given-names>S.</given-names></name>
        <name><surname>Agarwal</surname><given-names>A.</given-names></name>
        <name><surname>Belgrave</surname><given-names>D.</given-names></name>
        <name><surname>Cho</surname><given-names>K.</given-names></name>
        <name><surname>Oh</surname><given-names>A.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>35</volume>
      <uri>https://proceedings.neurips.cc/paper_files/paper/2022/file/dbca58f35bddc6e4003b2dd80e42f838-Paper-Conference.pdf</uri>
      <fpage>33985</fpage>
      <lpage>33998</lpage>
    </element-citation>
  </ref>
  <ref id="ref-musslick2024perspective">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Musslick</surname><given-names>Sebastian</given-names></name>
        <name><surname>Bartlett</surname><given-names>Laura K.</given-names></name>
        <name><surname>Chandramouli</surname><given-names>Suyog H.</given-names></name>
        <name><surname>Dubova</surname><given-names>Marina</given-names></name>
        <name><surname>Gobet</surname><given-names>Fernand</given-names></name>
        <name><surname>Griffiths</surname><given-names>Thomas L.</given-names></name>
        <name><surname>Hullman</surname><given-names>Jessica</given-names></name>
        <name><surname>King</surname><given-names>Ross D.</given-names></name>
        <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
        <name><surname>Lucas</surname><given-names>Christopher G.</given-names></name>
        <name><surname>Mahesh</surname><given-names>Suhas</given-names></name>
        <name><surname>Pestilli</surname><given-names>Franco</given-names></name>
        <name><surname>Sloman</surname><given-names>Sabina J.</given-names></name>
        <name><surname>Holmes</surname><given-names>William R.</given-names></name>
      </person-group>
      <article-title>Automating the practice of science–opportunities, challenges, and implications</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
    </element-citation>
  </ref>
  <ref id="ref-cranmer_discovering_2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cranmer</surname><given-names>Miles</given-names></name>
        <name><surname>Sanchez Gonzalez</surname><given-names>Alvaro</given-names></name>
        <name><surname>Battaglia</surname><given-names>Peter</given-names></name>
        <name><surname>Xu</surname><given-names>Rui</given-names></name>
        <name><surname>Cranmer</surname><given-names>Kyle</given-names></name>
        <name><surname>Spergel</surname><given-names>David</given-names></name>
        <name><surname>Ho</surname><given-names>Shirley</given-names></name>
      </person-group>
      <article-title>Discovering symbolic models from deep learning with inductive biases</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2020">2020</year>
      <volume>33</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.2006.11287</pub-id>
      <fpage>17429</fpage>
      <lpage>17442</lpage>
    </element-citation>
  </ref>
  <ref id="ref-guimera_bayesian_2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Guimerà</surname><given-names>Roger</given-names></name>
        <name><surname>Reichardt</surname><given-names>Ignasi</given-names></name>
        <name><surname>Aguilar-Mogas</surname><given-names>Antoni</given-names></name>
        <name><surname>Massucci</surname><given-names>Francesco A</given-names></name>
        <name><surname>Miranda</surname><given-names>Manuel</given-names></name>
        <name><surname>Pallarès</surname><given-names>Jordi</given-names></name>
        <name><surname>Sales-Pardo</surname><given-names>Marta</given-names></name>
      </person-group>
      <article-title>A Bayesian machine scientist to aid in the solution of challenging scientific problems</article-title>
      <source>Science advances</source>
      <year iso-8601-date="2020">2020</year>
      <volume>6</volume>
      <issue>5</issue>
      <issn>2375-2548</issn>
      <pub-id pub-id-type="doi">10.1126/sciadv.aav6971</pub-id>
      <fpage>eaav6971</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-musslick2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Musslick</surname><given-names>Sebastian</given-names></name>
        <name><surname>Strittmatter</surname><given-names>Younes</given-names></name>
        <name><surname>Dubova</surname><given-names>Marina</given-names></name>
      </person-group>
      <article-title>Closed-loop scientific discovery in the behavioral sciences</article-title>
      <publisher-name>PsyArXiv</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.31234/osf.io/c2ytb</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
