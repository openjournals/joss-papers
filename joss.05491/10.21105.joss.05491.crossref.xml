<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20230731T224315-b20c4b756e9be04f07a9fee2fd14309ddf982aa7</doi_batch_id>
    <timestamp>20230731224315</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>07</month>
          <year>2023</year>
        </publication_date>
        <journal_volume>
          <volume>8</volume>
        </journal_volume>
        <issue>87</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>ViMag: A Visual Vibration Analysis Toolbox</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Ricard</given_name>
            <surname>Lado-Roigé</surname>
            <ORCID>https://orcid.org/0000-0002-6421-7351</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Marco A.</given_name>
            <surname>Pérez</surname>
            <ORCID>https://orcid.org/0000-0003-4140-1823</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>07</month>
          <day>31</day>
          <year>2023</year>
        </publication_date>
        <pages>
          <first_page>5491</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.05491</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.8199675</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/5491</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.05491</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.05491</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.05491.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="LADOROIGE2022112218">
            <article_title>Learning-based video motion magnification
approach for vibration-based damage detection</article_title>
            <author>Lado-Roigé</author>
            <journal_title>Measurement</journal_title>
            <doi>10.1016/j.measurement.2022.112218</doi>
            <issn>0263-2241</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Lado-Roigé, R., Font-Moré, J., &amp;
Pérez, M. A. (2022). Learning-based video motion magnification approach
for vibration-based damage detection. Measurement, 112218.
https://doi.org/10.1016/j.measurement.2022.112218</unstructured_citation>
          </citation>
          <citation key="lado2022_STB-VMM">
            <article_title>STB-VMM: Swin transformer based video motion
magnification</article_title>
            <author>Lado-Roigé</author>
            <journal_title>Knowledge-Based Systems</journal_title>
            <doi>10.1016/j.knosys.2023.110493</doi>
            <issn>0950-7051</issn>
            <cYear>2023</cYear>
            <unstructured_citation>Lado-Roigé, R., &amp; Pérez, M. A.
(2023). STB-VMM: Swin transformer based video motion magnification.
Knowledge-Based Systems, 110493.
https://doi.org/10.1016/j.knosys.2023.110493</unstructured_citation>
          </citation>
          <citation key="oh_learning-based_2018">
            <article_title>Learning-based video motion
magnification</article_title>
            <author>Oh</author>
            <doi>10.48550/arXiv.1804.02684</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Oh, T.-H., Jaroensri, R., Kim, C.,
Elgharib, M., Durand, F., Freeman, W. T., &amp; Matusik, W. (2018).
Learning-based video motion magnification.
https://doi.org/10.48550/arXiv.1804.02684</unstructured_citation>
          </citation>
          <citation key="MOLINAVIEDMA2018245">
            <article_title>High frequency mode shapes characterisation
using digital image correlation and phase-based motion
magnification</article_title>
            <author>Molina-Viedma</author>
            <journal_title>Mech. Syst. Sig. Process.</journal_title>
            <volume>102</volume>
            <doi>10.1016/j.ymssp.2017.09.019</doi>
            <issn>0888-3270</issn>
            <cYear>2018</cYear>
            <unstructured_citation>Molina-Viedma, A. J., Felipe-Sesé,
L., López-Alba, E., &amp; Díaz, F. (2018). High frequency mode shapes
characterisation using digital image correlation and phase-based motion
magnification. Mech. Syst. Sig. Process., 102, 245–261.
https://doi.org/10.1016/j.ymssp.2017.09.019</unstructured_citation>
          </citation>
          <citation key="EITNER2021106995">
            <article_title>Effect of broad-band phase-based motion
magnification on modal parameter estimation</article_title>
            <author>Eitner</author>
            <journal_title>Mechanical Systems and Signal
Processing</journal_title>
            <volume>146</volume>
            <doi>10.1016/j.ymssp.2020.106995</doi>
            <issn>0888-3270</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Eitner, M., Miller, B., Sirohi, J.,
&amp; Tinney, C. (2021). Effect of broad-band phase-based motion
magnification on modal parameter estimation. Mechanical Systems and
Signal Processing, 146, 106995.
https://doi.org/10.1016/j.ymssp.2020.106995</unstructured_citation>
          </citation>
          <citation key="10.1145/2601097.2601119">
            <article_title>The visual microphone: Passive recovery of
sound from video</article_title>
            <author>Davis</author>
            <journal_title>ACM Trans. Graph.</journal_title>
            <issue>4</issue>
            <volume>33</volume>
            <doi>10.1145/2601097.2601119</doi>
            <issn>0730-0301</issn>
            <cYear>2014</cYear>
            <unstructured_citation>Davis, A., Rubinstein, M., Wadhwa,
N., Mysore, G. J., Durand, F., &amp; Freeman, W. T. (2014). The visual
microphone: Passive recovery of sound from video. ACM Trans. Graph.,
33(4). https://doi.org/10.1145/2601097.2601119</unstructured_citation>
          </citation>
          <citation key="frangopol_effects_1987">
            <article_title>Effects of damage and redundancy on
structural reliability</article_title>
            <author>Frangopol</author>
            <journal_title>J. Struct. Eng.</journal_title>
            <issue>7</issue>
            <volume>113</volume>
            <doi>10.1061/(ASCE)0733-9445(1987)113:7(1533)</doi>
            <issn>0733-9445</issn>
            <cYear>1987</cYear>
            <unstructured_citation>Frangopol, D. M., &amp; Curley, J. P.
(1987). Effects of damage and redundancy on structural reliability. J.
Struct. Eng., 113(7), 1533–1549.
https://doi.org/10.1061/(ASCE)0733-9445(1987)113:7(1533)</unstructured_citation>
          </citation>
          <citation key="cosenza_damage_2000">
            <article_title>Damage indices and damage
measures</article_title>
            <author>Cosenza</author>
            <journal_title>Prog. in Struct. Eng. Mater.s</journal_title>
            <issue>1</issue>
            <volume>2</volume>
            <doi>10.1002/(SICI)1528-2716(200001/03)2:1&lt;50::AID-PSE7&gt;3.0.CO;2-S</doi>
            <issn>1365-0556</issn>
            <cYear>2000</cYear>
            <unstructured_citation>Cosenza, E., &amp; Manfredi, G.
(2000). Damage indices and damage measures. Prog. In Struct. Eng.
Mater.s, 2(1), 50–59.
https://doi.org/10.1002/(SICI)1528-2716(200001/03)2:1&lt;50::AID-PSE7&gt;3.0.CO;2-S</unstructured_citation>
          </citation>
          <citation key="NEURIPS2019_9015">
            <article_title>PyTorch: An imperative style,
high-performance deep learning library</article_title>
            <author>Paszke</author>
            <journal_title>Advances in neural information processing
systems 32</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Paszke, A., Gross, S., Massa, F.,
Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein,
N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison,
M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., … Chintala, S.
(2019). PyTorch: An imperative style, high-performance deep learning
library. In Advances in neural information processing systems 32 (pp.
8024–8035). Curran Associates, Inc.
http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</unstructured_citation>
          </citation>
          <citation key="ViT">
            <article_title>An image is worth 16x16 words: Transformers
for image recognition at scale</article_title>
            <author>Dosovitskiy</author>
            <doi>10.48550/ARXIV.2010.11929</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Dosovitskiy, A., Beyer, L.,
Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani,
M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., &amp; Houlsby,
N. (2020). An image is worth 16x16 words: Transformers for image
recognition at scale.
https://doi.org/10.48550/ARXIV.2010.11929</unstructured_citation>
          </citation>
          <citation key="Vaswani2017AttentionIA">
            <article_title>Attention is all you need</article_title>
            <author>Vaswani</author>
            <doi>10.48550/ARXIV.1706.03762</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Vaswani, A., Shazeer, N., Parmar, N.,
Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I.
(2017). Attention is all you need.
https://doi.org/10.48550/ARXIV.1706.03762</unstructured_citation>
          </citation>
          <citation key="SWIN">
            <article_title>Swin transformer: Hierarchical vision
transformer using shifted windows</article_title>
            <author>Liu</author>
            <doi>10.48550/ARXIV.2103.14030</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Liu, Z., Lin, Y., Cao, Y., Hu, H.,
Wei, Y., Zhang, Z., Lin, S., &amp; Guo, B. (2021). Swin transformer:
Hierarchical vision transformer using shifted windows.
https://doi.org/10.48550/ARXIV.2103.14030</unstructured_citation>
          </citation>
          <citation key="10.1007/978-3-030-59716-0_34">
            <article_title>Surgical video motion magnification with
suppression of instrument artefacts</article_title>
            <author>Janatka</author>
            <journal_title>Medical image computing and computer assisted
intervention – MICCAI 2020</journal_title>
            <doi>10.48550/arXiv.2009.07432</doi>
            <isbn>978-3-030-59716-0</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Janatka, M., Marcus, H. J., Dorward,
N. L., &amp; Stoyanov, D. (2020). Surgical video motion magnification
with suppression of instrument artefacts. Medical Image Computing and
Computer Assisted Intervention – MICCAI 2020, 353–363.
https://doi.org/10.48550/arXiv.2009.07432</unstructured_citation>
          </citation>
          <citation key="liu_motion_2005">
            <article_title>Motion magnification</article_title>
            <author>Liu</author>
            <journal_title>ACM SIGGRAPH 2005 papers</journal_title>
            <doi>10.1145/1186822.1073223</doi>
            <isbn>9781450378253</isbn>
            <cYear>2005</cYear>
            <unstructured_citation>Liu, C., Torralba, A., Freeman, W.
T., Durand, F., &amp; Adelson, E. H. (2005). Motion magnification. ACM
SIGGRAPH 2005 Papers, 519–526.
https://doi.org/10.1145/1186822.1073223</unstructured_citation>
          </citation>
          <citation key="wu_eulerian_2012">
            <article_title>Eulerian video magnification for revealing
subtle changes in the world</article_title>
            <author>Wu</author>
            <journal_title>ACM Trans. Graph.</journal_title>
            <doi>10.1145/2185520.2185561</doi>
            <cYear>2012</cYear>
            <unstructured_citation>Wu, H.-Y., Rubinstein, M., Shih, E.,
Guttag, J., Durand, F., &amp; Freeman, W. (2012). Eulerian video
magnification for revealing subtle changes in the world. ACM Trans.
Graph. https://doi.org/10.1145/2185520.2185561</unstructured_citation>
          </citation>
          <citation key="wadhwa_riesz_2014">
            <article_title>Riesz pyramids for fast phase-based video
magnification</article_title>
            <author>Wadhwa</author>
            <journal_title>2014 IEEE ICCP</journal_title>
            <doi>10.1109/ICCPHOT.2014.6831820</doi>
            <isbn>978-1-4799-5188-8</isbn>
            <cYear>2014</cYear>
            <unstructured_citation>Wadhwa, N., Rubinstein, M., Durand,
F., &amp; Freeman, W. (2014). Riesz pyramids for fast phase-based video
magnification. 2014 IEEE ICCP, 1–10.
https://doi.org/10.1109/ICCPHOT.2014.6831820</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
