<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20241022171747-32e32d48c9a025fa55f29ec9bb02f572e4949832</doi_batch_id>
    <timestamp>20241022171747</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>102</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>ReLax: Efficient and Scalable Recourse Explanation
Benchmarking using JAX</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Hangzhi</given_name>
            <surname>Guo</surname>
            <ORCID>https://orcid.org/0009-0000-6277-9003</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Xinchang</given_name>
            <surname>Xiong</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Wenbo</given_name>
            <surname>Zhang</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Amulya</given_name>
            <surname>Yadav</surname>
            <ORCID>https://orcid.org/0009-0005-4638-9140</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>22</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>6567</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06567</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.13957805</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6567</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06567</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06567</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06567.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="ustun2019actionable">
            <article_title>Actionable recourse in linear
classification</article_title>
            <author>Ustun</author>
            <journal_title>Proceedings of the conference on fairness,
accountability, and transparency</journal_title>
            <doi>10.1145/3287560.3287566</doi>
            <isbn>9781450361255</isbn>
            <cYear>2019</cYear>
            <unstructured_citation>Ustun, B., Spangher, A., &amp; Liu,
Y. (2019). Actionable recourse in linear classification. Proceedings of
the Conference on Fairness, Accountability, and Transparency, 10–19.
https://doi.org/10.1145/3287560.3287566</unstructured_citation>
          </citation>
          <citation key="wachter2017counterfactual">
            <article_title>Counterfactual explanations without opening
the black box: Automated decisions and the GDPR</article_title>
            <author>Wachter</author>
            <journal_title>Cybersecurity</journal_title>
            <doi>10.2139/ssrn.3063289</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Wachter, S., Mittelstadt, B., &amp;
Russell, C. (2017). Counterfactual explanations without opening the
black box: Automated decisions and the GDPR. Cybersecurity.
https://doi.org/10.2139/ssrn.3063289</unstructured_citation>
          </citation>
          <citation key="verma2020counterfactual">
            <article_title>Counterfactual explanations for machine
learning: A review</article_title>
            <author>Verma</author>
            <journal_title>arXiv preprint
arXiv:2010.10596</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Verma, S., Dickerson, J., &amp;
Hines, K. (2020). Counterfactual explanations for machine learning: A
review. arXiv Preprint arXiv:2010.10596.</unstructured_citation>
          </citation>
          <citation key="stepin2021survey">
            <article_title>A survey of contrastive and counterfactual
explanation generation methods for explainable artificial
intelligence</article_title>
            <author>Stepin</author>
            <journal_title>IEEE Access</journal_title>
            <volume>9</volume>
            <doi>10.1109/ACCESS.2021.3051315</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Stepin, I., Alonso, J. M., Catala,
A., &amp; Pereira-Fariña, M. (2021). A survey of contrastive and
counterfactual explanation generation methods for explainable artificial
intelligence. IEEE Access, 9, 11974–12001.
https://doi.org/10.1109/ACCESS.2021.3051315</unstructured_citation>
          </citation>
          <citation key="karimi2020survey">
            <article_title>A survey of algorithmic recourse: Contrastive
explanations and consequential recommendations</article_title>
            <author>Karimi</author>
            <journal_title>ACM Comput. Surv.</journal_title>
            <issue>5</issue>
            <volume>55</volume>
            <doi>10.1145/3527848</doi>
            <issn>0360-0300</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Karimi, A.-H., Barthe, G., Schölkopf,
B., &amp; Valera, I. (2022). A survey of algorithmic recourse:
Contrastive explanations and consequential recommendations. ACM Comput.
Surv., 55(5). https://doi.org/10.1145/3527848</unstructured_citation>
          </citation>
          <citation key="binns2018s">
            <article_title>’It’s reducing a human being to a
percentage’: Perceptions of justice in algorithmic
decisions</article_title>
            <author>Binns</author>
            <journal_title>Proceedings of the 2018 CHI conference on
human factors in computing systems</journal_title>
            <doi>10.1145/3173574.3173951</doi>
            <isbn>9781450356206</isbn>
            <cYear>2018</cYear>
            <unstructured_citation>Binns, R., Van Kleek, M., Veale, M.,
Lyngs, U., Zhao, J., &amp; Shadbolt, N. (2018). ’It’s reducing a human
being to a percentage’: Perceptions of justice in algorithmic decisions.
Proceedings of the 2018 CHI Conference on Human Factors in Computing
Systems, 1–14.
https://doi.org/10.1145/3173574.3173951</unstructured_citation>
          </citation>
          <citation key="miller2019explanation">
            <article_title>Explanation in artificial intelligence:
Insights from the social sciences</article_title>
            <author>Miller</author>
            <journal_title>Artif. Intell.</journal_title>
            <volume>267</volume>
            <doi>10.1016/J.ARTINT.2018.07.007</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Miller, T. (2019). Explanation in
artificial intelligence: Insights from the social sciences. Artif.
Intell., 267, 1–38.
https://doi.org/10.1016/J.ARTINT.2018.07.007</unstructured_citation>
          </citation>
          <citation key="Bhatt20explainable">
            <article_title>Explainable machine learning in
deployment</article_title>
            <author>Bhatt</author>
            <journal_title>Proceedings of the 2020 conference on
fairness, accountability, and transparency</journal_title>
            <doi>10.1145/3351095.3375624</doi>
            <isbn>9781450369367</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Bhatt, U., Xiang, A., Sharma, S.,
Weller, A., Taly, A., Jia, Y., Ghosh, J., Puri, R., Moura, J. M. F.,
&amp; Eckersley, P. (2020). Explainable machine learning in deployment.
Proceedings of the 2020 Conference on Fairness, Accountability, and
Transparency, 648–657.
https://doi.org/10.1145/3351095.3375624</unstructured_citation>
          </citation>
          <citation key="mothilal2020explaining">
            <article_title>Explaining machine learning classifiers
through diverse counterfactual explanations</article_title>
            <author>Mothilal</author>
            <journal_title>Proceedings of the 2020 conference on
fairness, accountability, and transparency</journal_title>
            <doi>10.1145/3351095.3372850</doi>
            <isbn>9781450369367</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Mothilal, R. K., Sharma, A., &amp;
Tan, C. (2020). Explaining machine learning classifiers through diverse
counterfactual explanations. Proceedings of the 2020 Conference on
Fairness, Accountability, and Transparency, 607–617.
https://doi.org/10.1145/3351095.3372850</unstructured_citation>
          </citation>
          <citation key="upadhyay2021towards">
            <article_title>Towards robust and reliable algorithmic
recourse</article_title>
            <author>Upadhyay</author>
            <isbn>9781713845393</isbn>
            <cYear>2024</cYear>
            <unstructured_citation>Upadhyay, S., Joshi, S., &amp;
Lakkaraju, H. (2024). Towards robust and reliable algorithmic recourse.
ISBN: 9781713845393</unstructured_citation>
          </citation>
          <citation key="vo2023feature">
            <article_title>Feature-based learning for diverse and
privacy-preserving counterfactual explanations</article_title>
            <author>Vo</author>
            <journal_title>Proceedings of the 29th ACM SIGKDD conference
on knowledge discovery and data mining</journal_title>
            <doi>10.1145/3580305.3599343</doi>
            <isbn>9798400701030</isbn>
            <cYear>2023</cYear>
            <unstructured_citation>Vo, V., Le, T., Nguyen, V., Zhao, H.,
Bonilla, E. V., Haffari, G., &amp; Phung, D. (2023). Feature-based
learning for diverse and privacy-preserving counterfactual explanations.
Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, 2211–2222.
https://doi.org/10.1145/3580305.3599343</unstructured_citation>
          </citation>
          <citation key="guo2021counternet">
            <article_title>CounterNet: End-to-end training of prediction
aware counterfactual explanations</article_title>
            <author>Guo</author>
            <journal_title>Proceedings of the 29th ACM SIGKDD conference
on knowledge discovery and data mining</journal_title>
            <doi>10.1145/3580305.3599290</doi>
            <isbn>9798400701030</isbn>
            <cYear>2023</cYear>
            <unstructured_citation>Guo, H., Nguyen, T. H., &amp; Yadav,
A. (2023). CounterNet: End-to-end training of prediction aware
counterfactual explanations. Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining, 577–589.
https://doi.org/10.1145/3580305.3599290</unstructured_citation>
          </citation>
          <citation key="guo2023rocoursenet">
            <article_title>RoCourseNet: Robust training of a prediction
aware recourse model</article_title>
            <author>Guo</author>
            <journal_title>Proceedings of the 32nd ACM international
conference on information and knowledge management</journal_title>
            <doi>10.1145/3583780.3615040</doi>
            <isbn>9798400701245</isbn>
            <cYear>2023</cYear>
            <unstructured_citation>Guo, H., Jia, F., Chen, J.,
Squicciarini, A., &amp; Yadav, A. (2023). RoCourseNet: Robust training
of a prediction aware recourse model. Proceedings of the 32nd ACM
International Conference on Information and Knowledge Management,
619–628. https://doi.org/10.1145/3583780.3615040</unstructured_citation>
          </citation>
          <citation key="pawelczyk2021carla">
            <article_title>CARLA: A python library to benchmark
algorithmic recourse and counterfactual explanation
algorithms</article_title>
            <author>Pawelczyk</author>
            <journal_title>ArXiv</journal_title>
            <volume>abs/2108.00783</volume>
            <cYear>2021</cYear>
            <unstructured_citation>Pawelczyk, M., Bielawski, S., Heuvel,
J. van den, Richter, T., &amp; Kasneci, G. (2021). CARLA: A python
library to benchmark algorithmic recourse and counterfactual explanation
algorithms. ArXiv, abs/2108.00783.
https://api.semanticscholar.org/CorpusID:236772193</unstructured_citation>
          </citation>
          <citation key="klaise2021alibi">
            <article_title>Alibi explain: Algorithms for explaining
machine learning models</article_title>
            <author>Klaise</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <issue>181</issue>
            <volume>22</volume>
            <cYear>2021</cYear>
            <unstructured_citation>Klaise, J., Looveren, A. V., Vacanti,
G., &amp; Coca, A. (2021). Alibi explain: Algorithms for explaining
machine learning models. Journal of Machine Learning Research, 22(181),
1–7. http://jmlr.org/papers/v22/21-0017.html</unstructured_citation>
          </citation>
          <citation key="kohavi1996uci">
            <article_title>UCI machine learning repository: Adult data
set</article_title>
            <author>Kohavi</author>
            <journal_title>1996-05-01)[2014-10-01]. http: ff archive,
ies. uci. edu/ml/data-sets/Adult</journal_title>
            <cYear>1996</cYear>
            <unstructured_citation>Kohavi, R., &amp; Becker, B. (1996).
UCI machine learning repository: Adult data set. In
1996-05-01)[2014-10-01]. http: ff archive, ies. uci.
edu/ml/data-sets/Adult.</unstructured_citation>
          </citation>
          <citation key="jax2018github">
            <article_title>JAX: Composable transformations of
Python+NumPy programs</article_title>
            <author>Bradbury</author>
            <cYear>2018</cYear>
            <unstructured_citation>Bradbury, J., Frostig, R., Hawkins,
P., Johnson, M. J., Leary, C., Maclaurin, D., Necula, G., Paszke, A.,
VanderPlas, J., Wanderman-Milne, S., &amp; Zhang, Q. (2018). JAX:
Composable transformations of Python+NumPy programs (Version 0.4.10).
http://github.com/google/jax</unstructured_citation>
          </citation>
          <citation key="frostig2018jax">
            <article_title>Compiling machine learning programs via
high-level tracing</article_title>
            <author>Frostig</author>
            <cYear>2018</cYear>
            <unstructured_citation>Frostig, R., Johnson, M., &amp;
Leary, C. (2018). Compiling machine learning programs via high-level
tracing.
https://mlsys.org/Conferences/doc/2018/146.pdf</unstructured_citation>
          </citation>
          <citation key="laugel2017inverse">
            <article_title>Inverse classification for comparison-based
interpretability in machine learning</article_title>
            <author>Laugel</author>
            <journal_title>arXiv preprint
arXiv:1712.08443</journal_title>
            <cYear>2017</cYear>
            <unstructured_citation>Laugel, T., Lesot, M.-J., Marsala,
C., Renard, X., &amp; Detyniecki, M. (2017). Inverse classification for
comparison-based interpretability in machine learning. arXiv Preprint
arXiv:1712.08443.</unstructured_citation>
          </citation>
          <citation key="van2019interpretable">
            <article_title>Interpretable counterfactual explanations
guided by prototypes</article_title>
            <author>Van Looveren</author>
            <doi>10.1007/978-3-030-86520-7_40</doi>
            <isbn>978-3-030-86519-1</isbn>
            <cYear>2021</cYear>
            <unstructured_citation>Van Looveren, A., &amp; Klaise, J.
(2021). Interpretable counterfactual explanations guided by prototypes.
650–665.
https://doi.org/10.1007/978-3-030-86520-7_40</unstructured_citation>
          </citation>
          <citation key="pawelczyk2020learning">
            <article_title>Learning model-agnostic counterfactual
explanations for tabular data</article_title>
            <author>Pawelczyk</author>
            <journal_title>Proceedings of the web conference
2020</journal_title>
            <doi>10.1145/3366423.3380087</doi>
            <isbn>9781450370233</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Pawelczyk, M., Broelemann, K., &amp;
Kasneci, G. (2020). Learning model-agnostic counterfactual explanations
for tabular data. Proceedings of the Web Conference 2020, 3126–3132.
https://doi.org/10.1145/3366423.3380087</unstructured_citation>
          </citation>
          <citation key="antoran2021clue">
            <article_title>Getting a {CLUE}: A method for explaining
uncertainty estimates</article_title>
            <author>Antoran</author>
            <journal_title>International conference on learning
representations</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Antoran, J., Bhatt, U., Adel, T.,
Weller, A., &amp; Hernández-Lobato, J. M. (2021). Getting a {CLUE}: A
method for explaining uncertainty estimates. International Conference on
Learning Representations.
https://openreview.net/forum?id=XSLF1XFq5h</unstructured_citation>
          </citation>
          <citation key="mahajan2019preserving">
            <article_title>Preserving causal constraints in
counterfactual explanations for machine learning
classifiers</article_title>
            <author>Mahajan</author>
            <journal_title>arXiv preprint
arXiv:1912.03277</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Mahajan, D., Tan, C., &amp; Sharma,
A. (2019). Preserving causal constraints in counterfactual explanations
for machine learning classifiers. arXiv Preprint
arXiv:1912.03277.</unstructured_citation>
          </citation>
          <citation key="ding2021retiring">
            <article_title>Retiring adult: New datasets for fair machine
learning</article_title>
            <author>Ding</author>
            <isbn>9781713845393</isbn>
            <cYear>2024</cYear>
            <unstructured_citation>Ding, F., Hardt, M., Miller, J.,
&amp; Schmidt, L. (2024). Retiring adult: New datasets for fair machine
learning. ISBN: 9781713845393</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
