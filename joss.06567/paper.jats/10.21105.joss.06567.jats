<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6567</article-id>
<article-id pub-id-type="doi">10.21105/joss.06567</article-id>
<title-group>
<article-title>ReLax: Efficient and Scalable Recourse Explanation
Benchmarking using JAX</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0000-6277-9003</contrib-id>
<name>
<surname>Guo</surname>
<given-names>Hangzhi</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xiong</surname>
<given-names>Xinchang</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Wenbo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0005-4638-9140</contrib-id>
<name>
<surname>Yadav</surname>
<given-names>Amulya</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Penn State University, University Park, PA,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Duke University, Durham, NC, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-12-10">
<day>10</day>
<month>12</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>103</issue>
<fpage>6567</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>JAX</kwd>
<kwd>machine learning</kwd>
<kwd>interpretability</kwd>
<kwd>counterfactual explanation</kwd>
<kwd>recourse</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>From healthcare to criminal justice, machine learning (ML) models
  have permeated society to support domain experts in making decisions.
  Given the high-stakes nature of decision outcomes in some real-world
  domains, concerns over the trustworthiness of ML model predictions
  have raised increasing attention. These concerns have spurred surging
  research interests in explainable artificial intelligence (XAI), whose
  mission is to equip end-users with an understanding (or explanation)
  of AI decision making, and to help provide assessments to end-users
  about when to rely on ML models and when to exercise caution.</p>
  <p>Within the XAI domain,
  recourse<xref ref-type="fn" rid="fn1">1</xref> has emerged as a
  notable technique, which provides alternative scenarios (which lead to
  desirable AI decisions) to individuals adversely affected by ML
  predictions, thereby elucidating the underlying decision-making
  mechanisms to end users. For instance, recourse methods can provide
  corrective suggestions for loan applicants who have been rejected by a
  bank’s ML algorithm, or give practical advice to teachers handling
  students at risk of dropping out from school. Numerous recourse
  explanation methods have been recently proposed. Yet, the substantial
  runtime overhead imposed by many recourse explanation methods compels
  current research to limit their evaluation and benchmarking to
  medium-sized datasets (i.e., ~50k data points). This limitation has
  significantly impeded progress in the field of algorithmic recourse,
  while it also raises valid concerns about the scalability of existing
  approaches.</p>
  <p>To address this challenge, we propose <monospace>ReLax</monospace>,
  a JAX-based benchmarking library, designed for efficient and scalable
  recourse generation. <monospace>ReLax</monospace> supports a variety
  of recourse methods and datasets, demonstrating performance
  improvements of at least two orders of magnitude over current
  libraries. Notably, ReLax can benchmark real-world datasets up to 10
  million data points, a 200-fold increase over existing norms, without
  imposing prohibitive computational costs.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Recourse and counterfactual explanation methods concentrate on the
  generation of new instances that lead to contrastive predicted
  outcomes
  (<xref alt="Karimi et al., 2022" rid="ref-karimi2020survey" ref-type="bibr">Karimi
  et al., 2022</xref>;
  <xref alt="Stepin et al., 2021" rid="ref-stepin2021survey" ref-type="bibr">Stepin
  et al., 2021</xref>;
  <xref alt="Verma et al., 2020" rid="ref-verma2020counterfactual" ref-type="bibr">Verma
  et al., 2020</xref>). Given their ability to provide actionable
  recourse, these explanations are often favored by human end-users
  (<xref alt="Bhatt et al., 2020" rid="ref-Bhatt20explainable" ref-type="bibr">Bhatt
  et al., 2020</xref>;
  <xref alt="Binns et al., 2018" rid="ref-binns2018s" ref-type="bibr">Binns
  et al., 2018</xref>;
  <xref alt="Miller, 2019" rid="ref-miller2019explanation" ref-type="bibr">Miller,
  2019</xref>).</p>
  <p>Despite progress made in counterfactual explanation research
  (<xref alt="Guo, Nguyen, et al., 2023" rid="ref-guo2021counternet" ref-type="bibr">Guo,
  Nguyen, et al., 2023</xref>;
  <xref alt="Guo, Jia, et al., 2023" rid="ref-guo2023rocoursenet" ref-type="bibr">Guo,
  Jia, et al., 2023</xref>;
  <xref alt="Mothilal et al., 2020" rid="ref-mothilal2020explaining" ref-type="bibr">Mothilal
  et al., 2020</xref>;
  <xref alt="Upadhyay et al., 2024" rid="ref-upadhyay2021towards" ref-type="bibr">Upadhyay
  et al., 2024</xref>;
  <xref alt="Ustun et al., 2019" rid="ref-ustun2019actionable" ref-type="bibr">Ustun
  et al., 2019</xref>;
  <xref alt="Vo et al., 2023" rid="ref-vo2023feature" ref-type="bibr">Vo
  et al., 2023</xref>;
  <xref alt="Wachter et al., 2017" rid="ref-wachter2017counterfactual" ref-type="bibr">Wachter
  et al., 2017</xref>), current research practices often restrict the
  evaluation of recourse explanation methods on medium-sized datasets
  (with under 50k data points). This constraint primarily stems from the
  excessive runtime overhead of recourse generation by existing
  open-source recourse libraries
  (<xref alt="Klaise et al., 2021" rid="ref-klaise2021alibi" ref-type="bibr">Klaise
  et al., 2021</xref>;
  <xref alt="Mothilal et al., 2020" rid="ref-mothilal2020explaining" ref-type="bibr">Mothilal
  et al., 2020</xref>;
  <xref alt="Pawelczyk et al., 2021" rid="ref-pawelczyk2021carla" ref-type="bibr">Pawelczyk
  et al., 2021</xref>). For instance, as shown in
  <xref alt="[fig:speed]" rid="figU003Aspeed">[fig:speed]</xref>, the
  CARLA library
  (<xref alt="Pawelczyk et al., 2021" rid="ref-pawelczyk2021carla" ref-type="bibr">Pawelczyk
  et al., 2021</xref>) requires roughly 30 minutes to benchmark the
  adult dataset
  (<xref alt="Kohavi &amp; Becker, 1996" rid="ref-kohavi1996uci" ref-type="bibr">Kohavi
  &amp; Becker, 1996</xref>) containing <inline-formula><alternatives>
  <tex-math><![CDATA[\sim32,000]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>32</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  data points. At this speed, because the runtime scales linearly with
  the number of data points, it would take CARLA approximately 15 hours
  to benchmark a dataset with 1 million samples, and nearly one week to
  benchmark a 10-million sized dataset. Consequently, this severe
  runtime overhead hinders the large-scale analysis of recourse
  explanations and the research development of new recourse methods.</p>
  <fig>
    <caption><p><styled-content id="figU003Aspeed"></styled-content>Runtime
    comparison of the <italic>adult</italic> dataset
    (<xref alt="Kohavi &amp; Becker, 1996" rid="ref-kohavi1996uci" ref-type="bibr">Kohavi
    &amp; Becker, 1996</xref>) between <monospace>ReLax</monospace> and
    three open-source recourse librarires (CARLA
    (<xref alt="Pawelczyk et al., 2021" rid="ref-pawelczyk2021carla" ref-type="bibr">Pawelczyk
    et al., 2021</xref>), DiCE
    (<xref alt="Mothilal et al., 2020" rid="ref-mothilal2020explaining" ref-type="bibr">Mothilal
    et al., 2020</xref>), and alibi
    (<xref alt="Klaise et al., 2021" rid="ref-klaise2021alibi" ref-type="bibr">Klaise
    et al., 2021</xref>).</p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="./figs/speed-compare.pdf" />
  </fig>
  <p>In this work, we present <monospace>ReLax</monospace>
  (<bold>Re</bold>course Explanation <bold>L</bold>ibrary using
  J<bold>ax</bold>), the <italic>first</italic> recourse explanation
  library in JAX
  (<xref alt="Bradbury et al., 2018" rid="ref-jax2018github" ref-type="bibr">Bradbury
  et al., 2018</xref>;
  <xref alt="Frostig et al., 2018" rid="ref-frostig2018jax" ref-type="bibr">Frostig
  et al., 2018</xref>). Our contributions are three-fold:</p>
  <list list-type="bullet">
    <list-item>
      <p>(Fast and Scalable System) <monospace>ReLax</monospace> is an
      <italic>efficient and scalable benchmarking library</italic> for
      recourse and counterfactual explanations.</p>
    </list-item>
    <list-item>
      <p>(Comprehensive set of Methods) <monospace>ReLax</monospace>
      implements 9 widely-used and popular recourse explanation methods.
      In addition, <monospace>ReLax</monospace> includes 14 medium-sized
      publicly available datasets, and one large-scale publicly
      available dataset.</p>
    </list-item>
    <list-item>
      <p>(Extensive Experiments) We perform comprehensive experiments on
      both medium-sized and large-sized datasets, which showcases the
      usability and scalability of <monospace>ReLax</monospace>.</p>
    </list-item>
  </list>
  <sec id="efficiency-and-scalability-in-relax">
    <title>Efficiency and Scalability in
    <monospace>ReLax</monospace></title>
    <p><monospace>ReLax</monospace> supports three recourse generation
    strategies: <italic>sequential</italic>,
    <italic>vectorized</italic>, and <italic>parallelized</italic>
    strategy. In particular, the <italic>sequential</italic> generation
    strategy involves generating recourse explanations one after
    another. Unfortunately, while widely used in existing recourse
    libraries
    (<xref alt="Klaise et al., 2021" rid="ref-klaise2021alibi" ref-type="bibr">Klaise
    et al., 2021</xref>;
    <xref alt="Mothilal et al., 2020" rid="ref-mothilal2020explaining" ref-type="bibr">Mothilal
    et al., 2020</xref>;
    <xref alt="Pawelczyk et al., 2021" rid="ref-pawelczyk2021carla" ref-type="bibr">Pawelczyk
    et al., 2021</xref>), this strategy is inefficient when benchmarking
    large datasets.</p>
    <p>On the other hand, the <italic>vectorized</italic> and
    <italic>parallelized</italic> strategies play a vital role in
    equipping <monospace>ReLax</monospace> to benchmark large-scale
    datasets with a practical computational cost. The
    <italic>vectorized</italic> strategy takes advantage of modern
    hardware by applying recourse generation operations to the entire
    dataset <italic>at once</italic>. This strategy considerably
    accelerates recourse generation by performing Single Instruction on
    Multiple Data (SIMD). Additionally, the
    <italic>parallelized</italic> strategy enables the usage of multiple
    computing devices (e.g., multiple GPUs/TPUs) to further improve
    scalability. Furthermore, <monospace>ReLax</monospace> further
    enhances its performance by fusing inner recourse generation steps
    via the Just-In-Time (JIT) compilation feature provided by
    <monospace>jax</monospace>. Together, <monospace>ReLax</monospace>
    ensures efficient and scalable performance across diverse data
    scales and complexities.</p>
  </sec>
  <sec id="recourse-methods-datasets">
    <title>Recourse Methods &amp; Datasets</title>
    <p><monospace>ReLax</monospace> implements nine recourse methods
    using JAX including (i) three non-parametric methods (VanillaCF
    (<xref alt="Wachter et al., 2017" rid="ref-wachter2017counterfactual" ref-type="bibr">Wachter
    et al., 2017</xref>), DiverseCF
    (<xref alt="Mothilal et al., 2020" rid="ref-mothilal2020explaining" ref-type="bibr">Mothilal
    et al., 2020</xref>), GrowingSphere
    (<xref alt="Laugel et al., 2017" rid="ref-laugel2017inverse" ref-type="bibr">Laugel
    et al., 2017</xref>)); (ii) three semi-parametric methods (ProtoCF
    (<xref alt="Van Looveren &amp; Klaise, 2021" rid="ref-van2019interpretable" ref-type="bibr">Van
    Looveren &amp; Klaise, 2021</xref>), C-CHVAE
    (<xref alt="Pawelczyk et al., 2020" rid="ref-pawelczyk2020learning" ref-type="bibr">Pawelczyk
    et al., 2020</xref>), CLUE
    (<xref alt="Antoran et al., 2021" rid="ref-antoran2021clue" ref-type="bibr">Antoran
    et al., 2021</xref>)); and (iii) three parametric methods (VAE-CF
    (<xref alt="Mahajan et al., 2019" rid="ref-mahajan2019preserving" ref-type="bibr">Mahajan
    et al., 2019</xref>), CounterNet
    (<xref alt="Guo, Nguyen, et al., 2023" rid="ref-guo2021counternet" ref-type="bibr">Guo,
    Nguyen, et al., 2023</xref>), L2C
    (<xref alt="Vo et al., 2023" rid="ref-vo2023feature" ref-type="bibr">Vo
    et al., 2023</xref>)).</p>
    <p>Furthermore, we gather 14 medium-sized binary-classification
    tabular datasets. We also benchmark over the forktable dataset
    (<xref alt="Ding et al., 2024" rid="ref-ding2021retiring" ref-type="bibr">Ding
    et al., 2024</xref>) for predicting individuals’ annual income. This
    US censuring dataset contains <inline-formula><alternatives>
    <tex-math><![CDATA[\sim 10]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    million data points. To our knowledge, this is the first attempt to
    benchmark a dataset at the scale of 10 million data points in the
    recourse explanation community.</p>
    <fig>
      <caption><p><styled-content id="figU003Acomparison"></styled-content>Comparison
      of recourse method performance across 14 medium-sized datasets. It
      is desirable to achieve <italic>high</italic> validity,
      <italic>low</italic> proximity, and <italic>low</italic>
      runtime.</p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="./figs/results.pdf" />
    </fig>
    <fig>
      <caption><p><styled-content id="figU003Atradeoff"></styled-content>Illustration
      of the cost-invalidity trade-off across 14 medium-sized datasets
      (left) and the forktable dataset (right) for each recourse method.
      Methods positioned at the bottom left are better.</p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="./figs/tradeoffs.pdf" />
    </fig>
    <fig>
      <caption><p><styled-content id="figU003Astrategy_runtime"></styled-content>Runtime
      comparison of different recourse generation strategies on the
      forktable dataset
      (<xref alt="Ding et al., 2024" rid="ref-ding2021retiring" ref-type="bibr">Ding
      et al., 2024</xref>).</p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="./figs/strategy_compare.pdf" />
    </fig>
  </sec>
  <sec id="experimental-results">
    <title>Experimental Results</title>
    <p><xref alt="[fig:comparison]" rid="figU003Acomparison">[fig:comparison]</xref>
    compares the validity, proximity, and runtime achieved by nine
    recourse methods averaged on 14 medium-sized datasets. In
    particular, validity and proximity measure the quality of the
    generated counterfactual explanations. We observe that CounterNet
    and Growing Sphere achieve the best validity score, and C-CHVAE
    achieves the best proximity score. In terms of runtime, all recourse
    methods complete the entire recourse generation process within 10
    seconds, while CounterNet and VAECF outperform others by finishing
    execution under 2 seconds.</p>
    <p>We further analyze the validity and proximity through the lens of
    the cost-invalidity tradeoff on medium-sized datasets and forktable
    dataset in
    <xref alt="[fig:tradeoff]" rid="figU003Atradeoff">[fig:tradeoff]</xref>.
    It is vital to ensure that the recourse explanation balances the
    trade-off between the cost of change (i.e., proximity) and the
    invalidation percentage (or invalidity, which is computed as 1 -
    <italic>validity</italic>). We observe that there is no definitive
    winner in optimally balancing this cost-invalidity trade-off, as
    none of the recourse methods are positioned at the bottom left of
    the figure. This analysis underscores the importance of considering
    both proximity and invalidity in recourse explanations, and presents
    an open challenge to the research community to devise methods that
    optimally balance this trade-off.</p>
    <p><xref alt="[fig:strategy_runtime]" rid="figU003Astrategy_runtime">[fig:strategy_runtime]</xref>
    compares the runtime for each recourse explanation method in
    adopting the vectorized and parallelized strategies on the forktable
    dataset (with 10M data points). First, <monospace>ReLax</monospace>
    is highly efficient in benchmarking the large-scale dataset, with
    the maximum runtime being under 30 minutes. On the other hand, by
    estimation, existing libraries should take at least one week to
    complete recourse generation on datasets at this scale. In addition,
    the parallelized strategy cuts the runtime by roughly 4X, which
    demonstrates <monospace>ReLax</monospace>’s potential in
    benchmarking even larger datasets.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-ustun2019actionable">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ustun</surname><given-names>Berk</given-names></name>
        <name><surname>Spangher</surname><given-names>Alexander</given-names></name>
        <name><surname>Liu</surname><given-names>Yang</given-names></name>
      </person-group>
      <article-title>Actionable recourse in linear classification</article-title>
      <source>Proceedings of the conference on fairness, accountability, and transparency</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2019">2019</year>
      <isbn>9781450361255</isbn>
      <uri>https://doi.org/10.1145/3287560.3287566</uri>
      <pub-id pub-id-type="doi">10.1145/3287560.3287566</pub-id>
      <fpage>10</fpage>
      <lpage>19</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wachter2017counterfactual">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wachter</surname><given-names>Sandra</given-names></name>
        <name><surname>Mittelstadt</surname><given-names>Brent</given-names></name>
        <name><surname>Russell</surname><given-names>Chris</given-names></name>
      </person-group>
      <article-title>Counterfactual explanations without opening the black box: Automated decisions and the GDPR</article-title>
      <source>Cybersecurity</source>
      <year iso-8601-date="2017">2017</year>
      <uri>https://api.semanticscholar.org/CorpusID:3995299</uri>
      <pub-id pub-id-type="doi">10.2139/ssrn.3063289</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-verma2020counterfactual">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Verma</surname><given-names>Sahil</given-names></name>
        <name><surname>Dickerson</surname><given-names>John</given-names></name>
        <name><surname>Hines</surname><given-names>Keegan</given-names></name>
      </person-group>
      <article-title>Counterfactual explanations for machine learning: A review</article-title>
      <source>arXiv preprint arXiv:2010.10596</source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-stepin2021survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stepin</surname><given-names>Ilia</given-names></name>
        <name><surname>Alonso</surname><given-names>Jose M.</given-names></name>
        <name><surname>Catala</surname><given-names>Alejandro</given-names></name>
        <name><surname>Pereira-Fariña</surname><given-names>Martín</given-names></name>
      </person-group>
      <article-title>A survey of contrastive and counterfactual explanation generation methods for explainable artificial intelligence</article-title>
      <source>IEEE Access</source>
      <year iso-8601-date="2021">2021</year>
      <volume>9</volume>
      <issue></issue>
      <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3051315</pub-id>
      <fpage>11974</fpage>
      <lpage>12001</lpage>
    </element-citation>
  </ref>
  <ref id="ref-karimi2020survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Karimi</surname><given-names>Amir-Hossein</given-names></name>
        <name><surname>Barthe</surname><given-names>Gilles</given-names></name>
        <name><surname>Schölkopf</surname><given-names>Bernhard</given-names></name>
        <name><surname>Valera</surname><given-names>Isabel</given-names></name>
      </person-group>
      <article-title>A survey of algorithmic recourse: Contrastive explanations and consequential recommendations</article-title>
      <source>ACM Comput. Surv.</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2022-12">2022</year><month>12</month>
      <volume>55</volume>
      <issue>5</issue>
      <issn>0360-0300</issn>
      <uri>https://doi.org/10.1145/3527848</uri>
      <pub-id pub-id-type="doi">10.1145/3527848</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-binns2018s">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Binns</surname><given-names>Reuben</given-names></name>
        <name><surname>Van Kleek</surname><given-names>Max</given-names></name>
        <name><surname>Veale</surname><given-names>Michael</given-names></name>
        <name><surname>Lyngs</surname><given-names>Ulrik</given-names></name>
        <name><surname>Zhao</surname><given-names>Jun</given-names></name>
        <name><surname>Shadbolt</surname><given-names>Nigel</given-names></name>
      </person-group>
      <article-title>’It’s reducing a human being to a percentage’: Perceptions of justice in algorithmic decisions</article-title>
      <source>Proceedings of the 2018 CHI conference on human factors in computing systems</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2018">2018</year>
      <isbn>9781450356206</isbn>
      <uri>https://doi.org/10.1145/3173574.3173951</uri>
      <pub-id pub-id-type="doi">10.1145/3173574.3173951</pub-id>
      <fpage>1</fpage>
      <lpage>14</lpage>
    </element-citation>
  </ref>
  <ref id="ref-miller2019explanation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miller</surname><given-names>Tim</given-names></name>
      </person-group>
      <article-title>Explanation in artificial intelligence: Insights from the social sciences</article-title>
      <source>Artif. Intell.</source>
      <year iso-8601-date="2019">2019</year>
      <volume>267</volume>
      <uri>https://doi.org/10.1016/j.artint.2018.07.007</uri>
      <pub-id pub-id-type="doi">10.1016/J.ARTINT.2018.07.007</pub-id>
      <fpage>1</fpage>
      <lpage>38</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Bhatt20explainable">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bhatt</surname><given-names>Umang</given-names></name>
        <name><surname>Xiang</surname><given-names>Alice</given-names></name>
        <name><surname>Sharma</surname><given-names>Shubham</given-names></name>
        <name><surname>Weller</surname><given-names>Adrian</given-names></name>
        <name><surname>Taly</surname><given-names>Ankur</given-names></name>
        <name><surname>Jia</surname><given-names>Yunhan</given-names></name>
        <name><surname>Ghosh</surname><given-names>Joydeep</given-names></name>
        <name><surname>Puri</surname><given-names>Ruchir</given-names></name>
        <name><surname>Moura</surname><given-names>José M. F.</given-names></name>
        <name><surname>Eckersley</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>Explainable machine learning in deployment</article-title>
      <source>Proceedings of the 2020 conference on fairness, accountability, and transparency</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <isbn>9781450369367</isbn>
      <uri>https://doi.org/10.1145/3351095.3375624</uri>
      <pub-id pub-id-type="doi">10.1145/3351095.3375624</pub-id>
      <fpage>648</fpage>
      <lpage>657</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mothilal2020explaining">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mothilal</surname><given-names>Ramaravind K.</given-names></name>
        <name><surname>Sharma</surname><given-names>Amit</given-names></name>
        <name><surname>Tan</surname><given-names>Chenhao</given-names></name>
      </person-group>
      <article-title>Explaining machine learning classifiers through diverse counterfactual explanations</article-title>
      <source>Proceedings of the 2020 conference on fairness, accountability, and transparency</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <isbn>9781450369367</isbn>
      <uri>https://doi.org/10.1145/3351095.3372850</uri>
      <pub-id pub-id-type="doi">10.1145/3351095.3372850</pub-id>
      <fpage>607</fpage>
      <lpage>617</lpage>
    </element-citation>
  </ref>
  <ref id="ref-upadhyay2021towards">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Upadhyay</surname><given-names>Sohini</given-names></name>
        <name><surname>Joshi</surname><given-names>Shalmali</given-names></name>
        <name><surname>Lakkaraju</surname><given-names>Himabindu</given-names></name>
      </person-group>
      <article-title>Towards robust and reliable algorithmic recourse</article-title>
      <publisher-name>Curran Associates Inc.</publisher-name>
      <publisher-loc>Red Hook, NY, USA</publisher-loc>
      <year iso-8601-date="2024">2024</year>
      <isbn>9781713845393</isbn>
    </element-citation>
  </ref>
  <ref id="ref-vo2023feature">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Vo</surname><given-names>Vy</given-names></name>
        <name><surname>Le</surname><given-names>Trung</given-names></name>
        <name><surname>Nguyen</surname><given-names>Van</given-names></name>
        <name><surname>Zhao</surname><given-names>He</given-names></name>
        <name><surname>Bonilla</surname><given-names>Edwin V.</given-names></name>
        <name><surname>Haffari</surname><given-names>Gholamreza</given-names></name>
        <name><surname>Phung</surname><given-names>Dinh</given-names></name>
      </person-group>
      <article-title>Feature-based learning for diverse and privacy-preserving counterfactual explanations</article-title>
      <source>Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>9798400701030</isbn>
      <uri>https://doi.org/10.1145/3580305.3599343</uri>
      <pub-id pub-id-type="doi">10.1145/3580305.3599343</pub-id>
      <fpage>2211</fpage>
      <lpage>2222</lpage>
    </element-citation>
  </ref>
  <ref id="ref-guo2021counternet">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Guo</surname><given-names>Hangzhi</given-names></name>
        <name><surname>Nguyen</surname><given-names>Thanh H.</given-names></name>
        <name><surname>Yadav</surname><given-names>Amulya</given-names></name>
      </person-group>
      <article-title>CounterNet: End-to-end training of prediction aware counterfactual explanations</article-title>
      <source>Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>9798400701030</isbn>
      <uri>https://doi.org/10.1145/3580305.3599290</uri>
      <pub-id pub-id-type="doi">10.1145/3580305.3599290</pub-id>
      <fpage>577</fpage>
      <lpage>589</lpage>
    </element-citation>
  </ref>
  <ref id="ref-guo2023rocoursenet">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Guo</surname><given-names>Hangzhi</given-names></name>
        <name><surname>Jia</surname><given-names>Feiran</given-names></name>
        <name><surname>Chen</surname><given-names>Jinghui</given-names></name>
        <name><surname>Squicciarini</surname><given-names>Anna</given-names></name>
        <name><surname>Yadav</surname><given-names>Amulya</given-names></name>
      </person-group>
      <article-title>RoCourseNet: Robust training of a prediction aware recourse model</article-title>
      <source>Proceedings of the 32nd ACM international conference on information and knowledge management</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>9798400701245</isbn>
      <uri>https://doi.org/10.1145/3583780.3615040</uri>
      <pub-id pub-id-type="doi">10.1145/3583780.3615040</pub-id>
      <fpage>619</fpage>
      <lpage>628</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pawelczyk2021carla">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pawelczyk</surname><given-names>Martin</given-names></name>
        <name><surname>Bielawski</surname><given-names>Sascha</given-names></name>
        <name><surname>Heuvel</surname><given-names>Jan van den</given-names></name>
        <name><surname>Richter</surname><given-names>Tobias</given-names></name>
        <name><surname>Kasneci</surname><given-names>Gjergji</given-names></name>
      </person-group>
      <article-title>CARLA: A Python library to benchmark algorithmic recourse and counterfactual explanation algorithms</article-title>
      <source>ArXiv</source>
      <year iso-8601-date="2021">2021</year>
      <volume>abs/2108.00783</volume>
      <uri>https://api.semanticscholar.org/CorpusID:236772193</uri>
    </element-citation>
  </ref>
  <ref id="ref-klaise2021alibi">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Klaise</surname><given-names>Janis</given-names></name>
        <name><surname>Looveren</surname><given-names>Arnaud Van</given-names></name>
        <name><surname>Vacanti</surname><given-names>Giovanni</given-names></name>
        <name><surname>Coca</surname><given-names>Alexandru</given-names></name>
      </person-group>
      <article-title>Alibi explain: Algorithms for explaining machine learning models</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2021">2021</year>
      <volume>22</volume>
      <issue>181</issue>
      <uri>http://jmlr.org/papers/v22/21-0017.html</uri>
      <fpage>1</fpage>
      <lpage>7</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kohavi1996uci">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Kohavi</surname><given-names>R</given-names></name>
        <name><surname>Becker</surname><given-names>B</given-names></name>
      </person-group>
      <article-title>UCI machine learning repository: Adult data set</article-title>
      <source>1996-05-01)[2014-10-01]. http: ff archive, ies. uci. edu/ml/data-sets/Adult</source>
      <year iso-8601-date="1996">1996</year>
    </element-citation>
  </ref>
  <ref id="ref-jax2018github">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Hawkins</surname><given-names>Peter</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew James</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Necula</surname><given-names>George</given-names></name>
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Wanderman-Milne</surname><given-names>Skye</given-names></name>
        <name><surname>Zhang</surname><given-names>Qiao</given-names></name>
      </person-group>
      <article-title>JAX: Composable transformations of Python+NumPy programs</article-title>
      <year iso-8601-date="2018">2018</year>
      <uri>http://github.com/google/jax</uri>
    </element-citation>
  </ref>
  <ref id="ref-frostig2018jax">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
      </person-group>
      <article-title>Compiling machine learning programs via high-level tracing</article-title>
      <year iso-8601-date="2018">2018</year>
      <uri>https://mlsys.org/Conferences/doc/2018/146.pdf</uri>
    </element-citation>
  </ref>
  <ref id="ref-laugel2017inverse">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Laugel</surname><given-names>Thibault</given-names></name>
        <name><surname>Lesot</surname><given-names>Marie-Jeanne</given-names></name>
        <name><surname>Marsala</surname><given-names>Christophe</given-names></name>
        <name><surname>Renard</surname><given-names>Xavier</given-names></name>
        <name><surname>Detyniecki</surname><given-names>Marcin</given-names></name>
      </person-group>
      <article-title>Inverse classification for comparison-based interpretability in machine learning</article-title>
      <source>arXiv preprint arXiv:1712.08443</source>
      <year iso-8601-date="2017">2017</year>
    </element-citation>
  </ref>
  <ref id="ref-van2019interpretable">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Van Looveren</surname><given-names>Arnaud</given-names></name>
        <name><surname>Klaise</surname><given-names>Janis</given-names></name>
      </person-group>
      <article-title>Interpretable counterfactual explanations guided by prototypes</article-title>
      <publisher-name>Springer-Verlag</publisher-name>
      <publisher-loc>Berlin, Heidelberg</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <isbn>978-3-030-86519-1</isbn>
      <uri>https://doi.org/10.1007/978-3-030-86520-7_40</uri>
      <pub-id pub-id-type="doi">10.1007/978-3-030-86520-7_40</pub-id>
      <fpage>650</fpage>
      <lpage>665</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pawelczyk2020learning">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pawelczyk</surname><given-names>Martin</given-names></name>
        <name><surname>Broelemann</surname><given-names>Klaus</given-names></name>
        <name><surname>Kasneci</surname><given-names>Gjergji</given-names></name>
      </person-group>
      <article-title>Learning model-agnostic counterfactual explanations for tabular data</article-title>
      <source>Proceedings of the web conference 2020</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <isbn>9781450370233</isbn>
      <uri>https://doi.org/10.1145/3366423.3380087</uri>
      <pub-id pub-id-type="doi">10.1145/3366423.3380087</pub-id>
      <fpage>3126</fpage>
      <lpage>3132</lpage>
    </element-citation>
  </ref>
  <ref id="ref-antoran2021clue">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Antoran</surname><given-names>Javier</given-names></name>
        <name><surname>Bhatt</surname><given-names>Umang</given-names></name>
        <name><surname>Adel</surname><given-names>Tameem</given-names></name>
        <name><surname>Weller</surname><given-names>Adrian</given-names></name>
        <name><surname>Hernández-Lobato</surname><given-names>José Miguel</given-names></name>
      </person-group>
      <article-title>Getting a CLUE: A method for explaining uncertainty estimates</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://openreview.net/forum?id=XSLF1XFq5h</uri>
    </element-citation>
  </ref>
  <ref id="ref-mahajan2019preserving">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mahajan</surname><given-names>Divyat</given-names></name>
        <name><surname>Tan</surname><given-names>Chenhao</given-names></name>
        <name><surname>Sharma</surname><given-names>Amit</given-names></name>
      </person-group>
      <article-title>Preserving causal constraints in counterfactual explanations for machine learning classifiers</article-title>
      <source>arXiv preprint arXiv:1912.03277</source>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-ding2021retiring">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ding</surname><given-names>Frances</given-names></name>
        <name><surname>Hardt</surname><given-names>Moritz</given-names></name>
        <name><surname>Miller</surname><given-names>John</given-names></name>
        <name><surname>Schmidt</surname><given-names>Ludwig</given-names></name>
      </person-group>
      <article-title>Retiring adult: New datasets for fair machine learning</article-title>
      <publisher-name>Curran Associates Inc.</publisher-name>
      <publisher-loc>Red Hook, NY, USA</publisher-loc>
      <year iso-8601-date="2024">2024</year>
      <isbn>9781713845393</isbn>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>Algorithmic recourse
    (<xref alt="Ustun et al., 2019" rid="ref-ustun2019actionable" ref-type="bibr">Ustun
    et al., 2019</xref>) and counterfactual explanation
    (<xref alt="Wachter et al., 2017" rid="ref-wachter2017counterfactual" ref-type="bibr">Wachter
    et al., 2017</xref>) share close connections
    (<xref alt="Stepin et al., 2021" rid="ref-stepin2021survey" ref-type="bibr">Stepin
    et al., 2021</xref>;
    <xref alt="Verma et al., 2020" rid="ref-verma2020counterfactual" ref-type="bibr">Verma
    et al., 2020</xref>), which leads us to use these terms
    interchangeably</p>
  </fn>
</fn-group>
</back>
</article>
