<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>49a8a1ba855e44f9f8e853280c74a1f9</doi_batch_id>
    <timestamp>20191104153355</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>11</month>
          <year>2019</year>
        </publication_date>
        <journal_volume>
          <volume>4</volume>
        </journal_volume>
        <issue>43</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>modelStudio: Interactive Studio with Explanations for ML Predictive Models</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Hubert</given_name>
            <surname>Baniecki</surname>
            <ORCID>http://orcid.org/0000-0001-6661-5364</ORCID>
          </person_name>
          <person_name sequence="additional" contributor_role="author">
            <given_name>Przemyslaw</given_name>
            <surname>Biecek</surname>
            <ORCID>http://orcid.org/0000-0001-8423-1823</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>11</month>
          <day>04</day>
          <year>2019</year>
        </publication_date>
        <pages>
          <first_page>1798</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.01798</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">https://doi.org/10.5281/zenodo.3527770</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/1798</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.01798</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.01798</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">http://www.theoj.org/openjournals/joss-papers/joss.01798/10.21105.joss.01798.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="ref1">
            <doi>10.18653/v1/n16-3020</doi>
          </citation>
          <citation key="ref2">
            <unstructured_citation>Biecek, Przemys&#x142;aw, DALEX: explainers for complex predictive models, http://arxiv.org/abs/1806.08915, 1806.08915, stat.ML, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Applications, 2018, http://adsabs.harvard.edu/abs/2018arXiv180608915B, Provided by the SAO/NASA Astrophysics Data System</unstructured_citation>
          </citation>
          <citation key="ref3">
            <unstructured_citation>A Unified Approach to Interpreting Model Predictions, Lundberg, Scott M and Lee, Su-In, Advances in Neural Information Processing Systems 30, Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R., 4765&#x2013;4774, 2017, Curran Associates, Inc., http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</unstructured_citation>
          </citation>
          <citation key="ref4">
            <unstructured_citation>Machine Learning Interpretability with H 2 O Driverless, Gill, Navdeep and Kurka, Megan and Phan, Wen, 2017</unstructured_citation>
          </citation>
          <citation key="ref5">
            <doi>10.32614/rj-2018-072</doi>
          </citation>
          <citation key="ref6">
            <unstructured_citation>Towards Automated Machine Learning: Evaluation and Comparison of AutoML Approaches and Tools, Truong, Anh and Walters, Austin and Goodsitt, Jeremy and Hines, Keegan and Bruss, C. Bayan and Farivar, Reza, ArXiv, 2019, abs/1908.05557</unstructured_citation>
          </citation>
          <citation key="ref7">
            <unstructured_citation>R: A Language and Environment for Statistical Computing, R Core Team, R Foundation for Statistical Computing, Vienna, Austria, 2019, https://www.R-project.org/</unstructured_citation>
          </citation>
          <citation key="ref8">
            <unstructured_citation>D3.js-data-driven documents (2016), Bostock, Mike, URL: https://d3js.org, 2016</unstructured_citation>
          </citation>
          <citation key="ref9">
            <doi>10.21105/joss.01444</doi>
          </citation>
          <citation key="ref10">
            <unstructured_citation>iBreakDown: Uncertainty of Model Explanations for Non-additive Predictive Models, Gosiewska, Alicja and Biecek, Przemyslaw, arXiv preprint arXiv:1903.11420, 2019</unstructured_citation>
          </citation>
          <citation key="ref11">
            <unstructured_citation>iBreakDown: Model Agnostic Instance Level Variable Attributions, Biecek, Przemyslaw and Gosiewska, Alicja and Baniecki, Hubert and Izdebski, Adam, 2019, R package version 0.9.9, https://CRAN.R-project.org/package=iBreakDown</unstructured_citation>
          </citation>
          <citation key="ref12">
            <unstructured_citation>ingredients: Effects and Importances of Model Ingredients, Biecek, Przemyslaw and Baniecki, Hubert and Izdebski, Adam and Pekala, Katarzyna, 2019, https://ModelOriented.github.io/ingredients/, https://github.com/ModelOriented/ingredients, http://CRAN.R-project.org/package=ingredients</unstructured_citation>
          </citation>
          <citation key="ref13">
            <doi>10.21105/joss.00786</doi>
          </citation>
          <citation key="ref14">
            <unstructured_citation>Interpretability Methods for tf.keras models with Tensorflow 2.0, Meudec, Raphael, 2019, https://tf-explain.readthedocs.io, https://tf-explain.readthedocs.io</unstructured_citation>
          </citation>
          <citation key="ref15">
            <unstructured_citation>sklearn explain, Carme, Antoine, 2019, https://github.com/antoinecarme/sklearn_explain, https://github.com/antoinecarme/sklearn_explain</unstructured_citation>
          </citation>
          <citation key="ref16">
            <unstructured_citation>InterpretML, Jenkins, Samuel and Nori, Harsha and Koch, Paul and Caruana, Rich, 2019, https://github.com/microsoft/interpret, https://github.com/microsoft/interpret</unstructured_citation>
          </citation>
          <citation key="ref17">
            <unstructured_citation>ceterisParibus: Ceteris Paribus Profiles, Biecek, Przemyslaw, 2019, R package version 0.3.1, https://CRAN.R-project.org/package=ceterisParibus</unstructured_citation>
          </citation>
          <citation key="ref18">
            <unstructured_citation>All models are wrong but many are useful: Variable importance for black-box, proprietary, or misspecified prediction models, using model class reliance, Fisher, Aaron and Rudin, Cynthia and Dominici, Francesca, arXiv preprint arXiv:1801.01489, 2018</unstructured_citation>
          </citation>
          <citation key="ref19">
            <doi>10.32614/rj-2017-016</doi>
          </citation>
          <citation key="ref20">
            <unstructured_citation>Visualizing the effects of predictor variables in black box supervised learning models, Apley, Daniel W, arXiv preprint arXiv:1612.08468, 2016</unstructured_citation>
          </citation>
          <citation key="ref21">
            <unstructured_citation>Predictive Models: Explore, Explain, and Debug, Biecek, Przemyslaw and Burzykowski, Tomasz, 2019, https://pbiecek.github.io/PM_VEE/, https://pbiecek.github.io/PM_VEE/</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
