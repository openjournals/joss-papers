<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5118</article-id>
<article-id pub-id-type="doi">10.21105/joss.05118</article-id>
<title-group>
<article-title>FitSNAP: Atomistic machine learning with
LAMMPS</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2712-8296</contrib-id>
<name>
<surname>Rohskopf</surname>
<given-names>A.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sievers</surname>
<given-names>C.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9001-9973</contrib-id>
<name>
<surname>Lubbers</surname>
<given-names>N.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9505-6442</contrib-id>
<name>
<surname>Cusentino</surname>
<given-names>M. A.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7026-7200</contrib-id>
<name>
<surname>Goff</surname>
<given-names>J.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9948-7119</contrib-id>
<name>
<surname>Janssen</surname>
<given-names>J.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4388-4953</contrib-id>
<name>
<surname>McCarthy</surname>
<given-names>M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7890-0859</contrib-id>
<name>
<surname>de Oca Zapiain</surname>
<given-names>D. Montes</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2907-6629</contrib-id>
<name>
<surname>Nikolov</surname>
<given-names>S.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1037-786X</contrib-id>
<name>
<surname>Sargsyan</surname>
<given-names>K.</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0160-1743</contrib-id>
<name>
<surname>Sema</surname>
<given-names>D.</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3292-6564</contrib-id>
<name>
<surname>Sikorski</surname>
<given-names>E.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9062-8293</contrib-id>
<name>
<surname>Williams</surname>
<given-names>L.</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0324-9114</contrib-id>
<name>
<surname>Thompson</surname>
<given-names>A. P.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5878-4096</contrib-id>
<name>
<surname>Wood</surname>
<given-names>M. A.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Center for Computing Research, Sandia National
Laboratories, Albuquerque, NM, United States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Boeing, Seattle, WA, United States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Los Alamos National Laboratory, Los Alamos, NM, United
States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Material, Physical, and Chemical Sciences Center, Sandia
National Laboratories, Albuquerque, NM, United States of
America</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Center for Integrated Nanotechnologies, Sandia National
Laboratories, Albuquerque, NM, United States of America</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Chemistry, Combustion and Materials Science Center, Sandia
National Laboratories, Livermore, CA, United States of
America</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Department of Mechanical Engineering, Massachusetts
Institute of Technology, Cambridge, MA, United States of
America</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-11-29">
<day>29</day>
<month>11</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>84</issue>
<fpage>5118</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>machine learning</kwd>
<kwd>interatomic potentials</kwd>
<kwd>neural networks</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <graphic mimetype="image" mime-subtype="png" xlink:href="media/01a1f2bc5994182fd86613bf69a106da784ec167.png" />
  <p>Chemical and physical properties of complex materials emerge from
  the collective motions of the constituent atoms. These motions are in
  turn determined by a variety of interatomic interactions mediated by
  the local redistribution of valence electrons about the fixed core
  electrons and nuclear charges. Scientific and engineering advances in
  materials science, chemistry, and many related fields benefit from our
  ability to directly sample the equilibrium and kinetic probability
  distributions of large collections of atoms and molecules. Classical
  molecular dynamics (MD) is a widely used simulation method in which
  Newton’s equations of motion are numerically integrated forward in
  time to generate representative atomic trajectories of the atoms, from
  which insight into a wide range of material behaviors can be obtained.
  This simulation technique is not restricted to the definition of
  particles as atoms, but is generalizable to other types of interacting
  particles, such as coarse-grained beads in polymers, discrete elements
  representing granular materials, and fluid mass elements in
  dissipative particle dynamics. While all of these simulation methods
  use the same core algorithms as MD, we restrict our discussion here to
  the treatment of interactions between atoms.</p>
  <p>Forces on atoms arise from the electronic structure, from electron
  charge densities that can be accurately calculated using quantum
  mechanical methods such as Density Functional Theory (DFT). While
  quantum mechanical methods (QM) are accurate, their computational cost
  scales at best as the third power of the number of electrons in the
  system, preventing application of the method to size and time scales
  relevant to many phenomena. It is therefore of great benefit to
  approximate the forces on atoms using simple empirical expressions for
  the energy of a configuration of atoms as a function of their local
  relative positions. From these functions, called interatomic
  potentials or just “potentials”, the forces on atoms can be obtained
  by taking gradients with respect to atomic positions. Many of these
  empirical potentials are derived from known physical and chemical
  interaction models, i.e. covalent, metallic, ionic, etc. By smoothly
  truncating these potentials at a suitable cutoff distance, the
  computational cost scales linearly in the number of atoms in the
  system and is amenable to efficient parallel algorithms available in
  MD codes such as LAMMPS
  (<xref alt="Thompson et al., 2022" rid="ref-thompson2022lammps" ref-type="bibr">Thompson
  et al., 2022</xref>). As a result, these empirical models can be used
  to simulate systems that are far beyond the reach of QM. However,
  except for highly idealized structures, such as bulk crystals, these
  empirical models do not provide reliable surrogates for QM, and are
  prone to exhibiting unphysical behaviors. In the last decade, great
  progress has been made in constructing machine learning (ML)
  surrogates for QM potential energy functions. Large datasets of small
  atomic configurations with energies and forces evaluated using QM are
  used to train regression models that map local atomic environments to
  atomic energies and forces. By implementing these ML potentials in
  LAMMPS and running on large supercomputers, it is possible to simulate
  systems containing billions of particles with QM accuracy
  (<xref alt="Nguyen-Cong et al., 2021" rid="ref-nguyen2021billion" ref-type="bibr">Nguyen-Cong
  et al., 2021</xref>). However, the lack of general tools to facilitate
  this ML research limits widespread use and progress in the field. To
  address this need, we have developed a software package called
  FitSNAP. FitSNAP provides a general set of tools that can be used to
  train and test a wide range of atomistic simulation models.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>FitSNAP is a Python package for constructing a wide variety of ML
  interatomic interaction models that map local atomic environments to
  energies, forces, stress or other quantities associated with atoms.
  This mapping is achieved by first calculating atomic environment
  feature vectors (descriptors), and then using these to learn a
  regression model. There are other high-quality atomistic ML software
  packages in this application space, such as DeepMD
  (<xref alt="Wang et al., 2018" rid="ref-wang2018deepmd" ref-type="bibr">Wang
  et al., 2018</xref>), n2p2
  (<xref alt="Singraber et al., 2019" rid="ref-singraber2019library" ref-type="bibr">Singraber
  et al., 2019</xref>), pacemaker
  (<xref alt="Bochkarev et al., 2022" rid="ref-bochkarev2022efficient" ref-type="bibr">Bochkarev
  et al., 2022</xref>), NequIP
  (<xref alt="Batzner et al., 2022" rid="ref-batzner20223" ref-type="bibr">Batzner
  et al., 2022</xref>), Allegro
  (<xref alt="Musaelian et al., 2023" rid="ref-musaelian2023learning" ref-type="bibr">Musaelian
  et al., 2023</xref>), and GAP
  (<xref alt="Bartók et al., 2010" rid="ref-bartok2010gaussian" ref-type="bibr">Bartók
  et al., 2010</xref>). All of these provide excellent capabilities for
  their particular class of ML potentials, but lack the flexibility to
  accommodate a wide range of descriptors and regression models. Other
  software packages like amp
  (<xref alt="Khorshidi &amp; Peterson, 2016" rid="ref-khorshidi2016amp" ref-type="bibr">Khorshidi
  &amp; Peterson, 2016</xref>), TorchANI
  (<xref alt="Gao et al., 2020" rid="ref-gao2020torchani" ref-type="bibr">Gao
  et al., 2020</xref>), and ACEsuit
  (<xref alt="Ortner &amp; Kermode, 2020" rid="ref-ortner-acesuit" ref-type="bibr">Ortner
  &amp; Kermode, 2020</xref>) generalize the ML problem to models with
  multiple kinds of descriptors and model forms. After constructing a ML
  potential, a critical test of its viability is using it in large-scale
  production simulations. This ensures its stability and tests its
  ability to predict properties and phenomena that it was not explicitly
  trained on, colloquially referred to as extrapolation. To achieve this
  important step some of the aforementioned software packages provide
  excellent support for their respective models in large-scale molecular
  simulation packages like LAMMPS
  (<xref alt="Thompson et al., 2022" rid="ref-thompson2022lammps" ref-type="bibr">Thompson
  et al., 2022</xref>).</p>
  <p>A seamless interface with LAMMPS is where FitSNAP stands out; we
  use native components of LAMMPS to calculate inputs to our ML models,
  ensuring full consistency between the model produced in training and
  the model used in production MD simulations. In this regard FitSNAP
  acts as a multi-scale link between quantum and classical methods; a
  model is trained on fine-scale QM data and then seamlessly deployed in
  large-scale classical MD simulations on high-performance computing
  platforms. By using the same LAMMPS code to compute descriptors in
  both training and production simulations, we also reduce code
  duplication, and increase the rate of innovation by eliminating
  barriers to deploying new descriptors and models in large-scale
  simulations. While FitSNAP uses the Python interface to the LAMMPS
  library, it is not tightly integrated with LAMMPS. This allows greater
  flexibility and speed in development that would not be possible if it
  was fully integrated, given the much larger user base and diversity of
  use cases that LAMMPS must support. FitSNAP is therefore free to
  improve and grow independently of LAMMPS in the area of ML models,
  while at the same time maintaining full consistency with LAMMPS data
  structures and descriptor calculations. Our interface is achieved by
  using LAMMPS <monospace>compute</monospace> objects; these calculate
  quantities for a single configurations of atoms, without performing
  MD. The <monospace>compute</monospace> objects calculate the
  descriptors for our ML models, ensuring that descriptors used during
  training are identical to the descriptors used in
  performance-optimized LAMMPS production simulations. This also allows
  performance improvements achieved in the LAMMPS production code to
  immediately speed up the training process, rather than having to
  replicate the code improvements in the training software. FitSNAP has
  already taken advantage of this intrinsic LAMMPS interface in a number
  of publications that performed large-scale simulations with innovative
  ML atomistic models
  (<xref alt="Cusentino et al., 2020" rid="ref-cusentino2020explicit" ref-type="bibr">Cusentino
  et al., 2020</xref>,
  <xref alt="2021" rid="ref-cusentino2021beryllium" ref-type="bibr">2021</xref>;
  <xref alt="Nikolov et al., 2021" rid="ref-nikolov2021data" ref-type="bibr">Nikolov
  et al., 2021</xref>,
  <xref alt="2022" rid="ref-nikolov2022dissociating" ref-type="bibr">2022</xref>;
  <xref alt="Wood &amp; Thompson, 2018" rid="ref-wood2018extending" ref-type="bibr">Wood
  &amp; Thompson, 2018</xref>). LAMMPS supports a rapidly growing and
  diverse set of descriptors and ML model
  forms(<xref alt="Zuo et al., 2020" rid="ref-zuo2020performance" ref-type="bibr">Zuo
  et al., 2020</xref>). The interface ensures that all of these can be
  made accessible to FitSNAP users, with a small amount of extra glue
  code. This flexibility is paramount for achieving a general use ML
  potential software, since different descriptors and models are
  appropriate for different materials physics, different accuracy
  requirements, and different performance needs
  (<xref alt="Zuo et al., 2020" rid="ref-zuo2020performance" ref-type="bibr">Zuo
  et al., 2020</xref>). The modularity of FitSNAP components allows one
  to choose different models combined with different descriptors; this
  rapid prototyping can help users find the best atomistic ML model for
  their particular application.</p>
</sec>
<sec id="components">
  <title>Components</title>
  <fig>
    <caption><p>FitSNAP components and flow of control. The typical
    workflow involves scraping configurations of atoms which serve as
    training data; this is done in the <monospace>Scraper</monospace>
    class. Then we calculate ML features (atomic environment
    descriptors) in the <monospace>Calculator</monospace> class. Next,
    the ML problem is solved in the <monospace>Solver</monospace> class,
    which includes both linear and nonlinear models. This is followed by
    error analysis and/or model deployment in
    LAMMPS.<styled-content id="figU003Acomponents"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/b1a68de6ce4aaa996420bc11f5b57847176d6b2e.png" />
  </fig>
  <p>To generally approach the atomistic ML problem, we abstract
  components required for scraping data, calculating descriptors, and
  solving the optimization problem. The main software components driving
  this flow of control are shown in
  <xref alt="[fig:components]" rid="figU003Acomponents">[fig:components]</xref>.
  Scraping of training data and calculating atomic environment
  descriptors is parallelized over configurations of atoms with help
  from our <monospace>ParallelTools</monospace> class. This stores data
  such as atomic positions, and fitting targets such as forces and
  energies, in shared memory arrays accessible to all processors on a
  compute node. This is achieved using the Python
  <monospace>mpi4py</monospace> package, allowing both (1) calculation
  of atomic environment descriptors in parallel across many
  configurations of atoms and (2) shared storage of training data
  including atomic environment descriptors and fitting targets. The
  latter point is vital for storing large amounts of data when using
  multiple processes on a single node; without shared arrays the
  required memory can easily exceed that available on many-core CPU
  platforms, since each processor would need to store all the data. The
  contents of these shared arrays are then accessible to the FitSNAP
  components on all processors in a node, throughout the rest of the
  workflow. The typical workflow begins with the Scraper class, which
  also uses <monospace>ParallelTools</monospace> to collect training
  data in parallel.</p>
  <sec id="scraper">
    <title>Scraper</title>
    <p>The first step in the typical FitSNAP flow of control is a file
    I/O step to scrape the training data, the configurations of atoms
    and their associated energies, forces, spins, charges, or whatever
    fitting quantity; this is achieved with the
    <monospace>Scraper</monospace> class. Training data includes basic
    structural information about the set of atoms such as Cartesian
    coordinates and DFT simulation box vectors. Ground truth values used
    in the loss function during the regression step are collected at
    this stage; this “scraping” occurs in parallel using MPI. Accepted
    file formats currently include XYZ and JSON files, which are
    commonly used in the atomistic modelling community. These files are
    stored in directories in a manner determined by the user, where each
    directory can designate a FitSNAP data <monospace>group</monospace>;
    each group of configurations can receive its own training/testing
    fractions and fitting target weights, offering flexibility in how
    different configurations of atoms are weighted or tested during
    training. When scraping, the data is stored in a FitSNAP data
    dictionary that houses positions of atoms and their associated
    fitting quantities. While the typical flow of control involves first
    scraping training data from these files, using FitSNAP in library
    mode allows one to bypass this step if the training data is collated
    in some other manner, such as with the Atomistic Simulation
    Environment (ASE), stored in RAM, and inserted into the FitSNAP data
    dictionary that houses training data. Nonetheless, the FitSNAP data
    dictionary contains atomic positions that are then converted to
    atomic environment descriptors in the
    <monospace>Calculator</monospace> class.</p>
  </sec>
  <sec id="calculator">
    <title>Calculator</title>
    <p>To transform this structural information into physically
    appropriate models, we employ the <monospace>Calculator</monospace>
    class which provides permutation, translationally and rotationally
    invariant descriptors. These descriptors can be calculated from
    their performant implementations in LAMMPS, and then extracted via
    the LAMMPS Python/C API, which inserts descriptors into the shared
    memory arrays of <monospace>ParallelTools</monospace>. For
    descriptors that are not implemented in LAMMPS, we provide a
    <monospace>Custom Calculator</monospace> class that extracts
    periodic-boundary-transformed LAMMPS positions which can be used to
    calculate custom coded descriptors in Python. This ensures
    extensibility of different descriptors for describing atomic
    environments. Regardless of the method of descriptor calculation,
    these calculations are parallelized via MPI over configurations of
    atoms stored in the FitSNAP data dictionary. Currently we include
    Spectral Neighbor Analysis Potential (SNAP)
    (<xref alt="Thompson et al., 2015" rid="ref-thompson2015spectral" ref-type="bibr">Thompson
    et al., 2015</xref>) and Atomic Cluster Environment (ACE)
    (<xref alt="Drautz, 2019" rid="ref-drautz2019atomic" ref-type="bibr">Drautz,
    2019</xref>) descriptors which are both calculated in LAMMPS.</p>
  </sec>
  <sec id="solver">
    <title>Solver</title>
    <p>After collating the necessary descriptors and their target
    fitting quantities, the <monospace>Solver</monospace> class can
    either proceed to regression of the ML problem or evaluating the
    model. The connection between descriptor calculation, which can
    happen in LAMMPS, and FitSNAP solvers is exemplified in
    <xref alt="[fig:connection]" rid="figU003Aconnection">[fig:connection]</xref>
    for a neural network potential inputting arbitrary atom-centered
    descriptors. In the typical flow of control for fitting a potential,
    <monospace>Solver</monospace> creates a loss function measuring
    difference between target and model fitting quantities such as
    energies and forces. This loss function is then minimized with a
    method depending on the choice of user input. For linear models,
    solver types include singular value decomposition (SVD) or adaptive
    rectangular decomposition (ARD). One advantage of linear models is
    the possibility to analytically determine uncertainties in fitting
    coefficients with Bayesian statistics. FitSNAP therefore also
    includes uncertainty quantification (UQ) solvers, which output model
    coefficient covariances for linear models.</p>
    <fig>
      <caption><p>LAMMPS-FitSNAP interface for calculating energies and
      forces with machine learned potentials, illustrated here with a
      neural network potential that calculates atomic energies.
      Descriptor and descriptor gradient calculations occur in LAMMPS,
      while model and model gradient calculations occur with automatic
      differentiation (autodiff) frameworks in
      FitSNAP.<styled-content id="figU003Aconnection"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/6452c10e99cb7e844ca6f478a01a8a4770003f2d.png" />
    </fig>
    <p>For nonlinear models, solver types include neural networks
    implemented in PyTorch or JAX. The set of available solver type
    depends on the form of the ML regression model. To ensure good
    computational performance when fitting nonlinear models to forces,
    we use a modified form of iterated back-propagation
    (<xref alt="Smith et al., 2020" rid="ref-smith2020simple" ref-type="bibr">Smith
    et al., 2020</xref>) where forces are calculated as a first
    back-propagation with respect to model inputs, but descriptor
    gradients are computed with their performant implementations in
    LAMMPS. This requires matching or aligning between descriptor
    gradients extracted from LAMMPS, and model gradients extracted from
    ML frameworks like PyTorch or JAX. To achieve this, we routinely
    verify the correctness of our forces by comparing them with finite
    difference estimates as a part of our continuous integration
    testing. Ultimately, after optimizing the ML model with the
    <monospace>Solver</monospace> class, FitSNAP produces LAMMPS-ready
    files which may be directly used as inputs to large-scale LAMMPS
    simulations.</p>
  </sec>
</sec>
<sec id="extensibility">
  <title>Extensibility</title>
  <p>The modularity of these components allows for different
  <monospace>Calculator</monospace> and <monospace>Solver</monospace>
  sub-classes, allowing for a variety of different descriptor and model
  combinations. Any descriptor may be programmed in the
  <monospace>Calculator</monospace> class, which can then be input to
  any ML model in the <monospace>Solver</monospace> class to perform
  fitting. This flexibility can also extend to model architectures
  entirely different to the commonly used atom-centered networks, such
  as pairwise networks
  (<xref alt="Jose et al., 2012" rid="ref-jose2012construction" ref-type="bibr">Jose
  et al., 2012</xref>) which are also included in FitSNAP. These custom
  and less traditional architectures are readily implemented using
  LAMMPS periodic-boundary-condition transformed positions. Aside from
  flexibility in choosing or implementing various descriptors and
  models, we also provide a library mode where a FitSNAP object can be
  created in any external Python script. This allows users to access
  internal methods and break the usual sequential flow of control for
  their specific applications. Some users for example may want to
  extract descriptors for a set of configurations and perform
  statistical analysis on that data, access hyperparameters in an
  external optimization tool, or even code an entirely new component not
  mentioned here. This Python library also allows interface to custom
  workflow frameworks like <monospace>pyiron</monospace>
  (<xref alt="Janssen et al., 2019" rid="ref-janssen2019pyiron" ref-type="bibr">Janssen
  et al., 2019</xref>), allowing users to save, share, and modify their
  workflows for training and using machine learned potentials. In all
  cases, the ability to program and use any descriptor or model based on
  position data extracted from LAMMPS ensures utmost extensibility to
  future atomic environment descriptors and models, while allowing users
  to enjoy connection to a high-performance MD engine immediately after
  training potentials.</p>
</sec>
<sec id="funding-statement">
  <title>Funding Statement</title>
  <p>This article has been authored by an employee of National
  Technology &amp; Engineering Solutions of Sandia, LLC under Contract
  No. DE-NA0003525 with the U.S. Department of Energy (DOE). The
  employee owns all right, title and interest in and to the article and
  is solely responsible for its contents. The United States Government
  retains and the publisher, by accepting the article for publication,
  acknowledges that the United States Government retains a
  non-exclusive, paid-up, irrevocable, world-wide license to publish or
  reproduce the published form of this article or allow others to do so,
  for United States Government purposes. The DOE will provide public
  access to these results of federally sponsored research in accordance
  with the DOE Public Access Plan
  https://www.energy.gov/downloads/doe-public-access-plan.</p>
  <p>This paper describes objective technical results and analysis. Any
  subjective views or opinions that might be expressed in the paper do
  not necessarily represent the views of the U.S. Department of Energy
  or the United States Government.</p>
  <p>All authors acknowledge funding support from the U.S. Department of
  Energy, Office of Fusion Energy Sciences (OFES) under Field Work
  Proposal Number 20-023149 and the Exascale Computing Project
  (17-SC-20-SC), a collaborative effort of the U.S. Department of Energy
  Office of Science and the National Nuclear Security
  Administration.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-wang2018deepmd">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Han</given-names></name>
        <name><surname>Zhang</surname><given-names>Linfeng</given-names></name>
        <name><surname>Han</surname><given-names>Jiequn</given-names></name>
        <name><surname>Weinan</surname><given-names>E</given-names></name>
      </person-group>
      <article-title>DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>228</volume>
      <uri>https://doi.org/10.1016/j.cpc.2018.03.016</uri>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2018.03.016</pub-id>
      <fpage>178</fpage>
      <lpage>184</lpage>
    </element-citation>
  </ref>
  <ref id="ref-singraber2019library">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Singraber</surname><given-names>Andreas</given-names></name>
        <name><surname>Behler</surname><given-names>Jörg</given-names></name>
        <name><surname>Dellago</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Library-based LAMMPS implementation of high-dimensional neural network potentials</article-title>
      <source>Journal of chemical theory and computation</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>15</volume>
      <issue>3</issue>
      <uri>https://doi.org/10.1021/acs.jctc.8b00770.s001</uri>
      <pub-id pub-id-type="doi">10.1021/acs.jctc.8b00770.s001</pub-id>
      <fpage>1827</fpage>
      <lpage>1840</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bochkarev2022efficient">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bochkarev</surname><given-names>Anton</given-names></name>
        <name><surname>Lysogorskiy</surname><given-names>Yury</given-names></name>
        <name><surname>Menon</surname><given-names>Sarath</given-names></name>
        <name><surname>Qamar</surname><given-names>Minaam</given-names></name>
        <name><surname>Mrovec</surname><given-names>Matous</given-names></name>
        <name><surname>Drautz</surname><given-names>Ralf</given-names></name>
      </person-group>
      <article-title>Efficient parametrization of the atomic cluster expansion</article-title>
      <source>Physical Review Materials</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>6</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1103/physrevmaterials.6.013804</uri>
      <pub-id pub-id-type="doi">10.1103/physrevmaterials.6.013804</pub-id>
      <fpage>013804</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-batzner20223">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Batzner</surname><given-names>Simon</given-names></name>
        <name><surname>Musaelian</surname><given-names>Albert</given-names></name>
        <name><surname>Sun</surname><given-names>Lixin</given-names></name>
        <name><surname>Geiger</surname><given-names>Mario</given-names></name>
        <name><surname>Mailoa</surname><given-names>Jonathan P</given-names></name>
        <name><surname>Kornbluth</surname><given-names>Mordechai</given-names></name>
        <name><surname>Molinari</surname><given-names>Nicola</given-names></name>
        <name><surname>Smidt</surname><given-names>Tess E</given-names></name>
        <name><surname>Kozinsky</surname><given-names>Boris</given-names></name>
      </person-group>
      <article-title>E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials</article-title>
      <source>Nature communications</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>13</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.21203/rs.3.rs-244137/v1</uri>
      <pub-id pub-id-type="doi">10.21203/rs.3.rs-244137/v1</pub-id>
      <fpage>1</fpage>
      <lpage>11</lpage>
    </element-citation>
  </ref>
  <ref id="ref-musaelian2023learning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Musaelian</surname><given-names>Albert</given-names></name>
        <name><surname>Batzner</surname><given-names>Simon</given-names></name>
        <name><surname>Johansson</surname><given-names>Anders</given-names></name>
        <name><surname>Sun</surname><given-names>Lixin</given-names></name>
        <name><surname>Owen</surname><given-names>Cameron J</given-names></name>
        <name><surname>Kornbluth</surname><given-names>Mordechai</given-names></name>
        <name><surname>Kozinsky</surname><given-names>Boris</given-names></name>
      </person-group>
      <article-title>Learning local equivariant representations for large-scale atomistic dynamics</article-title>
      <source>Nature Communications</source>
      <publisher-name>Nature Publishing Group UK London</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>14</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1038/s41467-023-36329-y</uri>
      <pub-id pub-id-type="doi">10.1038/s41467-023-36329-y</pub-id>
      <fpage>579</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-khorshidi2016amp">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Khorshidi</surname><given-names>Alireza</given-names></name>
        <name><surname>Peterson</surname><given-names>Andrew A</given-names></name>
      </person-group>
      <article-title>Amp: A modular approach to machine learning in atomistic simulations</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>207</volume>
      <uri>https://doi.org/10.1016/j.cpc.2016.05.010</uri>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2016.05.010</pub-id>
      <fpage>310</fpage>
      <lpage>324</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gao2020torchani">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gao</surname><given-names>Xiang</given-names></name>
        <name><surname>Ramezanghorbani</surname><given-names>Farhad</given-names></name>
        <name><surname>Isayev</surname><given-names>Olexandr</given-names></name>
        <name><surname>Smith</surname><given-names>Justin S</given-names></name>
        <name><surname>Roitberg</surname><given-names>Adrian E</given-names></name>
      </person-group>
      <article-title>TorchANI: A free and open source PyTorch-based deep learning implementation of the ANI neural network potentials</article-title>
      <source>Journal of chemical information and modeling</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>60</volume>
      <issue>7</issue>
      <uri>https://doi.org/10.26434/chemrxiv.12218294</uri>
      <pub-id pub-id-type="doi">10.26434/chemrxiv.12218294</pub-id>
      <fpage>3408</fpage>
      <lpage>3415</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nguyen2021billion">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Nguyen-Cong</surname><given-names>Kien</given-names></name>
        <name><surname>Willman</surname><given-names>Jonathan T</given-names></name>
        <name><surname>Moore</surname><given-names>Stan G</given-names></name>
        <name><surname>Belonoshko</surname><given-names>Anatoly B</given-names></name>
        <name><surname>Gayatri</surname><given-names>Rahulkumar</given-names></name>
        <name><surname>Weinberg</surname><given-names>Evan</given-names></name>
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Oleynik</surname><given-names>Ivan I</given-names></name>
      </person-group>
      <article-title>Billion atom molecular dynamics simulations of carbon at extreme conditions and experimental time and length scales</article-title>
      <source>Proceedings of the international conference for high performance computing, networking, storage and analysis</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://doi.org/10.1145/3458817.3487400</uri>
      <pub-id pub-id-type="doi">10.1145/3458817.3487400</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nikolov2021data">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nikolov</surname><given-names>Svetoslav</given-names></name>
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>Cangi</surname><given-names>Attila</given-names></name>
        <name><surname>Maillet</surname><given-names>Jean-Bernard</given-names></name>
        <name><surname>Marinica</surname><given-names>Mihai-Cosmin</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Desjarlais</surname><given-names>Michael P</given-names></name>
        <name><surname>Tranchida</surname><given-names>Julien</given-names></name>
      </person-group>
      <article-title>Data-driven magneto-elastic predictions with scalable classical spin-lattice dynamics</article-title>
      <source>npj Computational Materials</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>7</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1038/s41524-021-00617-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41524-021-00617-2</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cusentino2021beryllium">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cusentino</surname><given-names>Mary Alice</given-names></name>
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
      </person-group>
      <article-title>Beryllium-driven structural evolution at the divertor surface</article-title>
      <source>Nuclear Fusion</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>61</volume>
      <issue>4</issue>
      <uri>https://doi.org/10.1088/1741-4326/abe7bd</uri>
      <pub-id pub-id-type="doi">10.1088/1741-4326/abe7bd</pub-id>
      <fpage>046049</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-cusentino2020explicit">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cusentino</surname><given-names>Mary Alice</given-names></name>
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
      </person-group>
      <article-title>Explicit multielement extension of the spectral neighbor analysis potential for chemically complex systems</article-title>
      <source>The Journal of Physical Chemistry A</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>124</volume>
      <issue>26</issue>
      <uri>https://doi.org/10.1021/acs.jpca.0c02450.s001</uri>
      <pub-id pub-id-type="doi">10.1021/acs.jpca.0c02450.s001</pub-id>
      <fpage>5456</fpage>
      <lpage>5464</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zuo2020performance">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zuo</surname><given-names>Yunxing</given-names></name>
        <name><surname>Chen</surname><given-names>Chi</given-names></name>
        <name><surname>Li</surname><given-names>Xiangguo</given-names></name>
        <name><surname>Deng</surname><given-names>Zhi</given-names></name>
        <name><surname>Chen</surname><given-names>Yiming</given-names></name>
        <name><surname>Behler</surname><given-names>Jörg</given-names></name>
        <name><surname>Csányi</surname><given-names>Gábor</given-names></name>
        <name><surname>Shapeev</surname><given-names>Alexander V</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Performance and cost assessment of machine learning interatomic potentials</article-title>
      <source>The Journal of Physical Chemistry A</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>124</volume>
      <issue>4</issue>
      <uri>https://doi.org/10.1021/acs.jpca.9b08723.s001</uri>
      <pub-id pub-id-type="doi">10.1021/acs.jpca.9b08723.s001</pub-id>
      <fpage>731</fpage>
      <lpage>745</lpage>
    </element-citation>
  </ref>
  <ref id="ref-thompson2022lammps">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Aktulga</surname><given-names>H Metin</given-names></name>
        <name><surname>Berger</surname><given-names>Richard</given-names></name>
        <name><surname>Bolintineanu</surname><given-names>Dan S</given-names></name>
        <name><surname>Brown</surname><given-names>W Michael</given-names></name>
        <name><surname>Crozier</surname><given-names>Paul S</given-names></name>
        <name><surname>Veld</surname><given-names>Pieter J in’t</given-names></name>
        <name><surname>Kohlmeyer</surname><given-names>Axel</given-names></name>
        <name><surname>Moore</surname><given-names>Stan G</given-names></name>
        <name><surname>Nguyen</surname><given-names>Trung Dac</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>LAMMPS-a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>271</volume>
      <uri>https://doi.org/10.1016/j.cpc.2021.108171</uri>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2021.108171</pub-id>
      <fpage>108171</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-smith2020simple">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Smith</surname><given-names>Justin S</given-names></name>
        <name><surname>Lubbers</surname><given-names>Nicholas</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Barros</surname><given-names>Kipton</given-names></name>
      </person-group>
      <article-title>Simple and efficient algorithms for training machine learning potentials to force data</article-title>
      <source>arXiv preprint arXiv:2006.05475</source>
      <year iso-8601-date="2020">2020</year>
      <uri>https://doi.org/10.2172/1763572</uri>
      <pub-id pub-id-type="doi">10.2172/1763572</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ortner-acesuit">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ortner</surname><given-names>Christoph</given-names></name>
        <name><surname>Kermode</surname><given-names>James</given-names></name>
      </person-group>
      <article-title>ACEsuit</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/ACEsuit</uri>
    </element-citation>
  </ref>
  <ref id="ref-bartok2010gaussian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bartók</surname><given-names>Albert P</given-names></name>
        <name><surname>Payne</surname><given-names>Mike C</given-names></name>
        <name><surname>Kondor</surname><given-names>Risi</given-names></name>
        <name><surname>Csányi</surname><given-names>Gábor</given-names></name>
      </person-group>
      <article-title>Gaussian approximation potentials: The accuracy of quantum mechanics, without the electrons</article-title>
      <source>Physical review letters</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>104</volume>
      <issue>13</issue>
      <uri>https://doi.org/10.1103/physrevlett.104.136403</uri>
      <pub-id pub-id-type="doi">10.1103/physrevlett.104.136403</pub-id>
      <fpage>136403</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jose2012construction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jose</surname><given-names>KV Jovan</given-names></name>
        <name><surname>Artrith</surname><given-names>Nongnuch</given-names></name>
        <name><surname>Behler</surname><given-names>Jörg</given-names></name>
      </person-group>
      <article-title>Construction of high-dimensional neural network potentials using environment-dependent atom pairs</article-title>
      <source>The Journal of chemical physics</source>
      <publisher-name>American Institute of Physics</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>136</volume>
      <issue>19</issue>
      <uri>https://doi.org/10.1063/1.4712397</uri>
      <pub-id pub-id-type="doi">10.1063/1.4712397</pub-id>
      <fpage>194111</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-nikolov2022dissociating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nikolov</surname><given-names>Svetoslav</given-names></name>
        <name><surname>Tranchida</surname><given-names>Julien</given-names></name>
        <name><surname>Ramakrishna</surname><given-names>K</given-names></name>
        <name><surname>Lokamani</surname><given-names>M</given-names></name>
        <name><surname>Cangi</surname><given-names>A</given-names></name>
        <name><surname>Wood</surname><given-names>M</given-names></name>
      </person-group>
      <article-title>Dissociating the phononic, magnetic and electronic contributions to thermal conductivity: A computational study in alpha-iron</article-title>
      <source>Journal of Materials Science</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://doi.org/10.1007/s10853-021-06865-3</uri>
      <pub-id pub-id-type="doi">10.1007/s10853-021-06865-3</pub-id>
      <fpage>1</fpage>
      <lpage>14</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wood2018extending">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wood</surname><given-names>Mitchell A</given-names></name>
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
      </person-group>
      <article-title>Extending the accuracy of the SNAP interatomic potential form</article-title>
      <source>The Journal of chemical physics</source>
      <publisher-name>AIP Publishing LLC</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>148</volume>
      <issue>24</issue>
      <uri>https://doi.org/10.1063/1.5017641</uri>
      <pub-id pub-id-type="doi">10.1063/1.5017641</pub-id>
      <fpage>241721</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-thompson2015spectral">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Swiler</surname><given-names>Laura P</given-names></name>
        <name><surname>Trott</surname><given-names>Christian R</given-names></name>
        <name><surname>Foiles</surname><given-names>Stephen M</given-names></name>
        <name><surname>Tucker</surname><given-names>Garritt J</given-names></name>
      </person-group>
      <article-title>Spectral neighbor analysis method for automated generation of quantum-accurate interatomic potentials</article-title>
      <source>Journal of Computational Physics</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>285</volume>
      <uri>https://doi.org/10.1016/j.jcp.2014.12.018</uri>
      <pub-id pub-id-type="doi">10.1016/j.jcp.2014.12.018</pub-id>
      <fpage>316</fpage>
      <lpage>330</lpage>
    </element-citation>
  </ref>
  <ref id="ref-drautz2019atomic">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Drautz</surname><given-names>Ralf</given-names></name>
      </person-group>
      <article-title>Atomic cluster expansion for accurate and transferable interatomic potentials</article-title>
      <source>Physical Review B</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>99</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1103/physrevb.99.014104</uri>
      <pub-id pub-id-type="doi">10.1103/physrevb.99.014104</pub-id>
      <fpage>014104</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-janssen2019pyiron">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Janssen</surname><given-names>Jan</given-names></name>
        <name><surname>Surendralal</surname><given-names>Sudarsan</given-names></name>
        <name><surname>Lysogorskiy</surname><given-names>Yury</given-names></name>
        <name><surname>Todorova</surname><given-names>Mira</given-names></name>
        <name><surname>Hickel</surname><given-names>Tilmann</given-names></name>
        <name><surname>Drautz</surname><given-names>Ralf</given-names></name>
        <name><surname>Neugebauer</surname><given-names>Jörg</given-names></name>
      </person-group>
      <article-title>Pyiron: An integrated development environment for computational materials science</article-title>
      <source>Computational Materials Science</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>163</volume>
      <uri>https://doi.org/10.1016/j.commatsci.2018.07.043</uri>
      <pub-id pub-id-type="doi">10.1016/j.commatsci.2018.07.043</pub-id>
      <fpage>24</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
