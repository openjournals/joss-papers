<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20250109154524-1f5bcdbab470dca7008ce3b37572d75f2bfaa5b8</doi_batch_id>
    <timestamp>20250109154524</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>01</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>105</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>G’MIC: An Open-Source Self-Extending Framework for Image Processing</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>David</given_name>
            <surname>Tschumperlé</surname>
            <affiliations>
              <institution><institution_name>GREYC Lab (IMAGE Team), CNRS, Normandie Univ, UNICAEN, ENSICAEN, F-14000 Caen, France </institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0003-3454-5079</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Sébastien</given_name>
            <surname>Fourey</surname>
            <affiliations>
              <institution><institution_name>GREYC Lab (IMAGE Team), CNRS, Normandie Univ, UNICAEN, ENSICAEN, F-14000 Caen, France </institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0001-9293-0771</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Garry</given_name>
            <surname>Osgood</surname>
            <affiliations>
              <institution><institution_name>Independent researcher, New York City, USA</institution_name></institution>
            </affiliations>
          </person_name>
        </contributors>
        <publication_date>
          <month>01</month>
          <day>09</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>6618</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06618</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.13936919</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6618</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06618</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06618</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06618.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="imagemagick">
            <article_title>ImageMagick</article_title>
            <author>ImageMagick Studio LLC</author>
            <cYear>2023</cYear>
            <unstructured_citation>ImageMagick Studio LLC. (2023). ImageMagick (Version 7.0.10). https://imagemagick.org</unstructured_citation>
          </citation>
          <citation key="graphicsmagick">
            <article_title>GraphicsMagick</article_title>
            <author>GraphicsMagick Group</author>
            <cYear>2023</cYear>
            <unstructured_citation>GraphicsMagick Group. (2023). GraphicsMagick (Version 1.3.40). http://www.graphicsmagick.org/</unstructured_citation>
          </citation>
          <citation key="cimg">
            <volume_title>Digital image processing with C++: Implementing reference algorithms with the Cimg Library (1st Ed.)</volume_title>
            <author>Tschumperle</author>
            <doi>10.1201/9781003323693</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Tschumperle, D., Tilmant, C., &amp; Barra, V. (2023). Digital image processing with C++: Implementing reference algorithms with the Cimg Library (1st Ed.). CRC Press. https://doi.org/10.1201/9781003323693</unstructured_citation>
          </citation>
          <citation key="tschumperle2022automatic">
            <article_title>Automatic illumination of flat-colored drawings by 3D augmentation of 2D silhouettes</article_title>
            <author>Tschumperlé</author>
            <journal_title>2022 IEEE international conference on image processing (ICIP)</journal_title>
            <doi>10.1109/icip46576.2022.9897386</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Tschumperlé, D., Porquet, C., &amp; Mahboubi, A. (2022). Automatic illumination of flat-colored drawings by 3D augmentation of 2D silhouettes. 2022 IEEE International Conference on Image Processing (ICIP), 371–375. https://doi.org/10.1109/icip46576.2022.9897386</unstructured_citation>
          </citation>
          <citation key="samuth2022patch">
            <article_title>A patch-based approach for artistic style transfer via constrained multi-scale image matching</article_title>
            <author>Samuth</author>
            <journal_title>2022 IEEE international conference on image processing (ICIP)</journal_title>
            <doi>10.1109/icip46576.2022.9897334</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Samuth, B., Tschumperlé, D., &amp; Rabin, J. (2022). A patch-based approach for artistic style transfer via constrained multi-scale image matching. 2022 IEEE International Conference on Image Processing (ICIP), 3490–3494. https://doi.org/10.1109/icip46576.2022.9897334</unstructured_citation>
          </citation>
          <citation key="fourey2018fast">
            <article_title>A fast and efficient semi-guided algorithm for flat coloring line-arts</article_title>
            <author>Fourey</author>
            <journal_title>International symposium on vision, modeling and visualization</journal_title>
            <cYear>2018</cYear>
            <unstructured_citation>Fourey, S., Tschumperlé, D., &amp; Revoy, D. (2018). A fast and efficient semi-guided algorithm for flat coloring line-arts. International Symposium on Vision, Modeling and Visualization.</unstructured_citation>
          </citation>
          <citation key="tschumperle2020reconstruction">
            <article_title>Reconstruction of smooth 3D color functions from keypoints: Application to lossy compression and exemplar-based generation of color LUTs</article_title>
            <author>Tschumperlé</author>
            <journal_title>SIAM Journal on Imaging Sciences</journal_title>
            <issue>3</issue>
            <volume>13</volume>
            <doi>10.1137/19m1306798</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Tschumperlé, D., Porquet, C., &amp; Mahboubi, A. (2020). Reconstruction of smooth 3D color functions from keypoints: Application to lossy compression and exemplar-based generation of color LUTs. SIAM Journal on Imaging Sciences, 13(3), 1511–1535. https://doi.org/10.1137/19m1306798</unstructured_citation>
          </citation>
          <citation key="buyssens2015exemplar">
            <article_title>Exemplar-based inpainting: Technical review and new heuristics for better geometric reconstructions</article_title>
            <author>Buyssens</author>
            <journal_title>IEEE transactions on image processing</journal_title>
            <issue>6</issue>
            <volume>24</volume>
            <doi>10.1109/tip.2015.2411437</doi>
            <cYear>2015</cYear>
            <unstructured_citation>Buyssens, P., Daisy, M., Tschumperlé, D., &amp; Lézoray, O. (2015). Exemplar-based inpainting: Technical review and new heuristics for better geometric reconstructions. IEEE Transactions on Image Processing, 24(6), 1809–1824. https://doi.org/10.1109/tip.2015.2411437</unstructured_citation>
          </citation>
          <citation key="jehan18">
            <article_title>Lineart Bucket Fill</article_title>
            <author>GIMP</author>
            <cYear>2018</cYear>
            <unstructured_citation>GIMP. (2018). Lineart Bucket Fill. https://developer.gimp.org/core/algorithm/line-art-bucket-fill/</unstructured_citation>
          </citation>
          <citation key="mathmap">
            <article_title>The MathMap image processing application</article_title>
            <author>Probst</author>
            <cYear>2009</cYear>
            <unstructured_citation>Probst, M. (2009). The MathMap image processing application (Version 1.3.5). https://www.complang.tuwien.ac.at/schani/mathmap/</unstructured_citation>
          </citation>
          <citation key="pixelitor">
            <article_title>Pixelitor</article_title>
            <author>Balázs-Csíki</author>
            <cYear>2023</cYear>
            <unstructured_citation>Balázs-Csíki, László. (2023). Pixelitor (Version 4.3.0). https://pixelitor.sourceforge.io/index.html</unstructured_citation>
          </citation>
          <citation key="filterforge">
            <article_title>Filter forge</article_title>
            <author>Ashbrook</author>
            <journal_title>PSA Journal</journal_title>
            <issue>2</issue>
            <volume>84</volume>
            <cYear>2018</cYear>
            <unstructured_citation>Ashbrook, B. (2018). Filter forge. PSA Journal, 84(2), 8–10.</unstructured_citation>
          </citation>
          <citation key="qt">
            <article_title>A cross-platform software for creating graphical user interfaces</article_title>
            <author>Qt</author>
            <cYear>2020</cYear>
            <unstructured_citation>Qt. (2020). A cross-platform software for creating graphical user interfaces (Version 5). https://www.qt.io</unstructured_citation>
          </citation>
          <citation key="ray2023outflows">
            <article_title>Outflows from the youngest stars are mostly molecular</article_title>
            <author>Ray</author>
            <journal_title>Nature</journal_title>
            <issue>7981</issue>
            <volume>622</volume>
            <doi>10.1038/s41586-023-06551-1</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Ray, T. P., McCaughrean, M. J., Caratti o Garatti, A., Kavanagh, P., Justtanont, K., Dishoeck, E. F. van, Reitsma, M., Beuther, H., Francis, L., Gieser, C., &amp; others. (2023). Outflows from the youngest stars are mostly molecular. Nature, 622(7981), 48–52. https://doi.org/10.1038/s41586-023-06551-1</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
