<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8262</article-id>
<article-id pub-id-type="doi">10.21105/joss.08262</article-id>
<title-group>
<article-title>embedplyr: Tools for Working With Text
Embeddings</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0001-9347-0145</contrib-id>
<name>
<surname>Teitelbaum</surname>
<given-names>Louis</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Ben-Gurion University of the Negev, Israel</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-01-10">
<day>10</day>
<month>1</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>115</issue>
<fpage>8262</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>natural language processing</kwd>
<kwd>embeddings</kwd>
<kwd>word embeddings</kwd>
<kwd>sentiment analysis</kwd>
<kwd>psychology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Dense vector embeddings are the fundamental building block of
  modern natural language processing
  (<xref alt="Lauriola, Lavelli, &amp; Aiolli, 2022" rid="ref-lauriola2022" ref-type="bibr">Lauriola,
  Lavelli, &amp; Aiolli, 2022</xref>). The ability to represent the
  meaning of texts as a continuous, high dimensional space underlies the
  recent successes of large language models (LLMs). Embeddings have also
  revolutionized research methods and inspired new theoretical
  frameworks in linguistics, psychology, sociology, and neuroscience
  (see e.g.
  <xref alt="Duran, Paxton, &amp; Fusaroli, 2019" rid="ref-duran2019" ref-type="bibr">Duran,
  Paxton, &amp; Fusaroli, 2019</xref>;
  <xref alt="Feuerriegel et al., 2025" rid="ref-feuerriegel2025" ref-type="bibr">Feuerriegel
  et al., 2025</xref>;
  <xref alt="Grand, Blank, Pereira, &amp; Fedorenko, 2022" rid="ref-grand2022" ref-type="bibr">Grand,
  Blank, Pereira, &amp; Fedorenko, 2022</xref>;
  <xref alt="Hamilton, Leskovec, &amp; Jurafsky, 2018" rid="ref-hamilton2018" ref-type="bibr">Hamilton,
  Leskovec, &amp; Jurafsky, 2018</xref>;
  <xref alt="Kjell, Giorgi, &amp; Schwartz, 2023" rid="ref-kjell2023" ref-type="bibr">Kjell,
  Giorgi, &amp; Schwartz, 2023</xref>;
  <xref alt="Kozlowski, Taddy, &amp; Evans, 2019" rid="ref-kozlowski2019" ref-type="bibr">Kozlowski,
  Taddy, &amp; Evans, 2019</xref>;
  <xref alt="Schrimpf et al., 2021" rid="ref-schrimpf2021" ref-type="bibr">Schrimpf
  et al., 2021</xref>). As text embeddings become ubiquitous in the
  social and behavioral sciences, the need for flexible, easy-to-learn
  tools increases. Answering this need, <bold>embedplyr</bold>
  (pronounced “embe-DEE-plier”) enables common operations with word and
  text embeddings within familiar analysis workflows.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p><bold>embedplyr</bold> is designed for integration with a
  <bold>tidyverse</bold>
  (<xref alt="Wickham et al., 2019" rid="ref-wickham2019" ref-type="bibr">Wickham
  et al., 2019</xref>) and/or <bold>quanteda</bold>
  (<xref alt="Benoit et al., 2018" rid="ref-benoit2018" ref-type="bibr">Benoit
  et al., 2018</xref>) workflow, as demonstrated in Teitelbaum &amp;
  Simchon
  (<xref alt="2024" rid="ref-teitelbaum2024" ref-type="bibr">2024</xref>).
  Much as <bold>dplyr</bold> is “a grammar of data manipulation,
  providing a consistent set of verbs that help you solve the most
  common data manipulation challenges”
  (<xref alt="Wickham, François, Henry, Müller, &amp; Vaughan, 2025" rid="ref-wickham2025" ref-type="bibr">Wickham,
  François, Henry, Müller, &amp; Vaughan, 2025</xref>),
  <bold>embedplyr</bold> is a grammar of embeddings manipulation,
  designed to facilitate the use of word and text embeddings in common
  analysis workflows without introducing new syntax or unfamiliar data
  structures to R users.</p>
  <p>Existing tools for working with embeddings in R are generally
  specific to particular model architectures. For example,
  <bold>word2vec</bold>
  (<xref alt="Wijffels, Watanabe, &amp; Fomichev, 2023" rid="ref-wijffels2023" ref-type="bibr">Wijffels,
  Watanabe, &amp; Fomichev, 2023</xref>) provides access to word2vec
  models
  (<xref alt="Mikolov, Chen, Corrado, &amp; Dean, 2013" rid="ref-mikolov2013a" ref-type="bibr">Mikolov,
  Chen, Corrado, &amp; Dean, 2013</xref>;
  <xref alt="Mikolov, Sutskever, Chen, Corrado, &amp; Dean, 2013" rid="ref-mikolov2013b" ref-type="bibr">Mikolov,
  Sutskever, Chen, Corrado, &amp; Dean, 2013</xref>),
  <bold>text2vec</bold>
  (<xref alt="Selivanov, Bickel, &amp; Wang, 2023" rid="ref-selivanov2023" ref-type="bibr">Selivanov,
  Bickel, &amp; Wang, 2023</xref>) provides access to LDA, LSA, and
  GloVe models
  (<xref alt="Blei, Ng, &amp; Jordan, 2003" rid="ref-blei2003" ref-type="bibr">Blei,
  Ng, &amp; Jordan, 2003</xref>;
  <xref alt="Deerwester, Dumais, Furnas, Landauer, &amp; Harshman, 1990" rid="ref-deerwester1990" ref-type="bibr">Deerwester,
  Dumais, Furnas, Landauer, &amp; Harshman, 1990</xref>;
  <xref alt="Pennington, Socher, &amp; Manning, 2014" rid="ref-pennington2014" ref-type="bibr">Pennington,
  Socher, &amp; Manning, 2014</xref>), <bold>fastText</bold>
  (<xref alt="Mouselimis, 2024" rid="ref-mouselimis2024" ref-type="bibr">Mouselimis,
  2024</xref>) provides access to fastText models
  (<xref alt="Bojanowski, Grave, Joulin, &amp; Mikolov, 2017a" rid="ref-bojanowski2017b" ref-type="bibr">Bojanowski,
  Grave, Joulin, &amp; Mikolov, 2017a</xref>,
  <xref alt="2017b" rid="ref-bojanowski2017a" ref-type="bibr">2017b</xref>;
  <xref alt="Facebook, 2016" rid="ref-facebook2016" ref-type="bibr">Facebook,
  2016</xref>;
  <xref alt="Grave, Bojanowski, Gupta, Joulin, &amp; Mikolov, 2018" rid="ref-grave2018" ref-type="bibr">Grave,
  Bojanowski, Gupta, Joulin, &amp; Mikolov, 2018</xref>), and
  <bold>text</bold>
  (<xref alt="Kjell et al., 2023" rid="ref-kjell2023" ref-type="bibr">Kjell
  et al., 2023</xref>) provides access to transformers-based LLMs
  (<xref alt="Wolf et al., 2020" rid="ref-wolf2020" ref-type="bibr">Wolf
  et al., 2020</xref>). While these tools are already invaluable in the
  social and behavioral sciences, using different syntax and separate
  data structures for each model architecture can be cumbersome. This is
  especially true given the prevalence of studies that make use of
  multiple model architectures in parallel analyses (e.g.
  <xref alt="Carrella et al., 2023" rid="ref-carrella2023" ref-type="bibr">Carrella
  et al., 2023</xref>;
  <xref alt="Hussain, Mata, Newell, &amp; Wulff, 2024" rid="ref-hussain2024" ref-type="bibr">Hussain,
  Mata, Newell, &amp; Wulff, 2024</xref>;
  <xref alt="Markus, Levi, Sheafer, &amp; Shenhav, 2024" rid="ref-markus2024" ref-type="bibr">Markus,
  Levi, Sheafer, &amp; Shenhav, 2024</xref>). <bold>embedplyr</bold>
  fills this gap with a model-agnostic approach; it can be used to work
  with embeddings from any model framework using syntax that will be
  familiar to any <bold>tidyverse</bold> user. While some existing tools
  focus on convenience functions for encouraging expert-recommended best
  practices (e.g.
  <xref alt="Kjell et al., 2023" rid="ref-kjell2023" ref-type="bibr">Kjell
  et al., 2023</xref>), <bold>embedplyr</bold> prioritizes
  flexibility—much like its namesake, <bold>dplyr</bold>
  (<xref alt="Wickham et al., 2025" rid="ref-wickham2025" ref-type="bibr">Wickham
  et al., 2025</xref>). This approach yields simple, modular functions
  that are useful both for educating students (see
  <xref alt="Teitelbaum &amp; Simchon, 2024" rid="ref-teitelbaum2024" ref-type="bibr">Teitelbaum
  &amp; Simchon, 2024</xref>) and experimenting with novel methods.</p>
</sec>
<sec id="features">
  <title>Features</title>
  <sec id="loading-pretrained-token-embeddings">
    <title>Loading Pretrained Token Embeddings</title>
    <p><bold>embedplyr</bold> does not include tools for training new
    embedding models, but it can load embeddings from a file or download
    them from online. This is especially useful for pretrained word
    embedding models like GloVe
    (<xref alt="Pennington et al., 2014" rid="ref-pennington2014" ref-type="bibr">Pennington
    et al., 2014</xref>), word2vec
    (<xref alt="Mikolov, Chen, et al., 2013" rid="ref-mikolov2013a" ref-type="bibr">Mikolov,
    Chen, et al., 2013</xref>;
    <xref alt="Mikolov, Sutskever, et al., 2013" rid="ref-mikolov2013b" ref-type="bibr">Mikolov,
    Sutskever, et al., 2013</xref>), HistWords
    (<xref alt="Hamilton et al., 2018" rid="ref-hamilton2018" ref-type="bibr">Hamilton
    et al., 2018</xref>), and fastText
    (<xref alt="Bojanowski et al., 2017b" rid="ref-bojanowski2017a" ref-type="bibr">Bojanowski
    et al., 2017b</xref>). Hundreds of these models can be conveniently
    downloaded from online sources with
    <monospace>load_embeddings()</monospace>, forgoing the need to
    search for model files online and juggle incompatible file
    types.</p>
    <p>One particularly useful feature of
    <monospace>load_embeddings()</monospace> is the optional
    <monospace>words</monospace> parameter, which allows the user to
    specify a subset of words to load from the model. This allows users
    to work with large models, which are often too large to load into an
    interactive environment in their entirety.</p>
    <code language="r script"># load 25d GloVe model trained on Twitter
glove_twitter_25d &lt;- load_embeddings(&quot;glove.twitter.27B.25d&quot;)</code>
    <code language="r script"># load words from model trained on Google Books English Fiction 1800-1810
eng.fiction.all_sgns.1800 &lt;- load_embeddings(
    &quot;eng.fiction.all_sgns.1800&quot;,
    words = c(&quot;word&quot;, &quot;token&quot;, &quot;lemma&quot;)
    )</code>
    <p>The output of <monospace>load_embeddings()</monospace> is an
    embeddings object. An embeddings object is simply a numeric matrix
    with fast hash table indexing by rownames (generally tokens). This
    means that it can be easily coerced to a dataframe or tibble, while
    also allowing special embeddings-specific methods and functions,
    such as <monospace>emb()</monospace> and
    <monospace>find_nearest()</monospace>:</p>
    <code language="r script">moral_embeddings &lt;- emb(glove_twitter_25d, c(&quot;good&quot;, &quot;bad&quot;))
moral_embeddings</code>
    <preformat>## # 25-dimensional embeddings with 2 rows</preformat>
    <preformat>##      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..      
## good -0.54  0.60 -0.15 -0.02 -0.14  0.60  2.19  0.21 -0.52 -0.23 ...  
## bad   0.41  0.02  0.06 -0.01  0.27  0.71  1.64 -0.11 -0.26  0.11 ...</preformat>
    <code language="r script">find_nearest(glove_twitter_25d, &quot;dog&quot;, 5L, method = &quot;cosine&quot;)</code>
    <preformat>## # 25-dimensional embeddings with 5 rows</preformat>
    <preformat>##        dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..      
## dog    -1.24 -0.36  0.57  0.37  0.60 -0.19  1.27 -0.37  0.09  0.40 ...  
## cat    -0.96 -0.61  0.67  0.35  0.41 -0.21  1.38  0.13  0.32  0.66 ...  
## dogs   -0.63 -0.11  0.22  0.27  0.28  0.13  1.44 -1.18 -0.26  0.60 ...  
## horse  -0.76 -0.63  0.43  0.04  0.25 -0.18  1.08 -0.94  0.30  0.07 ...  
## monkey -0.96 -0.38  0.49  0.66  0.21 -0.09  1.28 -0.11  0.27  0.42 ...</preformat>
    <p>Whereas indexing a regular matrix by rownames gets slower as the
    number of rows increases, <bold>embedplyr</bold>’s hash table
    indexing means that token embeddings can be retrieved in
    milliseconds even from models with millions of rows (see the
    <ext-link ext-link-type="uri" xlink:href="vignettes/performance.html">performance
    vignette</ext-link>).</p>
  </sec>
  <sec id="embed-texts-of-interest">
    <title>Embed Texts of Interest</title>
    <p>Given a tidy dataframe of texts,
    <monospace>embed_docs()</monospace> will generate embeddings by
    averaging the embeddings of tokens in each text (see
    <xref alt="Ethayarajh, Duvenaud, &amp; Hirst, 2019" rid="ref-ethayarajh2019" ref-type="bibr">Ethayarajh,
    Duvenaud, &amp; Hirst, 2019</xref>;
    <xref alt="Teitelbaum &amp; Simchon, 2024, chap. 18" rid="ref-teitelbaum2024" ref-type="bibr">Teitelbaum
    &amp; Simchon, 2024, chap. 18</xref>). By default,
    <monospace>embed_docs()</monospace> uses a simple unweighted mean,
    but many other averaging methods are available.</p>
    <p>The following example embeds three texts, which for the sake of
    the example can be considered to have been written by one
    participant diagnosed with depression, one diagnosed with anxiety,
    and one control.</p>
    <code language="r script">library(dplyr)

psych_df &lt;- tribble(
    ~id,           ~text,
    &quot;control&quot;,     &quot;yesterday I took my dog for a walk&quot;,
    &quot;depression&quot;,  &quot;I slept all day and cried in the evening&quot;,
    &quot;anxiety&quot;,     &quot;I kept thinking of all the things I needed to do&quot;
    )

# add embeddings to data frame
psych_embeddings_df &lt;- psych_df |&gt; 
    embed_docs(&quot;text&quot;, glove_twitter_25d, id_col = &quot;id&quot;, .keep_all = TRUE)</code>
    <p><monospace>embed_tokens()</monospace> is similar to
    <monospace>embed_docs()</monospace>, but returns the embedding of
    each individual token, rather than averaging within documents.</p>
  </sec>
  <sec id="embed-dictionaries">
    <title>Embed Dictionaries</title>
    <p>Distributed Dictionary Representation (DDR) enables the
    application of validated psychometric lexicons (e.g.
    <xref alt="Boyd, Ashokkumar, Seraj, &amp; Pennebaker, 2022" rid="ref-boyd2022" ref-type="bibr">Boyd,
    Ashokkumar, Seraj, &amp; Pennebaker, 2022</xref>) to rich,
    embedding-based semantic representation
    (<xref alt="Garten et al., 2018" rid="ref-garten2018" ref-type="bibr">Garten
    et al., 2018</xref>). This is achieved by retrieving pretrained word
    embeddings for each word in the dictionary, and averaging them to
    create a single vector—the DDR. The dictionary construct can then be
    measured by comparing text embeddings to the DDR.</p>
    <p>In the following example, DDRs are constructed for high and low
    anxiety using example dictionaries. Once embeddings are produced for
    each word in the dictionary, they are averaged using
    <monospace>average_embedding()</monospace>. By default this is a
    simple mean, but <monospace>average_embedding()</monospace> also
    supports the geometric median
    (<xref alt="Cardot, 2022" rid="ref-cardot2022" ref-type="bibr">Cardot,
    2022</xref>), weighted geometric median, and weighted mean,
    including weighting by word frequency or smooth inverse frequency
    (<xref alt="Arora, Liang, &amp; Ma, 2017" rid="ref-arora2017" ref-type="bibr">Arora,
    Liang, &amp; Ma, 2017</xref>).</p>
    <code language="r script"># positive and negative construct dictionaries
high_anx_dict &lt;- c(&quot;anxious&quot;, &quot;overwhelmed&quot;, &quot;nervous&quot;, &quot;stressed&quot;)
low_anx_dict &lt;- c(&quot;relaxed&quot;, &quot;calm&quot;, &quot;mellow&quot;)

# embed dictionaries
high_anx_dict_embeddings &lt;- emb(glove_twitter_25d, high_anx_dict)
low_anx_dict_embeddings &lt;- emb(glove_twitter_25d, low_anx_dict)

# average embeddings to create DDR
high_anx_DDR &lt;- average_embedding(high_anx_dict_embeddings)
low_anx_DDR &lt;- average_embedding(low_anx_dict_embeddings)</code>
    <p><monospace>average_embedding()</monospace> could be used in a
    similar manner to construct contextualized construct representations
    (<xref alt="Atari, Omrani, &amp; Dehghani, 2023" rid="ref-atari2023" ref-type="bibr">Atari,
    Omrani, &amp; Dehghani, 2023</xref>).</p>
  </sec>
  <sec id="calculate-similarity-metrics">
    <title>Calculate Similarity Metrics</title>
    <p>To complete the DDR analysis initiated above, the embeddings of
    each the corpus texts are compared to that of the DDR. This could be
    done by computing cosine similarity between each text and
    <monospace>high_anx_DDR</monospace>
    (<monospace>&quot;cosine&quot;</monospace> is the default method for
    <monospace>get_sims()</monospace>). In this case however, an
    anchored vector is used to quantify the extent to which these texts
    reflect high anxiety <italic>as opposed to low anxiety</italic>.
    <monospace>method = &quot;anchored&quot;</monospace> gives the
    position of each embedding on the spectrum between two anchor
    points, where vectors aligned with <monospace>pos</monospace> are
    given a score of 1 and those aligned with <monospace>neg</monospace>
    are given a score of 0. This approach is also known as semantic
    projection
    (<xref alt="Grand et al., 2022" rid="ref-grand2022" ref-type="bibr">Grand
    et al., 2022</xref>).</p>
    <code language="r script">anxiety_scores_df &lt;- psych_embeddings_df |&gt; 
  get_sims(
    dim_1:dim_25, 
    list(anxiety = list(pos = high_anx_DDR, neg = low_anx_DDR)),
    method = &quot;anchored&quot;
    )
anxiety_scores_df</code>
    <preformat>## # A tibble: 3 x 3
##   id         text                                             anxiety
##   &lt;chr&gt;      &lt;chr&gt;                                              &lt;dbl&gt;
## 1 control    yesterday I took my dog for a walk                 0.210
## 2 depression I slept all day and cried in the evening           0.338
## 3 anxiety    I kept thinking of all the things I needed to do   0.354</preformat>
    <p>Note that <monospace>get_sims()</monospace> requires only a
    dataframe, tibble, or embeddings object with numeric columns; the
    embeddings can come from any source.</p>
  </sec>
</sec>
<sec id="licensing-and-availability">
  <title>Licensing and Availability</title>
  <p><bold>embedplyr</bold> is licensed under the GNU General Public
  License (v3.0). All of its source code is stored publicly on Github
  (https://github.com/rimonim/embedplyr), with a corresponding issue
  tracker.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The author thanks Almog Simchon for helpful feedback in the early
  stages of development. This work was supported in part by a grant by
  the Ministry of Aliyah and Integration of the State of Israel.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-atari2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Atari</surname><given-names>Mohammad</given-names></name>
        <name><surname>Omrani</surname><given-names>Ali</given-names></name>
        <name><surname>Dehghani</surname><given-names>Morteza</given-names></name>
      </person-group>
      <article-title>Contextualized Construct Representation: Leveraging Psychometric Scales to Advance Theory-Driven Text Analysis</article-title>
      <publisher-name>PsyArXiv</publisher-name>
      <year iso-8601-date="2023-02">2023</year><month>02</month>
      <uri>osf.io/preprints/psyarxiv/m93pd</uri>
      <pub-id pub-id-type="doi">10.31234/osf.io/m93pd</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-duran2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Duran</surname><given-names>Nicholas D.</given-names></name>
        <name><surname>Paxton</surname><given-names>Alexandra</given-names></name>
        <name><surname>Fusaroli</surname><given-names>Riccardo</given-names></name>
      </person-group>
      <article-title>ALIGN: Analyzing Linguistic Interactions With Generalizable techNiques-A Python Library</article-title>
      <source>Psychological methods</source>
      <year iso-8601-date="2019">2019</year>
      <volume>24</volume>
      <issue>4</issue>
      <issn>1082-989X</issn>
      <pub-id pub-id-type="doi">10.31234/osf.io/a5yh9</pub-id>
      <fpage>419</fpage>
      <lpage>438</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kjell2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Kjell</surname><given-names>Oscar N E</given-names></name>
        <name><surname>Giorgi</surname><given-names>Salvatore</given-names></name>
        <name><surname>Schwartz</surname><given-names>H. A</given-names></name>
      </person-group>
      <article-title>The text-package: An R-package for Analyzing and Visualizing Human Language Using Natural Language Processing and Deep Learning</article-title>
      <publisher-name>PsyArXiv</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>osf.io/preprints/psyarxiv/293kt</uri>
      <pub-id pub-id-type="doi">10.31234/osf.io/293kt</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-grand2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Grand</surname><given-names>Gabriel</given-names></name>
        <name><surname>Blank</surname><given-names>Idan Asher</given-names></name>
        <name><surname>Pereira</surname><given-names>Francisco</given-names></name>
        <name><surname>Fedorenko</surname><given-names>Evelina</given-names></name>
      </person-group>
      <article-title>Semantic projection recovers rich human knowledge of multiple object features from word embeddings</article-title>
      <source>Nature Human Behaviour</source>
      <year iso-8601-date="2022-07">2022</year><month>07</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-07">2024</year><month>04</month><day>07</day></date-in-citation>
      <volume>6</volume>
      <issue>7</issue>
      <issn>2397-3374</issn>
      <uri>https://www.nature.com/articles/s41562-022-01316-8</uri>
      <pub-id pub-id-type="doi">10.1038/s41562-022-01316-8</pub-id>
      <fpage>975</fpage>
      <lpage>987</lpage>
    </element-citation>
  </ref>
  <ref id="ref-deerwester1990">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Deerwester</surname><given-names>Scott</given-names></name>
        <name><surname>Dumais</surname><given-names>Susan T.</given-names></name>
        <name><surname>Furnas</surname><given-names>George W.</given-names></name>
        <name><surname>Landauer</surname><given-names>Thomas K.</given-names></name>
        <name><surname>Harshman</surname><given-names>Richard</given-names></name>
      </person-group>
      <article-title>Indexing by latent semantic analysis</article-title>
      <source>Journal of the American Society for Information Science</source>
      <year iso-8601-date="1990">1990</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-05-01">2024</year><month>05</month><day>01</day></date-in-citation>
      <volume>41</volume>
      <issue>6</issue>
      <issn>1097-4571</issn>
      <uri>https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9</uri>
      <pub-id pub-id-type="doi">10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9</pub-id>
      <fpage>391</fpage>
      <lpage>407</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mikolov2013a">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Mikolov</surname><given-names>Tomas</given-names></name>
        <name><surname>Chen</surname><given-names>Kai</given-names></name>
        <name><surname>Corrado</surname><given-names>Greg</given-names></name>
        <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
      </person-group>
      <article-title>Efficient Estimation of Word Representations in Vector Space</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2013-09">2013</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-05-08">2024</year><month>05</month><day>08</day></date-in-citation>
      <uri>http://arxiv.org/abs/1301.3781</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1301.3781</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mikolov2013b">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Mikolov</surname><given-names>Tomas</given-names></name>
        <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>
        <name><surname>Chen</surname><given-names>Kai</given-names></name>
        <name><surname>Corrado</surname><given-names>Greg</given-names></name>
        <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
      </person-group>
      <article-title>Distributed Representations of Words and Phrases and their Compositionality</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2013-10">2013</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-05-10">2024</year><month>05</month><day>10</day></date-in-citation>
      <uri>http://arxiv.org/abs/1310.4546</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1310.4546</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bojanowski2017a">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Bojanowski</surname><given-names>Piotr</given-names></name>
        <name><surname>Grave</surname><given-names>Edouard</given-names></name>
        <name><surname>Joulin</surname><given-names>Armand</given-names></name>
        <name><surname>Mikolov</surname><given-names>Tomas</given-names></name>
      </person-group>
      <article-title>Enriching Word Vectors with Subword Information</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2017-06">2017</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-07-01">2024</year><month>07</month><day>01</day></date-in-citation>
      <uri>http://arxiv.org/abs/1607.04606</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1607.04606</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-grave2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Grave</surname><given-names>Edouard</given-names></name>
        <name><surname>Bojanowski</surname><given-names>Piotr</given-names></name>
        <name><surname>Gupta</surname><given-names>Prakhar</given-names></name>
        <name><surname>Joulin</surname><given-names>Armand</given-names></name>
        <name><surname>Mikolov</surname><given-names>Tomas</given-names></name>
      </person-group>
      <article-title>Learning Word Vectors for 157 Languages</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2018-03">2018</year><month>03</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-07-01">2024</year><month>07</month><day>01</day></date-in-citation>
      <uri>http://arxiv.org/abs/1802.06893</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1802.06893</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-benoit2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
        <name><surname>Watanabe</surname><given-names>Kohei</given-names></name>
        <name><surname>Wang</surname><given-names>Haiyan</given-names></name>
        <name><surname>Nulty</surname><given-names>Paul</given-names></name>
        <name><surname>Obeng</surname><given-names>Adam</given-names></name>
        <name><surname>Müller</surname><given-names>Stefan</given-names></name>
        <name><surname>Matsuo</surname><given-names>Akitaka</given-names></name>
      </person-group>
      <article-title>quanteda: An R package for the quantitative analysis of textual data</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2018-10">2018</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-03">2025</year><month>01</month><day>03</day></date-in-citation>
      <volume>3</volume>
      <issue>30</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.00774</uri>
      <pub-id pub-id-type="doi">10.21105/joss.00774</pub-id>
      <fpage>774</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-garten2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Garten</surname><given-names>Justin</given-names></name>
        <name><surname>Hoover</surname><given-names>Joe</given-names></name>
        <name><surname>Johnson</surname><given-names>Kate M.</given-names></name>
        <name><surname>Boghrati</surname><given-names>Reihane</given-names></name>
        <name><surname>Iskiwitch</surname><given-names>Carol</given-names></name>
        <name><surname>Dehghani</surname><given-names>Morteza</given-names></name>
      </person-group>
      <article-title>Dictionaries and distributions: Combining expert knowledge and large scale textual data content analysis : Distributed dictionary representation</article-title>
      <source>Behavior Research Methods</source>
      <year iso-8601-date="2018-02">2018</year><month>02</month>
      <volume>50</volume>
      <issue>1</issue>
      <issn>1554-3528</issn>
      <pub-id pub-id-type="doi">10.3758/s13428-017-0875-9</pub-id>
      <pub-id pub-id-type="pmid">28364281</pub-id>
      <fpage>344</fpage>
      <lpage>361</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ethayarajh2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ethayarajh</surname><given-names>Kawin</given-names></name>
        <name><surname>Duvenaud</surname><given-names>David</given-names></name>
        <name><surname>Hirst</surname><given-names>Graeme</given-names></name>
      </person-group>
      <article-title>Towards Understanding Linear Word Analogies</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2019-08">2019</year><month>08</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-03">2025</year><month>01</month><day>03</day></date-in-citation>
      <uri>http://arxiv.org/abs/1810.04882</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1810.04882</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-schrimpf2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schrimpf</surname><given-names>Martin</given-names></name>
        <name><surname>Blank</surname><given-names>Idan Asher</given-names></name>
        <name><surname>Tuckute</surname><given-names>Greta</given-names></name>
        <name><surname>Kauf</surname><given-names>Carina</given-names></name>
        <name><surname>Hosseini</surname><given-names>Eghbal A.</given-names></name>
        <name><surname>Kanwisher</surname><given-names>Nancy</given-names></name>
        <name><surname>Tenenbaum</surname><given-names>Joshua B.</given-names></name>
        <name><surname>Fedorenko</surname><given-names>Evelina</given-names></name>
      </person-group>
      <article-title>The neural architecture of language: Integrative modeling converges on predictive processing</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <volume>118</volume>
      <issue>45</issue>
      <issn>0027-8424</issn>
      <uri>https://pnas.org/doi/full/10.1073/pnas.2105646118</uri>
      <pub-id pub-id-type="doi">10.1073/pnas.2105646118</pub-id>
      <fpage>e2105646118</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-hamilton2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hamilton</surname><given-names>William L.</given-names></name>
        <name><surname>Leskovec</surname><given-names>Jure</given-names></name>
        <name><surname>Jurafsky</surname><given-names>Dan</given-names></name>
      </person-group>
      <article-title>Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2018-10">2018</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>http://arxiv.org/abs/1605.09096</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1605.09096</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-kozlowski2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kozlowski</surname><given-names>Austin C.</given-names></name>
        <name><surname>Taddy</surname><given-names>Matt</given-names></name>
        <name><surname>Evans</surname><given-names>James A.</given-names></name>
      </person-group>
      <article-title>The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings</article-title>
      <source>American Sociological Review</source>
      <year iso-8601-date="2019-10">2019</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <volume>84</volume>
      <issue>5</issue>
      <issn>0003-1224</issn>
      <uri>https://doi.org/10.1177/0003122419877135</uri>
      <pub-id pub-id-type="doi">10.1177/0003122419877135</pub-id>
      <fpage>905</fpage>
      <lpage>949</lpage>
    </element-citation>
  </ref>
  <ref id="ref-teitelbaum2024">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Teitelbaum</surname><given-names>Louis</given-names></name>
        <name><surname>Simchon</surname><given-names>Almog</given-names></name>
      </person-group>
      <source>Data Science for Psychology: Natural Language</source>
      <publisher-name>Computational Social Psychology Lab</publisher-name>
      <year iso-8601-date="2024-04">2024</year><month>04</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>https://zenodo.org/records/10908367</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.10908367</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wickham2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
        <name><surname>Averick</surname><given-names>Mara</given-names></name>
        <name><surname>Bryan</surname><given-names>Jennifer</given-names></name>
        <name><surname>Chang</surname><given-names>Winston</given-names></name>
        <name><surname>McGowan</surname><given-names>Lucy D’Agostino</given-names></name>
        <name><surname>François</surname><given-names>Romain</given-names></name>
        <name><surname>Grolemund</surname><given-names>Garrett</given-names></name>
        <name><surname>Hayes</surname><given-names>Alex</given-names></name>
        <name><surname>Henry</surname><given-names>Lionel</given-names></name>
        <name><surname>Hester</surname><given-names>Jim</given-names></name>
        <name><surname>Kuhn</surname><given-names>Max</given-names></name>
        <name><surname>Pedersen</surname><given-names>Thomas Lin</given-names></name>
        <name><surname>Miller</surname><given-names>Evan</given-names></name>
        <name><surname>Bache</surname><given-names>Stephan Milton</given-names></name>
        <name><surname>Müller</surname><given-names>Kirill</given-names></name>
        <name><surname>Ooms</surname><given-names>Jeroen</given-names></name>
        <name><surname>Robinson</surname><given-names>David</given-names></name>
        <name><surname>Seidel</surname><given-names>Dana Paige</given-names></name>
        <name><surname>Spinu</surname><given-names>Vitalie</given-names></name>
        <name><surname>Takahashi</surname><given-names>Kohske</given-names></name>
        <name><surname>Vaughan</surname><given-names>Davis</given-names></name>
        <name><surname>Wilke</surname><given-names>Claus</given-names></name>
        <name><surname>Woo</surname><given-names>Kara</given-names></name>
        <name><surname>Yutani</surname><given-names>Hiroaki</given-names></name>
      </person-group>
      <article-title>Welcome to the Tidyverse</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2019-11">2019</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <volume>4</volume>
      <issue>43</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.01686</uri>
      <pub-id pub-id-type="doi">10.21105/joss.01686</pub-id>
      <fpage>1686</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-wickham2025">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
        <name><surname>François</surname><given-names>Romain</given-names></name>
        <name><surname>Henry</surname><given-names>Lionel</given-names></name>
        <name><surname>Müller</surname><given-names>Kirill</given-names></name>
        <name><surname>Vaughan</surname><given-names>Davis</given-names></name>
      </person-group>
      <source>Dplyr: A grammar of data manipulation</source>
      <year iso-8601-date="2025">2025</year>
      <uri>https://dplyr.tidyverse.org</uri>
    </element-citation>
  </ref>
  <ref id="ref-feuerriegel2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Feuerriegel</surname><given-names>Stefan</given-names></name>
        <name><surname>Maarouf</surname><given-names>Abdurahman</given-names></name>
        <name><surname>Bär</surname><given-names>Dominik</given-names></name>
        <name><surname>Geissler</surname><given-names>Dominique</given-names></name>
        <name><surname>Schweisthal</surname><given-names>Jonas</given-names></name>
        <name><surname>Pröllochs</surname><given-names>Nicolas</given-names></name>
        <name><surname>Robertson</surname><given-names>Claire E.</given-names></name>
        <name><surname>Rathje</surname><given-names>Steve</given-names></name>
        <name><surname>Hartmann</surname><given-names>Jochen</given-names></name>
        <name><surname>Mohammad</surname><given-names>Saif M.</given-names></name>
        <name><surname>Netzer</surname><given-names>Oded</given-names></name>
        <name><surname>Siegel</surname><given-names>Alexandra A.</given-names></name>
        <name><surname>Plank</surname><given-names>Barbara</given-names></name>
        <name><surname>Van Bavel</surname><given-names>Jay J.</given-names></name>
      </person-group>
      <article-title>Using natural language processing to analyse text data in behavioural science</article-title>
      <source>Nature Reviews Psychology</source>
      <year iso-8601-date="2025-01">2025</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <issn>2731-0574</issn>
      <uri>https://www.nature.com/articles/s44159-024-00392-z</uri>
      <pub-id pub-id-type="doi">10.1038/s44159-024-00392-z</pub-id>
      <fpage>1</fpage>
      <lpage>16</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lauriola2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lauriola</surname><given-names>Ivano</given-names></name>
        <name><surname>Lavelli</surname><given-names>Alberto</given-names></name>
        <name><surname>Aiolli</surname><given-names>Fabio</given-names></name>
      </person-group>
      <article-title>An introduction to Deep Learning in Natural Language Processing: Models, techniques, and tools</article-title>
      <source>Neurocomputing</source>
      <year iso-8601-date="2022-01">2022</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <volume>470</volume>
      <issn>0925-2312</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0925231221010997</uri>
      <pub-id pub-id-type="doi">10.1016/j.neucom.2021.05.103</pub-id>
      <fpage>443</fpage>
      <lpage>456</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wijffels2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wijffels</surname><given-names>Jan</given-names></name>
        <name><surname>Watanabe</surname><given-names>Kohei</given-names></name>
        <name><surname>Fomichev</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>word2vec: Distributed Representations of Words</article-title>
      <year iso-8601-date="2023-10">2023</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>https://cran.r-project.org/web/packages/word2vec/index.html</uri>
      <pub-id pub-id-type="doi">10.32614/cran.package.word2vec</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-selivanov2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Selivanov</surname><given-names>Dmitriy</given-names></name>
        <name><surname>Bickel</surname><given-names>Manuel</given-names></name>
        <name><surname>Wang</surname><given-names>Qing</given-names></name>
      </person-group>
      <article-title>text2vec: Modern Text Mining Framework for R</article-title>
      <year iso-8601-date="2023-11">2023</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>https://cran.r-project.org/web/packages/text2vec/index.html</uri>
      <pub-id pub-id-type="doi">10.32614/cran.package.text2vec</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-blei2003">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blei</surname><given-names>David M.</given-names></name>
        <name><surname>Ng</surname><given-names>Andrew Y.</given-names></name>
        <name><surname>Jordan</surname><given-names>Michael I.</given-names></name>
      </person-group>
      <article-title>Latent dirichlet allocation</article-title>
      <source>J. Mach. Learn. Res.</source>
      <year iso-8601-date="2003-03">2003</year><month>03</month>
      <volume>3</volume>
      <issn>1532-4435</issn>
      <pub-id pub-id-type="doi">10.7551/mitpress/1120.003.0082</pub-id>
      <fpage>993</fpage>
      <lpage>1022</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pennington2014">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pennington</surname><given-names>Jeffrey</given-names></name>
        <name><surname>Socher</surname><given-names>Richard</given-names></name>
        <name><surname>Manning</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>GloVe: Global Vectors for Word Representation</article-title>
      <source>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</source>
      <publisher-name>Association for Computational Linguistics</publisher-name>
      <publisher-loc>Doha, Qatar</publisher-loc>
      <year iso-8601-date="2014">2014</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>http://aclweb.org/anthology/D14-1162</uri>
      <pub-id pub-id-type="doi">10.3115/v1/D14-1162</pub-id>
      <fpage>1532</fpage>
      <lpage>1543</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wolf2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wolf</surname><given-names>Thomas</given-names></name>
        <name><surname>Debut</surname><given-names>Lysandre</given-names></name>
        <name><surname>Sanh</surname><given-names>Victor</given-names></name>
        <name><surname>Chaumond</surname><given-names>Julien</given-names></name>
        <name><surname>Delangue</surname><given-names>Clement</given-names></name>
        <name><surname>Moi</surname><given-names>Anthony</given-names></name>
        <name><surname>Cistac</surname><given-names>Pierric</given-names></name>
        <name><surname>Rault</surname><given-names>Tim</given-names></name>
        <name><surname>Louf</surname><given-names>Remi</given-names></name>
        <name><surname>Funtowicz</surname><given-names>Morgan</given-names></name>
        <name><surname>Davison</surname><given-names>Joe</given-names></name>
        <name><surname>Shleifer</surname><given-names>Sam</given-names></name>
        <name><surname>Platen</surname><given-names>Patrick von</given-names></name>
        <name><surname>Ma</surname><given-names>Clara</given-names></name>
        <name><surname>Jernite</surname><given-names>Yacine</given-names></name>
        <name><surname>Plu</surname><given-names>Julien</given-names></name>
        <name><surname>Xu</surname><given-names>Canwen</given-names></name>
        <name><surname>Le Scao</surname><given-names>Teven</given-names></name>
        <name><surname>Gugger</surname><given-names>Sylvain</given-names></name>
        <name><surname>Drame</surname><given-names>Mariama</given-names></name>
        <name><surname>Lhoest</surname><given-names>Quentin</given-names></name>
        <name><surname>Rush</surname><given-names>Alexander</given-names></name>
      </person-group>
      <article-title>Transformers: State-of-the-Art Natural Language Processing</article-title>
      <source>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</source>
      <person-group person-group-type="editor">
        <name><surname>Liu</surname><given-names>Qun</given-names></name>
        <name><surname>Schlangen</surname><given-names>David</given-names></name>
      </person-group>
      <publisher-name>Association for Computational Linguistics</publisher-name>
      <publisher-loc>Online</publisher-loc>
      <year iso-8601-date="2020-10">2020</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>https://aclanthology.org/2020.emnlp-demos.6/</uri>
      <pub-id pub-id-type="doi">10.18653/v1/2020.emnlp-demos.6</pub-id>
      <fpage>38</fpage>
      <lpage>45</lpage>
    </element-citation>
  </ref>
  <ref id="ref-carrella2023">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Carrella</surname><given-names>Fabio</given-names></name>
        <name><surname>Aroyehun</surname><given-names>Segun Taofeek</given-names></name>
        <name><surname>Lasser</surname><given-names>Jana</given-names></name>
        <name><surname>Simchon</surname><given-names>Almog</given-names></name>
        <name><surname>Garcia</surname><given-names>David</given-names></name>
        <name><surname>Lewandowsky</surname><given-names>Stephan</given-names></name>
      </person-group>
      <article-title>The ’Truth Contagion’ Effect in the US Political Online Debate</article-title>
      <publisher-name>OSF</publisher-name>
      <year iso-8601-date="2023-12">2023</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>https://osf.io/qx34w</uri>
      <pub-id pub-id-type="doi">10.31234/osf.io/qx34w</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hussain2024">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hussain</surname><given-names>Zak</given-names></name>
        <name><surname>Mata</surname><given-names>Rui</given-names></name>
        <name><surname>Newell</surname><given-names>Ben R.</given-names></name>
        <name><surname>Wulff</surname><given-names>Dirk U.</given-names></name>
      </person-group>
      <article-title>Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2024-12">2024</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>http://arxiv.org/abs/2412.04936</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2412.04936</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-markus2024">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Markus</surname><given-names>Dror K.</given-names></name>
        <name><surname>Levi</surname><given-names>Effi</given-names></name>
        <name><surname>Sheafer</surname><given-names>Tamir</given-names></name>
        <name><surname>Shenhav</surname><given-names>Shaul R.</given-names></name>
      </person-group>
      <article-title>Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2024-04">2024</year><month>04</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-05">2025</year><month>01</month><day>05</day></date-in-citation>
      <uri>http://arxiv.org/abs/2404.09299</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2404.09299</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mouselimis2024">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Mouselimis</surname><given-names>Lampros</given-names></name>
      </person-group>
      <source>fastText: Efficient Learning of Word Representations and Sentence Classification using R</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://CRAN.R-project.org/package=fastText</uri>
    </element-citation>
  </ref>
  <ref id="ref-facebook2016">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Facebook</surname><given-names>Inc</given-names></name>
      </person-group>
      <source>fastText: Library for fast text representation and classification</source>
      <year iso-8601-date="2016">2016</year>
      <uri>https://github.com/facebookresearch/fastText</uri>
    </element-citation>
  </ref>
  <ref id="ref-bojanowski2017b">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bojanowski</surname><given-names>Piotr</given-names></name>
        <name><surname>Grave</surname><given-names>Edouard</given-names></name>
        <name><surname>Joulin</surname><given-names>Armand</given-names></name>
        <name><surname>Mikolov</surname><given-names>Tomas</given-names></name>
      </person-group>
      <article-title>Bag of Tricks for Efficient Text Classification</article-title>
      <source>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</source>
      <publisher-name>Association for Computational Linguistics</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1607.01759</pub-id>
      <fpage>427</fpage>
      <lpage>431</lpage>
    </element-citation>
  </ref>
  <ref id="ref-boyd2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Boyd</surname><given-names>Ryan L</given-names></name>
        <name><surname>Ashokkumar</surname><given-names>Ashwini</given-names></name>
        <name><surname>Seraj</surname><given-names>Sarah</given-names></name>
        <name><surname>Pennebaker</surname><given-names>James W</given-names></name>
      </person-group>
      <article-title>The development and psychometric properties of LIWC-22</article-title>
      <source>Austin, TX: University of Texas at Austin</source>
      <year iso-8601-date="2022">2022</year>
      <volume>10</volume>
    </element-citation>
  </ref>
  <ref id="ref-cardot2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Cardot</surname><given-names>Herve</given-names></name>
      </person-group>
      <source>Gmedian: Geometric Median, k-Medians Clustering and Robust Median PCA</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=Gmedian</uri>
      <pub-id pub-id-type="doi">10.32614/cran.package.gmedian</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-arora2017">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Arora</surname><given-names>Sanjeev</given-names></name>
        <name><surname>Liang</surname><given-names>Yingyu</given-names></name>
        <name><surname>Ma</surname><given-names>Tengyu</given-names></name>
      </person-group>
      <article-title>A simple but tough-to-beat baseline for sentence embeddings</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2017">2017</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
