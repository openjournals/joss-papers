<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9127</article-id>
<article-id pub-id-type="doi">10.21105/joss.09127</article-id>
<title-group>
<article-title>Speckle Cn2 Profiler: Improving Satellite Communications
with Machine Learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9247-139X</contrib-id>
<name>
<surname>Ciarella</surname>
<given-names>Simone</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9153-650X</contrib-id>
<name>
<surname>Orozco</surname>
<given-names>Luisa</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3535-8320</contrib-id>
<name>
<surname>Azizi</surname>
<given-names>Victor</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-7409-3985</contrib-id>
<name>
<surname>Arvis</surname>
<given-names>Marguerite</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0368-0139</contrib-id>
<name>
<surname>Saathof</surname>
<given-names>Rudolf</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Netherlands eScience Center, Amsterdam, The
Netherlands</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Faculty of Aerospace Engineering, Delft University of
Technology, Delft, The Netherlands</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-12-13">
<day>13</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>9127</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>machine learning</kwd>
<kwd>signal processing</kwd>
<kwd>turbulence</kwd>
<kwd>image processing</kwd>
<kwd>equivariance</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Optical satellite communications is a growing research field in
  which -using lasers- signals can be sent from the ground to
  satellites, from satellites to satellites and then back to the ground.
  The main advantage of using laser communication over radio waves is
  increased bandwidth that enables the transfer of more data in less
  time. However, one of the challenges for this protocol is the
  turbulence in the atmosphere that perturbs such transmission. The
  reduction of the quality of signal communication can be calculated and
  then compensated, but this requires a knowledge of the turbulence
  strength. A common way to model the turbulence is to use the
  refractive index structure constant, <inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>,
  which is a measure of the strength of the turbulence. Its profile can
  be used to estimate the effect of the turbulence on the signal and
  then apply a correction. To measure <inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>,
  there are several alternative instruments, each one with its own
  limitations. One possibility is to use speckle-based observation,
  which consists on looking at the twinkling of the stars and use their
  pattern to infer the turbulence profile. This is a non-intrusive
  method that can be used in real time, but it requires a deep
  understanding of the turbulence and the observed speckle patterns,
  which are highly influenced by the turbulence profile. The connection
  between speckle observation, and turbulence
  (<inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>)
  is not clearly understood, so an analytical theory does not exist.
  Here we present <monospace>speckcn2</monospace>, a Python package that
  uses machine learning to provide a numerical reconstruction of the
  turbulence profile from a speckle pattern
  (<xref alt="Ciarella, 2024" rid="ref-ciarella2024" ref-type="bibr">Ciarella,
  2024</xref>).</p>
  <fig>
    <caption><p>Example of <monospace>speckcn2</monospace> pipeline:
    speckle pattern as input to output a prediction of the turbulence
    profile (J).
    <styled-content id="figU003Aprediction"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="" xlink:href="https://github.com/MALES-project/SpeckleCn2Profiler/blob/main/src/speckcn2/assets/single_prediction.png?raw=true" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>While deep learning has been applied to mitigate atmospheric
  turbulence effects in imaging through temporal mitigation using videos
  (<xref alt="Zhang et al., 2024" rid="ref-zhang2024spatio" ref-type="bibr">Zhang
  et al., 2024</xref>) and static image degradation compensation
  (<xref alt="Yasarla &amp; Patel, 2021" rid="ref-9506614" ref-type="bibr">Yasarla
  &amp; Patel, 2021</xref>), these approaches focus on visual correction
  rather than quantitative turbulence characterization. In contrast,
  <monospace>speckcn2</monospace> addresses the critical need for
  numerical reconstruction of <inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>
  profiles, enabling both scientific understanding of atmospheric
  turbulence and practical integration into communication system models
  for performance optimization.</p>
  <p>The primary target users of <monospace>speckcn2</monospace> are
  aerospace engineers working on optical satellite communication
  systems, atmospheric scientists studying turbulence phenomena, and
  astronomers developing adaptive optics systems. The package provides
  these communities with a tool to estimate turbulence profiles from
  speckle observations where analytical theories are lacking, using
  machine learning to bridge this gap.</p>
  <p>Existing software packages address atmospheric turbulence from
  different perspectives. AOtools
  (<xref alt="Townson et al., 2019" rid="ref-AOtools" ref-type="bibr">Townson
  et al., 2019</xref>) provides general-purpose adaptive optics
  utilities including phase screen generation and turbulence parameter
  conversions, but lacks ML-based profile reconstruction from
  observations. FAST
  (<xref alt="Farley et al., 2022" rid="ref-FAST" ref-type="bibr">Farley
  et al., 2022</xref>) (Fourier domain Adaptive optics Simulation Tool)
  offers rapid Monte Carlo characterization of free space optical links
  with turbulence modeling, while OOPAO
  (<xref alt="Heritier et al., 2023" rid="ref-OOPAO" ref-type="bibr">Heritier
  et al., 2023</xref>) (Object-Oriented Python Adaptive Optics) provides
  end-to-end adaptive optics simulation. However, both focus on forward
  modeling—simulating turbulence effects given known profiles—rather
  than the inverse problem of reconstructing profiles from measurements.
  Traditional <inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>
  profiling instruments such as radiosondes, SCIDAR, or MASS require
  specialized hardware and intrusive deployment.
  <monospace>speckcn2</monospace> uniquely combines ML-based inverse
  modeling with speckle pattern analysis to provide explicit turbulence
  profile reconstruction in real-time, using only optical detection
  systems without specialized hardware. This fills a critical gap for
  applications requiring quantitative atmospheric characterization from
  passive observations.</p>
  <p>Built on PyTorch
  (<xref alt="Ansel et al., 2024" rid="ref-pytorch" ref-type="bibr">Ansel
  et al., 2024</xref>), the package is designed to handle diverse image
  regression tasks with both synthetic and experimental data. By
  combining techniques like equivariance and ensemble learning,
  <monospace>speckcn2</monospace> provides a robust framework applicable
  beyond aerospace engineering to any field requiring image-to-profile
  regression. Complete documentation and API references are available at
  https://males-project.github.io/SpeckleCn2Profiler/, with installation
  instructions and examples to facilitate adoption across different
  research communities.</p>
</sec>
<sec id="key-features">
  <title>Key features</title>
  <sec id="instrument-specialization">
    <title>Instrument specialization</title>
    <p>When estimating the turbulence features, it is of fundamental
    importance to not mix the instrumental noise with the real effects
    that are being measured. A fundamental aspect of
    <monospace>speckcn2</monospace> is the possibility to train models
    with different noise profiles, representing the noise of different
    instruments and modeling different detectors, whether real or
    simulated. By adapting the <monospace>apply_noise</monospace>
    function, users can model any type of effect related to their
    research and instruments. The current API provides a series of
    parameters that can be tuned to simulate the noise of different
    instruments, such as the signal-to-noise ratio, the detector gain,
    and the obscuration.</p>
  </sec>
  <sec id="equivariant-model">
    <title>Equivariant model</title>
    <p>To take advantage of the symmetry in the input data,
    <monospace>speckcn2</monospace> uses a concept called equivariance
    (<xref alt="Cohen &amp; Welling, 2016" rid="ref-cohen2016" ref-type="bibr">Cohen
    &amp; Welling, 2016</xref>). This means that the model can learn the
    same features independently of the input data orientation. This is
    especially helpful for turbulence reconstruction, where the
    direction of the speckle pattern is not relevant.</p>
    <p><monospace>speckcn2</monospace> supports two types of
    equivariance: weak and strong. Weak equivariance is achieved by
    randomly rotating the input data, which can then be used with any
    model from torchvision
    (<xref alt="TorchVision maintainers and contributors, 2016" rid="ref-torchvision" ref-type="bibr">TorchVision
    maintainers and contributors, 2016</xref>), including fine-tuning
    ResNets
    (<xref alt="He et al., 2015" rid="ref-resnet" ref-type="bibr">He et
    al., 2015</xref>).</p>
    <p>Strong equivariance is achieved by using the equivariant sparse
    convolutional neural network (escnn)
    (<xref alt="Cesa et al., 2021" rid="ref-escnn2" ref-type="bibr">Cesa
    et al., 2021</xref>;
    <xref alt="Weiler &amp; Cesa, 2021" rid="ref-escnn1" ref-type="bibr">Weiler
    &amp; Cesa, 2021</xref>). These networks are more powerful for this
    type of problem but are harder to train.</p>
  </sec>
  <sec id="ensemble-learning">
    <title>Ensemble learning</title>
    <p><monospace>speckcn2</monospace> can also use ensemble learning by
    averaging the predictions from multiple input images. This means
    that the prediction of each model requires a set of multiple input
    images. This is only useful if the input images change faster than
    the output. Since this is not the case for laser communications,
    this feature is optional and can be turned off.</p>
  </sec>
</sec>
<sec id="applications-storm-for-laser-satellite-communications">
  <title>Applications: STORM for Laser Satellite Communications</title>
  <p>A notable application of <monospace>speckcn2</monospace> is STORM
  (Speckle-based Turbulence Observation and Reconstruction via Machine
  learning)
  (<xref alt="Arvis et al., 2025" rid="ref-arvis2024storm" ref-type="bibr">Arvis
  et al., 2025</xref>), designed for line-of-sight turbulence profiling
  in laser satellite communications. STORM reconstructs 8-layer
  <inline-formula><alternatives>
  <tex-math><![CDATA[C_n^2(h)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  profiles from single-shot speckle patterns, addressing limitations of
  traditional methods like SCIDAR or SLODAR that require binary sources
  or time-series measurements. This single-source-single-shot capability
  is crucial for tracking fast-moving LEO satellites where the air
  column changes rapidly between measurements. Simulation results show
  over 90% accuracy on the Fried parameter, isoplanatic angle, and Rytov
  index, enabling improved adaptive optics design and communication link
  optimization for optical space communications.</p>
  <sec id="software-implementation">
    <title>Software implementation</title>
    <p><monospace>speckcn2</monospace> is implemented in Python and uses
    PyTorch
    (<xref alt="Ansel et al., 2024" rid="ref-pytorch" ref-type="bibr">Ansel
    et al., 2024</xref>) for its machine learning tasks. This allows the
    user to take advantage of GPU acceleration, making computations
    faster and more efficient.</p>
    <p>The package is published to PyPI and is easy to install via pip,
    and it works on both Linux and MacOS. It has a simple and
    user-friendly API that lets users quickly build, train, and evaluate
    models. Whether you are a beginner or an experienced user,
    <monospace>speckcn2</monospace> is designed to be accessible and
    flexible.</p>
    <p>For new users, the documentation and examples provide a great
    starting point, helping them get up to speed quickly. Experienced
    users will appreciate the flexibility of the package, which allows
    for customization to meet specific research needs.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors would like to acknowledge the Netherlands eScience
  Center for the funding provided under grant number
  NLESC.SSIML.2022c.021.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-pytorch">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ansel</surname><given-names>Jason</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>He</surname><given-names>Horace</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Jain</surname><given-names>Animesh</given-names></name>
        <name><surname>Voznesensky</surname><given-names>Michael</given-names></name>
        <name><surname>Bao</surname><given-names>Bin</given-names></name>
        <name><surname>Bell</surname><given-names>Peter</given-names></name>
        <name><surname>Berard</surname><given-names>David</given-names></name>
        <name><surname>Burovski</surname><given-names>Evgeni</given-names></name>
        <name><surname>Chauhan</surname><given-names>Geeta</given-names></name>
        <name><surname>Chourdia</surname><given-names>Anjali</given-names></name>
        <name><surname>Constable</surname><given-names>Will</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Ellison</surname><given-names>Elias</given-names></name>
        <name><surname>Feng</surname><given-names>Will</given-names></name>
        <name><surname>Gong</surname><given-names>Jiong</given-names></name>
        <name><surname>Gschwind</surname><given-names>Michael</given-names></name>
        <name><surname>Hirsh</surname><given-names>Brian</given-names></name>
        <name><surname>Huang</surname><given-names>Sherlock</given-names></name>
        <name><surname>Kalambarkar</surname><given-names>Kshiteej</given-names></name>
        <name><surname>Kirsch</surname><given-names>Laurent</given-names></name>
        <name><surname>Lazos</surname><given-names>Michael</given-names></name>
        <name><surname>Lezcano</surname><given-names>Mario</given-names></name>
        <name><surname>Liang</surname><given-names>Yanbo</given-names></name>
        <name><surname>Liang</surname><given-names>Jason</given-names></name>
        <name><surname>Lu</surname><given-names>Yinghai</given-names></name>
        <name><surname>Luk</surname><given-names>CK</given-names></name>
        <name><surname>Maher</surname><given-names>Bert</given-names></name>
        <name><surname>Pan</surname><given-names>Yunjie</given-names></name>
        <name><surname>Puhrsch</surname><given-names>Christian</given-names></name>
        <name><surname>Reso</surname><given-names>Matthias</given-names></name>
        <name><surname>Saroufim</surname><given-names>Mark</given-names></name>
        <name><surname>Siraichi</surname><given-names>Marcos Yukio</given-names></name>
        <name><surname>Suk</surname><given-names>Helen</given-names></name>
        <name><surname>Suo</surname><given-names>Michael</given-names></name>
        <name><surname>Tillet</surname><given-names>Phil</given-names></name>
        <name><surname>Wang</surname><given-names>Eikan</given-names></name>
        <name><surname>Wang</surname><given-names>Xiaodong</given-names></name>
        <name><surname>Wen</surname><given-names>William</given-names></name>
        <name><surname>Zhang</surname><given-names>Shunting</given-names></name>
        <name><surname>Zhao</surname><given-names>Xu</given-names></name>
        <name><surname>Zhou</surname><given-names>Keren</given-names></name>
        <name><surname>Zou</surname><given-names>Richard</given-names></name>
        <name><surname>Mathews</surname><given-names>Ajit</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Wu</surname><given-names>Peng</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation</article-title>
      <source>29th ACM international conference on architectural support for programming languages and operating systems, volume 2 (ASPLOS ’24)</source>
      <publisher-name>ACM</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <uri>https://pytorch.org/assets/pytorch2-2.pdf</uri>
      <pub-id pub-id-type="doi">10.1145/3620665.3640366</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-cohen2016">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cohen</surname><given-names>Taco</given-names></name>
        <name><surname>Welling</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Group Equivariant Convolutional Networks</article-title>
      <source>Proceedings of The 33rd International Conference on Machine Learning</source>
      <person-group person-group-type="editor">
        <name><surname>Balcan</surname><given-names>Maria Florina</given-names></name>
        <name><surname>Weinberger</surname><given-names>Kilian Q</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <publisher-loc>New York, New York, USA</publisher-loc>
      <year iso-8601-date="2016-03">2016</year><month>03</month>
      <volume>48</volume>
      <uri>https://proceedings.mlr.press/v48/cohenc16.html</uri>
      <fpage>2990</fpage>
      <lpage>2999</lpage>
    </element-citation>
  </ref>
  <ref id="ref-escnn1">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>Weiler</surname><given-names>Maurice</given-names></name>
        <name><surname>Cesa</surname><given-names>Gabriele</given-names></name>
      </person-group>
      <article-title>General $E(2)$-Equivariant Steerable CNNs</article-title>
      <year iso-8601-date="2021-04-06">2021</year><month>04</month><day>06</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-15">2024</year><month>11</month><day>15</day></date-in-citation>
      <uri>http://arxiv.org/abs/1911.08251</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1911.08251</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-escnn2">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cesa</surname><given-names>Gabriele</given-names></name>
        <name><surname>Lang</surname><given-names>Leon</given-names></name>
        <name><surname>Weiler</surname><given-names>Maurice</given-names></name>
      </person-group>
      <article-title>A Program to Build E(N)-Equivariant Steerable CNNs</article-title>
      <year iso-8601-date="2021-10-06">2021</year><month>10</month><day>06</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-15">2024</year><month>11</month><day>15</day></date-in-citation>
      <uri>https://openreview.net/forum?id=WE4qe9xlnQw</uri>
    </element-citation>
  </ref>
  <ref id="ref-torchvision">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>TorchVision maintainers and contributors</string-name>
      </person-group>
      <article-title>TorchVision: PyTorch’s Computer Vision library</article-title>
      <year iso-8601-date="2016-11">2016</year><month>11</month>
      <uri>https://github.com/pytorch/vision</uri>
    </element-citation>
  </ref>
  <ref id="ref-resnet">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>He</surname><given-names>Kaiming</given-names></name>
        <name><surname>Zhang</surname><given-names>Xiangyu</given-names></name>
        <name><surname>Ren</surname><given-names>Shaoqing</given-names></name>
        <name><surname>Sun</surname><given-names>Jian</given-names></name>
      </person-group>
      <article-title>Deep residual learning for image recognition</article-title>
      <year iso-8601-date="2015">2015</year>
      <uri>https://arxiv.org/abs/1512.03385</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1512.03385</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-9506614">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Yasarla</surname><given-names>Rajeev</given-names></name>
        <name><surname>Patel</surname><given-names>Vishal M.</given-names></name>
      </person-group>
      <article-title>Learning to restore images degraded by atmospheric turbulence using uncertainty</article-title>
      <source>2021 IEEE international conference on image processing (ICIP)</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.1109/ICIP42928.2021.9506614</pub-id>
      <fpage>1694</fpage>
      <lpage>1698</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhang2024spatio">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Xingguang</given-names></name>
        <name><surname>Chimitt</surname><given-names>Nicholas</given-names></name>
        <name><surname>Chi</surname><given-names>Yiheng</given-names></name>
        <name><surname>Mao</surname><given-names>Zhiyuan</given-names></name>
        <name><surname>Chan</surname><given-names>Stanley H</given-names></name>
      </person-group>
      <article-title>Spatio-temporal turbulence mitigation: A translational perspective</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1109/CVPR52733.2024.00279</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ciarella2024">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Ciarella</surname><given-names>Simone</given-names></name>
      </person-group>
      <article-title>Speckle to Cn2</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024-11">2024</year><month>11</month>
      <uri>https://doi.org/10.5281/zenodo.14178688</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.14178688</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-arvis2024storm">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Arvis</surname><given-names>Marguerite</given-names></name>
        <name><surname>Ciarella</surname><given-names>Simone</given-names></name>
        <name><surname>Loicq</surname><given-names>Jérôme</given-names></name>
        <name><surname>Saathof</surname><given-names>Rudolf</given-names></name>
      </person-group>
      <article-title>Single shot line-of-sight atmospheric turbulence profiling for laser satellite communications with STORM</article-title>
      <source>Applied Optics</source>
      <year iso-8601-date="2025">2025</year>
    </element-citation>
  </ref>
  <ref id="ref-AOtools">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Townson</surname><given-names>M. J.</given-names></name>
        <name><surname>Farley</surname><given-names>O. J. D.</given-names></name>
        <name><surname>Xivry</surname><given-names>G. Orban de</given-names></name>
        <name><surname>Osborn</surname><given-names>J.</given-names></name>
        <name><surname>Reeves</surname><given-names>A. P.</given-names></name>
      </person-group>
      <article-title>AOtools: a Python package for adaptive optics modelling and analysis</article-title>
      <source>Opt. Express</source>
      <publisher-name>Optica Publishing Group</publisher-name>
      <year iso-8601-date="2019-10">2019</year><month>10</month>
      <volume>27</volume>
      <issue>22</issue>
      <uri>https://opg.optica.org/oe/abstract.cfm?URI=oe-27-22-31316</uri>
      <pub-id pub-id-type="doi">10.1364/OE.27.031316</pub-id>
      <fpage>31316</fpage>
      <lpage>31329</lpage>
    </element-citation>
  </ref>
  <ref id="ref-FAST">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Farley</surname><given-names>O. J. D.</given-names></name>
        <name><surname>Townson</surname><given-names>M. J.</given-names></name>
        <name><surname>Osborn</surname><given-names>J.</given-names></name>
      </person-group>
      <article-title>FAST: Fourier domain adaptive optics simulation tool for bidirectional ground-space optical links through atmospheric turbulence</article-title>
      <source>Opt. Express</source>
      <publisher-name>Optica Publishing Group</publisher-name>
      <year iso-8601-date="2022-06">2022</year><month>06</month>
      <volume>30</volume>
      <issue>13</issue>
      <uri>https://opg.optica.org/oe/abstract.cfm?URI=oe-30-13-23050</uri>
      <pub-id pub-id-type="doi">10.1364/OE.458659</pub-id>
      <fpage>23050</fpage>
      <lpage>23064</lpage>
    </element-citation>
  </ref>
  <ref id="ref-OOPAO">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Heritier</surname><given-names>Cedric Taissir</given-names></name>
        <name><surname>Verinaud</surname><given-names>Christophe</given-names></name>
        <name><surname>Correia</surname><given-names>Carlos M.</given-names></name>
      </person-group>
      <article-title>OOPAO: Object Oriented Python Adaptive Optics</article-title>
      <source>Adaptive Optics for Extremely Large Telescopes 7th Edition</source>
      <publisher-name>ONERA</publisher-name>
      <publisher-loc>Avignon, France</publisher-loc>
      <year iso-8601-date="2023-06">2023</year><month>06</month>
      <uri>https://hal.science/hal-04402878</uri>
      <pub-id pub-id-type="doi">10.13009/AO4ELT7-2023-052</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
