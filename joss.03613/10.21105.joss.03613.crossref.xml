<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>88968c1dc614a2c2565d01ac523d48c1</doi_batch_id>
    <timestamp>20210927140838</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>09</month>
          <year>2021</year>
        </publication_date>
        <journal_volume>
          <volume>6</volume>
        </journal_volume>
        <issue>65</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>AuditoryStimuli.jl: A Julia package for generating real-time auditory stimuli</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Robert</given_name>
            <surname>Luke</surname>
            <ORCID>http://orcid.org/0000-0002-4930-8351</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>09</month>
          <day>27</day>
          <year>2021</year>
        </publication_date>
        <pages>
          <first_page>3613</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.03613</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">“https://doi.org/10.5281/zenodo.5525443”</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/3613</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.03613</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.03613</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.03613.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="ref1">
            <doi>10.1117/1.NPh.8.2.025008</doi>
          </citation>
          <citation key="ref2">
            <unstructured_citation>Carcagno, Samuele, Pychoacoustics, 2012, GitHub, GitHub repository, https://github.com/sam81/pychoacoustics</unstructured_citation>
          </citation>
          <citation key="ref3">
            <doi>10.3758/s13428-018-01193-y</doi>
          </citation>
          <citation key="ref4">
            <doi>10.25080/majora-7b98e3ed-003</doi>
          </citation>
          <citation key="ref5">
            <unstructured_citation>Lossner, Jannika, Spatially Oriented Format for Acoustics (SOFA) API for Python, 2019, GitHub, GitHub repository, https://github.com/spatialaudio/python-sofa</unstructured_citation>
          </citation>
          <citation key="ref6">
            <unstructured_citation>Keller, Andrew, Unitful.jl, 2016, GitHub, GitHub repository, https://github.com/PainterQubits/Unitful.jl</unstructured_citation>
          </citation>
          <citation key="ref7">
            <unstructured_citation>Russell, Spencer, SampledSignals.jl, 2016, GitHub, GitHub repository, https://github.com/JuliaAudio/SampledSignals.jl</unstructured_citation>
          </citation>
          <citation key="ref8">
            <doi>10.1016/j.neuroimage.2013.10.027</doi>
          </citation>
          <citation key="ref9">
            <doi>10.1155/2011/156869</doi>
          </citation>
          <citation key="ref10">
            <doi>10.1137/141000671</doi>
          </citation>
          <citation key="ref11">
            <unstructured_citation>Cirrus Logic, Sapozhnykov, Vitaliy and Harvey, Thomas Ivan and Luke, Robert, dec, December, US, Patent, 10,504,537, Wind noise measurement, 2019, https://patents.google.com/patent/US10504537B2/en, 12</unstructured_citation>
          </citation>
          <citation key="ref12">
            <unstructured_citation>Cirrus Logic, Luke, Robert and Sapozhnykov, Vitaliy and Harvey, Thomas Ivan, sep, September, US, Patent, 10,412,518, Blocked microphone detection, 2020, https://patents.google.com/patent/US10412518B2/en, 9</unstructured_citation>
          </citation>
          <citation key="ref13">
            <unstructured_citation>Cirrus Logic, Sapozhnykov, Vitaliy and Harvey, Thomas Ivan and Erfaniansaeedi, Nafiseh and Luke, Robert, oct, October, US, Patent, 10,812,889, Headset on ear state detection, 2019, https://patents.google.com/patent/US10812889B2/en, 10</unstructured_citation>
          </citation>
          <citation key="ref14">
            <doi>10.1109/TNSRE.2016.2551302</doi>
          </citation>
          <citation key="ref15">
            <doi>10.1016/j.neuroimage.2018.01.033</doi>
          </citation>
          <citation key="ref16">
            <unstructured_citation>Fast music and audio processing using the Julia language, Kim, Jong Wook and Russell, Spencer and Bello, Juan, Audio Engineering Society Conference: 2017 AES International Conference on Semantic Audio, 2017, Audio Engineering Society</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
