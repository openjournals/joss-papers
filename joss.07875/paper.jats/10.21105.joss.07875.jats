<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7875</article-id>
<article-id pub-id-type="doi">10.21105/joss.07875</article-id>
<title-group>
<article-title>strauss: Sonification Tools and Resources for Analysis
Using Sound Synthesis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1530-1634</contrib-id>
<name>
<surname>Trayford</surname>
<given-names>James W.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7520-5911</contrib-id>
<name>
<surname>Youles</surname>
<given-names>Samantha</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8618-4223</contrib-id>
<name>
<surname>Harrison</surname>
<given-names>Chris</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0002-0369-5146</contrib-id>
<name>
<surname>Shepherd</surname>
<given-names>Rose</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9569-8808</contrib-id>
<name>
<surname>Bonne</surname>
<given-names>Nicolas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institute of Cosmology and Gravitation, University of
Portsmouth, Dennis Sciama Building, Burnaby Road, Portsmouth PO1 3FX,
UK</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>School of Mathematics, Statistics and Physics, Newcastle
University, NE1 7RU, UK</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-01-15">
<day>15</day>
<month>1</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>109</issue>
<fpage>7875</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>sonification</kwd>
<kwd>data inspection</kwd>
<kwd>astronomy</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><italic>Sonification</italic>, or conveying data using non-verbal
  audio, is a relatively niche but growing approach for presenting data
  across multiple specialist domains including astronomy, climate
  science, and beyond
  (<xref alt="Lenzi et al., 2021" rid="ref-Lenzi21" ref-type="bibr">Lenzi
  et al., 2021</xref>;
  <xref alt="Lindborg et al., 2023" rid="ref-Lindborg23" ref-type="bibr">Lindborg
  et al., 2023</xref>;
  <xref alt="Zanella et al., 2022" rid="ref-Zanella22" ref-type="bibr">Zanella
  et al., 2022</xref>). The <monospace>strauss</monospace> Python
  package aims to provide such a tool that builds upon previous
  approaches to provide a powerful means to explore different ways of
  expressing data, with fine control over the output audio and its
  format. <monospace>strauss</monospace> is a free, open source (FOSS)
  Python package, designed to allow flexible and effective sonification
  to be straightforwardly integrated into data workflows, in analogy to
  widely used visualisation packages.</p>
  <p>The remit of <monospace>strauss</monospace> is broad; it is
  intended to be able to bridge between <italic>ad-hoc</italic>
  solutions for sonifying very particular datasets, and highly technical
  compositional and sound-design tools that are not optimised for
  sonification, or may have a steep learning curve. The code offers a
  range of approaches to sonification for a variety of contexts
  (e.g. science education, science communication, technical data
  analysis, etc.). To this end, <monospace>strauss</monospace> is
  packaged with a number of examples of different sonification
  approaches, and preset configurations to support a
  <italic>low-barrier, high-ceiling</italic> approach.
  <monospace>strauss</monospace> has been used to produce both
  educational resources
  (<xref alt="Harrison et al., 2022" rid="ref-Harrison22" ref-type="bibr">Harrison
  et al., 2022</xref>), and analysis tools
  (<xref alt="Trayford et al., 2023" rid="ref-Trayford23b" ref-type="bibr">Trayford
  et al., 2023</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Sonification has great potential as a fundamental approach for
  interfacing with data. This provides new perspectives on data that
  complement visual approaches, as well as an accessible channel to data
  for those who cannot access visual presentation, e.g. those who are
  blind or visually impaired (BVI). As with the dominant approach of
  data <italic>visualisation</italic>, what can constitute sonification
  is very broad, with different considerations for aspects such as the
  audience, information content and aesthetics of the sonification. In
  order for sonification to become more established and realise its
  potential as a way of interfacing with data, accessible and flexible
  tools are needed to make sonification intuitive and accessible to
  those who routinely work with data.</p>
  <p>Unlike data <italic>visualisation</italic>, however, sonification
  of data is a far less developed methodology, with a lack of widely
  adopted, cross-domain tools and interfaces for those dealing with data
  to use. E.g., in the Python programming language, a number of packages
  exist for visualising data, such as Matplotlib
  (<xref alt="Hunter, 2007" rid="ref-Hunter07" ref-type="bibr">Hunter,
  2007</xref>), yt
  (<xref alt="Turk et al., 2011" rid="ref-Turk11" ref-type="bibr">Turk
  et al., 2011</xref>), seaborn
  (<xref alt="Waskom, 2021" rid="ref-Waskom21" ref-type="bibr">Waskom,
  2021</xref>), or Plotly
  (<xref alt="Technologies Inc., 2015" rid="ref-plotly" ref-type="bibr">Technologies
  Inc., 2015</xref>). The lack of dedicated and accessible tools for
  sonifying data is a barrier to exploring the approach. Most solutions
  are piecemeal, using <italic>ad-hoc</italic> tools to parse data and
  map it to properties of sound as well as generating and outputting
  sound in different formats. What’s more, many of the tools being
  repurposed to sonify data are proprietary and platform-dependent,
  requiring paid-for licenses.</p>
  <p>A number of effective python packages for data sonification have
  emerged, e.g. <monospace>astronify</monospace>
  (<xref alt="Brasseur et al., 2023" rid="ref-Brasseur23" ref-type="bibr">Brasseur
  et al., 2023</xref>) and <monospace>SonoUno</monospace>
  (<xref alt="Casado et al., 2024" rid="ref-Casado24" ref-type="bibr">Casado
  et al., 2024</xref>), but these are typically feature-limited in how
  sonification is produced, namely continuous pitch-mapped
  sonification.</p>
  <p>Realising the potential of sonification may require a
  “crowdsourced” approach; via broad adoption of the technique and
  innovation in sonification approaches driven by the scientific
  community. In this context, we identify a need for Python package
  that:</p>
  <list list-type="bullet">
    <list-item>
      <p>Provides a full pipeline from data to sonified audio that can
      be integrated into the workflows of scientists and data
      analysts.</p>
    </list-item>
    <list-item>
      <p>Is modular and enables complex, multi-variate sonification to
      be produced and fine tuned, while being simple enough to produce
      simple sonifications, for instance for novice users or in
      educational contexts.</p>
    </list-item>
    <list-item>
      <p>Is fully open-source and platform-independent, such that
      sonification is able to be integrated more broadly into scientific
      practice.</p>
    </list-item>
  </list>
  <p><monospace>strauss</monospace> (<bold>S</bold>onification
  <bold>T</bold>ools and <bold>R</bold>esources for
  <bold>A</bold>nalysis <bold>U</bold>sing <bold>S</bold>ound
  <bold>S</bold>ynthesis) is a Python package for data sonification. The
  code uses an object-oriented structure to provide a clear conceptual
  framework for the different components of a sonification
  (<xref alt="Trayford &amp; Harrison, 2023" rid="ref-Trayford23" ref-type="bibr">Trayford
  &amp; Harrison, 2023</xref>). <monospace>strauss</monospace> is
  designed to be used by analysts to fully sonify their data in a way
  analogous to a plotting pipeline, to be analysed independently or in
  conjunction with visuals.</p>
  <p>By choosing the mapping between the variables being communicated
  and the expressive properties of sound, <monospace>strauss</monospace>
  is designed to be a <italic>low-barrier, high-ceiling</italic> tool;
  providing the means to make diverse and highly customised
  sonifications with a high degree of low-level control as the user
  becomes more experienced, while providing a relatively simple path to
  produce sonifications quickly for a novice. This is intended to
  provide the bridge between typical analysts who know their data and
  the facets of it that they want to communicate, and the sound experts
  or musicians that understand how to express data with sound.</p>
  <p>The <monospace>strauss</monospace> code minimises dependencies
  where possible, implementing built-in signal generation and audio
  parsing and encoding based on low-level python libraries like NumPy
  (<xref alt="Harris et al., 2020" rid="ref-numpy" ref-type="bibr">Harris
  et al., 2020</xref>) and SciPy
  (<xref alt="Virtanen et al., 2020" rid="ref-scipy" ref-type="bibr">Virtanen
  et al., 2020</xref>), as well as being tested on multiple platforms
  (MacOS, Linux, Windows). This also provides means to interface with
  commonly used audio formats, such as <italic>“Soundfont”</italic>
  files (<monospace>.sf2</monospace>) to open a range of possibilities
  for representing data using different instruments. This helps to
  ensure that the free and open source status of
  <monospace>strauss</monospace> is maintained and does not require
  difficult to install or proprietary software, that may themselves have
  steep learning curves.</p>
  <p>Towards our <italic>low-barrier</italic> aspirations for
  <monospace>strauss</monospace>, a tutorial-driven development (TDD)
  approach is used where each major feature should have an associated
  tutorial example, which are packaged with the code, in both Python
  Notebook (<monospace>examples/.ipynb</monospace>) and Python script
  (<monospace>examples/*.py</monospace>) formats.
  <monospace>strauss</monospace> provides tools for inline playback of
  sound in both formats. In addition, a further collection of modified
  examples is provided specifically for the <italic>Google
  Colab</italic> platform
  (<monospace>examples/colab/*.ipynb</monospace>), allowing examples to
  be run fully in-browser without requiring a local install of the
  code.</p>
  <p>Offering both formats for examples in
  <monospace>strauss</monospace> allows us to exploit the interactivity
  and low technical threshold needed to use notebooks, while also having
  the BVI accessibility of the raw-text scripts, given the difficulties
  of using notebooks with screen readers
  (<xref alt="Trayford et al., 2024" rid="ref-Trayford24" ref-type="bibr">Trayford
  et al., 2024</xref>). <monospace>strauss</monospace> is provided with
  extensive documentation, maintained and hosted via
  <ext-link ext-link-type="uri" xlink:href="https://strauss.readthedocs.io/en/latest/"><italic>Read
  The Docs</italic></ext-link>.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>JWT acknowledges support via the STFC Early Stage Research &amp;
  Development Grant, reference ST/X004651/1, CMH acknowledge funding
  from an United Kingdom Research and Innovation grant (code:
  MR/V022830/1). RS is supported by a studentship from an STFC Centre of
  Doctoral Training in Data Intensive Science (code: ST/W006790/1).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Lenzi21">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Lenzi</surname><given-names>Sara</given-names></name>
        <name><surname>Ciuccarelli</surname><given-names>Paolo</given-names></name>
        <name><surname>Liu</surname><given-names>Houjiang</given-names></name>
        <name><surname>Hua</surname><given-names>Yuan</given-names></name>
        <name><surname>Zizzi</surname><given-names>Nicole</given-names></name>
      </person-group>
      <article-title>Data sonification archive</article-title>
      <source>Data Sonification Archive</source>
      <year iso-8601-date="2021-01">2021</year><month>01</month>
      <uri>https://sonification.design/</uri>
    </element-citation>
  </ref>
  <ref id="ref-Lindborg23">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lindborg</surname><given-names>PerMagnus</given-names></name>
        <name><surname>Lenzi</surname><given-names>Sara</given-names></name>
        <name><surname>Chen</surname><given-names>Manni</given-names></name>
      </person-group>
      <article-title>Climate data sonification and visualization: An analysis of topics, aesthetics, and characteristics in 32 recent projects</article-title>
      <source>Frontiers in Psychology</source>
      <year iso-8601-date="2023">2023</year>
      <volume>13</volume>
      <issn>1664-1078</issn>
      <uri>https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.1020102</uri>
      <pub-id pub-id-type="doi">10.3389/fpsyg.2022.1020102</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-scipy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
        <name><surname>Haberland</surname><given-names>Matt</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Burovski</surname><given-names>Evgeni</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Bright</surname><given-names>Jonathan</given-names></name>
        <name><surname>van der Walt</surname><given-names>Stéfan J.</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Wilson</surname><given-names>Joshua</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Mayorov</surname><given-names>Nikolay</given-names></name>
        <name><surname>Nelson</surname><given-names>Andrew R. J.</given-names></name>
        <name><surname>Jones</surname><given-names>Eric</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Larson</surname><given-names>Eric</given-names></name>
        <name><surname>Carey</surname><given-names>C J</given-names></name>
        <name><surname>Polat</surname><given-names>İlhan</given-names></name>
        <name><surname>Feng</surname><given-names>Yu</given-names></name>
        <name><surname>Moore</surname><given-names>Eric W.</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Laxalde</surname><given-names>Denis</given-names></name>
        <name><surname>Perktold</surname><given-names>Josef</given-names></name>
        <name><surname>Cimrman</surname><given-names>Robert</given-names></name>
        <name><surname>Henriksen</surname><given-names>Ian</given-names></name>
        <name><surname>Quintero</surname><given-names>E. A.</given-names></name>
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Archibald</surname><given-names>Anne M.</given-names></name>
        <name><surname>Ribeiro</surname><given-names>Antônio H.</given-names></name>
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>van Mulbregt</surname><given-names>Paul</given-names></name>
        <string-name>SciPy 1.0 Contributors</string-name>
      </person-group>
      <article-title>SciPy 1.0: Fundamental algorithms for scientific computing in Python</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2020">2020</year>
      <volume>17</volume>
      <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>
      <fpage>261</fpage>
      <lpage>272</lpage>
    </element-citation>
  </ref>
  <ref id="ref-numpy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Walt</surname><given-names>Stéfan J. van der</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Wieser</surname><given-names>Eric</given-names></name>
        <name><surname>Taylor</surname><given-names>Julian</given-names></name>
        <name><surname>Berg</surname><given-names>Sebastian</given-names></name>
        <name><surname>Smith</surname><given-names>Nathaniel J.</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Picus</surname><given-names>Matti</given-names></name>
        <name><surname>Hoyer</surname><given-names>Stephan</given-names></name>
        <name><surname>Kerkwijk</surname><given-names>Marten H. van</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Haldane</surname><given-names>Allan</given-names></name>
        <name><surname>Río</surname><given-names>Jaime Fernández del</given-names></name>
        <name><surname>Wiebe</surname><given-names>Mark</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>Gérard-Marchant</surname><given-names>Pierre</given-names></name>
        <name><surname>Sheppard</surname><given-names>Kevin</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Abbasi</surname><given-names>Hameer</given-names></name>
        <name><surname>Gohlke</surname><given-names>Christoph</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2020-09">2020</year><month>09</month>
      <volume>585</volume>
      <issue>7825</issue>
      <uri>https://doi.org/10.1038/s41586-020-2649-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hunter07">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hunter</surname><given-names>J. D.</given-names></name>
      </person-group>
      <article-title>Matplotlib: A 2D graphics environment</article-title>
      <source>Computing in Science &amp; Engineering</source>
      <publisher-name>IEEE COMPUTER SOC</publisher-name>
      <year iso-8601-date="2007">2007</year>
      <volume>9</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
      <fpage>90</fpage>
      <lpage>95</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Harrison22">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harrison</surname><given-names>Chris</given-names></name>
        <name><surname>Zanella</surname><given-names>Anita</given-names></name>
        <name><surname>Bonne</surname><given-names>Nic</given-names></name>
        <name><surname>Meredith</surname><given-names>Kate</given-names></name>
        <name><surname>Misdariis</surname><given-names>Nicolas</given-names></name>
      </person-group>
      <article-title>Audible universe</article-title>
      <source>Nature Astronomy</source>
      <year iso-8601-date="2022-01">2022</year><month>01</month>
      <volume>6</volume>
      <uri>https://arxiv.org/abs/2206.13542</uri>
      <pub-id pub-id-type="doi">10.1038/s41550-021-01582-y</pub-id>
      <fpage>22</fpage>
      <lpage>23</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Trayford23b">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Trayford</surname><given-names>J. W.</given-names></name>
        <name><surname>Harrison</surname><given-names>C. M.</given-names></name>
        <name><surname>Hinz</surname><given-names>R. C.</given-names></name>
        <name><surname>Kavanagh Blatt</surname><given-names>M.</given-names></name>
        <name><surname>Dougherty</surname><given-names>S.</given-names></name>
        <name><surname>Girdhar</surname><given-names>A.</given-names></name>
      </person-group>
      <article-title>Inspecting spectra with sound: proof-of-concept and extension to datacubes</article-title>
      <source>RAS Techniques and Instruments</source>
      <year iso-8601-date="2023-01">2023</year><month>01</month>
      <volume>2</volume>
      <issue>1</issue>
      <uri>https://arxiv.org/abs/2306.10126</uri>
      <pub-id pub-id-type="doi">10.1093/rasti/rzad021</pub-id>
      <fpage>387</fpage>
      <lpage>392</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Trayford23">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Trayford</surname><given-names>J. W.</given-names></name>
        <name><surname>Harrison</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Introducing strauss: A flexible sonification Python package</article-title>
      <source>Proceedings of the 28th International Conference on Auditory Display (ICAD 2023)</source>
      <person-group person-group-type="editor">
        <name><surname>Weger</surname><given-names>Marian</given-names></name>
        <name><surname>Ziemer</surname><given-names>Tim</given-names></name>
        <name><surname>Rönnberg</surname><given-names>Niklas</given-names></name>
      </person-group>
      <year iso-8601-date="2023-06">2023</year><month>06</month>
      <pub-id pub-id-type="doi">10.21785/icad2023.1978</pub-id>
      <fpage>249</fpage>
      <lpage>256</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Trayford24">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Trayford</surname><given-names>J. W.</given-names></name>
        <name><surname>Youles</surname><given-names>S.</given-names></name>
        <name><surname>Bonne</surname><given-names>N.</given-names></name>
        <name><surname>Harrison</surname><given-names>C. M.</given-names></name>
      </person-group>
      <article-title>Ear to the sky: Astronomical sonification for accessible outreach, education and research with STRAUSS</article-title>
      <source>Revista Mexicana de Astronomía y Astrofísica Serie de Conferencias</source>
      <year iso-8601-date="2024-06">2024</year><month>06</month>
      <volume>57</volume>
      <uri>https://www.astroscu.unam.mx/rmaa/RMxAC..57/PDF/RMxAC..57_jtrayford-X.pdf</uri>
      <fpage>42</fpage>
      <lpage>46</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Casado24">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Casado</surname><given-names>Johanna</given-names></name>
        <name><surname>Vega</surname><given-names>Gonzalo de la</given-names></name>
        <name><surname>García</surname><given-names>Beatriz</given-names></name>
      </person-group>
      <article-title>SonoUno development: A user-centered sonification software for data analysis</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>9</volume>
      <issue>93</issue>
      <uri>https://doi.org/10.21105/joss.05819</uri>
      <pub-id pub-id-type="doi">10.21105/joss.05819</pub-id>
      <fpage>5819</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Brasseur23">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Brasseur</surname><given-names>Clara</given-names></name>
        <name><surname>Fleming</surname><given-names>Scott</given-names></name>
        <name><surname>Kotler</surname><given-names>Jennifer</given-names></name>
        <name><surname>Meredith</surname><given-names>Kate</given-names></name>
      </person-group>
      <article-title>Astronify: v0.1</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2023-03">2023</year><month>03</month>
      <uri>https://doi.org/10.5281/zenodo.7713214</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.7713214</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-plotly">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>Technologies Inc.</surname><given-names>Plotly &amp;</given-names></name>
      </person-group>
      <article-title>Collaborative data science</article-title>
      <publisher-name>Plotly Technologies Inc, from</publisher-name>
      <publisher-loc>Montreal, QC</publisher-loc>
      <year iso-8601-date="2015">2015</year>
      <uri>https://plot.ly</uri>
    </element-citation>
  </ref>
  <ref id="ref-Waskom21">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Waskom</surname><given-names>Michael L.</given-names></name>
      </person-group>
      <article-title>Seaborn: Statistical data visualization</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>60</issue>
      <uri>https://doi.org/10.21105/joss.03021</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03021</pub-id>
      <fpage>3021</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Turk11">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Turk</surname><given-names>M. J.</given-names></name>
        <name><surname>Smith</surname><given-names>B. D.</given-names></name>
        <name><surname>Oishi</surname><given-names>J. S.</given-names></name>
        <name><surname>Skory</surname><given-names>S.</given-names></name>
        <name><surname>Skillman</surname><given-names>S. W.</given-names></name>
        <name><surname>Abel</surname><given-names>T.</given-names></name>
        <name><surname>Norman</surname><given-names>M. L.</given-names></name>
      </person-group>
      <article-title>yt: A multi-code analysis toolkit for astrophysical simulation data</article-title>
      <source>The Astrophysical Journal Supplement Series</source>
      <year iso-8601-date="2011-01">2011</year><month>01</month>
      <volume>192</volume>
      <uri>https://arxiv.org/abs/1011.3514</uri>
      <pub-id pub-id-type="doi">10.1088/0067-0049/192/1/9</pub-id>
      <fpage>9</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Zanella22">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zanella</surname><given-names>A.</given-names></name>
        <name><surname>Harrison</surname><given-names>C. M.</given-names></name>
        <name><surname>Lenzi</surname><given-names>S.</given-names></name>
        <name><surname>Cooke</surname><given-names>J.</given-names></name>
        <name><surname>Damsma</surname><given-names>P.</given-names></name>
        <name><surname>Fleming</surname><given-names>S. W.</given-names></name>
      </person-group>
      <article-title>Sonification and sound design for astronomy research, education and public engagement</article-title>
      <source>Nature Astronomy</source>
      <year iso-8601-date="2022-11">2022</year><month>11</month>
      <volume>6</volume>
      <uri>https://arxiv.org/abs/2206.13536</uri>
      <pub-id pub-id-type="doi">10.1038/s41550-022-01721-z</pub-id>
      <fpage>1241</fpage>
      <lpage>1248</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
