<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4554</article-id>
<article-id pub-id-type="doi">10.21105/joss.04554</article-id>
<title-group>
<article-title>Panako: a scalable audio search system</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7671-1907</contrib-id>
<name>
<surname>Six</surname>
<given-names>Joren</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>IPEM, Ghent University, Belgium</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-07-01">
<day>1</day>
<month>7</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>78</issue>
<fpage>4554</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Acoustic fingerprinting</kwd>
<kwd>Music Information Retreival</kwd>
<kwd>Java software</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Panako solves the problem of finding short audio fragments in large
  digital audio archives. The content based audio search algorithm
  implemented in Panako is able to identify a short audio query in a
  large database of thousands of hours of audio using an acoustic
  fingerprinting technique.</p>
  <fig>
    <caption><p>A general acoustic fingerprinting system. Features are
    extracted from audio and combined into fingerprints. The
    fingerprints are matched with fingerprints in a reference database.
    Finally a match is
    reported.<styled-content id="figU003Ageneral"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/resources/media/general_acoustic_fingerprinting_schema.png" xlink:title="" />
  </fig>
  <p>The dataflow in Panako closely resembles the flow depicted in
  <xref alt="Figure 1" rid="figU003Ageneral">Figure 1</xref>. Audio is
  transformed to features which are grouped in recognizable
  fingerprints. The fingerprints are compared with a database of
  reference fingerprints. If a match is found, it is reported or, in
  case of a true negative, the system reports that the audio is not
  present in the database. The properties of the acoustic fingerprinting
  system mainly depend on the selection of features, the information
  captured by the fingerprints and the performance of the matching
  step.</p>
  <p>There are three algorithms implemented in Panako. The first is
  based on pitch class histograms Six &amp; Cornelis
  (<xref alt="2012" rid="ref-six2012ethnic_fingerprinter" ref-type="bibr">2012</xref>).
  The other two are based on peaks in a spectral representation: a
  baseline algorithm
  (<xref alt="Six, 2020" rid="ref-six2020olaf" ref-type="bibr">Six,
  2020</xref>;
  <xref alt="Avery L. Wang, 2003" rid="ref-Wang2003a" ref-type="bibr">Avery
  L. Wang, 2003</xref>) and the main Panako algorithm
  (<xref alt="Six &amp; Leman, 2014" rid="ref-six2014panako" ref-type="bibr">Six
  &amp; Leman, 2014</xref>;
  <xref alt="Six, Joren, 2021" rid="ref-six2021panakovtwo" ref-type="bibr">Six,
  Joren, 2021</xref>;
  <xref alt="A. Li-chun Wang &amp; Culbert, 2003" rid="ref-wang2003patent" ref-type="bibr">A.
  Li-chun Wang &amp; Culbert, 2003</xref>).</p>
  <p>The main algorithm in Panako finds matches between a short query
  fragment and the audio in the database even if the query is
  time-stretched, pitch-shifted, slowed down or sped up while
  maintaining other desirable features such as scalability, robustness
  and reliability. This is important since changes in replay speed do
  occur commonly, they are either introduced by accident during an
  analog to digital conversion or are introduced deliberately.</p>
  <p>Accidental audio speed changes are often the result of varying or
  uncalibrated recording or playback speeds of analogue physical media
  such as wax cylinders, wire recordings, magnetic tapes or gramophone
  records. To identify duplicates in a digitized archive, a music search
  algorithm should be robust against replay speed. Deliberate speed
  manipulations are sometimes introduced during radio broadcasts:
  occasionally songs are played a bit faster to fit into a time-slot.
  During a DJ-set speed changes are almost always present. To correctly
  identify audio in these cases as well, a music search algorithm must
  be robust against pitch shifting, time stretching and speed
  changes.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Audio search algorithms have been described for decades
  (<xref alt="Cano et al., 2005" rid="ref-cano2005fingerprinting_overview" ref-type="bibr">Cano
  et al., 2005</xref>;
  <xref alt="Fenet et al., 2011" rid="ref-fenet2011pitch_shift_fingerprinting" ref-type="bibr">Fenet
  et al., 2011</xref>;
  <xref alt="Haitsma &amp; Kalker, 2002" rid="ref-haitsma2002fingerprinter" ref-type="bibr">Haitsma
  &amp; Kalker, 2002</xref>;
  <xref alt="Herre et al., 2002" rid="ref-herre2002scalable" ref-type="bibr">Herre
  et al., 2002</xref>;
  <xref alt="Sonnleitner &amp; Widmer, 2014" rid="ref-sonnleitner2014quad_based_fingerprinter" ref-type="bibr">Sonnleitner
  &amp; Widmer, 2014</xref>;
  <xref alt="Avery L. Wang, 2003" rid="ref-Wang2003a" ref-type="bibr">Avery
  L. Wang, 2003</xref>) but have not been accessible for researchers due
  to the lack of proper, scalable, freely available implementations.
  Panako solves this problem by providing an acoustic fingerprinting
  system which can be used by researchers for DJ-set analysis, digital
  music archive management and audio-to-audio alignment.</p>
  <p>In DJ-set analysis the aim is to automatically identify music in
  sets and how that music was modified and mixed
  (<xref alt="Kim et al., 2020" rid="ref-kim2020djset" ref-type="bibr">Kim
  et al., 2020</xref>;
  <xref alt="Schwarz &amp; Fourer, 2018" rid="ref-black2018unmixdb" ref-type="bibr">Schwarz
  &amp; Fourer, 2018</xref>;
  <xref alt="Sonnleitner et al., 2016" rid="ref-sonnleitner2016landmark" ref-type="bibr">Sonnleitner
  et al., 2016</xref>). With its robustness for time-stretch/pitch-shift
  and speed-up Panako is ideally suited to gather large scale insights
  in DJ performance practice.</p>
  <p>Six et al.
  (<xref alt="2018" rid="ref-six2018dupapps" ref-type="bibr">2018</xref>)
  describes the applications of acoustic fingerprints for digital music
  archive management. These range from meta-data quality verification -
  through the identification of duplicates - to merging archives with
  potential duplicate material.</p>
  <p>A less straightforward application of Panako is audio-to-audio
  alignment and synchronization
  (<xref alt="Six &amp; Leman, 2015" rid="ref-six2015synchronizing" ref-type="bibr">Six
  &amp; Leman, 2015</xref>,
  <xref alt="2017" rid="ref-six2017framework" ref-type="bibr">2017</xref>).
  In that case the matching fingerprints are used to align e.g. multiple
  video recordings of the same event by aligning the audio attached to
  each video.</p>
  <p>Alternative systems with available implementations are by Chang et
  al. (<xref alt="2021" rid="ref-neuralfp" ref-type="bibr">2021</xref>)
  and audfprint by Ellis
  (<xref alt="2014" rid="ref-ellis20142014" ref-type="bibr">2014</xref>).
  Both systems however lack robustness to significant speed changes of
  more than 5%. Note that there are two implementations of the audfprint
  system: there is a MatLab<xref ref-type="fn" rid="fn1">1</xref> and
  Python<xref ref-type="fn" rid="fn2">2</xref> version. The matlab
  version has support for small amounts time scaling. The details on how
  Panako handles time-scaling are described in two papers
  (<xref alt="Six &amp; Leman, 2014" rid="ref-six2014panako" ref-type="bibr">Six
  &amp; Leman, 2014</xref>;
  <xref alt="Six, Joren, 2021" rid="ref-six2021panakovtwo" ref-type="bibr">Six,
  Joren, 2021</xref>).</p>
</sec>
<sec id="design">
  <title>Design</title>
  <p>Simplicity and maintainability are two keywords in the design of
  Panako. The code aims to be as readable and simple as possible. The
  second version of Panako is a complete rewrite to ensure this
  simplicity while still keeping query and computational performance in
  check.</p>
  <p>Relying on conservative platforms with a long history of backwards
  compatibility should allow Panako to stand the test of time. Panako is
  developed in Java and targets the long term support release Java SE
  11. Panako also relies on software in C and C++. Java, C and C++ have
  been around for decades and it is reasonable to assume that these
  platforms will be supported for decades to come. Boring technology
  enables longevity.</p>
  <p>Next to Java 11, Panako depends on three libraries: a DSP library,
  a key-value store and a spectral transform library. The first is a
  pure Java DSP library called
  TarsosDSP<xref ref-type="fn" rid="fn3">3</xref>
  (<xref alt="Six et al., 2014" rid="ref-six2014tarsosdsp" ref-type="bibr">Six
  et al., 2014</xref>). LMDB<xref ref-type="fn" rid="fn4">4</xref> is
  used as a high performance key-value store. It is a C library and
  accessible through lmdbjava. The third and final dependency is
  JGaborator<xref ref-type="fn" rid="fn5">5</xref>: a wrapper around the
  Gaborator<xref ref-type="fn" rid="fn6">6</xref> library which
  implements a constant-Q non-stationary Gabor transform in C++11
  (<xref alt="Velasco, Gino Angelo and Holighaus, Nicki and Dörfler, Monika and Grill, Thomas, 2011" rid="ref-velasco2011constructing" ref-type="bibr">Velasco,
  Gino Angelo and Holighaus, Nicki and Dörfler, Monika and Grill,
  Thomas, 2011</xref>). The last two have native compiled parts and need
  to be ported to new or exotic platforms if the need arises. The
  transition to aarch64 (Apple M1), for example consisted of a
  straightforward compilation step and repackaging of this native
  library. Panako can be containerized and the Docker file supports both
  ARM and x86 platforms and always compiles these native
  dependencies.</p>
  <p>The code of Panako is hosted in a publicly available GitHub
  repository. Internal documentation follows the JavaDoc standards. Two
  papers give the rationale behind the algorithms
  (<xref alt="Six &amp; Leman, 2014" rid="ref-six2014panako" ref-type="bibr">Six
  &amp; Leman, 2014</xref>;
  <xref alt="Six, Joren, 2021" rid="ref-six2021panakovtwo" ref-type="bibr">Six,
  Joren, 2021</xref>). Panako can be installed using a Gradle wrapper
  script which automatically downloads the Gradle build-system if it is
  not present on the system. The Gradle wrapper compiles and installs
  Panako.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Development of Panako is partially funded by the Ghent University
  BOF Project PaPiOM.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-six2012ethnic_fingerprinter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Cornelis</surname><given-names>Olmo</given-names></name>
      </person-group>
      <article-title>A Robust Audio Fingerprinter Based on Pitch Class Histograms - Applications for Ethnic Music Archives</article-title>
      <source>Proceedings of the Folk Music Analysis conference (FMA 2012)</source>
      <year iso-8601-date="2012">2012</year>
    </element-citation>
  </ref>
  <ref id="ref-velasco2011constructing">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <string-name>Velasco, Gino Angelo and Holighaus, Nicki and Dörfler, Monika and Grill, Thomas</string-name>
      </person-group>
      <article-title>Constructing an invertible constant-q transform with non-stationary gabor frames</article-title>
      <source>Proceedings of the 14th International Conference on Digital Audio Effects (DAFx-11)</source>
      <year iso-8601-date="2011">2011</year>
      <volume>33</volume>
    </element-citation>
  </ref>
  <ref id="ref-six2014tarsosdsp">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Cornelis</surname><given-names>Olmo</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>TarsosDSP, a Real-Time Audio Processing Framework in Java</article-title>
      <source>Proceedings of the 53rd AES Conference (AES 53rd)</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-herre2002scalable">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Herre</surname><given-names>Jürgen</given-names></name>
        <name><surname>Hellmuth</surname><given-names>Oliver</given-names></name>
        <name><surname>Cremer</surname><given-names>Markus</given-names></name>
      </person-group>
      <article-title>Scalable robust audio fingerprinting using MPEG-7 content description</article-title>
      <source>Multimedia signal processing, 2002 IEEE workshop on</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <pub-id pub-id-type="doi">10.1109/MMSP.2002.1203273</pub-id>
      <fpage>165</fpage>
      <lpage>168</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Wang2003a">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Avery L.</given-names></name>
      </person-group>
      <article-title>An Industrial-Strength Audio Search Algorithm</article-title>
      <source>Proceedings of the 4th International Symposium on Music Information Retrieval (ISMIR 2003)</source>
      <publisher-loc>Baltimore, MD, USA</publisher-loc>
      <year iso-8601-date="2003">2003</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1416340</pub-id>
      <fpage>7</fpage>
      <lpage>13</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fenet2011pitch_shift_fingerprinting">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Fenet</surname><given-names>Sébastien</given-names></name>
        <name><surname>Richard</surname><given-names>Gaël</given-names></name>
        <name><surname>Grenier</surname><given-names>Yves</given-names></name>
      </person-group>
      <article-title>A Scalable Audio Fingerprint Method with Robustness to Pitch-Shifting</article-title>
      <source>Proceedings of the 12th International Symposium on Music Information Retrieval (ISMIR 2011)</source>
      <year iso-8601-date="2011">2011</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1417593</pub-id>
      <fpage>121</fpage>
      <lpage>126</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2018dupapps">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Bressan</surname><given-names>Federica</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Applications of duplicate detection in music archives: From metadata comparison to storage optimisation</article-title>
      <source>Digital libraries and multimedia archives</source>
      <person-group person-group-type="editor">
        <name><surname>Serra</surname><given-names>Giuseppe</given-names></name>
        <name><surname>Tasso</surname><given-names>Carlo</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2018">2018</year>
      <isbn>978-3-319-73165-0</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-319-73165-0_10</pub-id>
      <fpage>101</fpage>
      <lpage>113</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cano2005fingerprinting_overview">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cano</surname><given-names>Pedro</given-names></name>
        <name><surname>Batlle</surname><given-names>Eloi</given-names></name>
        <name><surname>Kalker</surname><given-names>Ton</given-names></name>
        <name><surname>Haitsma</surname><given-names>Jaap</given-names></name>
      </person-group>
      <article-title>A review of audio fingerprinting</article-title>
      <source>The Journal of VLSI Signal Processing</source>
      <publisher-name>Springer Netherlands</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <volume>41</volume>
      <issn>0922-5773</issn>
      <pub-id pub-id-type="doi">10.1007/s11265-005-4151-3</pub-id>
      <fpage>271</fpage>
      <lpage>284</lpage>
    </element-citation>
  </ref>
  <ref id="ref-sonnleitner2014quad_based_fingerprinter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Sonnleitner</surname><given-names>Reinhard</given-names></name>
        <name><surname>Widmer</surname><given-names>Gerhard</given-names></name>
      </person-group>
      <article-title>Quad-based Audio Fingerprinting Robust To Time And Frequency Scaling</article-title>
      <source>Proceedings of the 17th International Conference on Digital Audio Effects (DAFx-14)</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-ellis20142014">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ellis</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>The 2014 labrosa audio fingerprint system</article-title>
      <source>MIREX abstracts of the 15th International Symposium on Music Information Retrieval (ISMIR 2014)</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-neuralfp">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Chang</surname><given-names>Sungkyun</given-names></name>
        <name><surname>Lee</surname><given-names>Donmoon</given-names></name>
        <name><surname>Park</surname><given-names>Jeongsoo</given-names></name>
        <name><surname>Lim</surname><given-names>Hyungui</given-names></name>
        <name><surname>Lee</surname><given-names>Kyogu</given-names></name>
        <name><surname>Ko</surname><given-names>Karam</given-names></name>
        <name><surname>Han</surname><given-names>Yoonchang</given-names></name>
      </person-group>
      <article-title>Neural audio fingerprint for high-specific audio retrieval based on contrastive learning</article-title>
      <source>ICASSP 2021 - 2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)</source>
      <year iso-8601-date="2021">2021</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/ICASSP39728.2021.9414337</pub-id>
      <fpage>3025</fpage>
      <lpage>3029</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2003patent">
    <element-citation publication-type="patent">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>A Li-chun</given-names></name>
        <name><surname>Culbert</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>Robust and invariant audio pattern matching</article-title>
      <source>Patent US7627477 B</source>
      <year iso-8601-date="2003">2003</year>
      <volume>2</volume>
    </element-citation>
  </ref>
  <ref id="ref-sonnleitner2016landmark">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Sonnleitner</surname><given-names>Reinhard</given-names></name>
        <name><surname>Arzt</surname><given-names>Andreas</given-names></name>
        <name><surname>Widmer</surname><given-names>Gerhard</given-names></name>
      </person-group>
      <article-title>Landmark-based audio fingerprinting for DJ mix monitoring.</article-title>
      <source>Proceedings of the 17th International Symposium on Music Information Retrieval (ISMIR 2016)</source>
      <year iso-8601-date="2016">2016</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1417008</pub-id>
      <fpage>185</fpage>
      <lpage>191</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2021panakovtwo">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <string-name>Six, Joren</string-name>
      </person-group>
      <article-title>Panako 2.0 : updates for an acoustic fingerprinting system</article-title>
      <source>Extended abstracts for the Late-Breaking Demo Session of the 22st International Society for Music Information Conference (ISMIR 2021) </source>
      <publisher-loc>Online</publisher-loc>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-six2014panako">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Panako - A scalable acoustic fingerprinting system handling time-scale and pitch modification</article-title>
      <source>Proceedings of the 15th ISMIR Conference (ISMIR 2014)</source>
      <year iso-8601-date="2014">2014</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1416190</pub-id>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2015synchronizing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Synchronizing multimodal recordings using audio-to-audio alignment</article-title>
      <source>Journal on Multimodal User Interfaces</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>9</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1007/s12193-015-0196-1</pub-id>
      <fpage>223</fpage>
      <lpage>229</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2017framework">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>A framework to provide fine-grained time-dependent context for active listening experiences</article-title>
      <source>Audio engineering society conference: 2017 AES international conference on semantic audio</source>
      <publisher-name>Audio Engineering Society</publisher-name>
      <year iso-8601-date="2017">2017</year>
    </element-citation>
  </ref>
  <ref id="ref-black2018unmixdb">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Schwarz</surname><given-names>Diemo</given-names></name>
        <name><surname>Fourer</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>Unmixdb: A dataset for DJ-mix information retrieval</article-title>
      <source>Proceedings of the 19th International Symposium on Music Information Retrieval (ISMIR 2018)</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1422385</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-haitsma2002fingerprinter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Haitsma</surname><given-names>Jaap</given-names></name>
        <name><surname>Kalker</surname><given-names>Ton</given-names></name>
      </person-group>
      <article-title>A highly robust audio fingerprinting system.</article-title>
      <source>Proceedings of the 3th International Symposium on Music Information Retrieval (ISMIR 2002)</source>
      <year iso-8601-date="2002">2002</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1417973</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-kim2020djset">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Kim</surname><given-names>Taejun</given-names></name>
        <name><surname>Choi</surname><given-names>Minsuk</given-names></name>
        <name><surname>Sacks</surname><given-names>Evan</given-names></name>
        <name><surname>Yang</surname><given-names>Yi-Hsuan</given-names></name>
        <name><surname>Nam</surname><given-names>Juhan</given-names></name>
      </person-group>
      <article-title>A computational analysis of real-world DJ mixes using mix-to-track subsequence alignment</article-title>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.4245544</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-six2020olaf">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
      </person-group>
      <article-title>OLAF: Overly lightweight acoustic fingerprinting</article-title>
      <source>Extended abstracts for the Late-Breaking Demo Session of the 21st International Society for Music Information Conference (ISMIR 2020) </source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p><ext-link ext-link-type="uri" xlink:href="https://www.ee.columbia.edu/~dpwe/resources/matlab/audfprint/">https://www.ee.columbia.edu/~dpwe/resources/matlab/audfprint/</ext-link></p>
  </fn>
  <fn id="fn2">
    <label>2</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/dpwe/audfprint">https://github.com/dpwe/audfprint</ext-link></p>
  </fn>
  <fn id="fn3">
    <label>3</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/JorenSix/TarsosDSP">https://github.com/JorenSix/TarsosDSP</ext-link></p>
  </fn>
  <fn id="fn4">
    <label>4</label><p><ext-link ext-link-type="uri" xlink:href="https://www.symas.com/lmdb">https://www.symas.com/lmdb</ext-link></p>
  </fn>
  <fn id="fn5">
    <label>5</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/JorenSix/JGaborator">https://github.com/JorenSix/JGaborator</ext-link></p>
  </fn>
  <fn id="fn6">
    <label>6</label><p><ext-link ext-link-type="uri" xlink:href="https://gaborator.com">https://gaborator.com</ext-link></p>
  </fn>
</fn-group>
</back>
</article>
