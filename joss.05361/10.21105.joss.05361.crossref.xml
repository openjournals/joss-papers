<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20230624T193831-d8f554fbee2306991affebdb0d4b92654f55ce33</doi_batch_id>
    <timestamp>20230624193831</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>06</month>
          <year>2023</year>
        </publication_date>
        <journal_volume>
          <volume>8</volume>
        </journal_volume>
        <issue>86</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>normflows: A PyTorch Package for Normalizing
Flows</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Vincent</given_name>
            <surname>Stimper</surname>
            <ORCID>https://orcid.org/0000-0002-4965-4297</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>David</given_name>
            <surname>Liu</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Andrew</given_name>
            <surname>Campbell</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Vincent</given_name>
            <surname>Berenz</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Lukas</given_name>
            <surname>Ryll</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Bernhard</given_name>
            <surname>Schölkopf</surname>
            <ORCID>https://orcid.org/0000-0002-8177-0925</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>José Miguel</given_name>
            <surname>Hernández-Lobato</surname>
          </person_name>
        </contributors>
        <publication_date>
          <month>06</month>
          <day>24</day>
          <year>2023</year>
        </publication_date>
        <pages>
          <first_page>5361</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.05361</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.8027667</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/5361</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.05361</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.05361</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.05361.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="Tabak2010">
            <article_title>Density estimation by dual ascent of the
log-likelihood</article_title>
            <author>Tabak</author>
            <journal_title>Communications in Mathematical
Sciences</journal_title>
            <issue>1</issue>
            <volume>8</volume>
            <doi>10.4310/CMS.2010.v8.n1.a11</doi>
            <cYear>2010</cYear>
            <unstructured_citation>Tabak, E. G., &amp; Vanden-Eijnden,
E. (2010). Density estimation by dual ascent of the log-likelihood.
Communications in Mathematical Sciences, 8(1), 217–233.
https://doi.org/10.4310/CMS.2010.v8.n1.a11</unstructured_citation>
          </citation>
          <citation key="tabak2013family">
            <article_title>A family of nonparametric density estimation
algorithms</article_title>
            <author>Tabak</author>
            <journal_title>Communications on Pure and Applied
Mathematics</journal_title>
            <issue>2</issue>
            <volume>66</volume>
            <doi>10.1002/cpa.21423</doi>
            <cYear>2013</cYear>
            <unstructured_citation>Tabak, E. G., &amp; Turner, C. V.
(2013). A family of nonparametric density estimation algorithms.
Communications on Pure and Applied Mathematics, 66(2), 145–164.
https://doi.org/10.1002/cpa.21423</unstructured_citation>
          </citation>
          <citation key="rezende2015variational">
            <article_title>Variational inference with normalizing
flows</article_title>
            <author>Rezende</author>
            <journal_title>Proceedings of the 32nd international
conference on machine learning</journal_title>
            <cYear>2015</cYear>
            <unstructured_citation>Rezende, D., &amp; Mohamed, S.
(2015). Variational inference with normalizing flows. Proceedings of the
32nd International Conference on Machine Learning,
1530–1538.</unstructured_citation>
          </citation>
          <citation key="kingma2018glow">
            <article_title>Glow: Generative flow with invertible 1x1
convolutions</article_title>
            <author>Kingma</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>31</volume>
            <cYear>2018</cYear>
            <unstructured_citation>Kingma, D. P., &amp; Dhariwal, P.
(2018). Glow: Generative flow with invertible 1x1 convolutions. Advances
in Neural Information Processing Systems, 31.</unstructured_citation>
          </citation>
          <citation key="grcic2021">
            <article_title>Densely connected normalizing
flows</article_title>
            <author>Grcić</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>34</volume>
            <cYear>2021</cYear>
            <unstructured_citation>Grcić, M., Grubišić, I., &amp;
Šegvić, S. (2021). Densely connected normalizing flows. Advances in
Neural Information Processing Systems, 34.</unstructured_citation>
          </citation>
          <citation key="wang2019text">
            <article_title>Riemannian normalizing flow on variational
Wasserstein autoencoder for text modeling</article_title>
            <author>Wang</author>
            <journal_title>Proceedings of the 2019 conference of the
north American chapter of the association for computational linguistics:
Human language technologies, volume 1 (long and short
papers)</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Wang, P. Z., &amp; Wang, W. Y.
(2019). Riemannian normalizing flow on variational Wasserstein
autoencoder for text modeling. Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long and Short
Papers).</unstructured_citation>
          </citation>
          <citation key="noe2019boltzmann">
            <article_title>Boltzmann generators: Sampling equilibrium
states of many-body systems with deep learning</article_title>
            <author>Noé</author>
            <journal_title>Science</journal_title>
            <issue>6457</issue>
            <volume>365</volume>
            <doi>10.1126/science.aaw1147</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Noé, F., Olsson, S., Köhler, J.,
&amp; Wu, H. (2019). Boltzmann generators: Sampling equilibrium states
of many-body systems with deep learning. Science, 365(6457).
https://doi.org/10.1126/science.aaw1147</unstructured_citation>
          </citation>
          <citation key="kobyzev2021">
            <article_title>Normalizing flows: An introduction and review
of current methods</article_title>
            <author>Kobyzev</author>
            <journal_title>IEEE Transactions on Pattern Analysis and
Machine Intelligence</journal_title>
            <issue>11</issue>
            <volume>43</volume>
            <doi>10.1109/TPAMI.2020.2992934</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Kobyzev, I., Prince, S. J. D., &amp;
Brubaker, M. A. (2021). Normalizing flows: An introduction and review of
current methods. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 43(11), 3964–3979.
https://doi.org/10.1109/TPAMI.2020.2992934</unstructured_citation>
          </citation>
          <citation key="papamakarios2021normalizing">
            <article_title>Normalizing flows for probabilistic modeling
and inference</article_title>
            <author>Papamakarios</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <issue>57</issue>
            <volume>22</volume>
            <cYear>2021</cYear>
            <unstructured_citation>Papamakarios, G., Nalisnick, E.,
Rezende, D. J., Mohamed, S., &amp; Lakshminarayanan, B. (2021).
Normalizing flows for probabilistic modeling and inference. Journal of
Machine Learning Research, 22(57), 1–64.</unstructured_citation>
          </citation>
          <citation key="paszke2019pytorch">
            <article_title>PyTorch: An imperative style,
high-performance deep learning library</article_title>
            <author>Paszke</author>
            <journal_title>Advances in neural information processing
systems 32</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Paszke, A., Gross, S., Massa, F.,
Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein,
N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison,
M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., … Chintala, S.
(2019). PyTorch: An imperative style, high-performance deep learning
library. In Advances in neural information processing systems 32 (pp.
8024–8035).</unstructured_citation>
          </citation>
          <citation key="dinh2017RealNVP">
            <article_title>Density estimation using Real
NVP</article_title>
            <author>Dinh</author>
            <journal_title>International Conference on Learning
Representations</journal_title>
            <cYear>2017</cYear>
            <unstructured_citation>Dinh, L., Sohl-Dickstein, J., &amp;
Bengio, S. (2017). Density estimation using Real NVP. International
Conference on Learning Representations.</unstructured_citation>
          </citation>
          <citation key="papamakarios2017">
            <article_title>Masked autoregressive flow for density
estimation</article_title>
            <author>Papamakarios</author>
            <journal_title>Proceedings of the 31st International
Conference on Neural Information Processing Systems</journal_title>
            <cYear>2017</cYear>
            <unstructured_citation>Papamakarios, G., Pavlakou, T., &amp;
Murray, I. (2017). Masked autoregressive flow for density estimation.
Proceedings of the 31st International Conference on Neural Information
Processing Systems, 2335–2344.</unstructured_citation>
          </citation>
          <citation key="muller2019neural">
            <article_title>Neural importance sampling</article_title>
            <author>Müller</author>
            <journal_title>ACM Transactions on Graphics
(TOG)</journal_title>
            <issue>5</issue>
            <volume>38</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Müller, T., McWilliams, B.,
Rousselle, F., Gross, M., &amp; Novák, J. (2019). Neural importance
sampling. ACM Transactions on Graphics (TOG), 38(5),
1–19.</unstructured_citation>
          </citation>
          <citation key="durkan2019neuralspline">
            <article_title>Neural spline flows</article_title>
            <author>Durkan</author>
            <journal_title>Advances in Neural Information Processing
Systems</journal_title>
            <volume>32</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Durkan, C., Bekasov, A., Murray, I.,
&amp; Papamakarios, G. (2019). Neural spline flows. Advances in Neural
Information Processing Systems, 32, 7511–7522.</unstructured_citation>
          </citation>
          <citation key="chen2019residual">
            <article_title>Residual flows for invertible generative
modeling</article_title>
            <author>Chen</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>32</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Chen, R. T. Q., Behrmann, J.,
Duvenaud, D. K., &amp; Jacobsen, J.-H. (2019). Residual flows for
invertible generative modeling. Advances in Neural Information
Processing Systems, 32.</unstructured_citation>
          </citation>
          <citation key="Chen2018a">
            <article_title>Neural Ordinary Differential
Equations</article_title>
            <author>Chen</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>31</volume>
            <cYear>2018</cYear>
            <unstructured_citation>Chen, R. T. Q., Rubanova, Y.,
Bettencourt, J., &amp; Duvenaud, D. (2018). Neural Ordinary Differential
Equations. Advances in Neural Information Processing Systems,
31.</unstructured_citation>
          </citation>
          <citation key="dillon2017">
            <article_title>TensorFlow Distributions</article_title>
            <author>Dillon</author>
            <journal_title>arXiv preprint
arXiv:1711.10604</journal_title>
            <doi>10.48550/arXiv.1711.10604</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Dillon, J. V., Langmore, I., Tran,
D., Brevdo, E., Vasudevan, S., Moore, D., Patton, B., Alemi, A.,
Hoffman, M., &amp; Saurous, R. A. (2017). TensorFlow Distributions.
arXiv Preprint arXiv:1711.10604.
https://doi.org/10.48550/arXiv.1711.10604</unstructured_citation>
          </citation>
          <citation key="deepmind2020jax">
            <article_title>The DeepMind JAX Ecosystem</article_title>
            <author>Babuschkin</author>
            <cYear>2020</cYear>
            <unstructured_citation>Babuschkin, I., Baumli, K., Bell, A.,
Bhupatiraju, S., Bruce, J., Buchlovsky, P., Budden, D., Cai, T., Clark,
A., Danihelka, I., Fantacci, C., Godwin, J., Jones, C., Hemsley, R.,
Hennigan, T., Hessel, M., Hou, S., Kapturowski, S., Keck, T., … Viola,
F. (2020). The DeepMind JAX Ecosystem.</unstructured_citation>
          </citation>
          <citation key="nflows">
            <article_title>nflows: Normalizing flows in
PyTorch</article_title>
            <author>Durkan</author>
            <journal_title>Zenodo</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Durkan, C., Bekasov, A., Murray, I.,
&amp; Papamakarios, G. (2020). nflows: Normalizing flows in PyTorch.
Zenodo. https://doi.org/10.5281/zenodo.4296287</unstructured_citation>
          </citation>
          <citation key="freia">
            <article_title>Framework for Easily Invertible Architectures
(FrEIA)</article_title>
            <author>Ardizzone</author>
            <unstructured_citation>Ardizzone, L., Bungert, T., Draxler,
F., Köthe, U., Kruse, J., Schmier, R., &amp; Sorrenson, P. (2018-2022).
Framework for Easily Invertible Architectures (FrEIA).
https://github.com/vislearn/FrEIA</unstructured_citation>
          </citation>
          <citation key="wu2020stochasticNF">
            <article_title>Stochastic normalizing flows</article_title>
            <author>Wu</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>33</volume>
            <cYear>2020</cYear>
            <unstructured_citation>Wu, H., Köhler, J., &amp; Noe, F.
(2020). Stochastic normalizing flows. Advances in Neural Information
Processing Systems, 33, 5933–5944.</unstructured_citation>
          </citation>
          <citation key="nielsen2020">
            <article_title>SurVAE flows: Surjections to bridge the gap
between VAEs and flows</article_title>
            <author>Nielsen</author>
            <journal_title>Advances in Neural Information Processing
Systems 33</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Nielsen, D., Jaini, P., Hoogeboom,
E., Winther, O., &amp; Welling, M. (2020). SurVAE flows: Surjections to
bridge the gap between VAEs and flows. Advances in Neural Information
Processing Systems 33.</unstructured_citation>
          </citation>
          <citation key="rezende2020">
            <article_title>Normalizing flows on tori and
spheres</article_title>
            <author>Rezende</author>
            <journal_title>Proceedings of the 37th international
conference on machine learning</journal_title>
            <volume>119</volume>
            <cYear>2020</cYear>
            <unstructured_citation>Rezende, D. J., Papamakarios, G.,
Racanière, S., Albergo, M. S., Kanwar, G., Shanahan, P. E., &amp;
Cranmer, K. (2020). Normalizing flows on tori and spheres. Proceedings
of the 37th International Conference on Machine Learning, 119,
8083–8092.</unstructured_citation>
          </citation>
          <citation key="Midgley2023">
            <article_title>Flow Annealed Importance Sampling
Bootstrap</article_title>
            <author>Midgley</author>
            <journal_title>International Conference on Learning
Representations</journal_title>
            <cYear>2023</cYear>
            <unstructured_citation>Midgley, L. I., Stimper, V., Simm, G.
N. C., Schölkopf, B., &amp; Hernández-Lobato, J. M. (2023). Flow
Annealed Importance Sampling Bootstrap. International Conference on
Learning Representations.</unstructured_citation>
          </citation>
          <citation key="boltzgen">
            <article_title>Implementing Boltzmann generators with
normflows</article_title>
            <author>Stimper</author>
            <journal_title>Zenodo</journal_title>
            <cYear>2023</cYear>
            <unstructured_citation>Stimper, V., Campbell, A., &amp;
Hernández-Lobato, J. M. (2023). Implementing Boltzmann generators with
normflows. Zenodo.
https://doi.org/10.5281/zenodo.7565800</unstructured_citation>
          </citation>
          <citation key="campbell2021gradient">
            <article_title>A gradient based strategy for Hamiltonian
Monte Carlo hyperparameter optimization</article_title>
            <author>Campbell</author>
            <journal_title>Proceedings of the 38th international
conference on machine learning</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Campbell, A., Chen, W., Stimper, V.,
Hernandez-Lobato, J. M., &amp; Zhang, Y. (2021). A gradient based
strategy for Hamiltonian Monte Carlo hyperparameter optimization.
Proceedings of the 38th International Conference on Machine Learning,
1238–1248.</unstructured_citation>
          </citation>
          <citation key="stimper2021">
            <article_title>Resampling Base Distributions of Normalizing
Flows</article_title>
            <author>Stimper</author>
            <journal_title>Proceedings of the 25th international
conference on artificial intelligence and statistics</journal_title>
            <volume>151</volume>
            <cYear>2022</cYear>
            <unstructured_citation>Stimper, V., Schölkopf, B., &amp;
Hernández-Lobato, J. M. (2022). Resampling Base Distributions of
Normalizing Flows. Proceedings of the 25th International Conference on
Artificial Intelligence and Statistics, 151,
4915–4936.</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
