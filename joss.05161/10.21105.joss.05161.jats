<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5161</article-id>
<article-id pub-id-type="doi">10.21105/joss.05161</article-id>
<title-group>
<article-title>RxInfer: A Julia package for reactive real-time Bayesian
inference</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9655-7986</contrib-id>
<name>
<surname>Bagaev</surname>
<given-names>Dmitry</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0515-0465</contrib-id>
<name>
<surname>Podusenko</surname>
<given-names>Albert</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0839-174X</contrib-id>
<name>
<surname>de Vries</surname>
<given-names>Bert</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Technical University of Eindhoven</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-12-09">
<day>9</day>
<month>12</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>84</issue>
<fpage>5161</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>statistics</kwd>
<kwd>Bayesian inference</kwd>
<kwd>variational optimization</kwd>
<kwd>message passing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Bayesian inference realizes optimal information processing through
  a full commitment to reasoning by probability theory. The Bayesian
  framework is positioned at the core of modern AI technology for
  applications such as speech and image recognition and generation,
  medical analysis, robot navigation, and more. The framework describes
  how a rational agent should update its beliefs when new information is
  revealed by the agent’s environment. Unfortunately, perfect Bayesian
  reasoning is generally intractable, since calculations of (often) very
  high-dimensional integrals are required for many models of interest.
  As a result, a number of numerical algorithms for approximating
  Bayesian inference have been developed and implemented in
  probabilistic programming packages. Successful methods include the
  Laplace approximation
  (<xref alt="Gelman et al., 2015" rid="ref-gelman_bayesian_2015" ref-type="bibr">Gelman
  et al., 2015</xref>), variants of Monte Carlo (MC) sampling
  (<xref alt="Salimans et al., n.d." rid="ref-salimans_markov_nodate" ref-type="bibr">Salimans
  et al., n.d.</xref>), Variational Inference (VI)
  (<xref alt="Blei et al., 2017" rid="ref-blei_variational_2017" ref-type="bibr">Blei
  et al., 2017</xref>), Automatic-Differentiation Variational Inference
  (ADVI)
  (<xref alt="Kucukelbir et al., 2017" rid="ref-kucukelbir_automatic_2017" ref-type="bibr">Kucukelbir
  et al., 2017</xref>), and Black-Box Variational Inference (BBVI)
  (<xref alt="Bamler &amp; Mandt, 2017" rid="ref-bamler_structured_2017" ref-type="bibr">Bamler
  &amp; Mandt, 2017</xref>).</p>
  <p>We present <bold>RxInfer.jl</bold>, which is a Julia
  (<xref alt="Jeff Bezanson et al., 2012" rid="ref-bezanson_julia_2012" ref-type="bibr">Jeff
  Bezanson et al., 2012</xref>;
  <xref alt="J. Bezanson et al., 2017" rid="ref-bezanson_julia_2017" ref-type="bibr">J.
  Bezanson et al., 2017</xref>) package for real-time variational
  Bayesian inference based on reactive message passing in a factor graph
  representation of the model under study
  (<xref alt="Bagaev &amp; Vries, 2021" rid="ref-bagaev_reactive_2021" ref-type="bibr">Bagaev
  &amp; Vries, 2021</xref>). <bold>RxInfer.jl</bold> provides access to
  a powerful model specification language that translates a textual
  description of a probabilistic model into a corresponding factor graph
  representation. In addition, <bold>RxInfer.jl</bold> supports hybrid
  variational inference processes, where different Bayesian inference
  methods can be combined in different parts of the model, resulting in
  a straightforward mechanism to trade off accuracy for computational
  speed. The underlying implementation relies on a reactive programming
  paradigm and supports by design the processing of infinite
  asynchronous data streams. In the proposed framework, the inference
  engine <italic>reacts</italic> to new data and automatically updates
  relevant posteriors.</p>
  <p>Over the past few years, the inference methods in this package have
  been tested on many advanced probabilistic models, resulting in
  several publications in highly ranked journals such as Entropy
  (<xref alt="Podusenko, Kouw, et al., 2021" rid="ref-podusenko_message_2021-1" ref-type="bibr">Podusenko,
  Kouw, et al., 2021</xref>;
  <xref alt="Şenöz et al., 2021" rid="ref-senoz_variational_2021" ref-type="bibr">Şenöz
  et al., 2021</xref>), Frontiers
  (<xref alt="Podusenko, Erp, Koudahl, et al., 2021" rid="ref-podusenko_aida_2021" ref-type="bibr">Podusenko,
  Erp, Koudahl, et al., 2021</xref>), and conferences such as MLSP-2021
  (<xref alt="Podusenko, Erp, Bagaev, et al., 2021" rid="ref-podusenko_message_2021" ref-type="bibr">Podusenko,
  Erp, Bagaev, et al., 2021</xref>), EUSIPCO-2022
  (<xref alt="Erp &amp; Vries, 2022" rid="ref-van_erp_hybrid_2022" ref-type="bibr">Erp
  &amp; Vries, 2022</xref>;
  <xref alt="Podusenko et al., 2022" rid="ref-podusenko_message_2022" ref-type="bibr">Podusenko
  et al., 2022</xref>) and SiPS
  (<xref alt="Nguyen et al., 2022" rid="ref-nguyen_efficient_2022" ref-type="bibr">Nguyen
  et al., 2022</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Many important AI applications, including audio processing,
  self-driving vehicles, weather forecasting, and extended-reality video
  processing, and others require continually solving an inference task
  in sophisticated probabilistic models with a large number of latent
  variables. Often, the inference task in these applications must be
  performed continually and in real time in response to new
  observations. Popular MC-based inference methods, such as the No
  U-Turn Sampler (NUTS)
  (<xref alt="Hoffman &amp; Gelman, 2011" rid="ref-hoffman_nuts" ref-type="bibr">Hoffman
  &amp; Gelman, 2011</xref>) or Hamiltonian Monte Carlo (HMC) sampling
  (<xref alt="Brooks et al., 2011" rid="ref-hmc_ref_2011" ref-type="bibr">Brooks
  et al., 2011</xref>), rely on computationally heavy sampling
  procedures that do not scale well to probabilistic models with
  thousands of latent states. Therefore, MC-based inference is
  practically not suitable for real-time applications. While the
  alternative variational inference method (VI) promises to scale better
  to large models than sampling-based inference, VI requires the
  derivation of gradients of the “variational Free Energy” cost
  function. For large models, manual derivation of these gradients might
  not be feasible, while automated “black-box” gradient methods do not
  scale either because they are not capable of taking advantage of
  sparsity or conjugate pairs in the model. Therefore, while Bayesian
  inference is known as the optimal data processing framework, in
  practice, real-time AI applications rely on much simpler, often ad
  hoc, data processing algorithms.</p>
</sec>
<sec id="solution-proposal">
  <title>Solution proposal</title>
  <p>We present <bold>RxInfer.jl</bold>, a package for processing
  infinite data streams by real-time Bayesian inference in large
  probabilistic models. <bold>RxInfer.jl</bold> implements variational
  Bayesian inference as a variational Constrained Bethe Free Energy
  (CBFE) functional optimization process
  (<xref alt="Şenöz et al., 2021" rid="ref-senoz_variational_2021" ref-type="bibr">Şenöz
  et al., 2021</xref>). The underlying inference engine derives its
  speed from taking advantage of both statistical independencies and
  conjugate pairings of variables in the factor graph. Inference
  proceeds continually by an automated reactive message passing process
  on the graph, where each message carves away a bit of the variational
  Free Energy cost function. Very often, closed-form message computation
  rules are available for specific nodes and node combinations, leading
  to much faster inference than sampling-based inference methods, and
  additionally enables hierarchical composition of different models
  without need for extra derivations. These properties distinguish
  <bold>RxInfer.jl</bold> from other popular Bayesian inference
  libraries in Julia, such as <bold>Turing.jl</bold>
  (<xref alt="Ge et al., 2018" rid="ref-ge2018t" ref-type="bibr">Ge et
  al., 2018</xref>), <bold>Stan.jl</bold>
  (<xref alt="Stan Development Team, 2022" rid="ref-standevteam" ref-type="bibr">Stan
  Development Team, 2022</xref>;
  <xref alt="Stan.jl Development Team, 2022" rid="ref-standevteam_jl" ref-type="bibr">Stan.jl
  Development Team, 2022</xref>), and others, which are not designed to
  run inference continually in response to new observations in
  real-time.</p>
</sec>
<sec id="overview-of-functionality">
  <title>Overview of functionality</title>
  <p><bold>RxInfer.jl</bold> is an open source package, available at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/biaslab/RxInfer.jl">https://github.com/biaslab/RxInfer.jl</ext-link>,
  and enjoys the following features:</p>
  <list list-type="bullet">
    <list-item>
      <p>A user-friendly specification of probabilistic models. Through
      Julia macros, <bold>RxInfer.jl</bold> is capable of automatically
      transforming a textual description of a probabilistic model to a
      factor graph representation of that model.</p>
    </list-item>
    <list-item>
      <p>A hybrid inference engine. The inference engine supports a
      variety of well-known message passing-based inference methods such
      as belief propagation, structured and mean-field variational
      message passing, expectation propagation, expectation
      maximization, and conjugate-computation variational inference
      (CVI)
      (<xref alt="Akbayrak et al., 2022" rid="ref-AKBAYRAK2022235" ref-type="bibr">Akbayrak
      et al., 2022</xref>).</p>
    </list-item>
    <list-item>
      <p>A customized trade-off between accuracy and speed. For each
      location (node and edge) in the graph, <bold>RxInfer.jl</bold>
      allows a custom specification of the inference constraints on the
      variational family of distributions in the CBFE optimization
      procedure. This enables the use of different Bayesian inference
      methods at different locations of the graph, leading to an
      optimized trade-off between accuracy and speed.</p>
    </list-item>
    <list-item>
      <p>Support for real-time processing of infinite data streams.
      <bold>RxInfer.jl</bold> is based on a reactive programming
      paradigm that enables asynchronous data processing as soon as data
      arrives.</p>
    </list-item>
    <list-item>
      <p>Support for large static data sets. The package is not limited
      to real-time processing of data streams and also scales well to
      batch processing of large data sets and large probabilistic models
      that can include hundreds of thousands of latent variables
      (<xref alt="Bagaev, 2021" rid="ref-bagaev_dmitry_reactivempjl_2021" ref-type="bibr">Bagaev,
      2021</xref>).</p>
    </list-item>
    <list-item>
      <p><bold>RxInfer.jl</bold> is extensible. The public API defines a
      straightforward and user-friendly way to extend the built-in
      functionality with custom nodes and message update rules.</p>
    </list-item>
    <list-item>
      <p>A large collection of precomputed analytical inference
      solutions. Current built-in functionality includes fast inference
      solutions for linear Gaussian dynamical systems, autoregressive
      models, hierarchical models, discrete-valued models, mixture
      models, invertible neural networks
      (<xref alt="Erp &amp; Vries, 2022" rid="ref-van_erp_hybrid_2022" ref-type="bibr">Erp
      &amp; Vries, 2022</xref>), arbitrary nonlinear state transition
      functions, and conjugate pair primitives.</p>
    </list-item>
    <list-item>
      <p>The inference procedure is auto-differentiable with external
      packages, such as <bold>ForwardDiff.jl</bold>
      (<xref alt="Revels et al., 2016" rid="ref-revels_forward-mode_2016" ref-type="bibr">Revels
      et al., 2016</xref>) or <bold>ReverseDiff.jl</bold>.</p>
    </list-item>
    <list-item>
      <p>The inference engine supports different types of floating-point
      numbers, such as <monospace>Float32</monospace>,
      <monospace>Float64</monospace>, and
      <monospace>BigFloat</monospace>.</p>
    </list-item>
  </list>
  <p>A large collection of examples is available at
  <ext-link ext-link-type="uri" xlink:href="https://biaslab.github.io/RxInfer.jl/stable/examples/overview/">https://biaslab.github.io/RxInfer.jl/stable/examples/overview/</ext-link>.</p>
</sec>
<sec id="example-usage">
  <title>Example usage</title>
  <p>In this section, we show a small example based on Example 3.7 in
  Sarkka
  (<xref alt="Särkkä, 2013" rid="ref-sarkka_bayesian_2013" ref-type="bibr">Särkkä,
  2013</xref>), where the goal is to track in real-time the state (angle
  and velocity) of a simple pendulum system. The differential equations
  for a simple pendulum can be written as a special case of a
  continuous-time nonlinear dynamic system where the hidden state
  <inline-formula><alternatives>
  <tex-math><![CDATA[x(t)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is a two-dimensional vector <inline-formula><alternatives>
  <tex-math><![CDATA[\begin{bmatrix}x^{(1)} \\ x^{(2)}\end{bmatrix}\equiv\begin{bmatrix}\alpha \\ v\end{bmatrix}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>α</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>v</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  with <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[v]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>v</mml:mi></mml:math></alternatives></inline-formula>
  being the angle and velocity, respectively, and the state transition
  function <inline-formula><alternatives>
  <tex-math><![CDATA[f(x) = \begin{bmatrix}x^{(1)} + x^{(2)} \Delta t \\ x^{(2)} - g \cdot \sin(x^{(1)}) \Delta t\end{bmatrix}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mo>⋅</mml:mo><mml:mo>sin</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  For more detailed derivations we refer interested reader to Särkkä
  (<xref alt="2013" rid="ref-sarkka_bayesian_2013" ref-type="bibr">2013</xref>).</p>
  <p>We use the <bold>RxInfer</bold>’s <monospace>@model</monospace>
  macro to specify the probabilistic model. We use the
  <monospace>@meta</monospace> macro to specify an approximation method
  for the nonlinearity in the model, the
  <monospace>@constraints</monospace> macro to define constraints for
  the variational distributions in the Bethe Free Energy optimization
  procedure, and the <monospace>@autoupdates</monospace> macro to
  specify how to update priors about the current state of the system.
  Finally, we use the <monospace>rxinference</monospace> function to
  execute the inference process, see
  <xref alt="[fig:example]" rid="figU003Aexample">[fig:example]</xref>.
  The inference process runs in real time and takes 162 microseconds on
  average per observation on a single CPU of a regular office laptop
  (MacBook Pro 2018, <inline-formula><alternatives>
  <tex-math><![CDATA[2.6]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2.6</mml:mn></mml:math></alternatives></inline-formula>
  GHz Intel Core i7).</p>
  <code language="julia"># `g` is the gravitational constant
f(x) = [x[1] + x[2] * Δt, x[2] - g * sin(x[1]) * Δt]

# We use the `@model` macro to define the probabilistic model 
@model function pendulum()
    # Define reactive inputs for the `prior` 
    # of the current angle state
    prior_mean = datavar(Vector{Float64})
    prior_cov  = datavar(Matrix{Float64})

    previous_state ~ MvNormal(mean = prior_mean, cov = prior_cov)
    # Use `f` as state transition function
    state ~ f(previous_state)

    # Assign a prior for the noise component
    noise_shape = datavar(Float64)
    noise_scale = datavar(Float64)
    noise ~ Gamma(shape = noise_shape, scale = noise_scale)

    # Define reactive input for the `observation`
    observation = datavar(Float64)
    # We observe only the first component of the state 
    observation ~ Normal(mean = dot([1.0, 0.0], state), precision = noise)
end</code>
  <code language="julia">@constraints function pendulum_constraint()
    # Assume the `state` and the `noise` are independent
    q(state, noise) = q(state)q(noise)
end</code>
  <code language="julia">@meta function pendulum_meta()
    # Use the `Linearization` approximation method 
    # around the nonlinear function `f`
    f() -&gt; Linearization()
end</code>
  <code language="julia">function pendulum_experiment(observations)

    # The `@autoupdates` structure defines how to update 
    # the priors for the next observation
    autoupdates = @autoupdates begin
        prior_mean  = mean(q(state))
        prior_cov   = cov(q(state))
        noise_shape = shape(q(noise))
        noise_scale = scale(q(noise))
    end

    results = rxinference(
        model = pendulum(),
        constraints = pendulum_constraint(),
        meta = pendulum_meta(),
        autoupdates = autoupdates,
        data = (observation = observations,),
        initmarginals = (
            # We assume a relatively good prior for the very first state
            state = MvNormalMeanPrecision([0.5, 0.0], [100.0 0.0; 0.0 100.0]),
            # And we assign a vague prior for the noise component
            noise = Gamma(1.0, 100.0)
        ),
        # We indicate that we want to keep a history of estimated 
        # states and the noise component
        historyvars = (state = KeepLast(), noise = KeepLast()),
        keephistory = length(observations),
        # We perform 5 VMP iterations on each observation
        iterations = 5,
        # We start the inference procedure automatically
        autostart = true
    )

    return results
end</code>
  <fig>
    <caption><p>The inference results for the pendulum example. X-axis
    represents time <inline-formula><alternatives>
    <tex-math><![CDATA[t]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>
    (in seconds). Y-axis represents the current angle of the pendulum
    (in radians) at time <inline-formula><alternatives>
    <tex-math><![CDATA[t]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>.
    Real (unobserved) signal is shown in blue line. Observations are
    shown as orange dots. The inference results are shown as green line
    with area, which represents posterior uncertainty (one standard
    deviation). The inference process runs in real time and takes 162
    microseconds on average per observation on a single CPU of a regular
    office laptop (MacBook Pro 2018, <inline-formula><alternatives>
    <tex-math><![CDATA[2.6]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2.6</mml:mn></mml:math></alternatives></inline-formula>
    GHz Intel Core i7).
    <styled-content id="figU003Aexample"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="media/inference.pdf" />
  </fig>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>The authors gratefully acknowledge contributions and support from
  colleagues in the BIASlab in the Department of Electrical Engineering
  at the University of Eindhoven of Technology.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-gelman_bayesian_2015">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Carlin</surname><given-names>John B.</given-names></name>
        <name><surname>Stern</surname><given-names>Hal S.</given-names></name>
        <name><surname>Dunson</surname><given-names>David B.</given-names></name>
        <name><surname>Vehtari</surname><given-names>Aki</given-names></name>
        <name><surname>Rubin</surname><given-names>Donald B.</given-names></name>
      </person-group>
      <source>Bayesian Data Analysis</source>
      <publisher-name>Chapman; Hall/CRC</publisher-name>
      <publisher-loc>New York</publisher-loc>
      <year iso-8601-date="2015-07">2015</year><month>07</month>
      <edition>3</edition>
      <isbn>978-0-429-11307-9</isbn>
      <pub-id pub-id-type="doi">10.1201/b16018</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-salimans_markov_nodate">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Salimans</surname><given-names>Tim</given-names></name>
        <name><surname>Kingma</surname><given-names>Diederik P</given-names></name>
        <name><surname>Welling</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Markov Chain Monte Carlo and Variational Inference:Bridging the Gap</article-title>
      <source>Bridging the Gap</source>
      <fpage>9</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-blei_variational_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blei</surname><given-names>David M.</given-names></name>
        <name><surname>Kucukelbir</surname><given-names>Alp</given-names></name>
        <name><surname>McAuliffe</surname><given-names>Jon D.</given-names></name>
      </person-group>
      <article-title>Variational Inference: A Review for Statisticians</article-title>
      <source>Journal of the American Statistical Association</source>
      <year iso-8601-date="2017-04">2017</year><month>04</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-06-22">2018</year><month>06</month><day>22</day></date-in-citation>
      <volume>112</volume>
      <issue>518</issue>
      <issn>0162-1459</issn>
      <uri>https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773</uri>
      <pub-id pub-id-type="doi">10.1080/01621459.2017.1285773</pub-id>
      <fpage>859</fpage>
      <lpage>877</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kucukelbir_automatic_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kucukelbir</surname><given-names>Alp</given-names></name>
        <name><surname>Tran</surname><given-names>Dustin</given-names></name>
        <name><surname>Ranganath</surname><given-names>Rajesh</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Blei</surname><given-names>David M.</given-names></name>
      </person-group>
      <article-title>Automatic Differentiation Variational Inference</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2017">2017</year>
      <volume>18</volume>
      <issue>1</issue>
      <uri>http://www.jmlr.org/papers/volume18/16-107/16-107.pdf</uri>
      <fpage>430</fpage>
      <lpage>474</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bamler_structured_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bamler</surname><given-names>Robert</given-names></name>
        <name><surname>Mandt</surname><given-names>Stephan</given-names></name>
      </person-group>
      <article-title>Structured Black Box Variational Inference for Latent Time Series Models</article-title>
      <source>arXiv:1707.01069 [cs, stat]</source>
      <year iso-8601-date="2017-07">2017</year><month>07</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-11-29">2018</year><month>11</month><day>29</day></date-in-citation>
      <uri>http://arxiv.org/abs/1707.01069</uri>
    </element-citation>
  </ref>
  <ref id="ref-bezanson_julia_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>J.</given-names></name>
        <name><surname>Edelman</surname><given-names>A.</given-names></name>
        <name><surname>Karpinski</surname><given-names>S.</given-names></name>
        <name><surname>Shah</surname><given-names>V.</given-names></name>
      </person-group>
      <article-title>Julia: A Fresh Approach to Numerical Computing</article-title>
      <source>SIAM Review</source>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-04-10">2018</year><month>04</month><day>10</day></date-in-citation>
      <volume>59</volume>
      <issue>1</issue>
      <issn>0036-1445</issn>
      <uri>https://epubs.siam.org/doi/abs/10.1137/141000671</uri>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bezanson_julia_2012">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
      </person-group>
      <article-title>Julia: A Fast Dynamic Language for Technical Computing</article-title>
      <source>arXiv:1209.5145 [cs]</source>
      <year iso-8601-date="2012-09">2012</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-11-27">2018</year><month>11</month><day>27</day></date-in-citation>
      <uri>http://arxiv.org/abs/1209.5145</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1209.5145</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bagaev_reactive_2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bagaev</surname><given-names>Dmitry</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Reactive Message Passing for Scalable Bayesian Inference</article-title>
      <source>arXiv:2112.13251 [cs]</source>
      <year iso-8601-date="2021-12">2021</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-01-04">2022</year><month>01</month><day>04</day></date-in-citation>
      <uri>http://arxiv.org/abs/2112.13251</uri>
    </element-citation>
  </ref>
  <ref id="ref-podusenko_message_2021-1">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Podusenko</surname><given-names>Albert</given-names></name>
        <name><surname>Kouw</surname><given-names>Wouter M.</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Message Passing-Based Inference for Time-Varying Autoregressive Models</article-title>
      <source>Entropy</source>
      <year iso-8601-date="2021-06">2021</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2021-07-07">2021</year><month>07</month><day>07</day></date-in-citation>
      <volume>23</volume>
      <issue>6</issue>
      <uri>https://www.mdpi.com/1099-4300/23/6/683</uri>
      <pub-id pub-id-type="doi">10.3390/e23060683</pub-id>
      <fpage>683</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-senoz_variational_2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Şenöz</surname><given-names>İsmail</given-names></name>
        <name><surname>Laar</surname><given-names>Thijs van de</given-names></name>
        <name><surname>Bagaev</surname><given-names>Dmitry</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Variational Message Passing and Local Constraint Manipulation in Factor Graphs</article-title>
      <source>Entropy</source>
      <year iso-8601-date="2021-07">2021</year><month>07</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-03-15">2022</year><month>03</month><day>15</day></date-in-citation>
      <volume>23</volume>
      <issue>7</issue>
      <issn>1099-4300</issn>
      <uri>https://www.mdpi.com/1099-4300/23/7/807</uri>
      <pub-id pub-id-type="doi">10.3390/e23070807</pub-id>
      <fpage>807</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-podusenko_aida_2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Podusenko</surname><given-names>Albert</given-names></name>
        <name><surname>Erp</surname><given-names>Bart van</given-names></name>
        <name><surname>Koudahl</surname><given-names>Magnus</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>AIDA: An Active Inference-based Design Agent for Audio Processing Algorithms</article-title>
      <source>arXiv:2112.13366 [cs, eess, stat]</source>
      <year iso-8601-date="2021-12">2021</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-01-04">2022</year><month>01</month><day>04</day></date-in-citation>
      <uri>http://arxiv.org/abs/2112.13366</uri>
      <pub-id pub-id-type="doi">10.3389/frsip.2022.842477</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-podusenko_message_2021">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Podusenko</surname><given-names>Albert</given-names></name>
        <name><surname>Erp</surname><given-names>Bart van</given-names></name>
        <name><surname>Bagaev</surname><given-names>Dmitry</given-names></name>
        <string-name>Şenöz, İsmail</string-name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Message Passing-Based Inference in the Gamma Mixture Model</article-title>
      <source>2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)</source>
      <publisher-name>IEEE</publisher-name>
      <publisher-loc>Gold Coast, Australia</publisher-loc>
      <year iso-8601-date="2021-10">2021</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2021-11-29">2021</year><month>11</month><day>29</day></date-in-citation>
      <isbn>978-1-72816-338-3</isbn>
      <uri>https://ieeexplore.ieee.org/document/9596329/</uri>
      <pub-id pub-id-type="doi">10.1109/MLSP52302.2021.9596329</pub-id>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-podusenko_message_2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Podusenko</surname><given-names>Albert</given-names></name>
        <name><surname>Erp</surname><given-names>Bart van</given-names></name>
        <name><surname>Bagaev</surname><given-names>Dmitry</given-names></name>
        <name><surname>şenöz</surname><given-names>Ïsmail</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Message Passing-based Inference in Switching Autoregressive Models</article-title>
      <source>2022 30th European Signal Processing Conference (EUSIPCO)</source>
      <publisher-loc>Belgrade, Serbia</publisher-loc>
      <year iso-8601-date="2022-08">2022</year><month>08</month>
      <pub-id pub-id-type="doi">10.23919/EUSIPCO55093.2022.9909828</pub-id>
      <fpage>1497</fpage>
      <lpage>1501</lpage>
    </element-citation>
  </ref>
  <ref id="ref-van_erp_hybrid_2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Erp</surname><given-names>Bart van</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Hybrid Inference with Invertible Neural Networks in Factor Graphs</article-title>
      <source>2022 30th European Signal Processing Conference (EUSIPCO)</source>
      <publisher-name>IEEE</publisher-name>
      <publisher-loc>Belgrade, Serbia</publisher-loc>
      <year iso-8601-date="2022-08">2022</year><month>08</month>
      <pub-id pub-id-type="doi">10.23919/EUSIPCO55093.2022.9909873</pub-id>
      <fpage>1397</fpage>
      <lpage>1401</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nguyen_efficient_2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Nguyen</surname><given-names>Hoang M H</given-names></name>
        <name><surname>Erp</surname><given-names>Bart van</given-names></name>
        <name><surname>Senoz</surname><given-names>Ismail</given-names></name>
        <name><surname>Vries</surname><given-names>Bert de</given-names></name>
      </person-group>
      <article-title>Efficient Model Evidence Computation in Tree-structured Factor Graphs</article-title>
      <source>2022 IEEE Workshop on Signal Processing Systems (SiPS)</source>
      <publisher-loc>Rennes, France</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1109/SiPS55645.2022.9919250</pub-id>
      <fpage>6</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-bagaev_dmitry_reactivempjl_2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Bagaev</surname><given-names>Dmitry</given-names></name>
      </person-group>
      <article-title>ReactiveMP.jl: A Julia package for automatic Bayesian inference on a factor graph with reactive message passing.</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2021-01">2021</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-04-05">2022</year><month>04</month><day>05</day></date-in-citation>
      <uri>https://zenodo.org/record/6365000</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.6365000</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-sarkka_bayesian_2013">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Särkkä</surname><given-names>Simo</given-names></name>
      </person-group>
      <source>Bayesian Filtering and Smoothing</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <publisher-loc>London ; New York</publisher-loc>
      <year iso-8601-date="2013-10">2013</year><month>10</month>
      <isbn>978-0-415-55809-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-AKBAYRAK2022235">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Akbayrak</surname><given-names>Semih</given-names></name>
        <name><surname>Şenöz</surname><given-names>İsmail</given-names></name>
        <name><surname>Sarı</surname><given-names>Alp</given-names></name>
        <name><surname>de Vries</surname><given-names>Bert</given-names></name>
      </person-group>
      <article-title>Probabilistic programming with stochastic variational message passing</article-title>
      <source>International Journal of Approximate Reasoning</source>
      <year iso-8601-date="2022">2022</year>
      <volume>148</volume>
      <issn>0888-613X</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0888613X22000950</uri>
      <pub-id pub-id-type="doi">10.1016/j.ijar.2022.06.006</pub-id>
      <fpage>235</fpage>
      <lpage>252</lpage>
    </element-citation>
  </ref>
  <ref id="ref-revels_forward-mode_2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Revels</surname><given-names>Jarrett</given-names></name>
        <name><surname>Lubin</surname><given-names>Miles</given-names></name>
        <name><surname>Papamarkou</surname><given-names>Theodore</given-names></name>
      </person-group>
      <article-title>Forward-Mode Automatic Differentiation in Julia</article-title>
      <source>arXiv:1607.07892 [cs]</source>
      <year iso-8601-date="2016-07">2016</year><month>07</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-07-22">2018</year><month>07</month><day>22</day></date-in-citation>
      <uri>http://arxiv.org/abs/1607.07892</uri>
    </element-citation>
  </ref>
  <ref id="ref-hoffman_nuts">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hoffman</surname><given-names>Matthew D.</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <uri>https://arxiv.org/abs/1111.4246</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.1111.4246</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hmc_ref_2011">
    <element-citation publication-type="book">
      <source>Handbook of markov chain monte carlo</source>
      <person-group person-group-type="editor">
        <name><surname>Brooks</surname><given-names>Steve</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Jones</surname><given-names>Galin</given-names></name>
        <name><surname>Meng</surname><given-names>Xiao-Li</given-names></name>
      </person-group>
      <publisher-name>Chapman; Hall/CRC</publisher-name>
      <year iso-8601-date="2011-05">2011</year><month>05</month>
      <uri>https://doi.org/10.1201%2Fb10905</uri>
      <pub-id pub-id-type="doi">10.1201/b10905</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ge2018t">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ge</surname><given-names>Hong</given-names></name>
        <name><surname>Xu</surname><given-names>Kai</given-names></name>
        <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
      </person-group>
      <article-title>Turing: A language for flexible probabilistic inference</article-title>
      <source>International conference on artificial intelligence and statistics, AISTATS 2018, 9-11 april 2018, playa blanca, lanzarote, canary islands, spain</source>
      <year iso-8601-date="2018">2018</year>
      <uri>http://proceedings.mlr.press/v84/ge18b.html</uri>
      <fpage>1682</fpage>
      <lpage>1690</lpage>
    </element-citation>
  </ref>
  <ref id="ref-standevteam">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <string-name>Stan Development Team</string-name>
      </person-group>
      <article-title>Stan modeling language users guide and reference manual, version 2.31</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://mc-stan.org</uri>
    </element-citation>
  </ref>
  <ref id="ref-standevteam_jl">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <string-name>Stan.jl Development Team</string-name>
      </person-group>
      <article-title>Stan modeling language in julia, version 10.3.2</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/StanJulia/Stan.jl</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
