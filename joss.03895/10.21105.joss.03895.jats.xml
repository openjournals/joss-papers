<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3895</article-id>
<article-id pub-id-type="doi">10.21105/joss.03895</article-id>
<title-group>
<article-title>VeridicalFlow: a Python package for building trustworthy
data science pipelines with PCS</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">0000-0003-3297-681X</contrib-id>
<name>
<surname>Duncan</surname>
<given-names>James</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Kapoor</surname>
<given-names>Rush</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Agarwal</surname>
<given-names>Abhineet</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">0000-0003-0318-2340</contrib-id>
<name>
<surname>Singh</surname>
<given-names>Chandan</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Bin</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Graduate Group in Biostatistics, University of California,
Berkeley</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>EECS Department, University of California,
Berkeley</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Physics Department, University of California,
Berkeley</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Statistics Department, University of California,
Berkeley</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-10-21">
<day>21</day>
<month>10</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>69</issue>
<fpage>3895</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>python</kwd>
<kwd>stability</kwd>
<kwd>reproducibility</kwd>
<kwd>data science</kwd>
<kwd>caching</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>VeridicalFlow</monospace> is a Python package that
  simplifies building reproducible and trustworthy data science
  pipelines using the PCS (predictability-computability-stability)
  framework
  (<xref alt="Yu &amp; Kumbier, 2020" rid="ref-yu2020veridical" ref-type="bibr">Yu
  &amp; Kumbier, 2020</xref>). It provides users with a simple interface
  for stability analysis, i.e., checking the robustness of results from
  a data science pipeline to various judgement calls made during
  modeling. This ensures that arbitrary judgement calls made by data
  practitioners (e.g., specifying a default imputation strategy) do not
  dramatically alter the final conclusions made in a modeling pipeline.
  In addition to wrappers facilitating stability analysis,
  <monospace>VeridicalFlow</monospace> also automates many cumbersome
  coding aspects of Python pipelines, including experiment tracking and
  saving, parallelization, and caching, all through integrations with
  existing Python packages. Overall, the package helps to code using the
  PCS framework by screening models for predictive performance, helping
  automate computation, and facilitating stability analysis.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Predictability, computability, and stability are central concerns
  in modern statistical/machine learning practice, as they are required
  to help vet that findings reflect reality, can be reasonably computed,
  and are robust to the many judgment calls during the data science life
  cycle that often go unchecked
  (<xref alt="Yu &amp; Kumbier, 2020" rid="ref-yu2020veridical" ref-type="bibr">Yu
  &amp; Kumbier, 2020</xref>).</p>
  <p>The package focuses on stability but also provides wrappers to help
  support and improve predictability and computability. Stability is a
  common-sense principle related to notions of scientific
  reproducibility
  (<xref alt="Ivie &amp; Thain, 2018" rid="ref-ivie2018reproducibility" ref-type="bibr">Ivie
  &amp; Thain, 2018</xref>), sample variability, robust statistics,
  sensitivity analysis
  (<xref alt="Saltelli, 2002" rid="ref-saltelli2002sensitivity" ref-type="bibr">Saltelli,
  2002</xref>), and stability in numerical analysis and control theory.
  Moreover, stability serves as a prerequisite for understanding which
  parts of a model will generalize and can be interpreted
  (<xref alt="Murdoch et al., 2019" rid="ref-murdoch2019definitions" ref-type="bibr">Murdoch
  et al., 2019</xref>).</p>
  <p>Importantly, current software packages offer very little support to
  facilitate stability analyses. <monospace>VeridicalFlow</monospace>
  helps fill this gap by making stability analysis simple, reproducible,
  and computationally efficient. This enables a practitioner to
  represent a pipeline with many different perturbations in a
  simple-to-code way while using prediction analysis as a reality check
  to screen out poor models.</p>
</sec>
<sec id="features">
  <title>Features</title>
  <p>Using <monospace>VeridicalFlow</monospace>’s simple wrappers easily
  enables many best practices for data science and makes writing
  powerful pipelines straightforward (see <bold>Table 1</bold>).</p>
  <table-wrap>
    <caption>
      <p>Features overview</p>
    </caption>
    <table>
      <colgroup>
        <col width="38%" />
        <col width="38%" />
        <col width="25%" />
      </colgroup>
      <thead>
        <tr>
          <th>Stability</th>
          <th>Computability</th>
          <th>Reproducibility</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Replace a single function (e.g., preprocessing) with a set
          of functions representing different judgment calls and easily
          assess the stability of downstream results</td>
          <td>Automatic parallelization and caching throughout the
          pipeline</td>
          <td>Automatic experiment tracking and saving</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>The main features of <monospace>VeridicalFlow</monospace> center
  around stability analysis, a method for evaluating the constancy of
  some target quantity relative to a set of reasonable or realistic
  perturbations. The central concept is the <monospace>Vset</monospace>,
  short for “veridical set”, which replaces a given static pipeline step
  with a set of functions subject to different pipeline perturbations
  that are documented and argued for via PCS documentation
  (<xref alt="Yu &amp; Kumbier, 2020" rid="ref-yu2020veridical" ref-type="bibr">Yu
  &amp; Kumbier, 2020</xref>). Then, a set of useful analysis functions
  and computations enable simple assessment of the pipeline’s stability
  to these perturbations on top of predictive screening for reality
  checks to filter unstable pipeline paths from further analysis.</p>
  <sec id="a-stability-analysis-example">
    <title>A stability analysis example</title>
    <sec id="define-stability-target">
      <title>1. Define stability target</title>
      <p>In the example below, we will probe the stability of the
      permutation feature importance metric for random forest relative
      to data resampling, data preprocessing, and model hyperparameter
      perturbations. Below, we create a <monospace>Vset</monospace> that
      applies three custom data preprocessing functions and another that
      calculates the permutation importance metric via the function
      <monospace>sklearn.inspection.permutation_importance</monospace>.</p>
      <code language="python">from vflow import Vset, build_vset
from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.inspection import permutation_importance

preproc_list = [SimpleImputer(strategy='mean'),
                SimpleImputer(strategy='median'),
                KNNImputer()]

# create a Vset which varies over preproc_list
# we use output_matching=True to ensure that preprocessing strategies
# match throughout the pipeline
preproc_set = Vset('preproc', preproc_list, ['mean', 'med', 'knn'],
                   output_matching=True)

# create the feature importance Vset using helper build_vset
feat_imp_set = build_vset('feat_imp', permutation_importance,
                          n_repeats=4)</code>
    </sec>
    <sec id="define-model-hyperparameter-perturbations">
      <title>2. Define model hyperparameter perturbations</title>
      <p>We can also specify modeling perturbations, both within a
      single class of models (hyperparameter perturbations) and across
      different classes. Here we’ll use the helper
      <monospace>build_vset</monospace> to create hyperparameter
      perturbations for random forest.</p>
      <code language="python">from sklearn.ensemble import RandomForestRegressor as RF

# hyperparameters to try
RF_params = {
    'n_estimators': [100, 300],
    'min_samples_split': [2, 10]
}

# we could instead pass a list of distinct models
# and corresponding param dicts
RF_set = build_vset('RF', RF, param_dict=RF_params)</code>
    </sec>
    <sec id="define-data-perturbations">
      <title>3. Define data perturbations</title>
      <p>For stability analysis, it is often useful to add data
      perturbations such as the bootstrap in order to assess stability
      over resampling variability in the data.</p>
      <code language="python">from sklearn.utils import resample

# create a Vset for bootstrapping from data 100 times
# we use lazy=True so that the data will not be resampled until needed
boot_set = build_vset('boot', resample, reps=100, lazy=True)</code>
    </sec>
    <sec id="fit-all-models-for-all-combinations-of-resampling-and-preprocessing">
      <title>4. Fit all models for all combinations of resampling and
      preprocessing</title>
      <p>Now we can load in our data and fit each of the four random
      forest models to the 300 combinations of resampled training data
      and preprocessing functions.</p>
      <code language="python">from vflow import init_args

# read in some data
X_train, y_train, X_val, y_val = ...

# wrap data for use with vflow
X_train, y_train, X_val, y_val = \
    init_args([X_train, y_train, X_val, y_val])

# bootstrap from training data by calling boot_fun
X_trains, y_trains = boot_set(X_train, y_train)

# apply three preprocessing methods to each bootstrap sample
X_trains = preproc_set.fit_transform(X_trains)

# fit the 4 RF models to each of the boot/preproc combos
RF_set.fit(X_trains, y_trains)</code>
      <p>We can examine the pipeline graph to see what happened so far
      using the utility function <monospace>build_graph</monospace>,
      which results in
      <xref alt="Figure 1" rid="figU003Agraph">Figure 1</xref>.</p>
      <code language="python">from vflow import build_graph
build_graph(RF_set)</code>
      <p><named-content content-type="image">The pipeline graph that
      results from fitting
      <monospace>RF_set</monospace>.<styled-content id="figU003Agraph"></styled-content></named-content></p>
    </sec>
    <sec id="calculate-feature-importances-and-perturbation-statistics">
      <title>5. Calculate feature importances and perturbation
      statistics</title>
      <p>Finally, we calculate the importance metric and examine its
      mean and standard deviation across bootstrap perturbations for
      each combination of data preprocessing and modeling
      hyperparameters. This allows us to assess the stability of the
      feature importances conditioned on different pipeline paths:</p>
      <code language="python">from vflow import dict_to_df, perturbation_stats

# calculate importances
importances = feat_imp_set(RF_set.out,
                           preproc_set.fit_transform(X_val), y_val)

# the helper dict_to_df converts the output to a pandas.DataFrame and
# using param_key='out' separates the importance dict into multiple cols
importances_df = dict_to_df(importances, param_key='out')

# get count, mean, and std of the permutation importances
perturbation_stats(importances_df, 'preproc', 'RF',
                   wrt='out-importances_mean',
                   prefix='X', split=True)</code>
      <p><named-content content-type="image">Perturbation statistics of
      permutation feature
      importances.<styled-content id="figU003Aperturb"></styled-content></named-content></p>
      <p>As seen in
      <xref alt="Figure 2" rid="figU003Aperturb">Figure 2</xref>, we can
      filter over the data preprocessing and modeling perturbations via
      the helper <monospace>filter_vset_by_metric</monospace> to select
      the top combinations in terms of stability (or another metric of
      interest) and continue our analysis on a held-out test set.</p>
    </sec>
  </sec>
  <sec id="computation-and-tracking">
    <title>Computation and tracking</title>
    <p>The package also helps users to improve the efficiency of their
    computational pipelines. Computation is (optionally) handled through
    Ray
    (<xref alt="Moritz et al., 2018" rid="ref-moritz2018ray" ref-type="bibr">Moritz
    et al., 2018</xref>), which easily facilitates parallelization
    across different machines and along different perturbations of the
    pipeline. Caching is handled via
    <ext-link ext-link-type="uri" xlink:href="https://joblib.readthedocs.io/en/latest/">joblib</ext-link>,
    so that individual parts of the pipeline do not need to be rerun.
    Moreover, <monospace>vflow</monospace> supports lazy evaluation of
    <monospace>Vset</monospace>s, as shown in the example above. Thus,
    computation and data can be deferred to when it is needed, saving on
    memory and allowing the pipeline graph to be built and examined
    before beginning computation.</p>
    <p>Experiment-tracking and saving are (optionally) handled via
    integration with MLFlow
    (<xref alt="Zaharia et al., 2018" rid="ref-zaharia2018accelerating" ref-type="bibr">Zaharia
    et al., 2018</xref>), which enables automatic experiment tracking
    and saving.</p>
  </sec>
</sec>
<sec id="related-packages">
  <title>Related packages</title>
  <p>The code here heavily derives from the wonderful work of previous
  projects. It hinges on the data science infrastructure of Python,
  including packages such as pandas
  (<xref alt="Reback et al., 2011" rid="ref-mckinney2011pandas" ref-type="bibr">Reback
  et al., 2011</xref>), NumPy
  (<xref alt="Van Der Walt et al., 2011" rid="ref-van2011numpy" ref-type="bibr">Van
  Der Walt et al., 2011</xref>), and scikit-learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa2011scikit" ref-type="bibr">Pedregosa
  et al., 2011</xref>) as well as newer projects such as imodels
  (<xref alt="Singh et al., 2021" rid="ref-singh2021imodels" ref-type="bibr">Singh
  et al., 2021</xref>) and NetworkX
  (<xref alt="Hagberg &amp; Conway, n.d." rid="ref-hagbergnetworkx" ref-type="bibr">Hagberg
  &amp; Conway, n.d.</xref>).</p>
  <p>The functionality provided by <monospace>VeridicalFlow</monospace>
  is related to the <monospace>sklearn.pipeline.Pipeline</monospace>
  class but allows for more general pipeline steps (e.g., steps need not
  use the <monospace>fit</monospace> or <monospace>transform</monospace>
  methods) and for reuse of those steps in the same or other pipelines.
  Moreover, pipeline graphs in <monospace>VeridicalFlow</monospace> are
  generated dynamically by interactions between
  <monospace>Vsets</monospace>. This added flexibility of pipelines in
  <monospace>VeridicalFlow</monospace> is akin to the dynamic
  computational graphs in TensorFlow (via
  <monospace>tensorflow.keras.layers</monospace> and
  <monospace>tensorflow.function</monospace>) and Ray (via
  <monospace>@ray.remote</monospace>). Indeed, when a
  <monospace>Vset</monospace> is created with
  <monospace>is_async=True</monospace>,
  <monospace>VeridicalFlow</monospace>’s pipeline graph is backed by
  Ray’s task graph.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported in part by National Science Foundation
  (NSF) Grants DMS-1613002, DMS-1953191, DMS-2015341, IIS-1741340, the
  Center for Science of Information (CSoI, an NSF Science and Technology
  Center) under grant agreement CCF-0939370, NSF Grant DMS-2023505 on
  Collaborative Research: Foundations of Data Science Institute (FODSI),
  the NSF and the Simons Foundation for the Collaboration on the
  Theoretical Foundations of Deep Learning through awards DMS-2031883
  and DMS-814639, a Chan Zuckerberg Biohub Intercampus Research Award,
  and a grant from the Weill Neurohub.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-singh2021imodels">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Singh</surname><given-names>Chandan</given-names></name>
        <name><surname>Nasseri</surname><given-names>Keyan</given-names></name>
        <name><surname>Tan</surname><given-names>Yan Shuo</given-names></name>
        <name><surname>Tang</surname><given-names>Tiffany</given-names></name>
        <name><surname>Yu</surname><given-names>Bin</given-names></name>
      </person-group>
      <article-title>imodels: A python package for fitting interpretable models</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>61</issue>
      <pub-id pub-id-type="doi">10.21105/joss.03192</pub-id>
      <fpage>3192</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-van2011numpy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Van Der Walt</surname><given-names>Stefan</given-names></name>
        <name><surname>Colbert</surname><given-names>S Chris</given-names></name>
        <name><surname>Varoquaux</surname><given-names>Gael</given-names></name>
      </person-group>
      <article-title>The NumPy array: A structure for efficient numerical computation</article-title>
      <source>Computing in science &amp; engineering</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>13</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1109/mcse.2011.37</pub-id>
      <fpage>22</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mckinney2011pandas">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Reback</surname><given-names>Jeff</given-names></name>
        <name><surname>McKinney</surname><given-names>Wes</given-names></name>
        <name><surname>jbrockmendel</surname></name>
        <name><surname>Bossche</surname><given-names>Joris Van den</given-names></name>
        <name><surname>Augspurger</surname><given-names>Tom</given-names></name>
        <name><surname>Cloud</surname><given-names>Phillip</given-names></name>
        <name><surname>gfyoung</surname></name>
        <name><surname>Sinhrks</surname></name>
        <name><surname>Klein</surname><given-names>Adam</given-names></name>
        <name><surname>Roeschke</surname><given-names>Matthew</given-names></name>
        <name><surname>Tratner</surname><given-names>Jeff</given-names></name>
        <name><surname>She</surname><given-names>Chang</given-names></name>
        <name><surname>Ayd</surname><given-names>William</given-names></name>
        <name><surname>Hawkins</surname><given-names>Simon</given-names></name>
        <name><surname>Petersen</surname><given-names>Terji</given-names></name>
        <name><surname>Schendel</surname><given-names>Jeremy</given-names></name>
        <name><surname>Hayden</surname><given-names>Andy</given-names></name>
        <name><surname>Garcia</surname><given-names>Marc</given-names></name>
        <name><surname>Jancauskas</surname><given-names>Vytautas</given-names></name>
        <name><surname>MomIsBestFriend</surname></name>
        <name><surname>Battiston</surname><given-names>Pietro</given-names></name>
        <name><surname>Seabold</surname><given-names>Skipper</given-names></name>
        <name><surname>chris- b1</surname></name>
        <name><surname>h-vetinari</surname></name>
        <name><surname>Hoyer</surname><given-names>Stephan</given-names></name>
        <name><surname>Overmeire</surname><given-names>Wouter</given-names></name>
        <name><surname>alimcmaster1</surname></name>
        <name><surname>Mehyar</surname><given-names>Mortada</given-names></name>
        <name><surname>Whelan</surname><given-names>Christopher</given-names></name>
        <name><surname>Kluyver</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>pandas: A foundational python library for data analysis and statistics</article-title>
      <source>Python for high performance and scientific computing</source>
      <publisher-name>Dallas, TX</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>14</volume>
      <issue>9</issue>
      <pub-id pub-id-type="doi">10.5281/zenodo.3509134</pub-id>
      <fpage>1</fpage>
      <lpage>9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-moritz2018ray">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Moritz</surname><given-names>Philipp</given-names></name>
        <name><surname>Nishihara</surname><given-names>Robert</given-names></name>
        <name><surname>Wang</surname><given-names>Stephanie</given-names></name>
        <name><surname>Tumanov</surname><given-names>Alexey</given-names></name>
        <name><surname>Liaw</surname><given-names>Richard</given-names></name>
        <name><surname>Liang</surname><given-names>Eric</given-names></name>
        <name><surname>Elibol</surname><given-names>Melih</given-names></name>
        <name><surname>Yang</surname><given-names>Zongheng</given-names></name>
        <name><surname>Paul</surname><given-names>William</given-names></name>
        <name><surname>Jordan</surname><given-names>Michael I</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Ray: A distributed framework for emerging AI applications</article-title>
      <source>13th USENIX symposium on operating systems design and implementation (OSDI 18)</source>
      <year iso-8601-date="2018">2018</year>
      <fpage>561</fpage>
      <lpage>577</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zaharia2018accelerating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zaharia</surname><given-names>Matei</given-names></name>
        <name><surname>Chen</surname><given-names>Andrew</given-names></name>
        <name><surname>Davidson</surname><given-names>Aaron</given-names></name>
        <name><surname>Ghodsi</surname><given-names>Ali</given-names></name>
        <name><surname>Hong</surname><given-names>Sue Ann</given-names></name>
        <name><surname>Konwinski</surname><given-names>Andy</given-names></name>
        <name><surname>Murching</surname><given-names>Siddharth</given-names></name>
        <name><surname>Nykodym</surname><given-names>Tomas</given-names></name>
        <name><surname>Ogilvie</surname><given-names>Paul</given-names></name>
        <name><surname>Parkhe</surname><given-names>Mani</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Accelerating the machine learning lifecycle with MLflow</article-title>
      <source>IEEE Data Eng. Bull.</source>
      <year iso-8601-date="2018">2018</year>
      <volume>41</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1145/3399579.3399867</pub-id>
      <fpage>39</fpage>
      <lpage>45</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ivie2018reproducibility">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ivie</surname><given-names>Peter</given-names></name>
        <name><surname>Thain</surname><given-names>Douglas</given-names></name>
      </person-group>
      <article-title>Reproducibility in scientific computing</article-title>
      <source>ACM Computing Surveys (CSUR)</source>
      <publisher-name>ACM New York, NY, USA</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>51</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1145/3186266</pub-id>
      <fpage>1</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-saltelli2002sensitivity">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Saltelli</surname><given-names>Andrea</given-names></name>
      </person-group>
      <article-title>Sensitivity analysis for importance assessment</article-title>
      <source>Risk analysis</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <volume>22</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1111/0272-4332.00040</pub-id>
      <fpage>579</fpage>
      <lpage>590</lpage>
    </element-citation>
  </ref>
  <ref id="ref-yu2020veridical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yu</surname><given-names>Bin</given-names></name>
        <name><surname>Kumbier</surname><given-names>Karl</given-names></name>
      </person-group>
      <article-title>Veridical data science</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
      <publisher-name>National Acad Sciences</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>117</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1145/3336191.3372191</pub-id>
      <fpage>3920</fpage>
      <lpage>3929</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pedregosa2011scikit">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>Varoquaux</surname><given-names>Gaël</given-names></name>
        <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
        <name><surname>Michel</surname><given-names>Vincent</given-names></name>
        <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
        <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
        <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
        <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
        <name><surname>Weiss</surname><given-names>Ron</given-names></name>
        <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Scikit-learn: Machine learning in Python</article-title>
      <source>the Journal of machine Learning research</source>
      <publisher-name>JMLR. org</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>12</volume>
      <uri>http://jmlr.org/papers/v12/pedregosa11a.html</uri>
      <fpage>2825</fpage>
      <lpage>2830</lpage>
    </element-citation>
  </ref>
  <ref id="ref-murdoch2019definitions">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Murdoch</surname><given-names>W James</given-names></name>
        <name><surname>Singh</surname><given-names>Chandan</given-names></name>
        <name><surname>Kumbier</surname><given-names>Karl</given-names></name>
        <name><surname>Abbasi-Asl</surname><given-names>Reza</given-names></name>
        <name><surname>Yu</surname><given-names>Bin</given-names></name>
      </person-group>
      <article-title>Definitions, methods, and applications in interpretable machine learning</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
      <publisher-name>National Acad Sciences</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>116</volume>
      <issue>44</issue>
      <pub-id pub-id-type="doi">10.1073/pnas.1900654116</pub-id>
      <fpage>22071</fpage>
      <lpage>22080</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hagbergnetworkx">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hagberg</surname><given-names>Aric</given-names></name>
        <name><surname>Conway</surname><given-names>Drew</given-names></name>
      </person-group>
      <article-title>NetworkX: Network analysis with Python</article-title>
      <uri>https://networkx.org/</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
