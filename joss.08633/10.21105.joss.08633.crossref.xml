<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20251020122804-4f45e3407a532725168b6b0241f9c832e68a1df1</doi_batch_id>
    <timestamp>20251020122804</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>114</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>maze-dataset: Maze Generation with Algorithmic Variety and Representational Flexibility</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Michael Igorevich</given_name>
            <surname>Ivanitskiy</surname>
            <affiliations>
              <institution><institution_name>Colorado School of Mines, Department of Applied Mathematics and Statistics</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-4213-4993</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Aaron</given_name>
            <surname>Sandoval</surname>
            <affiliations>
              <institution><institution_name>Independent</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0002-8380-6140</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Alexander F.</given_name>
            <surname>Spies</surname>
            <affiliations>
              <institution><institution_name>Imperial College London</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-8708-1530</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Tilman</given_name>
            <surname>Räuker</surname>
            <affiliations>
              <institution><institution_name>UnSearch.org</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0009-6321-4413</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Brandon</given_name>
            <surname>Knutson</surname>
            <affiliations>
              <institution><institution_name>Colorado School of Mines, Department of Applied Mathematics and Statistics</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0004-8413-0239</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Cecilia Diniz</given_name>
            <surname>Behn</surname>
            <affiliations>
              <institution><institution_name>Colorado School of Mines, Department of Applied Mathematics and Statistics</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-8078-5105</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Samy Wu</given_name>
            <surname>Fung</surname>
            <affiliations>
              <institution><institution_name>Colorado School of Mines, Department of Applied Mathematics and Statistics</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-2926-4582</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>20</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>8633</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.08633</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.16915900</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/8633</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.08633</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.08633</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.08633.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="fung2022jfb">
            <article_title>Jfb: Jacobian-free backpropagation for implicit networks</article_title>
            <author>Fung</author>
            <journal_title>Proceedings of the AAAI conference on artificial intelligence</journal_title>
            <volume>36</volume>
            <doi>10.1609/aaai.v36i6.20619</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Fung, S. W., Heaton, H., Li, Q., McKenzie, D., Osher, S., &amp; Yin, W. (2022). Jfb: Jacobian-free backpropagation for implicit networks. Proceedings of the AAAI Conference on Artificial Intelligence, 36, 6648–6656. https://doi.org/10.1609/aaai.v36i6.20619</unstructured_citation>
          </citation>
          <citation key="eval-LLM-graphs">
            <article_title>Evaluating large language models on graphs: Performance insights and comparative analysis</article_title>
            <author>Liu</author>
            <journal_title>arXiv preprint arXiv:2308.11224</journal_title>
            <doi>10.48550/arXiv.2308.11224</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Liu, C., &amp; Wu, B. (2023). Evaluating large language models on graphs: Performance insights and comparative analysis. arXiv Preprint arXiv:2308.11224. https://doi.org/10.48550/arXiv.2308.11224</unstructured_citation>
          </citation>
          <citation key="zhang2025tscend">
            <article_title>T-SCEND: Test-time scalable MCTS-enhanced diffusion model</article_title>
            <author>Zhang</author>
            <journal_title>arXiv preprint arXiv:2502.01989</journal_title>
            <doi>10.48550/arXiv.2502.01989</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Zhang, T., Pan, J.-S., Feng, R., &amp; Wu, T. (2025). T-SCEND: Test-time scalable MCTS-enhanced diffusion model. arXiv Preprint arXiv:2502.01989. https://doi.org/10.48550/arXiv.2502.01989</unstructured_citation>
          </citation>
          <citation key="dao2025alphamaze">
            <article_title>AlphaMaze: Enhancing large language models’ spatial intelligence via GRPO</article_title>
            <author>Dao</author>
            <journal_title>arXiv preprint arXiv:2502.14669</journal_title>
            <doi>10.48550/arXiv.2502.14669</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Dao, A., &amp; Vu, D. B. (2025). AlphaMaze: Enhancing large language models’ spatial intelligence via GRPO. arXiv Preprint arXiv:2502.14669. https://doi.org/10.48550/arXiv.2502.14669</unstructured_citation>
          </citation>
          <citation key="mdl-suite">
            <article_title>MDL suite: A language, generator and compiler for describing mazes</article_title>
            <author>Nag</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>46</issue>
            <volume>5</volume>
            <doi>10.21105/joss.01815</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Nag, A. (2020). MDL suite: A language, generator and compiler for describing mazes. Journal of Open Source Software, 5(46), 1815. https://doi.org/10.21105/joss.01815</unstructured_citation>
          </citation>
          <citation key="mathematica-maze">
            <article_title>Maze generator and solver</article_title>
            <author>Guo</author>
            <cYear>2011</cYear>
            <unstructured_citation>Guo, C., Barthelet, L., &amp; Morris, R. (2011). Maze generator and solver. Wolfram Demonstrations Project, https://demonstrations.wolfram.com/MazeGeneratorAndSolver/.</unstructured_citation>
          </citation>
          <citation key="pysr">
            <article_title>Interpretable machine learning for science with PySR and SymbolicRegression. jl</article_title>
            <author>Cranmer</author>
            <journal_title>arXiv preprint arXiv:2305.01582</journal_title>
            <doi>10.48550/arXiv.2305.01582</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Cranmer, M. (2023). Interpretable machine learning for science with PySR and SymbolicRegression. jl. arXiv Preprint arXiv:2305.01582. https://doi.org/10.48550/arXiv.2305.01582</unstructured_citation>
          </citation>
          <citation key="mazegenerator-net">
            <article_title>Maze generator</article_title>
            <author>Alance AB</author>
            <cYear>2019</cYear>
            <unstructured_citation>Alance AB. (2019). Maze generator. http://www.mazegenerator.net.</unstructured_citation>
          </citation>
          <citation key="gh-oppenheimj2018maze">
            <article_title>Maze-generator: Generate a random maze represented as a 2D array using depth-first search</article_title>
            <author>Oppenheim</author>
            <cYear>2018</cYear>
            <unstructured_citation>Oppenheim, J. (2018). Maze-generator: Generate a random maze represented as a 2D array using depth-first search. https://github.com/oppenheimj/maze-generator/; GitHub.</unstructured_citation>
          </citation>
          <citation key="ayaz2008maze">
            <article_title>Maze suite 1.0: A complete set of tools to prepare, present, and analyze navigational and spatial cognitive neuroscience experiments</article_title>
            <author>Ayaz</author>
            <journal_title>Behavior research methods</journal_title>
            <volume>40</volume>
            <doi>10.3758/brm.40.1.353</doi>
            <cYear>2008</cYear>
            <unstructured_citation>Ayaz, H., Allen, S. L., Platek, S. M., &amp; Onaral, B. (2008). Maze suite 1.0: A complete set of tools to prepare, present, and analyze navigational and spatial cognitive neuroscience experiments. Behavior Research Methods, 40, 353–359. https://doi.org/10.3758/brm.40.1.353</unstructured_citation>
          </citation>
          <citation key="interpretability-survey">
            <article_title>Toward transparent ai: A survey on interpreting the inner structures of deep neural networks</article_title>
            <author>Räuker</author>
            <journal_title>2023 IEEE conference on secure and trustworthy machine learning (SaTML)</journal_title>
            <doi>10.1109/satml54575.2023.00039</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Räuker, T., Ho, A., Casper, S., &amp; Hadfield-Menell, D. (2023). Toward transparent ai: A survey on interpreting the inner structures of deep neural networks. 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 464–483. https://doi.org/10.1109/satml54575.2023.00039</unstructured_citation>
          </citation>
          <citation key="easy_to_hard">
            <article_title>Datasets for Studying Generalization from Easy to Hard Examples</article_title>
            <author>Schwarzschild</author>
            <doi>10.48550/arXiv.2108.06011</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Schwarzschild, A., Borgnia, E., Gupta, A., Bansal, A., Emam, Z., Huang, F., Goldblum, M., &amp; Goldstein, T. (2021). Datasets for Studying Generalization from Easy to Hard Examples (No. arXiv:2108.06011). arXiv. https://doi.org/10.48550/arXiv.2108.06011</unstructured_citation>
          </citation>
          <citation key="deepthinking">
            <article_title>Can you learn an algorithm? Generalizing from easy to hard problems with recurrent networks</article_title>
            <author>Schwarzschild</author>
            <journal_title>Advances in Neural Information Processing Systems</journal_title>
            <volume>34</volume>
            <doi>10.48550/arXiv.2106.04537</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Schwarzschild, A., Borgnia, E., Gupta, A., Huang, F., Vishkin, U., Goldblum, M., &amp; Goldstein, T. (2021). Can you learn an algorithm? Generalizing from easy to hard problems with recurrent networks. Advances in Neural Information Processing Systems, 34, 6695–6706. https://doi.org/10.48550/arXiv.2106.04537</unstructured_citation>
          </citation>
          <citation key="eval-gpt-visual">
            <article_title>Evaluating ChatGPT and GPT-4 for visual programming</article_title>
            <author>Singla</author>
            <journal_title>arXiv preprint arXiv:2308.02522</journal_title>
            <doi>10.48550/arXiv.2308.02522</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Singla, A. (2023). Evaluating ChatGPT and GPT-4 for visual programming. arXiv Preprint arXiv:2308.02522. https://doi.org/10.48550/arXiv.2308.02522</unstructured_citation>
          </citation>
          <citation key="maze-dataset-arxiv-2023">
            <article_title>A configurable library for generating and manipulating maze datasets</article_title>
            <author>Ivanitskiy</author>
            <journal_title>arXiv preprint arXiv:2309.10498</journal_title>
            <doi>10.48550/arXiv.2309.10498</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Ivanitskiy, M. I., Shah, R., Spies, A. F., Räuker, T., Valentine, D., Rager, C., Quirke, L., Mathwin, C., Corlouer, G., Behn, C. D., &amp; others. (2023). A configurable library for generating and manipulating maze datasets. arXiv Preprint arXiv:2309.10498. https://doi.org/10.48550/arXiv.2309.10498</unstructured_citation>
          </citation>
          <citation key="maze-dataset-github">
            <article_title>Maze dataset</article_title>
            <author>Ivanitskiy</author>
            <doi>10.48550/arXiv.2309.10498</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Ivanitskiy, M. I., Shah, R., Spies, A. F., Räuker, T., Valentine, D., Rager, C., Quirke, L., Corlouer, G., &amp; Mathwin, C. (2023). Maze dataset. https://doi.org/10.48550/arXiv.2309.10498</unstructured_citation>
          </citation>
          <citation key="maze-transformer-github">
            <article_title>Maze transformer interpretability</article_title>
            <author>Ivanitskiy</author>
            <doi>10.48550/arXiv.2312.02566</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Ivanitskiy, M. I., Shah, R., Spies, A. F., Räuker, T., Valentine, D., Rager, C., Quirke, L., Corlouer, G., &amp; Mathwin, C. (2023). Maze transformer interpretability. https://doi.org/10.48550/arXiv.2312.02566</unstructured_citation>
          </citation>
          <citation key="gh_Ehsan_2022">
            <article_title>Maze</article_title>
            <author>Ehsan</author>
            <cYear>2022</cYear>
            <unstructured_citation>Ehsan, E. (2022). Maze. https://github.com/emadehsan/maze</unstructured_citation>
          </citation>
          <citation key="gh_Nemeth_2019">
            <article_title>Maze-generation-algorithms</article_title>
            <author>Németh</author>
            <cYear>2019</cYear>
            <unstructured_citation>Németh, F. (2019). Maze-generation-algorithms. https://github.com/ferenc-nemeth/maze-generation-algorithms</unstructured_citation>
          </citation>
          <citation key="zanj">
            <article_title>ZANJ</article_title>
            <author>Ivanitskiy</author>
            <doi>10.5281/zenodo.15540393</doi>
            <unstructured_citation>Ivanitskiy, M. (n.d.). ZANJ. https://doi.org/10.5281/zenodo.15540393</unstructured_citation>
          </citation>
          <citation key="ivanitskiy2023structuredworldreps">
            <article_title>Structured world representations in maze-solving transformers</article_title>
            <author>Ivanitskiy</author>
            <journal_title>arXiv preprint arXiv:2312.02566</journal_title>
            <doi>10.48550/arXiv.2312.02566</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Ivanitskiy, M. I., Spies, A. F., Räuker, T., Corlouer, G., Mathwin, C., Quirke, L., Rager, C., Shah, R., Valentine, D., Behn, C. D., &amp; others. (2023). Structured world representations in maze-solving transformers. arXiv Preprint arXiv:2312.02566. https://doi.org/10.48550/arXiv.2312.02566</unstructured_citation>
          </citation>
          <citation key="spies2024causalworldmodels">
            <article_title>Transformers use causal world models in maze-solving tasks</article_title>
            <author>Spies</author>
            <journal_title>arXiv preprint arXiv:2412.11867</journal_title>
            <doi>10.48550/arXiv.2412.11867</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Spies, A. F., Edwards, W., Ivanitskiy, M. I., Skapars, A., Räuker, T., Inoue, K., Russo, A., &amp; Shanahan, M. (2024). Transformers use causal world models in maze-solving tasks. arXiv Preprint arXiv:2412.11867. https://doi.org/10.48550/arXiv.2412.11867</unstructured_citation>
          </citation>
          <citation key="knutson2024logicalextrapolation">
            <article_title>On logical extrapolation for mazes with recurrent and implicit networks</article_title>
            <author>Knutson</author>
            <journal_title>arXiv preprint arXiv:2410.03020</journal_title>
            <doi>10.48550/arXiv.2410.03020</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Knutson, B., Rabeendran, A. C., Ivanitskiy, M., Pettyjohn, J., Diniz-Behn, C., Fung, S. W., &amp; McKenzie, D. (2024). On logical extrapolation for mazes with recurrent and implicit networks. arXiv Preprint arXiv:2410.03020. https://doi.org/10.48550/arXiv.2410.03020</unstructured_citation>
          </citation>
          <citation key="nolte2024multistep">
            <article_title>Transformers can navigate mazes with multi-step prediction</article_title>
            <author>Nolte</author>
            <journal_title>arXiv preprint arXiv:2412.05117</journal_title>
            <doi>10.48550/arXiv.2412.05117</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Nolte, N., Kitouni, O., Williams, A., Rabbat, M., &amp; Ibrahim, M. (2024). Transformers can navigate mazes with multi-step prediction. arXiv Preprint arXiv:2412.05117. https://doi.org/10.48550/arXiv.2412.05117</unstructured_citation>
          </citation>
          <citation key="MLMU-kitouni2024factorization">
            <article_title>The factorization curse: Which tokens you predict underlie the reversal curse and more</article_title>
            <author>Kitouni</author>
            <journal_title>Advances in Neural Information Processing Systems</journal_title>
            <volume>37</volume>
            <doi>10.48550/arXiv.2406.05183</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Kitouni, O., Nolte, N. S., Williams, A., Rabbat, M., Bouchacourt, D., &amp; Ibrahim, M. (2024). The factorization curse: Which tokens you predict underlie the reversal curse and more. Advances in Neural Information Processing Systems, 37, 112329–112355. https://doi.org/10.48550/arXiv.2406.05183</unstructured_citation>
          </citation>
          <citation key="wang2024imperative">
            <article_title>Imperative learning: A self-supervised neural-symbolic learning framework for robot autonomy</article_title>
            <author>Wang</author>
            <journal_title>arXiv preprint arXiv:2406.16087</journal_title>
            <doi>10.48550/arXiv.2406.16087</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Wang, C., Ji, K., Geng, J., Ren, Z., Fu, T., Yang, F., Guo, Y., He, H., Chen, X., Zhan, Z., &amp; others. (2024). Imperative learning: A self-supervised neural-symbolic learning framework for robot autonomy. arXiv Preprint arXiv:2406.16087. https://doi.org/10.48550/arXiv.2406.16087</unstructured_citation>
          </citation>
          <citation key="pfau2024dotbydot">
            <article_title>Let’s think dot by dot: Hidden computation in transformer language models</article_title>
            <author>Pfau</author>
            <journal_title>arXiv preprint arXiv:2404.15758</journal_title>
            <doi>10.48550/arXiv.2404.15758</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Pfau, J., Merrill, W., &amp; Bowman, S. R. (2024). Let’s think dot by dot: Hidden computation in transformer language models. arXiv Preprint arXiv:2404.15758. https://doi.org/10.48550/arXiv.2404.15758</unstructured_citation>
          </citation>
          <citation key="chen2024iaimperative">
            <article_title>iA*: Imperative learning-based A* search for pathfinding</article_title>
            <author>Chen</author>
            <journal_title>arXiv preprint arXiv:2403.15870</journal_title>
            <doi>10.48550/arXiv.2403.15870</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Chen, X., Yang, F., &amp; Wang, C. (2024). iA*: Imperative learning-based A* search for pathfinding. arXiv Preprint arXiv:2403.15870. https://doi.org/10.48550/arXiv.2403.15870</unstructured_citation>
          </citation>
          <citation key="cai2025morse">
            <article_title>MORSE-500: A programmatically controllable video benchmark to stress-test multimodal reasoning</article_title>
            <author>Cai</author>
            <journal_title>arXiv preprint arXiv:2506.05523</journal_title>
            <doi>10.48550/arXiv.2506.05523</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Cai, Z., Wang, A., Satheesh, A., Nakhawa, A., Jae, H., Powell, K., Liu, M., Jay, N., Oh, S., Wang, X., &amp; others. (2025). MORSE-500: A programmatically controllable video benchmark to stress-test multimodal reasoning. arXiv Preprint arXiv:2506.05523. https://doi.org/10.48550/arXiv.2506.05523</unstructured_citation>
          </citation>
          <citation key="xu2025visual">
            <article_title>Visual planning: Let’s think only with images</article_title>
            <author>Xu</author>
            <journal_title>arXiv preprint arXiv:2505.11409</journal_title>
            <doi>10.48550/arXiv.2505.11409</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Xu, Y., Li, C., Zhou, H., Wan, X., Zhang, C., Korhonen, A., &amp; Vulić, I. (2025). Visual planning: Let’s think only with images. arXiv Preprint arXiv:2505.11409. https://doi.org/10.48550/arXiv.2505.11409</unstructured_citation>
          </citation>
          <citation key="lee2025adaptive">
            <article_title>Adaptive cyclic diffusion for inference scaling</article_title>
            <author>Lee</author>
            <journal_title>arXiv preprint arXiv:2505.14036</journal_title>
            <doi>10.48550/arXiv.2505.14036</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Lee, G., Bao, T. N. N., Yoon, J., Lee, D., Kim, M., Bengio, Y., &amp; Ahn, S. (2025). Adaptive cyclic diffusion for inference scaling. arXiv Preprint arXiv:2505.14036. https://doi.org/10.48550/arXiv.2505.14036</unstructured_citation>
          </citation>
          <citation key="zhang2025vfscale">
            <article_title>VFScale: Intrinsic reasoning through verifier-free test-time scalable diffusion model</article_title>
            <author>Zhang</author>
            <journal_title>arXiv preprint arXiv:2502.01989</journal_title>
            <doi>10.48550/arXiv.2502.01989</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Zhang, T., Pan, J.-S., Feng, R., &amp; Wu, T. (2025). VFScale: Intrinsic reasoning through verifier-free test-time scalable diffusion model. arXiv Preprint arXiv:2502.01989. https://doi.org/10.48550/arXiv.2502.01989</unstructured_citation>
          </citation>
          <citation key="harriesMazeExplorerCustomisable3D2019">
            <article_title>MazeExplorer: A Customisable 3D Benchmark for Assessing Generalisation in Reinforcement Learning</article_title>
            <author>Harries</author>
            <journal_title>2019 IEEE Conf. Games CoG</journal_title>
            <doi>10.1109/cig.2019.8848048</doi>
            <unstructured_citation>Harries, L., Lee, S., Rzepecki, J., Hofmann, K., &amp; Devlin, S. (n.d.). MazeExplorer: A Customisable 3D Benchmark for Assessing Generalisation in Reinforcement Learning. 2019 IEEE Conf. Games CoG, 1–4. https://doi.org/10.1109/cig.2019.8848048</unstructured_citation>
          </citation>
          <citation key="cobbe2019procgen">
            <article_title>Leveraging procedural generation to benchmark reinforcement learning</article_title>
            <author>Cobbe</author>
            <journal_title>arXiv preprint arXiv:1912.01588</journal_title>
            <doi>10.48550/arXiv.1912.01588</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Cobbe, K., Hesse, C., Hilton, J., &amp; Schulman, J. (2019). Leveraging procedural generation to benchmark reinforcement learning. arXiv Preprint arXiv:1912.01588. https://doi.org/10.48550/arXiv.1912.01588</unstructured_citation>
          </citation>
          <citation key="seaborn">
            <article_title>seaborn: Statistical data visualization</article_title>
            <author>Waskom</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>60</issue>
            <volume>6</volume>
            <doi>10.21105/joss.03021</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Waskom, M. L. (2021). seaborn: Statistical data visualization. Journal of Open Source Software, 6(60), 3021. https://doi.org/10.21105/joss.03021</unstructured_citation>
          </citation>
          <citation key="python">
            <article_title>Python reference manual</article_title>
            <author>Rossum</author>
            <cYear>1995</cYear>
            <unstructured_citation>Rossum, G. van. (1995). Python reference manual (CS-R9525). Centrum voor Wiskunde; Informatica (CWI). https://ir.cwi.nl/pub/5008/05008D.pdf</unstructured_citation>
          </citation>
          <citation key="numpy">
            <article_title>Array programming with NumPy</article_title>
            <author>Harris</author>
            <journal_title>Nature</journal_title>
            <volume>585</volume>
            <doi>10.1038/s41586-020-2649-2</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Harris, C. R., Millman, K. J., Walt, S. J. van der, Gommers, R., Virtanen, P., &amp; al., et. (2020). Array programming with NumPy. Nature, 585, 357–362. https://doi.org/10.1038/s41586-020-2649-2</unstructured_citation>
          </citation>
          <citation key="matplotlib">
            <article_title>Matplotlib: A 2D graphics environment</article_title>
            <author>Hunter</author>
            <journal_title>Computing in Science and Engineering</journal_title>
            <issue>3</issue>
            <volume>9</volume>
            <doi>10.1109/MCSE.2007.55</doi>
            <cYear>2007</cYear>
            <unstructured_citation>Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science and Engineering, 9(3), 90–95. https://doi.org/10.1109/MCSE.2007.55</unstructured_citation>
          </citation>
          <citation key="jupyter">
            <article_title>Jupyter notebooks - a publishing format for reproducible computational workflows</article_title>
            <author>Kluyver</author>
            <journal_title>Proceedings of the 20th international conference on electronic publishing</journal_title>
            <doi>10.3233/978-1-61499-649-1-87</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Kluyver, T., Ragan-Kelley, B., Perez, F., Granger, B., Bussonnier, M., Frederic, J., Kelley, K., Hamrick, J., Grout, J., Corlay, S., Ivanov, P., Avila, D., Abdalla, S., &amp; Willing, C. (2016). Jupyter notebooks - a publishing format for reproducible computational workflows. Proceedings of the 20th International Conference on Electronic Publishing, 87–90. https://doi.org/10.3233/978-1-61499-649-1-87</unstructured_citation>
          </citation>
          <citation key="Gallant2015Transducers">
            <article_title>Index 1,600,000,000 keys with automata and rust</article_title>
            <author>Gallant</author>
            <cYear>2015</cYear>
            <unstructured_citation>Gallant, A. (2015). Index 1,600,000,000 keys with automata and rust. https://burntsushi.net/transducers/.</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
