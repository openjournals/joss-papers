<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8633</article-id>
<article-id pub-id-type="doi">10.21105/joss.08633</article-id>
<title-group>
<article-title>maze-dataset: Maze Generation with Algorithmic Variety
and Representational Flexibility</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4213-4993</contrib-id>
<name>
<surname>Ivanitskiy</surname>
<given-names>Michael Igorevich</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0002-8380-6140</contrib-id>
<name>
<surname>Sandoval</surname>
<given-names>Aaron</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8708-1530</contrib-id>
<name>
<surname>Spies</surname>
<given-names>Alexander F.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0009-6321-4413</contrib-id>
<name>
<surname>Räuker</surname>
<given-names>Tilman</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0004-8413-0239</contrib-id>
<name>
<surname>Knutson</surname>
<given-names>Brandon</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8078-5105</contrib-id>
<name>
<surname>Behn</surname>
<given-names>Cecilia Diniz</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2926-4582</contrib-id>
<name>
<surname>Fung</surname>
<given-names>Samy Wu</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Colorado School of Mines, Department of Applied Mathematics
and Statistics</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Imperial College London</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>UnSearch.org</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Independent</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-04-09">
<day>9</day>
<month>4</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>8633</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>machine learning</kwd>
<kwd>distributional shift</kwd>
<kwd>maze generation</kwd>
<kwd>datasets</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Solving mazes is a classic problem in computer science and
  artificial intelligence, and humans have been constructing mazes for
  thousands of years. Although finding the shortest path through a maze
  is a solved problem, this very fact makes it an excellent testbed for
  studying how machine learning algorithms solve problems and represent
  spatial information. We introduce <monospace>maze-dataset</monospace>,
  a user-friendly Python library for generating, processing, and
  visualizing datasets of mazes. This library supports a variety of maze
  generation algorithms which can be configured with various parameters,
  and the resulting mazes can be filtered to satisfy desired properties.
  Also provided are tools for converting mazes to and from various
  formats suitable for a variety of neural network architectures, such
  as rasterized images, tokenized text sequences, and various
  visualizations. As well as providing a simple interface for
  generating, storing, and loading these datasets,
  <monospace>maze-dataset</monospace> is extensively tested, type
  hinted, benchmarked, and documented.</p>
  <fig id="figU003Adiagram">
    <caption><p> Usage of maze-dataset. We create a
    <monospace>MazeDataset</monospace> from a
    <monospace>MazeDatasetConfig</monospace>. This contains
    <monospace>SolvedMaze</monospace> objects which can be converted to
    and from a variety of formats. A variety of generated examples can
    be viewed on the , and more information can be found in the .
    </p></caption>
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>While maze generation itself is straightforward, the architectural
  challenge comes from building a system supporting many algorithms with
  configurable parameters, property filtering, representation
  transformation, and reproducibility. This library aims to greatly
  streamline the process of generating and working with datasets of
  mazes that can be described as subgraphs of an
  <inline-formula><alternatives>
  <tex-math><![CDATA[n \times n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  lattice with boolean connections and, optionally, start and end points
  that are nodes in the graph. Furthermore, we place emphasis on a wide
  variety of possible text output formats aimed at evaluating the
  spatial reasoning capabilities of Large Language Models (LLMs) and
  other text-based transformer models.</p>
  <p>For interpretability and behavioral research, algorithmic tasks
  offer benefits by allowing systematic data generation and task
  decomposition, as well as simplifying the process of circuit discovery
  (<xref alt="Räuker et al., 2023" rid="ref-interpretability-survey" ref-type="bibr">Räuker
  et al., 2023</xref>). Although mazes are well suited for these
  investigations, we found that existing maze generation packages
  (<xref alt="Cobbe et al., 2019" rid="ref-cobbe2019procgen" ref-type="bibr">Cobbe
  et al., 2019</xref>;
  <xref alt="Ehsan, 2022" rid="ref-gh_Ehsan_2022" ref-type="bibr">Ehsan,
  2022</xref>;
  <xref alt="Harries et al., n.d." rid="ref-harriesMazeExplorerCustomisable3D2019" ref-type="bibr">Harries
  et al., n.d.</xref>;
  <xref alt="Németh, 2019" rid="ref-gh_Nemeth_2019" ref-type="bibr">Németh,
  2019</xref>;
  <xref alt="Schwarzschild, Borgnia, Gupta, Bansal, et al., 2021" rid="ref-easy_to_hard" ref-type="bibr">Schwarzschild,
  Borgnia, Gupta, Bansal, et al., 2021</xref>) lack support for
  transforming between multiple representations and provide limited
  control over the maze generation process.</p>
  <sec id="related-works">
    <title>Related Works</title>
    <p>A multitude of public and open-source software packages exist for
    generating mazes
    (<xref alt="Ehsan, 2022" rid="ref-gh_Ehsan_2022" ref-type="bibr">Ehsan,
    2022</xref>;
    <xref alt="Németh, 2019" rid="ref-gh_Nemeth_2019" ref-type="bibr">Németh,
    2019</xref>;
    <xref alt="Schwarzschild, Borgnia, Gupta, Bansal, et al., 2021" rid="ref-easy_to_hard" ref-type="bibr">Schwarzschild,
    Borgnia, Gupta, Bansal, et al., 2021</xref>). However, nearly all of
    these packages produce mazes represented as rasterized images or
    other visual formats rather than the underlying graph structure, and
    this makes it difficult to work with these datasets.</p>
    <list list-type="bullet">
      <list-item>
        <p>Most prior works provide mazes in visual or raster formats,
        and we provide a variety of similar output formats:</p>
        <list list-type="bullet">
          <list-item>
            <p><ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/dataset/rasterized.html#RasterizedMazeDataset"><monospace>RasterizedMazeDataset</monospace></ext-link>,
            utilizing
            <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#LatticeMaze.as_pixels"><monospace>as_pixels()</monospace></ext-link>,
            which can exactly mimic the outputs provided in
            <monospace>easy-to-hard-data</monospace>
            (<xref alt="Schwarzschild, Borgnia, Gupta, Bansal, et al., 2021" rid="ref-easy_to_hard" ref-type="bibr">Schwarzschild,
            Borgnia, Gupta, Bansal, et al., 2021</xref>) and can be
            configured to be similar to the outputs of Németh
            (<xref alt="2019" rid="ref-gh_Nemeth_2019" ref-type="bibr">2019</xref>)</p>
          </list-item>
          <list-item>
            <p><ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#LatticeMaze.as_ascii"><monospace>as_ascii()</monospace></ext-link>
            provides a format similar to Singla
            (<xref alt="2023" rid="ref-eval-gpt-visual" ref-type="bibr">2023</xref>)
            and Oppenheim
            (<xref alt="2018" rid="ref-gh-oppenheimj2018maze" ref-type="bibr">2018</xref>)</p>
          </list-item>
          <list-item>
            <p><ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/plotting.html#MazePlot"><monospace>MazePlot</monospace></ext-link>
            provides a feature-rich plotting utility with support for
            multiple paths, heatmaps over positions, and more. This is
            similar to the outputs of many packages
            (<xref alt="Alance AB, 2019" rid="ref-mazegenerator-net" ref-type="bibr">Alance
            AB, 2019</xref>;
            <xref alt="Ehsan, 2022" rid="ref-gh_Ehsan_2022" ref-type="bibr">Ehsan,
            2022</xref>;
            <xref alt="Guo et al., 2011" rid="ref-mathematica-maze" ref-type="bibr">Guo
            et al., 2011</xref>;
            <xref alt="Nag, 2020" rid="ref-mdl-suite" ref-type="bibr">Nag,
            2020</xref>).</p>
          </list-item>
        </list>
      </list-item>
      <list-item>
        <p>The text format provided by
        <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#MazeDataset.as_tokens"><monospace>SolvedMaze(...).as_tokens()</monospace></ext-link>
        is similar to that of Liu &amp; Wu
        (<xref alt="2023" rid="ref-eval-LLM-graphs" ref-type="bibr">2023</xref>)
        but with many more options, detailed in
        <xref alt="section: " rid="secU003Atokenized-output-formats">section:
        <italic></italic></xref>.</p>
      </list-item>
      <list-item>
        <p>Preserving metadata about the generation algorithm with the
        dataset itself is essential for studying the effects of
        distributional shifts. Our package efficiently stores the
        dataset along with its metadata in a single human-readable file
        (<xref alt="M. Ivanitskiy, n.d." rid="ref-zanj" ref-type="bibr">M.
        Ivanitskiy, n.d.</xref>). As far as we are aware, no existing
        packages do this reliably.</p>
      </list-item>
      <list-item>
        <p>Storing mazes as images or adjacency matrices is not only
        difficult to work with, but also inefficient. We use a highly
        efficient method detailed in
        <xref alt="section: " rid="secU003Aimplementation">section:
        <italic></italic></xref>.</p>
      </list-item>
      <list-item>
        <p>Our package is easily installable with source code freely
        available. It is extensively tested, type hinted, benchmarked,
        and documented. Many other maze generation packages lack this
        level of rigor and scope, and some
        (<xref alt="Ayaz et al., 2008" rid="ref-ayaz2008maze" ref-type="bibr">Ayaz
        et al., 2008</xref>) appear to simply no longer be
        accessible.</p>
      </list-item>
    </list>
  </sec>
</sec>
<sec id="features">
  <title>Features</title>
  <p>We direct readers to our
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/examples/maze_examples.html">examples</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html">docs</ext-link>,
  and
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/notebooks/">notebooks</ext-link>
  for more information. Our package can be installed from
  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/maze-dataset/">PyPi</ext-link>
  via <monospace>pip install maze-dataset</monospace>, or directly from
  the
  <ext-link ext-link-type="uri" xlink:href="https://github.com/understanding-search/maze-dataset">git
  repository</ext-link>
  (<xref alt="Michael I. Ivanitskiy et al., 2023a" rid="ref-maze-dataset-github" ref-type="bibr">Michael
  I. Ivanitskiy et al., 2023a</xref>).</p>
  <p>Datasets of mazes are created from a
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#MazeDatasetConfig"><monospace>MazeDatasetConfig</monospace></ext-link>
  configuration object, which allows specifying the number of mazes,
  their size, the generation algorithm, and various parameters for the
  generation algorithm. Datasets can also be filtered after generation
  to satisfy certain properties. Custom filters can be specified, and
  some filters are included in
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/dataset/filters.html#MazeDatasetFilters"><monospace>MazeDatasetFilters</monospace></ext-link>.</p>
  <sec id="visual-output-formats">
    <title>Visual Output Formats</title>
    <p>Internally, mazes are
    <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#SolvedMaze"><monospace>SolvedMaze</monospace></ext-link>
    objects, which have path information and an array optimized for
    storing sub-graphs of a lattice. These objects can be converted to
    and from several formats, shown in
    <xref alt="[fig:output-fmts]" rid="figU003Aoutput-fmts">[fig:output-fmts]</xref>,
    to maximize their utility in different contexts.</p>
    <p>In previous work, maze tasks have been used with Recurrent
    Convolutional Neural Network (RCNN) derived architectures
    (<xref alt="Schwarzschild, Borgnia, Gupta, Huang, et al., 2021" rid="ref-deepthinking" ref-type="bibr">Schwarzschild,
    Borgnia, Gupta, Huang, et al., 2021</xref>). To facilitate the use
    of our package in this context, we replicate the format of
    Schwarzschild, Borgnia, Gupta, Bansal, et al.
    (<xref alt="2021" rid="ref-easy_to_hard" ref-type="bibr">2021</xref>)
    and provide the
    <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/dataset/rasterized.html#RasterizedMazeDataset"><monospace>RasterizedMazeDataset</monospace></ext-link>
    class which returns rasterized pairs of (input, target) mazes as
    shown in
    <xref alt="[fig:e2h-raster]" rid="figU003Ae2h-raster">[fig:e2h-raster]</xref>.</p>
    <fig id="figU003Aoutput-fmts">
      <caption><p>Various output formats. Top row (left to right): ASCII
      diagram, rasterized pixel grid, and advanced display
      tool.</p></caption>
      <table-wrap>
        <table>
          <tbody>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="left"></td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="left"></td>
            </tr>
            <tr>
              <td align="left"> NumPy array of
              <monospace>dtype=uint8</monospace> and shape
              <monospace>(height*2+1, width*2+1, 3)</monospace>. The
              last dimension is RGB color. </td>
              <td align="left"> Simple text format for displaying mazes,
              useful for debugging in a terminal environment. Text
              representation of <monospace>as_pixels()</monospace>.
              </td>
              <td align="left"> Feature-rich plotting utility with
              support for multiple paths, heatmaps over positions, and
              more. </td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="left"></td>
            </tr>
            <tr>
              <td align="center"><inline-graphic mimetype="application" mime-subtype="pdf" xlink:href="outputs-pixels.pdf">
                <alt-text>image</alt-text>
              </inline-graphic></td>
              <td align="left"></td>
              <td align="right"><inline-graphic mimetype="application" mime-subtype="pdf" xlink:href="outputs-mazeplot.pdf">
                <alt-text>image</alt-text>
              </inline-graphic></td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="left"></td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </fig>
    <fig id="figU003Ae2h-raster">
      <caption><p> Input is the rasterized maze without the path marked
      (left), and provide as a target the maze with all but the correct
      path removed (right). Configuration options exist to adjust
      whether endpoints are included and if empty cells should be filled
      in. </p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="maze-raster-input-target.pdf" />
    </fig>
  </sec>
  <sec id="secU003Atokenized-output-formats">
    <title>Tokenized Output Formats</title>
    <p>Autoregressive transformer models can be quite sensitive to the
    exact format of input data, and may even use delimiter tokens to
    perform reasoning steps
    (<xref alt="Pfau et al., 2024" rid="ref-pfau2024dotbydot" ref-type="bibr">Pfau
    et al., 2024</xref>;
    <xref alt="Spies et al., 2024" rid="ref-spies2024causalworldmodels" ref-type="bibr">Spies
    et al., 2024</xref>). To facilitate systematic investigation of the
    effects of different representations of data on text model
    performance, we provide a variety of text output formats, with an
    example given in
    <xref alt="[fig:token-regions]" rid="figU003Atoken-regions">[fig:token-regions]</xref>.
    We utilize Finite State Transducers
    (<xref alt="Gallant, 2015" rid="ref-Gallant2015Transducers" ref-type="bibr">Gallant,
    2015</xref>) for efficiently storing valid tokenizers.</p>
    <fig id="figU003Atoken-regions">
      <caption><p> Example text output format with token regions
      highlighted.
      <styled-content style="background-color:  217,210,233 ">Adjacency
      list</styled-content>: text representation of the graph,
      <styled-content style="background-color:  217,234,211 ">Origin</styled-content>:
      starting coordinate,
      <styled-content style="background-color:  234,209,220 ">Target</styled-content>:
      ending coordinate,
      <styled-content style="background-color:  207,226,243 ">Path</styled-content>:
      maze solution sequence. By passing an instance of
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/tokenization.html#MazeTokenizerModular"><monospace>MazeTokenizerModular</monospace></ext-link>
      to
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#MazeDataset.as_tokens"><monospace>as_tokens(...)</monospace></ext-link>
      a maze can be converted to a text sequence. The
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/tokenization.html#MazeTokenizerModular"><monospace>MazeTokenizerModular</monospace></ext-link>
      class contains a rich set of options with 19 discrete parameters,
      resulting in over 5.8 million unique possible tokenizers.
      </p></caption>
      <p><styled-content style="background-color:  217,210,233 ">
      <monospace> &lt;ADJLIST_START&gt; (0,0) &lt;–&gt; (1,0) ; (2,0) &lt;–&gt; (3,0) ; (4,1) &lt;–&gt; (4,0) ; (2,0) &lt;–&gt; (2,1) ; </monospace></styled-content>
      <styled-content style="background-color:  217,210,233 ">
      <monospace> (1,0) &lt;–&gt; (1,1) ; (3,4) &lt;–&gt; (2,4) ; (4,2) &lt;–&gt; (4,3) ; (0,0) &lt;–&gt; (0,1) ; (0,3) &lt;–&gt; (0,2) ; </monospace></styled-content>
      <styled-content style="background-color:  217,210,233 ">
      <monospace> (4,4) &lt;–&gt; (3,4) ; (4,3) &lt;–&gt; (4,4) ; (4,1) &lt;–&gt; (4,2) ; (2,1) &lt;–&gt; (2,2) ; (1,4) &lt;–&gt; (0,4) ; </monospace></styled-content>
      <styled-content style="background-color:  217,210,233 ">
      <monospace> (1,2) &lt;–&gt; (0,2) ; (2,4) &lt;–&gt; (2,3) ; (4,0) &lt;–&gt; (3,0) ; (2,2) &lt;–&gt; (3,2) ; (1,2) &lt;–&gt; (2,2) ; </monospace></styled-content>
      <styled-content style="background-color:  217,210,233 ">
      <monospace> (1,3) &lt;–&gt; (0,3) ; (3,2) &lt;–&gt; (3,3) ; (0,2) &lt;–&gt; (0,1) ; (3,1) &lt;–&gt; (3,2) ; (1,3) &lt;–&gt; (1,4) ; </monospace></styled-content></p>
      <p><styled-content style="background-color:  217,210,233 ">
      <monospace> &lt;ADJLIST_END&gt; </monospace> </styled-content>
      <styled-content style="background-color:  217,234,211 ">
      <monospace> &lt;ORIGIN_START&gt; (1,3) &lt;ORIGIN_END&gt; </monospace>
      </styled-content>
      <styled-content style="background-color:  234,209,220 ">
      <monospace> &lt;TARGET_START&gt; (2,3) &lt;TARGET_END&gt; </monospace>
      </styled-content></p>
      <p><styled-content style="background-color:  207,226,243 ">
      <monospace> &lt;PATH_START&gt; (1,3) (0,3) (0,2) (1,2) (2,2) (2,1) (2,0) (3,0) (4,0) (4,1) (4,2) (4,3) (4,4) </monospace></styled-content>
      <styled-content style="background-color:  207,226,243 ">
      <monospace> (3,4) (2,4) (2,3) &lt;PATH_END&gt; </monospace>
      </styled-content>
      </p>
    </fig>
  </sec>
</sec>
<sec id="secU003Aimplementation">
  <title>Implementation</title>
  <p>Using an adjacency matrix for storing mazes would be memory
  inefficient by failing to exploit the highly sparse structure, while
  using an adjacency list could lead to a poor lookup time. This package
  utilizes a simple, efficient representation of mazes as subgraphs of a
  finite lattice, detailed in
  <xref alt="[fig:maze-impl]" rid="figU003Amaze-impl">[fig:maze-impl]</xref>,
  which we call a
  <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#LatticeMaze"><monospace>LatticeMaze</monospace></ext-link>.</p>
  <fig id="figU003Amaze-impl">
    <caption><p> We describe mazes with the following representation:
    for a <inline-formula><alternatives>
    <tex-math><![CDATA[2]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2</mml:mn></mml:math></alternatives></inline-formula>-dimensional
    lattice with <inline-formula><alternatives>
    <tex-math><![CDATA[r]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>r</mml:mi></mml:math></alternatives></inline-formula>
    rows and <inline-formula><alternatives>
    <tex-math><![CDATA[c]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>c</mml:mi></mml:math></alternatives></inline-formula>
    columns, we initialize a boolean array
    <inline-formula><alternatives>
    <tex-math><![CDATA[A = \{0, 1\}^{2 \times r \times c}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>r</mml:mi><mml:mo>×</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
    which we refer to in the code as a
    <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset.html#LatticeMaze.connection_list"><monospace>connection_list</monospace></ext-link>.
    The value at <inline-formula><alternatives>
    <tex-math><![CDATA[A[0,i,j]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    determines whether a <italic>downward</italic> connection exists
    from node <inline-formula><alternatives>
    <tex-math><![CDATA[[i,j]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    to <inline-formula><alternatives>
    <tex-math><![CDATA[[i+1, j]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
    Likewise, the value at <inline-formula><alternatives>
    <tex-math><![CDATA[A[1,i,j]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    determines whether a <italic>rightward</italic> connection to
    <inline-formula><alternatives>
    <tex-math><![CDATA[[i, j+1]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    exists. Thus, we avoid duplication of data about the existence of
    connections and facilitate fast lookup time, at the cost of
    requiring additional care with indexing. </p></caption>
    <table-wrap>
      <table>
        <tbody>
          <tr>
            <td align="center">Maze</td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[A[0]]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
            (downward)</td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[A[1]]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
            (rightward)</td>
          </tr>
          <tr>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </fig>
  <p>Our package is implemented in Python
  (<xref alt="Rossum, 1995" rid="ref-python" ref-type="bibr">Rossum,
  1995</xref>), and makes use of the extensive scientific computing
  ecosystem, including NumPy
  (<xref alt="Harris et al., 2020" rid="ref-numpy" ref-type="bibr">Harris
  et al., 2020</xref>) for array manipulation, plotting tools
  (<xref alt="Hunter, 2007" rid="ref-matplotlib" ref-type="bibr">Hunter,
  2007</xref>;
  <xref alt="Waskom, 2021" rid="ref-seaborn" ref-type="bibr">Waskom,
  2021</xref>), Jupyter notebooks
  (<xref alt="Kluyver et al., 2016" rid="ref-jupyter" ref-type="bibr">Kluyver
  et al., 2016</xref>), and PySR
  (<xref alt="Cranmer, 2023" rid="ref-pysr" ref-type="bibr">Cranmer,
  2023</xref>) for symbolic regression.</p>
  <sec id="benchmarks">
    <title>Benchmarks</title>
    <p>We benchmarks for generation time across various configurations
    in
    <xref alt="[tab:benchmarks]" rid="tabU003Abenchmarks">[tab:benchmarks]</xref>
    and
    <xref alt="[fig:benchmarks]" rid="figU003Abenchmarks">[fig:benchmarks]</xref>.
    Experiments were performed on a
    <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners#standard-github-hosted-runners-for-public-repositories">standard
    GitHub runner</ext-link> without parallelism. Additionally, maze
    generation under certain constraints may not always be successful,
    and for this we provide a way to estimate the success rate of a
    given configuration, described in
    <xref alt="[fig:sre]" rid="figU003Asre">[fig:sre]</xref>.</p>
    <boxed-text id="tabU003Abenchmarks">
      <table-wrap>
        <caption>
          <p>Generation times in milliseconds for various algorithms and
          maze sizes. More information can be found on the .</p>
        </caption>
        <table>
          <tbody>
            <tr>
              <td align="left">maze_ctor</td>
              <td align="left">keyword args</td>
              <td align="right">all sizes</td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
            </tr>
            <tr>
              <td align="left"><inline-formula><alternatives>
              <tex-math><![CDATA[g \leq 10]]></tex-math>
              <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>g</mml:mi><mml:mo>≤</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
              <td align="left"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
            </tr>
            <tr>
              <td align="left"><inline-formula><alternatives>
              <tex-math><![CDATA[g \in (10, 32]]]></tex-math>
              <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>g</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>32</mml:mn><mml:mo stretchy="false" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></td>
              <td align="left"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
            </tr>
            <tr>
              <td align="left"><inline-formula><alternatives>
              <tex-math><![CDATA[g > 32]]></tex-math>
              <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>g</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
              <td align="left"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
              <td align="right"></td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="right">28.0</td>
              <td align="right">2.8</td>
              <td align="right">20.3</td>
              <td align="right">131.8</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">accessible_cells=20</td>
              <td align="right">2.3</td>
              <td align="right">2.2</td>
              <td align="right">2.4</td>
              <td align="right">2.2</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">do_forks=False</td>
              <td align="right">2.7</td>
              <td align="right">2.2</td>
              <td align="right">3.1</td>
              <td align="right">3.5</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">max_tree_depth=0.5</td>
              <td align="right">2.5</td>
              <td align="right">2.0</td>
              <td align="right">2.7</td>
              <td align="right">4.0</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">p=0.1</td>
              <td align="right">43.9</td>
              <td align="right">2.8</td>
              <td align="right">33.9</td>
              <td align="right">208.0</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">p=0.4</td>
              <td align="right">48.7</td>
              <td align="right">3.0</td>
              <td align="right">36.5</td>
              <td align="right">233.5</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="right">12.8</td>
              <td align="right">1.9</td>
              <td align="right">10.3</td>
              <td align="right">55.8</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left">p=1.0</td>
              <td align="right">50.2</td>
              <td align="right">2.6</td>
              <td align="right">37.2</td>
              <td align="right">242.5</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="right">10.2</td>
              <td align="right">1.7</td>
              <td align="right">8.9</td>
              <td align="right">42.1</td>
            </tr>
            <tr>
              <td align="left"></td>
              <td align="left"></td>
              <td align="right">676.5</td>
              <td align="right">7.8</td>
              <td align="right">188.6</td>
              <td align="right">3992.6</td>
            </tr>
            <tr>
              <td align="left">mean</td>
              <td align="left"></td>
              <td align="right">559.9</td>
              <td align="right">13.0</td>
              <td align="right">223.5</td>
              <td align="right">3146.9</td>
            </tr>
            <tr>
              <td align="left">median</td>
              <td align="left"></td>
              <td align="right">11.1</td>
              <td align="right">6.5</td>
              <td align="right">32.9</td>
              <td align="right">302.7</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </boxed-text>
    <fig id="figU003Abenchmarks">
      <caption><p> Plot of maze generation time. Generation time scales
      roughly exponentially with maze size for all algorithms.
      Generation time per maze does not depend on the number of mazes
      being generated, and there is minimal overhead to initializing the
      generation process for a small dataset. Wilson’s algorithm is
      notably less efficient than others and has high variance. Note
      that values are averaged across all parameter sets for that
      algorithm. More information can be found on the
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/benchmarks/">benchmarks
      page</ext-link>. </p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="gridsize-vs-gentime.pdf" />
    </fig>
    <fig id="figU003Asre">
      <caption><p> In order to replicate the exact dataset distribution
      of (), the parameter
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/maze_dataset/dataset/maze_dataset_config.html#MazeDatasetConfig.endpoint_kwargs"><monospace>MazeDatasetConfig.endpoint_kwargs</monospace></ext-link>
      allows for additional constraints, such as enforcing that the
      start or end point be in a “dead end” with only one accessible
      neighbor cell. However, combining these constraints with cyclic
      mazes can lead to an absence of valid start and end points. To
      deal with this, our package provides a way to estimate the success
      rate of a given configuration using a symbolic regression model
      trained with PySR (). An example of both empirical and predicted
      success rates as a function of the percolation probability
      <inline-formula><alternatives>
      <tex-math><![CDATA[p]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>p</mml:mi></mml:math></alternatives></inline-formula>
      for various maze sizes, percolation with and without depth first
      search, and <monospace>endpoint_kwargs</monospace> requiring that
      both the start and end be in unique dead ends. Empirical measures
      derived from a sample of 128 mazes. More information can be found
      on the
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/benchmarks/">benchmarks
      page</ext-link> and in the notebook
      <ext-link ext-link-type="uri" xlink:href="https://understanding-search.github.io/maze-dataset/notebooks/estimate_dataset_fractions.html"><monospace>estimate_dataset_fractions.ipynb</monospace></ext-link>.
      </p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="ep_deadends_unique-crop.pdf" />
    </fig>
  </sec>
</sec>
<sec id="usage-in-research">
  <title>Usage in Research</title>
  <p>This package was originally built for the needs of the
  <monospace>maze-transformer</monospace> project
  (<xref alt="Michael I. Ivanitskiy et al., 2023b" rid="ref-maze-transformer-github" ref-type="bibr">Michael
  I. Ivanitskiy et al., 2023b</xref>), which aims to investigate spatial
  planning and world models in autoregressive transformer models trained
  on mazes
  (<xref alt="Michael Igorevich Ivanitskiy, Spies, et al., 2023" rid="ref-ivanitskiy2023structuredworldreps" ref-type="bibr">Michael
  Igorevich Ivanitskiy, Spies, et al., 2023</xref>;
  <xref alt="Michael Igorevich Ivanitskiy, Shah, et al., 2023" rid="ref-maze-dataset-arxiv-2023" ref-type="bibr">Michael
  Igorevich Ivanitskiy, Shah, et al., 2023</xref>;
  <xref alt="Spies et al., 2024" rid="ref-spies2024causalworldmodels" ref-type="bibr">Spies
  et al., 2024</xref>). It was extended for work on understanding the
  mechanisms by which recurrent convolutional and implicit networks
  (<xref alt="Fung et al., 2022" rid="ref-fung2022jfb" ref-type="bibr">Fung
  et al., 2022</xref>) solve mazes given a rasterized view
  (<xref alt="Knutson et al., 2024" rid="ref-knutson2024logicalextrapolation" ref-type="bibr">Knutson
  et al., 2024</xref>), which required matching the pixel-padded and
  endpoint constrained output format of Schwarzschild, Borgnia, Gupta,
  Bansal, et al.
  (<xref alt="2021" rid="ref-easy_to_hard" ref-type="bibr">2021</xref>).
  Ongoing work using <monospace>maze-dataset</monospace> aims to
  investigate the effects of varying the tokenization format on the
  performance of pretrained LLMs on spatial reasoning.</p>
  <p>At the time of writing, this software package has been actively
  used in work by other groups:</p>
  <list list-type="bullet">
    <list-item>
      <p>By Nolte et al.
      (<xref alt="2024" rid="ref-nolte2024multistep" ref-type="bibr">2024</xref>)
      to compare the effectiveness of transformers trained with the
      MLM-<inline-formula><alternatives>
      <tex-math><![CDATA[\mathcal{U}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>𝒰</mml:mi></mml:math></alternatives></inline-formula>
      (<xref alt="Kitouni et al., 2024" rid="ref-MLMU-kitouni2024factorization" ref-type="bibr">Kitouni
      et al., 2024</xref>) multistep prediction objective against
      standard autoregressive training for multi-step planning on our
      maze task.</p>
    </list-item>
    <list-item>
      <p>By Wang et al.
      (<xref alt="2024" rid="ref-wang2024imperative" ref-type="bibr">2024</xref>)
      and Chen et al.
      (<xref alt="2024" rid="ref-chen2024iaimperative" ref-type="bibr">2024</xref>)
      to study imperative learning.</p>
    </list-item>
    <list-item>
      <p>By Zhang et al.
      (<xref alt="2025a" rid="ref-zhang2025tscend" ref-type="bibr">2025a</xref>)
      to introduce a novel framework for reasoning diffusion models.</p>
    </list-item>
    <list-item>
      <p>By Dao &amp; Vu
      (<xref alt="2025" rid="ref-dao2025alphamaze" ref-type="bibr">2025</xref>)
      to improve spatial reasoning in LLMs with GRPO.</p>
    </list-item>
    <list-item>
      <p>By Cai et al.
      (<xref alt="2025" rid="ref-cai2025morse" ref-type="bibr">2025</xref>)
      to create a multimodal reasoning benchmark, via mazes in
      videos.</p>
    </list-item>
    <list-item>
      <p>By Xu et al.
      (<xref alt="2025" rid="ref-xu2025visual" ref-type="bibr">2025</xref>)
      to study visual planning in LLMs.</p>
    </list-item>
    <list-item>
      <p>By Lee et al.
      (<xref alt="2025" rid="ref-lee2025adaptive" ref-type="bibr">2025</xref>)
      to evaluate adaptive inference-time scaling with diffusion models
      on maze navigation tasks.</p>
    </list-item>
    <list-item>
      <p>By Zhang et al.
      (<xref alt="2025b" rid="ref-zhang2025vfscale" ref-type="bibr">2025b</xref>)
      to test verifier-free diffusion models.</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was partially funded by National Science Foundation
  awards DMS-2110745 and DMS-2309810. We are also grateful to LTFF and
  FAR Labs for hosting authors MII, AFS, and TR for a residency visit,
  and to various members of FAR’s technical staff for their advice.</p>
  <p>This work was partially supported by AI Safety Camp and AI Safety
  Support, which also brought many of the authors together. We would
  like to thank our former collaborators at AI Safety Camp and other
  users and contributors to the <monospace>maze-dataset</monospace>
  package: Benji Berczi, Guillaume Corlouer, William Edwards, Leon
  Eshuijs, Chris Mathwin, Lucia Quirke, Can Rager, Adrians Skapars,
  Rusheb Shah, Johannes Treutlein, and Dan Valentine.</p>
  <p>We thank the Mines Optimization and Deep Learning group (MODL) for
  fruitful discussions. We also thank Michael Rosenberg for recommending
  the usage of Finite State Transducers for storing tokenizer validation
  information.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-fung2022jfb">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Fung</surname><given-names>Samy Wu</given-names></name>
        <name><surname>Heaton</surname><given-names>Howard</given-names></name>
        <name><surname>Li</surname><given-names>Qiuwei</given-names></name>
        <name><surname>McKenzie</surname><given-names>Daniel</given-names></name>
        <name><surname>Osher</surname><given-names>Stanley</given-names></name>
        <name><surname>Yin</surname><given-names>Wotao</given-names></name>
      </person-group>
      <article-title>Jfb: Jacobian-free backpropagation for implicit networks</article-title>
      <source>Proceedings of the AAAI conference on artificial intelligence</source>
      <year iso-8601-date="2022">2022</year>
      <volume>36</volume>
      <pub-id pub-id-type="doi">10.1609/aaai.v36i6.20619</pub-id>
      <fpage>6648</fpage>
      <lpage>6656</lpage>
    </element-citation>
  </ref>
  <ref id="ref-eval-LLM-graphs">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Liu</surname><given-names>Chang</given-names></name>
        <name><surname>Wu</surname><given-names>Bo</given-names></name>
      </person-group>
      <article-title>Evaluating large language models on graphs: Performance insights and comparative analysis</article-title>
      <source>arXiv preprint arXiv:2308.11224</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2308.11224</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-zhang2025tscend">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Tao</given-names></name>
        <name><surname>Pan</surname><given-names>Jia-Shu</given-names></name>
        <name><surname>Feng</surname><given-names>Ruiqi</given-names></name>
        <name><surname>Wu</surname><given-names>Tailin</given-names></name>
      </person-group>
      <article-title>T-SCEND: Test-time scalable MCTS-enhanced diffusion model</article-title>
      <source>arXiv preprint arXiv:2502.01989</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2502.01989</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dao2025alphamaze">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dao</surname><given-names>Alan</given-names></name>
        <name><surname>Vu</surname><given-names>Dinh Bach</given-names></name>
      </person-group>
      <article-title>AlphaMaze: Enhancing large language models’ spatial intelligence via GRPO</article-title>
      <source>arXiv preprint arXiv:2502.14669</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2502.14669</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mdl-suite">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nag</surname><given-names>Akash</given-names></name>
      </person-group>
      <article-title>MDL suite: A language, generator and compiler for describing mazes</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>46</issue>
      <pub-id pub-id-type="doi">10.21105/joss.01815</pub-id>
      <fpage>1815</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-mathematica-maze">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Guo</surname><given-names>Cong</given-names></name>
        <name><surname>Barthelet</surname><given-names>Luc</given-names></name>
        <name><surname>Morris</surname><given-names>Rob</given-names></name>
      </person-group>
      <article-title>Maze generator and solver</article-title>
      <publisher-name>Wolfram Demonstrations Project, https://demonstrations.wolfram.com/MazeGeneratorAndSolver/</publisher-name>
      <year iso-8601-date="2011">2011</year>
    </element-citation>
  </ref>
  <ref id="ref-pysr">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cranmer</surname><given-names>Miles</given-names></name>
      </person-group>
      <article-title>Interpretable machine learning for science with PySR and SymbolicRegression.jl</article-title>
      <source>arXiv preprint arXiv:2305.01582</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2305.01582</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mazegenerator-net">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Alance AB</string-name>
      </person-group>
      <article-title>Maze generator</article-title>
      <publisher-name>http://www.mazegenerator.net</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-gh-oppenheimj2018maze">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Oppenheim</surname><given-names>Jonas</given-names></name>
      </person-group>
      <article-title>Maze-generator: Generate a random maze represented as a 2D array using depth-first search</article-title>
      <publisher-name>https://github.com/oppenheimj/maze-generator/; GitHub</publisher-name>
      <year iso-8601-date="2018">2018</year>
    </element-citation>
  </ref>
  <ref id="ref-ayaz2008maze">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ayaz</surname><given-names>Hasan</given-names></name>
        <name><surname>Allen</surname><given-names>Sarah L</given-names></name>
        <name><surname>Platek</surname><given-names>Steven M</given-names></name>
        <name><surname>Onaral</surname><given-names>Banu</given-names></name>
      </person-group>
      <article-title>Maze suite 1.0: A complete set of tools to prepare, present, and analyze navigational and spatial cognitive neuroscience experiments</article-title>
      <source>Behavior research methods</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2008">2008</year>
      <volume>40</volume>
      <pub-id pub-id-type="doi">10.3758/brm.40.1.353</pub-id>
      <fpage>353</fpage>
      <lpage>359</lpage>
    </element-citation>
  </ref>
  <ref id="ref-interpretability-survey">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Ho</surname><given-names>Anson</given-names></name>
        <name><surname>Casper</surname><given-names>Stephen</given-names></name>
        <name><surname>Hadfield-Menell</surname><given-names>Dylan</given-names></name>
      </person-group>
      <article-title>Toward transparent ai: A survey on interpreting the inner structures of deep neural networks</article-title>
      <source>2023 IEEE conference on secure and trustworthy machine learning (SaTML)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/satml54575.2023.00039</pub-id>
      <fpage>464</fpage>
      <lpage>483</lpage>
    </element-citation>
  </ref>
  <ref id="ref-easy_to_hard">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Schwarzschild</surname><given-names>Avi</given-names></name>
        <name><surname>Borgnia</surname><given-names>Eitan</given-names></name>
        <name><surname>Gupta</surname><given-names>Arjun</given-names></name>
        <name><surname>Bansal</surname><given-names>Arpit</given-names></name>
        <name><surname>Emam</surname><given-names>Zeyad</given-names></name>
        <name><surname>Huang</surname><given-names>Furong</given-names></name>
        <name><surname>Goldblum</surname><given-names>Micah</given-names></name>
        <name><surname>Goldstein</surname><given-names>Tom</given-names></name>
      </person-group>
      <article-title>Datasets for Studying Generalization from Easy to Hard Examples</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2021-09">2021</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-03">2023</year><month>09</month><day>03</day></date-in-citation>
      <uri>http://arxiv.org/abs/2108.06011</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2108.06011</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-deepthinking">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schwarzschild</surname><given-names>Avi</given-names></name>
        <name><surname>Borgnia</surname><given-names>Eitan</given-names></name>
        <name><surname>Gupta</surname><given-names>Arjun</given-names></name>
        <name><surname>Huang</surname><given-names>Furong</given-names></name>
        <name><surname>Vishkin</surname><given-names>Uzi</given-names></name>
        <name><surname>Goldblum</surname><given-names>Micah</given-names></name>
        <name><surname>Goldstein</surname><given-names>Tom</given-names></name>
      </person-group>
      <article-title>Can you learn an algorithm? Generalizing from easy to hard problems with recurrent networks</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2021">2021</year>
      <volume>34</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.2106.04537</pub-id>
      <fpage>6695</fpage>
      <lpage>6706</lpage>
    </element-citation>
  </ref>
  <ref id="ref-eval-gpt-visual">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Singla</surname><given-names>Adish</given-names></name>
      </person-group>
      <article-title>Evaluating ChatGPT and GPT-4 for visual programming</article-title>
      <source>arXiv preprint arXiv:2308.02522</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2308.02522</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-maze-dataset-arxiv-2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ivanitskiy</surname><given-names>Michael Igorevich</given-names></name>
        <name><surname>Shah</surname><given-names>Rusheb</given-names></name>
        <name><surname>Spies</surname><given-names>Alex F</given-names></name>
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Valentine</surname><given-names>Dan</given-names></name>
        <name><surname>Rager</surname><given-names>Can</given-names></name>
        <name><surname>Quirke</surname><given-names>Lucia</given-names></name>
        <name><surname>Mathwin</surname><given-names>Chris</given-names></name>
        <name><surname>Corlouer</surname><given-names>Guillaume</given-names></name>
        <name><surname>Behn</surname><given-names>Cecilia Diniz</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>A configurable library for generating and manipulating maze datasets</article-title>
      <source>arXiv preprint arXiv:2309.10498</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2309.10498</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-maze-dataset-github">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ivanitskiy</surname><given-names>Michael I.</given-names></name>
        <name><surname>Shah</surname><given-names>Rusheb</given-names></name>
        <name><surname>Spies</surname><given-names>Alex F.</given-names></name>
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Valentine</surname><given-names>Dan</given-names></name>
        <name><surname>Rager</surname><given-names>Can</given-names></name>
        <name><surname>Quirke</surname><given-names>Lucia</given-names></name>
        <name><surname>Corlouer</surname><given-names>Guillaume</given-names></name>
        <name><surname>Mathwin</surname><given-names>Chris</given-names></name>
      </person-group>
      <article-title>Maze dataset</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/understanding-search/maze-dataset</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2309.10498</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-maze-transformer-github">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ivanitskiy</surname><given-names>Michael I.</given-names></name>
        <name><surname>Shah</surname><given-names>Rusheb</given-names></name>
        <name><surname>Spies</surname><given-names>Alex F.</given-names></name>
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Valentine</surname><given-names>Dan</given-names></name>
        <name><surname>Rager</surname><given-names>Can</given-names></name>
        <name><surname>Quirke</surname><given-names>Lucia</given-names></name>
        <name><surname>Corlouer</surname><given-names>Guillaume</given-names></name>
        <name><surname>Mathwin</surname><given-names>Chris</given-names></name>
      </person-group>
      <article-title>Maze transformer interpretability</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/understanding-search/maze-transformer</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2312.02566</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gh_Ehsan_2022">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ehsan</surname><given-names>Emad</given-names></name>
      </person-group>
      <article-title>Maze</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/emadehsan/maze</uri>
    </element-citation>
  </ref>
  <ref id="ref-gh_Nemeth_2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Németh</surname><given-names>Ferenc</given-names></name>
      </person-group>
      <article-title>Maze-generation-algorithms</article-title>
      <year iso-8601-date="2019">2019</year>
      <uri>https://github.com/ferenc-nemeth/maze-generation-algorithms</uri>
    </element-citation>
  </ref>
  <ref id="ref-zanj">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ivanitskiy</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>ZANJ</article-title>
      <uri>https://github.com/mivanit/ZANJ</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.15540393</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ivanitskiy2023structuredworldreps">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ivanitskiy</surname><given-names>Michael Igorevich</given-names></name>
        <name><surname>Spies</surname><given-names>Alex F</given-names></name>
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Corlouer</surname><given-names>Guillaume</given-names></name>
        <name><surname>Mathwin</surname><given-names>Chris</given-names></name>
        <name><surname>Quirke</surname><given-names>Lucia</given-names></name>
        <name><surname>Rager</surname><given-names>Can</given-names></name>
        <name><surname>Shah</surname><given-names>Rusheb</given-names></name>
        <name><surname>Valentine</surname><given-names>Dan</given-names></name>
        <name><surname>Behn</surname><given-names>Cecilia Diniz</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Structured world representations in maze-solving transformers</article-title>
      <source>arXiv preprint arXiv:2312.02566</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2312.02566</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-spies2024causalworldmodels">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spies</surname><given-names>Alex F</given-names></name>
        <name><surname>Edwards</surname><given-names>William</given-names></name>
        <name><surname>Ivanitskiy</surname><given-names>Michael I</given-names></name>
        <name><surname>Skapars</surname><given-names>Adrians</given-names></name>
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Inoue</surname><given-names>Katsumi</given-names></name>
        <name><surname>Russo</surname><given-names>Alessandra</given-names></name>
        <name><surname>Shanahan</surname><given-names>Murray</given-names></name>
      </person-group>
      <article-title>Transformers use causal world models in maze-solving tasks</article-title>
      <source>arXiv preprint arXiv:2412.11867</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2412.11867</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-knutson2024logicalextrapolation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Knutson</surname><given-names>Brandon</given-names></name>
        <name><surname>Rabeendran</surname><given-names>Amandin Chyba</given-names></name>
        <name><surname>Ivanitskiy</surname><given-names>Michael</given-names></name>
        <name><surname>Pettyjohn</surname><given-names>Jordan</given-names></name>
        <name><surname>Diniz-Behn</surname><given-names>Cecilia</given-names></name>
        <name><surname>Fung</surname><given-names>Samy Wu</given-names></name>
        <name><surname>McKenzie</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>On logical extrapolation for mazes with recurrent and implicit networks</article-title>
      <source>arXiv preprint arXiv:2410.03020</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2410.03020</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-nolte2024multistep">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nolte</surname><given-names>Niklas</given-names></name>
        <name><surname>Kitouni</surname><given-names>Ouail</given-names></name>
        <name><surname>Williams</surname><given-names>Adina</given-names></name>
        <name><surname>Rabbat</surname><given-names>Mike</given-names></name>
        <name><surname>Ibrahim</surname><given-names>Mark</given-names></name>
      </person-group>
      <article-title>Transformers can navigate mazes with multi-step prediction</article-title>
      <source>arXiv preprint arXiv:2412.05117</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2412.05117</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-MLMU-kitouni2024factorization">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kitouni</surname><given-names>Ouail</given-names></name>
        <name><surname>Nolte</surname><given-names>Niklas S</given-names></name>
        <name><surname>Williams</surname><given-names>Adina</given-names></name>
        <name><surname>Rabbat</surname><given-names>Michael</given-names></name>
        <name><surname>Bouchacourt</surname><given-names>Diane</given-names></name>
        <name><surname>Ibrahim</surname><given-names>Mark</given-names></name>
      </person-group>
      <article-title>The factorization curse: Which tokens you predict underlie the reversal curse and more</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2024">2024</year>
      <volume>37</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.2406.05183</pub-id>
      <fpage>112329</fpage>
      <lpage>112355</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2024imperative">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Chen</given-names></name>
        <name><surname>Ji</surname><given-names>Kaiyi</given-names></name>
        <name><surname>Geng</surname><given-names>Junyi</given-names></name>
        <name><surname>Ren</surname><given-names>Zhongqiang</given-names></name>
        <name><surname>Fu</surname><given-names>Taimeng</given-names></name>
        <name><surname>Yang</surname><given-names>Fan</given-names></name>
        <name><surname>Guo</surname><given-names>Yifan</given-names></name>
        <name><surname>He</surname><given-names>Haonan</given-names></name>
        <name><surname>Chen</surname><given-names>Xiangyu</given-names></name>
        <name><surname>Zhan</surname><given-names>Zitong</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Imperative learning: A self-supervised neural-symbolic learning framework for robot autonomy</article-title>
      <source>arXiv preprint arXiv:2406.16087</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2406.16087</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-pfau2024dotbydot">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pfau</surname><given-names>Jacob</given-names></name>
        <name><surname>Merrill</surname><given-names>William</given-names></name>
        <name><surname>Bowman</surname><given-names>Samuel R</given-names></name>
      </person-group>
      <article-title>Let’s think dot by dot: Hidden computation in transformer language models</article-title>
      <source>arXiv preprint arXiv:2404.15758</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2404.15758</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chen2024iaimperative">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>Xiangyu</given-names></name>
        <name><surname>Yang</surname><given-names>Fan</given-names></name>
        <name><surname>Wang</surname><given-names>Chen</given-names></name>
      </person-group>
      <article-title>iA*: Imperative learning-based A* search for pathfinding</article-title>
      <source>arXiv preprint arXiv:2403.15870</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2403.15870</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-cai2025morse">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cai</surname><given-names>Zikui</given-names></name>
        <name><surname>Wang</surname><given-names>Andrew</given-names></name>
        <name><surname>Satheesh</surname><given-names>Anirudh</given-names></name>
        <name><surname>Nakhawa</surname><given-names>Ankit</given-names></name>
        <name><surname>Jae</surname><given-names>Hyunwoo</given-names></name>
        <name><surname>Powell</surname><given-names>Keenan</given-names></name>
        <name><surname>Liu</surname><given-names>Minghui</given-names></name>
        <name><surname>Jay</surname><given-names>Neel</given-names></name>
        <name><surname>Oh</surname><given-names>Sungbin</given-names></name>
        <name><surname>Wang</surname><given-names>Xiyao</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>MORSE-500: A programmatically controllable video benchmark to stress-test multimodal reasoning</article-title>
      <source>arXiv preprint arXiv:2506.05523</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2506.05523</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-xu2025visual">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Xu</surname><given-names>Yi</given-names></name>
        <name><surname>Li</surname><given-names>Chengzu</given-names></name>
        <name><surname>Zhou</surname><given-names>Han</given-names></name>
        <name><surname>Wan</surname><given-names>Xingchen</given-names></name>
        <name><surname>Zhang</surname><given-names>Caiqi</given-names></name>
        <name><surname>Korhonen</surname><given-names>Anna</given-names></name>
        <name><surname>Vulić</surname><given-names>Ivan</given-names></name>
      </person-group>
      <article-title>Visual planning: Let’s think only with images</article-title>
      <source>arXiv preprint arXiv:2505.11409</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2505.11409</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lee2025adaptive">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lee</surname><given-names>Gyubin</given-names></name>
        <name><surname>Bao</surname><given-names>Truong Nhat Nguyen</given-names></name>
        <name><surname>Yoon</surname><given-names>Jaesik</given-names></name>
        <name><surname>Lee</surname><given-names>Dongwoo</given-names></name>
        <name><surname>Kim</surname><given-names>Minsu</given-names></name>
        <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>
        <name><surname>Ahn</surname><given-names>Sungjin</given-names></name>
      </person-group>
      <article-title>Adaptive cyclic diffusion for inference scaling</article-title>
      <source>arXiv preprint arXiv:2505.14036</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2505.14036</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-zhang2025vfscale">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Tao</given-names></name>
        <name><surname>Pan</surname><given-names>Jia-Shu</given-names></name>
        <name><surname>Feng</surname><given-names>Ruiqi</given-names></name>
        <name><surname>Wu</surname><given-names>Tailin</given-names></name>
      </person-group>
      <article-title>VFScale: Intrinsic reasoning through verifier-free test-time scalable diffusion model</article-title>
      <source>arXiv preprint arXiv:2502.01989</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2502.01989</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-harriesMazeExplorerCustomisable3D2019">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Harries</surname><given-names>Luke</given-names></name>
        <name><surname>Lee</surname><given-names>Sebastian</given-names></name>
        <name><surname>Rzepecki</surname><given-names>Jaroslaw</given-names></name>
        <name><surname>Hofmann</surname><given-names>Katja</given-names></name>
        <name><surname>Devlin</surname><given-names>Sam</given-names></name>
      </person-group>
      <article-title>MazeExplorer: A Customisable 3D Benchmark for Assessing Generalisation in Reinforcement Learning</article-title>
      <source>2019 IEEE Conf. Games CoG</source>
      <publisher-name>IEEE Press</publisher-name>
      <pub-id pub-id-type="doi">10.1109/cig.2019.8848048</pub-id>
      <fpage>1</fpage>
      <lpage>4</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cobbe2019procgen">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cobbe</surname><given-names>Karl</given-names></name>
        <name><surname>Hesse</surname><given-names>Christopher</given-names></name>
        <name><surname>Hilton</surname><given-names>Jacob</given-names></name>
        <name><surname>Schulman</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Leveraging procedural generation to benchmark reinforcement learning</article-title>
      <source>arXiv preprint arXiv:1912.01588</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.01588</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-seaborn">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Waskom</surname><given-names>Michael L.</given-names></name>
      </person-group>
      <article-title>seaborn: Statistical data visualization</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>60</issue>
      <uri>https://doi.org/10.21105/joss.03021</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03021</pub-id>
      <fpage>3021</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-python">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Rossum</surname><given-names>Guido van</given-names></name>
      </person-group>
      <article-title>Python reference manual</article-title>
      <publisher-name>Centrum voor Wiskunde; Informatica (CWI)</publisher-name>
      <year iso-8601-date="1995">1995</year>
      <uri>https://ir.cwi.nl/pub/5008/05008D.pdf</uri>
    </element-citation>
  </ref>
  <ref id="ref-numpy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Walt</surname><given-names>Stefan J. van der</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <year iso-8601-date="2020">2020</year>
      <volume>585</volume>
      <uri>https://doi.org/10.1038/s41586-020-2649-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
  <ref id="ref-matplotlib">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hunter</surname><given-names>John D.</given-names></name>
      </person-group>
      <article-title>Matplotlib: A 2D graphics environment</article-title>
      <source>Computing in Science and Engineering</source>
      <year iso-8601-date="2007">2007</year>
      <volume>9</volume>
      <issue>3</issue>
      <uri>https://doi.org/10.1109/MCSE.2007.55</uri>
      <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
      <fpage>90</fpage>
      <lpage>95</lpage>
    </element-citation>
  </ref>
  <ref id="ref-jupyter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Kluyver</surname><given-names>Thomas</given-names></name>
        <name><surname>Ragan-Kelley</surname><given-names>Benjamin</given-names></name>
        <name><surname>Perez</surname><given-names>Fernando</given-names></name>
        <name><surname>Granger</surname><given-names>Brian</given-names></name>
        <name><surname>Bussonnier</surname><given-names>Matthias</given-names></name>
        <name><surname>Frederic</surname><given-names>Jonathan</given-names></name>
        <name><surname>Kelley</surname><given-names>Kyle</given-names></name>
        <name><surname>Hamrick</surname><given-names>Jessica</given-names></name>
        <name><surname>Grout</surname><given-names>Jason</given-names></name>
        <name><surname>Corlay</surname><given-names>Sylvain</given-names></name>
        <name><surname>Ivanov</surname><given-names>Paul</given-names></name>
        <name><surname>Avila</surname><given-names>Damian</given-names></name>
        <name><surname>Abdalla</surname><given-names>Safia</given-names></name>
        <name><surname>Willing</surname><given-names>Carol</given-names></name>
      </person-group>
      <article-title>Jupyter notebooks - a publishing format for reproducible computational workflows</article-title>
      <source>Proceedings of the 20th international conference on electronic publishing</source>
      <publisher-name>IOS Press</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <uri>https://escholarship.org/uc/item/08b3d4s2</uri>
      <pub-id pub-id-type="doi">10.3233/978-1-61499-649-1-87</pub-id>
      <fpage>87</fpage>
      <lpage>90</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Gallant2015Transducers">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Gallant</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>Index 1,600,000,000 keys with automata and rust</article-title>
      <publisher-name>https://burntsushi.net/transducers/</publisher-name>
      <year iso-8601-date="2015">2015</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
