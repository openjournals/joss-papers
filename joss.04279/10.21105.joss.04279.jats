<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4279</article-id>
<article-id pub-id-type="doi">10.21105/joss.04279</article-id>
<title-group>
<article-title>DuoDIC: 3D Digital Image Correlation in
MATLAB</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">0000-0003-3215-0401</contrib-id>
<name>
<surname>Solav</surname>
<given-names>Dana</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Silverstein</surname>
<given-names>Asaf</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Faculty of Mechanical Engineering, Technion, Haifa,
Israel</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-02-13">
<day>13</day>
<month>2</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>74</issue>
<fpage>4279</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>MATLAB</kwd>
<kwd>digital image correlation</kwd>
<kwd>material testing</kwd>
<kwd>full-field strain</kwd>
<kwd>full-field deformations</kwd>
<kwd>Ncorr</kwd>
<kwd>Stereo camera calibration</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Three-dimensional Digital Image Correlation (3D-DIC) is a
  non-contact optical-numerical technique for measuring the 3D shape and
  full-field displacement, deformation, and strain, from stereo digital
  images of the surface of an object. 3D-DIC is useful in numerous
  applications, such as characterizing the mechanical behavior of
  materials and structures, quantifying material parameters, and
  validating numerical simulations.</p>
  <p><monospace>DuoDIC</monospace> is a freely available open source
  MATLAB toolbox for 2-camera stereo 3D-DIC, which can be used either as
  a standalone package or as functions in custom scripts.
  <monospace>DuoDIC</monospace> receives two series of synchronized
  images taken from two cameras: (1) images of a flat checkerboard
  target, which are used to calibrate the stereo camera pair; and (2)
  images of a speckled test object, which may undergo movement and
  deformation. The toolbox processes the image series and integrates
  several camera calibration algorithms with the 2D subset-based DIC
  software <monospace>Ncorr</monospace>
  (<xref alt="Blaber et al., 2015" rid="ref-Blaber2015" ref-type="bibr">Blaber
  et al., 2015</xref>), to transform matching image points into 3D
  points, and outputs a dynamic point cloud, meshed surfaces, rigid body
  motion, and full-field displacement, deformation, and strain measures.
  Furthermore, <monospace>DuoDIC</monospace> offers advanced functions
  to visualize various measures on the 3D meshes and overlaid on the
  original images.</p>
  <p>The simple user interface allows novice users to perform 3D-DIC
  analyses without interacting with MATLAB syntax, while stand-alone
  functions can be integrated in custom scripts by more proficient
  MATLAB users. As such, <monospace>DuoDIC</monospace> is suitable for
  students, researchers, and professionals in various fields.</p>
  <p>The package is composed of four main scripts: (1) stereo camera
  calibration; (2) image cross-correlation (2D-DIC); (3) 3D
  reconstruction; and (4) post-processing. This paper describes the
  algorithms implemented in each step and demonstrates its performance
  in two test cases, which are also included as
  <ext-link ext-link-type="uri" xlink:href="https://github.com/SolavLab/DuoDIC/tree/main/sample_data">sample
  data</ext-link>: rigid body translations of a cylindrical container
  and uniaxial tension of a rubber dog-bone specimen.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>3D-DIC is useful in numerous applications where the full-field
  displacements and strains are required, primarily for measuring the
  mechanical response of materials and structures and for characterizing
  mechanical properties, with widespread applications from nano- to
  macro-scale, and rapid progress and developments
  (<xref alt="Pan, 2018" rid="ref-Pan2018" ref-type="bibr">Pan,
  2018</xref>;
  <xref alt="Reu, 2015" rid="ref-Reu2015" ref-type="bibr">Reu,
  2015</xref>;
  <xref alt="Sutton et al., 2017" rid="ref-Sutton2017" ref-type="bibr">Sutton
  et al., 2017</xref>). 3D-DIC is preferable over strain gages and
  extensometers due to its non-contact nature and the large amount of
  local information that can be collected.</p>
  <p>Commercial 3D-DIC software (e.g., Correlated Solution, Dantec
  Dynamics, EikoSim, gom, LaVision, and MatchID) are typically
  expensive, proprietary and closed-source, which may pose a barrier,
  especially for students and researchers. Notable free and open-source
  3D-DIC contributions include <monospace>DICe</monospace>
  (<xref alt="Turner, 2015" rid="ref-Turner2015" ref-type="bibr">Turner,
  2015</xref>), <monospace>MultiDIC</monospace>
  (<xref alt="Solav et al., 2018" rid="ref-Solav2018" ref-type="bibr">Solav
  et al., 2018</xref>), and <monospace>ADIC3D</monospace>
  (<xref alt="Atkinson &amp; Becker, 2021" rid="ref-Atkinson2021" ref-type="bibr">Atkinson
  &amp; Becker, 2021</xref>). Each of these packages uses different
  algorithms for correlation and stereo calibration and requires
  different calibration targets. Specifically, our previous toolbox
  <monospace>MultiDIC</monospace> focused on multi-view applications,
  therefore required a non-planar calibration object, which is
  relatively difficult to make accurate, thus preventing easy
  implementation. To this end, <monospace>DuoDIC</monospace> enables a
  simpler calibration procedure that requires only a flat checkerboard
  pattern. In addition, with respect to <monospace>MultiDIC</monospace>
  we improved the post-processing and visualization options.
  <monospace>DuoDIC</monospace> is written in MATLAB, providing the
  flexibility and simple implementation of a high-level language, which
  meets the needs of the experimental mechanics community. Moreover, a
  main advantages of open-source software is the ability to compare
  results and performance, and to cross-validate the implementation of
  different algorithms and approaches. To this end,
  <monospace>DuoDIC</monospace> may also comprise a complementary tool
  for researchers in the field.</p>
</sec>
<sec id="algorithms-and-workflow">
  <title>Algorithms and workflow</title>
  <p>The entire 3D-DIC procedure in <monospace>DuoDIC</monospace> is
  organized in four main scripts, which the user can run without having
  to interact with any MATLAB syntax.
  <xref alt="Figure 1" rid="figU003Aworkflow">Figure 1</xref> outlines
  the workflow of the 3D-DIC procedure. The functionality and algorithms
  incorporated in each step are detailed in the sub-sections below. The
  figures in this section represent
  <ext-link ext-link-type="uri" xlink:href="https://github.com/SolavLab/DuoDIC/tree/main/sample_data">sample
  data</ext-link>, which are provided with the toolbox. The experimental
  setup used for taking these images consisted of two machine-vision
  cameras (BFS-U3-51S5M-C, FLIR, USA), each equipped with a 5.0 MP Sony
  IMX250 monochrome sensor and a 25 mm lens (Fujinon HF25SA-1, Fujifilm
  Corporation, Japan). The cameras were synchronously hardware-triggered
  using a MatchID Triggerbox (MatchID, Belgium). A rubber dog-bone
  specimen, cut out of a bicycle tube, was mounted on an optical table
  (Thorlabs, USA), such that its left end was fixed and its right end
  was moved to the right in 19 steps with 1 mm increments, such that a
  total of 20 images were taken from each camera (one reference state
  and 19 deformed states).</p>
  <fig>
    <caption><p>DuoDIC algorithm workflow. Each color represent one of
    the main steps of the 3D-DIC pipelines, which is executed in one of
    the four main
    scripts.<styled-content id="figU003Aworkflow"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_workflow.png" xlink:title="" />
  </fig>
  <sec id="step-1-stereo-camera-calibration">
    <title>Step 1: Stereo camera calibration</title>
    <p>In this step, the intrinsic and extrinsic parameters of both
    cameras are computed by integrating functions from MathWorks
    Computer Vision Toolbox, which implement algorithms by Zhang
    (<xref alt="Zhang, 2000" rid="ref-Zhang2000" ref-type="bibr">Zhang,
    2000</xref>), Heikkila and Silven
    (<xref alt="Heikkila &amp; Silven, 1997" rid="ref-Heikkila1997" ref-type="bibr">Heikkila
    &amp; Silven, 1997</xref>), Bouguet
    (<xref alt="Bougue, 2013" rid="ref-Bouguet" ref-type="bibr">Bougue,
    2013</xref>), and Bradski and Kaehler
    (<xref alt="Bradski &amp; Kaehler, 2008" rid="ref-Bradski2008" ref-type="bibr">Bradski
    &amp; Kaehler, 2008</xref>). This script takes as input multiple
    simultaneous images of a checkerboard target captured by two cameras
    in a stereo pair. The checkerboard pattern points in each image is
    automatically detected and used for calibrating the cameras’
    intrinsic and extrinsic parameters. The intrinsic parameters include
    focal lengths, principal point (optical center), and up to 6
    distortion coefficients. The user can choose between [0,2,3] radial
    distortion coefficients, [0,2] tangential distortion coefficients,
    and [0,1] skew parameter. The extrinsic (stereo) camera parameters
    comprise the 3D position and orientation of the second camera with
    respect to the first (a total of 6 degrees of freedom). Furthermore,
    the computed camera parameters are used for computing the
    reprojection errors, which represent the distance between the
    reprojected and the detected pattern points, and comprise the
    accuracy of the estimated camera parameters. An example of the
    results, which are presented at the end of this step is shown in
    <xref alt="Figure 2" rid="figU003Acalibration">Figure 2</xref>. This
    calibration was obtained using 52 stereo images of a pattern with a
    square size of 10 mm, which are included in the
    <ext-link ext-link-type="uri" xlink:href="https://github.com/SolavLab/DuoDIC/tree/main/sample_data">sample
    data</ext-link> provided with the toolbox.</p>
    <fig>
      <caption><p>Stereo Calibration results. The top panels show the
      detected and reprojected points for a pair of stereo images. The
      bottom left panel shows the mean reprojection error for all pairs
      of images, and the bottom right panel shows the estimated
      positions and orientations of the cameras with respect to the
      checkerboard pattern images.
      <styled-content id="figU003Acalibration"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_calibration.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="step-2-image-cross-correlation-2d-dic">
    <title>Step 2: Image cross-correlation (2D-DIC)</title>
    <p>In this step, the script receives multiple images of a speckled
    test object captured simultaneously by the stereo camera pair. The
    first image pair defines the reference configuration, to which the
    rest of the image are compared. Typically, the reference
    configuration represents an unloaded, or undeformed, state and the
    rest of the images represent deformed states.
    <monospace>Ncorr</monospace> toolbox
    (<xref alt="Blaber et al., 2015" rid="ref-Blaber2015" ref-type="bibr">Blaber
    et al., 2015</xref>) is utilized in this step to detect a dense grid
    of matching points on all images. Although Ncorr was created as a
    2D-DIC toolbox, typically receiving images from a single camera,
    <monospace>DuoDIC</monospace> utilizes it to detect matching points
    on images taken from two different views. The user can select the
    region of interest (ROI), the subset size and subset spacing, and
    then the images from both cameras in all states are cross-correlated
    with the reference image (first camera, first state), to detect a
    grid of corresponding points in the ROI, as demonstrated in
    <xref alt="Figure 3" rid="figU003Acorr">Figure 3</xref>. For
    interpreting the values of the correlation coefficients, refer to
    (<xref alt="Blaber et al., 2015" rid="ref-Blaber2015" ref-type="bibr">Blaber
    et al., 2015</xref>) and
    (<xref alt="Solav et al., 2018" rid="ref-Solav2018" ref-type="bibr">Solav
    et al., 2018</xref>). Furthermore, the point grid is meshed with
    triangular elements, which are then used in Step 4 for calculating
    the deformation and strain measures.</p>
    <fig>
      <caption><p>Image point matching computed using
      <monospace>Ncorr</monospace> and <monospace>DuoDIC</monospace>.
      The grid of corresponding matched points are plotted as crosses
      overlaid on each image, with the colors representing their
      correlation coefficient (CC) with the reference image (camera 1,
      state 1, top left panel).
      <styled-content id="figU003Acorr"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_corr.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="step-3-3d-reconstruction">
    <title>Step 3: 3D reconstruction</title>
    <p>The results from Step 1 and Step 2 are combined in this step to
    obtain the 3D position of each image point using stereo
    triangulation. The set of matching points on each pair of stereo
    images (as computed in Step 2) are first being undistorted using the
    intrinsic camera parameters of each camera, according to the
    distortion model selected in Step 1. Consequently, the image points
    are transformed into 3D world points using the stereo camera
    parameters computed in Step 1. In addition, the reprojection errors
    are obtained for each point, by calculating the distance (in pixels)
    between the detected and the reprojected points. At the end of this
    step, the 3D point cloud and triangulated surface are plotted and
    animated, utilizing function from the GIBBON toolbox
    (<xref alt="Moerman, 2018" rid="ref-Moerman2018" ref-type="bibr">Moerman,
    2018</xref>). Two animated figures plot the values of the matching
    correlation coefficient and the reprojection errors, as shown in
    <xref alt="Figure 4" rid="figU003Astep3">Figure 4</xref> for the
    last image in the series, which represents the configuration with
    the largest stretch.</p>
    <fig>
      <caption><p>Step 3 results: 3D reconstruction and animated plots
      of the correlation coefficients and the reprojection
      errors.<styled-content id="figU003Astep3"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_step3_plots.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="step-4-post-processing">
    <title>Step 4: Post processing</title>
    <p>The 3D coordinates calculated in Step 3 are used in this step to
    derive the full-field displacement, deformation, and strain maps.
    The displacements are calculated for each point, and the
    deformations and strains are calculated for each triangular element,
    using the Cosserat point element method
    (<xref alt="Solav et al., 2014" rid="ref-Solav2014" ref-type="bibr">Solav
    et al., 2014</xref>,
    <xref alt="2016" rid="ref-Solav2016" ref-type="bibr">2016</xref>;
    <xref alt="Solav, Camomilla, et al., 2017" rid="ref-Solav2017" ref-type="bibr">Solav,
    Camomilla, et al., 2017</xref>;
    <xref alt="Solav, Meric, et al., 2017" rid="ref-Solav2017b" ref-type="bibr">Solav,
    Meric, et al., 2017</xref>). Detailed information on the post
    processing methods can be found in the
    <monospace>MultiDIC</monospace> paper
    (<xref alt="Solav et al., 2018" rid="ref-Solav2018" ref-type="bibr">Solav
    et al., 2018</xref>). In short, for each triangular element, the
    position vectors of its vertices are used to calculate the
    deformation gradient tensor <inline-formula><alternatives>
    <tex-math><![CDATA[\mathbf{F}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐅</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>,
    from which the right and left Cauchy-Green deformation tensors
    (<inline-formula><alternatives>
    <tex-math><![CDATA[\mathbf{C}=\mathbf{F}^T\mathbf{F}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐂</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mi>𝐅</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold"><mml:mi>𝐅</mml:mi></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\mathbf{B}=\mathbf{FF}^T]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐁</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mi>𝐅</mml:mi><mml:mi>𝐅</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>,
    respectively) are derived, as well as the Green-Lagrangian and
    Eulerian-Almansi strain tensors (<inline-formula><alternatives>
    <tex-math><![CDATA[\mathbf{E}=0.5(C-I)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐄</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\mathbf{e}=0.5(\mathbf{I}-\mathbf{B}^{-1})]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐞</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐈</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mi>𝐁</mml:mi></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
    respectively). The principal components and directions of these
    tensors are computed for deriving the principal stretches
    <inline-formula><alternatives>
    <tex-math><![CDATA[\lambda_i]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    and strains <inline-formula><alternatives>
    <tex-math><![CDATA[E_i]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>E</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[e_i]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
    as well as the equivalent (Von-Mises) strain, maximal shear strain,
    and area change.</p>
    <p><xref alt="Figure 5" rid="figU003Adisp_img">Figure 5</xref> and
    <xref alt="Figure 6" rid="figU003Aprinc_strain_3d">Figure 6</xref>
    show two example figures, plotting the 3D displacement magnitudes
    overlaid on the images and first and second principal Lagrangian
    strains (magnitude and directions) on the 3D triangular mesh,
    respectively. Examples of animated GIF files exported using
    <monospace>DuoDIC</monospace> can be found in the GitHub
    repository.</p>
    <fig>
      <caption><p>Full-field displacement magnitudes (in mm) overlaid on
      the original
      images.<styled-content id="figU003Adisp_img"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_disp_img.png" xlink:title="" />
    </fig>
    <fig>
      <caption><p>First (minimal) and second (maximal) principal strains
      plotted as 3D surfaces represented by triangular meshes, with face
      colors depicting the strain magnitude and the black lines
      depicting the strain
      direction.<styled-content id="figU003Aprinc_strain_3d"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_princ_strain_3d.png" xlink:title="" />
    </fig>
  </sec>
</sec>
<sec id="validation-using-a-rigid-body-motion-rbm-test">
  <title>Validation using a rigid body motion (RBM) test</title>
  <p>To assess the metrological performance of
  <monospace>DuoDIC</monospace>, we performed a rigid body motion
  experiment, whereby a speckled cylinder was translated using a
  motorized linear translation stage (PT1/M-Z8, Thorlabs, USA), in 15
  increments of 0.2 mm. simultaneous images were captured using the same
  camera setup described in the previous section. By comparing the
  displacements measured using the translation stage with those computed
  using <monospace>DuoDIC</monospace>, the displacement errors were
  quantified, as shown in
  <xref alt="Figure 7" rid="figU003Adisp_err">Figure 7</xref>. In
  addition, since strain should vanish for any RBM, any non-zero strains
  represent measurement errors.
  <xref alt="Figure 8" rid="figU003Astrains">Figure 8</xref> plots the
  strains measured during the RBM translations. The results indicate
  that for this experimental setup, the translations were accurate to
  within <inline-formula><alternatives>
  <tex-math><![CDATA[(1.3 \pm 1.1)\cdot10^{-3}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1.3</mml:mn><mml:mo>±</mml:mo><mml:mn>1.1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
  mm (mean <inline-formula><alternatives>
  <tex-math><![CDATA[\pm]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
  STD absolute translation error) and the strains errors were
  <inline-formula><alternatives>
  <tex-math><![CDATA[(3.4\pm 2.3)\cdot10^{-4}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>3.4</mml:mn><mml:mo>±</mml:mo><mml:mn>2.3</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
  <fig>
    <caption><p>Translation errors representing the difference between
    the translations measured by the translation stage and those
    computed using <monospace>DuoDIC</monospace>. On each box, the
    central red line indicates the median, the bottom and top edges of
    the box indicate the 25th and 75th percentiles, the whiskers extend
    to the most extreme data points not considered outliers, and the
    outliers are plotted in
    red.<styled-content id="figU003Adisp_err"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_disp_err.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Strain values measurements during the RBM test represent
    the errors in the strain measurement. (a) 3D surface of the
    cylinder’s ROI in the last translation step, showing the
    distribution of strains across the surface. (b) Statistical strain
    results representing all the faces at each translation step. On each
    box, the central red line indicates the median, the bottom and top
    edges of the box indicate the 25th and 75th percentiles, the
    whiskers extend to the most extreme data points not considered
    outliers, and the outliers are plotted in
    red.<styled-content id="figU003Astrains"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_strains.png" xlink:title="" />
  </fig>
</sec>
<sec id="limitations">
  <title>Limitations</title>
  <p>The main limitations of <monospace>DuoDIC</monospace> are
  currently: (1) The number and/or total size of images that can be
  processed together is limited by <monospace>Ncorr</monospace>’s memory
  limitation; (2) <monospace>Ncorr</monospace>’s seed placement process
  might fail to correctly place the seeds in cases of large deformation,
  especially if, in addition, the stereo angle between the cameras is
  large.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This project was supported by Dana Solav’s Jacques Lewiner Career
  Advancement Chair.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Solav2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solav</surname><given-names>Dana</given-names></name>
        <name><surname>Moerman</surname><given-names>Kevin M.</given-names></name>
        <name><surname>Jaeger</surname><given-names>Aaron M.</given-names></name>
        <name><surname>Genovese</surname><given-names>Katia</given-names></name>
        <name><surname>Herr</surname><given-names>Hugh M.</given-names></name>
      </person-group>
      <article-title>MultiDIC: an Open-Source Toolbox for Multi-View 3D Digital Image Correlation</article-title>
      <source>IEEE Access</source>
      <publisher-name>Institute of Electrical; Electronics Engineers Inc.</publisher-name>
      <year iso-8601-date="2018-05">2018</year><month>05</month>
      <volume>6</volume>
      <uri>https://ieeexplore.ieee.org/document/8371235/ https://doi.org/10.5281/zenodo.1256041#.Ww6ude6-0Xc.mendeley</uri>
      <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2843725</pub-id>
      <fpage>30520</fpage>
      <lpage>30535</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Zhang2000">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Zhengyou</given-names></name>
      </person-group>
      <article-title>A Flexible New Technique for Camera Calibration</article-title>
      <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
      <year iso-8601-date="2000">2000</year>
      <volume>22</volume>
      <issue>11</issue>
      <uri>http://files/933/Zhang - 2002 - A Flexible New Technique for Camera Calibration (Technical Report).pdf</uri>
      <pub-id pub-id-type="doi">10.1109/34.888718</pub-id>
      <pub-id pub-id-type="pmid">131</pub-id>
      <fpage>1330</fpage>
      <lpage>1334</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Heikkila1997">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heikkila</surname><given-names>J.</given-names></name>
        <name><surname>Silven</surname><given-names>O.</given-names></name>
      </person-group>
      <article-title>A four-step camera calibration procedure with implicit image correction</article-title>
      <source>Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>
      <year iso-8601-date="1997">1997</year>
      <uri>http://ieeexplore.ieee.org/document/609468/ http://files/1348/Heikkila, Silven - 1997 - A four-step camera calibration procedure with implicit image correction.pdf</uri>
      <pub-id pub-id-type="doi">10.1109/CVPR.1997.609468</pub-id>
      <pub-id pub-id-type="pmid">1151469</pub-id>
      <fpage>1106</fpage>
      <lpage>1112</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Blaber2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blaber</surname><given-names>J.</given-names></name>
        <name><surname>Adair</surname><given-names>B.</given-names></name>
        <name><surname>Antoniou</surname><given-names>A.</given-names></name>
      </person-group>
      <article-title>Ncorr: Open-Source 2D Digital Image Correlation Matlab Software</article-title>
      <source>Experimental Mechanics</source>
      <year iso-8601-date="2015">2015</year>
      <volume>55</volume>
      <issue>6</issue>
      <uri>http://files/788/Blaber, Adair, Antoniou - 2015 - Ncorr Open-Source 2D Digital Image Correlation Matlab Software.pdf</uri>
      <pub-id pub-id-type="doi">10.1007/s11340-015-0009-1</pub-id>
      <fpage>1105</fpage>
      <lpage>1122</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Solav2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solav</surname><given-names>Dana</given-names></name>
        <name><surname>Rubin</surname><given-names>M. B. B.</given-names></name>
        <name><surname>Cereatti</surname><given-names>Andrea</given-names></name>
        <name><surname>Camomilla</surname><given-names>Valentina</given-names></name>
        <name><surname>Wolf</surname><given-names>Alon</given-names></name>
      </person-group>
      <article-title>Bone Pose Estimation in the Presence of Soft Tissue Artifact Using Triangular Cosserat Point Elements</article-title>
      <source>Annals of Biomedical Engineering</source>
      <publisher-name>Springer US</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>44</volume>
      <issue>4</issue>
      <uri>http://link.springer.com/10.1007/s10439-015-1384-6</uri>
      <pub-id pub-id-type="doi">10.1007/s10439-015-1384-6</pub-id>
      <pub-id pub-id-type="pmid">26194039</pub-id>
      <fpage>1181</fpage>
      <lpage>1190</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Solav2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solav</surname><given-names>Dana</given-names></name>
        <name><surname>Rubin</surname><given-names>M. B. B.</given-names></name>
        <name><surname>Wolf</surname><given-names>Alon</given-names></name>
      </person-group>
      <article-title>Soft Tissue Artifact compensation using Triangular Cosserat Point Elements (TCPEs)</article-title>
      <source>International Journal of Engineering Science</source>
      <publisher-name>Elsevier Ltd</publisher-name>
      <year iso-8601-date="2014-12">2014</year><month>12</month>
      <volume>85</volume>
      <uri>http://dx.doi.org/10.1016/j.ijengsci.2014.07.001 http://www.sciencedirect.com/science/article/pii/S002072251400144X http://linkinghub.elsevier.com/retrieve/pii/S002072251400144X</uri>
      <pub-id pub-id-type="doi">10.1016/j.ijengsci.2014.07.001</pub-id>
      <fpage>1</fpage>
      <lpage>9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Solav2017b">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solav</surname><given-names>Dana</given-names></name>
        <name><surname>Meric</surname><given-names>Henri</given-names></name>
        <name><surname>Rubin</surname><given-names>M. B.</given-names></name>
        <name><surname>Pradon</surname><given-names>Didier</given-names></name>
        <name><surname>Lofaso</surname><given-names>Frédéric</given-names></name>
        <name><surname>Wolf</surname><given-names>Alon</given-names></name>
      </person-group>
      <article-title>Chest Wall Kinematics Using Triangular Cosserat Point Elements in Healthy and Neuromuscular Subjects</article-title>
      <source>Annals of Biomedical Engineering</source>
      <year iso-8601-date="2017">2017</year>
      <volume>45</volume>
      <issue>8</issue>
      <uri>http://www.ncbi.nlm.nih.gov/pubmed/28451990 http://link.springer.com/10.1007/s10439-017-1840-6</uri>
      <pub-id pub-id-type="doi">10.1007/s10439-017-1840-6</pub-id>
      <pub-id pub-id-type="pmid">28451990</pub-id>
      <fpage>1963</fpage>
      <lpage>1973</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Solav2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solav</surname><given-names>Dana</given-names></name>
        <name><surname>Camomilla</surname><given-names>Valentina</given-names></name>
        <name><surname>Cereatti</surname><given-names>Andrea</given-names></name>
        <name><surname>Barré</surname><given-names>Arnaud</given-names></name>
        <name><surname>Aminian</surname><given-names>Kamiar</given-names></name>
        <name><surname>Wolf</surname><given-names>Alon</given-names></name>
      </person-group>
      <article-title>Bone orientation and position estimation errors using Cosserat point elements and least squares methods: Application to gait</article-title>
      <source>Journal of Biomechanics</source>
      <year iso-8601-date="2017">2017</year>
      <volume>62</volume>
      <uri>http://linkinghub.elsevier.com/retrieve/pii/S0021929017300398</uri>
      <pub-id pub-id-type="doi">10.1016/j.jbiomech.2017.01.026</pub-id>
      <fpage>110</fpage>
      <lpage>116</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Turner2015">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Turner</surname><given-names>DZ</given-names></name>
      </person-group>
      <article-title>Digital Image Correlation Engine (DICe) Reference Manual</article-title>
      <publisher-name>Sandia Report</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <uri>https://github.com/dicengine/</uri>
    </element-citation>
  </ref>
  <ref id="ref-Atkinson2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Atkinson</surname><given-names>Devan</given-names></name>
        <name><surname>Becker</surname><given-names>Thorsten Hermann</given-names></name>
      </person-group>
      <article-title>Stereo digital image correlation in MATLAB</article-title>
      <source>Applied Sciences (Switzerland)</source>
      <publisher-name>Multidisciplinary Digital Publishing Institute</publisher-name>
      <year iso-8601-date="2021-05">2021</year><month>05</month>
      <volume>11</volume>
      <issue>11</issue>
      <uri>https://www.mdpi.com/2076-3417/11/11/4904</uri>
      <pub-id pub-id-type="doi">10.3390/app11114904</pub-id>
      <fpage>4904</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Bouguet">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Bougue</surname><given-names>Jean-Yves</given-names></name>
      </person-group>
      <article-title>Camera Calibration Toolbox for Matlab: Calibration examples</article-title>
      <year iso-8601-date="2013">2013</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2018-01-25">2018</year><month>01</month><day>25</day></date-in-citation>
      <uri>http://www.vision.caltech.edu/bouguetj/calib_doc/htmls/example.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-Bradski2008">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bradski</surname><given-names>Gary</given-names></name>
        <name><surname>Kaehler</surname><given-names>Adrian</given-names></name>
      </person-group>
      <source>Learning OpenCV</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2008">2008</year>
      <edition>First Edit</edition>
      <uri>http://files/1329/Bradski, Kaehler - 2008 - Learning OpenCV.pdf</uri>
    </element-citation>
  </ref>
  <ref id="ref-Pan2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pan</surname><given-names>Bing</given-names></name>
      </person-group>
      <article-title>Digital image correlation for surface deformation measurement: Historical developments, recent advances and future goals</article-title>
      <source>Measurement Science and Technology</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>29</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1088/1361-6501/aac55b</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Sutton2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sutton</surname><given-names>M. A.</given-names></name>
        <name><surname>Matta</surname><given-names>F.</given-names></name>
        <name><surname>Rizos</surname><given-names>D.</given-names></name>
        <name><surname>Ghorbani</surname><given-names>R.</given-names></name>
        <name><surname>Rajan</surname><given-names>S.</given-names></name>
        <name><surname>Mollenhauer</surname><given-names>D. H.</given-names></name>
        <name><surname>Schreier</surname><given-names>H. W.</given-names></name>
        <name><surname>Lasprilla</surname><given-names>A. O.</given-names></name>
      </person-group>
      <article-title>Recent Progress in Digital Image Correlation: Background and Developments since the 2013 W M Murray Lecture</article-title>
      <source>Experimental Mechanics</source>
      <publisher-name>Springer US</publisher-name>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <volume>57</volume>
      <issue>1</issue>
      <issn>0014-4851</issn>
      <uri>http://link.springer.com/10.1007/s11340-016-0233-3 http://files/1010/Sutton et al. - 2017 - Recent Progress in Digital Image Correlation Background and Developments since the 2013 W M Murray Lecture.pdf</uri>
      <pub-id pub-id-type="doi">10.1007/s11340-016-0233-3</pub-id>
      <fpage>1</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Reu2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Reu</surname><given-names>Phillip</given-names></name>
      </person-group>
      <article-title>THE ART AND APPLICATION OF DIC DIC : A Revolution in Experimental Mechanics</article-title>
      <source>Experimental Techniques</source>
      <year iso-8601-date="2015">2015</year>
      <volume>39</volume>
      <issue>Dic</issue>
      <uri>https://onlinelibrary.wiley.com/doi/pdf/10.1111/ext.12173</uri>
      <fpage>1</fpage>
      <lpage>2</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Moerman2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Moerman</surname><given-names>Kevin M</given-names></name>
      </person-group>
      <article-title>GIBBON: The Geometry and Image-Based Bioengineering add-On</article-title>
      <source>The Journal of Open Source Software</source>
      <year iso-8601-date="2018">2018</year>
      <volume>3</volume>
      <issue>22</issue>
      <issn>2475-9066</issn>
      <uri>http://joss.theoj.org/papers/10.21105/joss.00506</uri>
      <pub-id pub-id-type="doi">10.21105/joss.00506</pub-id>
      <fpage>506</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
