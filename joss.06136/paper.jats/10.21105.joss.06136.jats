<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6136</article-id>
<article-id pub-id-type="doi">10.21105/joss.06136</article-id>
<title-group>
<article-title>Mantik: A Workflow Platform for the Development of
Artificial Intelligence on High-Performance Computing
Infrastructures</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<name>
<surname>Seidler</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Emmerich</surname>
<given-names>Fabian</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7094-6403</contrib-id>
<name>
<surname>Ehlert</surname>
<given-names>Kristian</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4821-3366</contrib-id>
<name>
<surname>Berner</surname>
<given-names>Rico</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nagel-Kanzler</surname>
<given-names>Oliver</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schultz</surname>
<given-names>Norbert</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Quade</surname>
<given-names>Markus</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3455-774X</contrib-id>
<name>
<surname>Schultz</surname>
<given-names>Martin G.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Abel</surname>
<given-names>Markus</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Ambrosys GmbH, Potsdam, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Institute of Physics and Astronomy, University of Potsdam,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>4Cast GmbH &amp; Co. KG, Potsdam, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Jülich Supercomputing Centre (JSC), Forschungszentrum
Jülich GmbH, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Reactive Core GmbH, Berlin, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-09-06">
<day>6</day>
<month>9</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>98</issue>
<fpage>6136</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>machine learning</kwd>
<kwd>mlflow</kwd>
<kwd>high-performance computing</kwd>
<kwd>MLOps</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The use of machine learning (ML) approaches is exponentially
  increasing, and for many scientific applications, high-performance
  computing (HPC) infrastructure is used to train large models. However,
  the tooling for an easy deployment of models for training or inference
  on HPC infrastructures is not satisfactory, e.g. reproducibility,
  collaboration and monitoring of ML models are not addressed in
  existing toolsets. With Mantik, we provide an open-source cloud
  platform, which simplifies the development of and collaboration on ML
  models on HPC facilities, and enhances reproducibility by supporting
  data and code versioning as well as experiment tracking. The users are
  able to develop their applications in the environment they are most
  comfortable with – their local machine. Usage of the best-choice IDE
  and most recent software versions allow to leverage the full potential
  of the software stack for their research. Using Mantik’s remote file
  service allows for simple management of data in remote storages and
  keeping track of it. As soon as an application is ready for training
  or inference, users can immediately submit it to an HPC cluster.
  During application development, users can train and/or evaluate their
  models on HPC clusters via CLI on their local machine or our
  browser-based Mantik cloud platform. The latter only requires an
  internet browser such that e.g., ML training from your phone becomes
  feasible. Once training or inference has begun, a user is able to
  monitor the application in real time on the Mantik cloud platform.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>With Mantik, we cover a variety of features that are at the heart
  of data science and ML. Mantik streamlines fundamental features that
  form the core of a data scientist’s workflow including easy access to
  external computing resources, data management and collaborative model
  development. The interest in platforms for ML operations (MLOps) is on
  the rise, resulting in a rapidly growing market for solutions. Due to
  this, we will here not provide references to other existing platforms
  but refer the interested reader to a recent survey by Kreuzberger
  et.al.
  (<xref alt="Kreuzberger et al., 2023" rid="ref-kreuzberger_2023" ref-type="bibr">Kreuzberger
  et al., 2023</xref>).</p>
  <p>The Mantik platform provides a secure interface for an easy and
  unified access to remote computing resources. The interface is
  extensible to a variety of infrastructures. Currently, the
  <ext-link ext-link-type="uri" xlink:href="https://www.unicore.eu">UNICORE</ext-link>
  connector is implemented for resources of the Jülich Supercomputing
  Centre. Further, Mantik supports the connection to commercial clouds
  by using their respective interfaces. The unified interface for HPC
  infrastructures simplifies training and deployment of ML models on
  different sites. The flexible deployment in Mantik is realized by
  containerization of the developed ML models, which is standard for
  commercial clouds to avoid dependencies on hardware. This allows to
  make use of the desired software packages and versions to fully
  exploit the potential of state-of-the-art ML frameworks.</p>
  <p>For data handling Mantik provides a remote file service that allows
  for storing data remotely, e.g. in a cloud, and tracking the data by
  keeping its location as a reference and supporting versioning. The
  data is therefore always available to the users and changes can be
  traced. Mantik assures that the actual data will only be accessed if
  necessary to optimize network load and wait times. Analogously, code
  and ML models can be versioned using git and their references can be
  stored. Whereas training often involves large data sets and big
  infrastructure, inference may run on small devices which may require
  optimized, or compiled code. In order to allow for these different use
  cases, the deployment and versioning of data, code, and models is
  fully supported by Mantik. For experiment tracking, our platform
  integrates the existing open-source framework MLflow
  (<xref alt="Chen et al., 2020" rid="ref-chen_2020" ref-type="bibr">Chen
  et al., 2020</xref>) to provide researchers with the ability to track
  their modeling results independent of user hardware. Storage of
  training workflows, experiments, and models, including records of
  input parameters, metrics, models, artifacts, ensures reproducibility
  and enables users to share their ML solutions with the community.</p>
  <p>A
  <ext-link ext-link-type="uri" xlink:href="https://cloud.mantik.ai/">browser-based
  GUI</ext-link> is provided for hosting and maintaining your ML
  projects. Here, ML tasks can be executed codeless on remote computing
  resources, including scheduling and interacting with submitted jobs
  (status, properties, log messages, access to file system). The
  platform allows the user to securely save credentials required to
  quickly access remote services. All references to existing data, code,
  models and experiments that are stored in a particular project are
  displayed on the Mantik web-platform. Project owners can invite other
  users to their projects to share their results and ML solutions
  effortlessly, which fosters collaboration and knowledge transfer.</p>
  <p>Mantik is designed to be used by researchers, data scientists as
  well as ML engineers. For example, project KI:STE
  (<xref alt="Seidler et al., 2021" rid="ref-seidler_talk_2021" ref-type="bibr">Seidler
  et al., 2021</xref>) aims for building a platform particularly based
  on Mantik for promoting the application of ML in earth system
  sciences. In the
  <ext-link ext-link-type="uri" xlink:href="https://www.maelstrom-eurohpc.eu/">project
  Maelstrom</ext-link> Mantik is already used to develop large-scale ML
  applications for weather and climate science. Due to the simple
  structure and the variety of built-in features, Mantik provides a
  kick-start for all users interested in running ML projects on HPC.
  Consequently, Mantik saves time allowing the user to focus on research
  and improving their ML approaches rather than bothering about tooling.
  Mantik allows for easy bookkeeping of key entities (data, models,
  experiments) that constitute the ML life cycle, therefore providing
  reproducibility that forms the basis of scientific work and supports
  its credibility. Moreover, shareable and open ML projects enable
  students and junior data scientists to familiarize themselves with
  state-of-the-art approaches. The ease of use and inherent
  reproducibility therefore renders Mantik also a great choice for
  education purposes in the field of ML.</p>
</sec>
<sec id="the-mantik-platform-architecture">
  <title>The Mantik platform architecture</title>
  <p>In Mantik the organizational entity is the Mantik project. In
  <xref alt="[fig:example]" rid="figU003Aexample">[fig:example]</xref>,
  we provide our vision for the Mantik platform and how the different
  core units within the Mantik project relate to the typical development
  lifecycle of ML solutions.</p>
  <list list-type="bullet">
    <list-item>
      <p>Data and AI modeling: In Mantik projects you can store
      references to all ingredients that you would need to develop your
      ML solution (data, code, infrastructure).</p>
    </list-item>
    <list-item>
      <p>Training: A training session of an ML algorithm (code) with
      some given data on a particular infrastructure, e.g. HPC, is
      organized in a run.</p>
    </list-item>
    <list-item>
      <p>AI engineering: Many runs form an experiment that can be used
      to find the best performing ML solution for your particular use
      case.</p>
    </list-item>
    <list-item>
      <p>Deployment: Your evaluation of the experiments results in
      models that are trained algorithms with fixed sets of parameters,
      trained on known architectures and meant be used for specific
      types of data, e.g. video data or texts.</p>
    </list-item>
  </list>
  <fig>
    <caption><p>Overview of the organization of the Mantik
    platform.<styled-content id="figU003Aexample"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="Mantik_scetch.png" />
  </fig>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>T.S. and M.A. acknowledge financial support from the project KI:STE
  funded by Bundesministerium für Bildung und Forschung (BMBF). R.B.,
  M.Q. and M.A. acknowledge financial support EMDRIVE and CECAS funded
  by BMBF. F.E., K.E., M.S. and M.A. gratefully acknowledge funding from
  the MAELSTROM EuroHPC-JU project (JU) under 955513. The JU receives
  support from the European Union’s Horizon Research and Innovation
  Programme and United Kingdom, Germany, Italy, Luxembourg, Switzerland,
  and Norway. We are grateful for all contributions to the Mantik
  platform and in particular to the outstanding people involved in its
  development: the
  <ext-link ext-link-type="uri" xlink:href="https://mantik-ai.gitlab.io/mantik/contributing.html#contributors">Mantik
  contributors</ext-link>.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-seidler_talk_2021">
    <element-citation publication-type="manuscript">
      <person-group person-group-type="author">
        <name><surname>Seidler</surname><given-names>T.</given-names></name>
        <name><surname>Schultz</surname><given-names>N.</given-names></name>
        <name><surname>Quade</surname><given-names>Dr. M.</given-names></name>
        <name><surname>Autermann</surname><given-names>C.</given-names></name>
        <name><surname>Gräler</surname><given-names>Dr. B.</given-names></name>
        <name><surname>Abel</surname><given-names>P. Dr. M.</given-names></name>
      </person-group>
      <article-title>Easing and promoting the application of ML and AI in earth system sciences - introducing the KI:STE platform</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://doi.org/10.5194/egusphere-egu21-9632</uri>
      <pub-id pub-id-type="doi">10.5194/egusphere-egu21-9632</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chen_2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>A.</given-names></name>
        <name><surname>Chow</surname><given-names>A.</given-names></name>
        <name><surname>Davidson</surname><given-names>A.</given-names></name>
        <name><surname>DCunha</surname><given-names>A.</given-names></name>
        <name><surname>Ghodsi</surname><given-names>A.</given-names></name>
        <name><surname>Hong</surname><given-names>S. A.</given-names></name>
        <name><surname>Konwinski</surname><given-names>A.</given-names></name>
        <name><surname>Mewald</surname><given-names>C.</given-names></name>
        <name><surname>Murching</surname><given-names>S.</given-names></name>
        <name><surname>Nykodym</surname><given-names>T.</given-names></name>
        <name><surname>Ogilvie</surname><given-names>P.</given-names></name>
        <name><surname>Parkhe</surname><given-names>M.</given-names></name>
        <name><surname>Singh</surname><given-names>A.</given-names></name>
        <name><surname>Xie</surname><given-names>F.</given-names></name>
        <name><surname>Zaharia</surname><given-names>M.</given-names></name>
        <name><surname>Zang</surname><given-names>R.</given-names></name>
        <name><surname>Zheng</surname><given-names>J.</given-names></name>
        <name><surname>Zumar</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Developments in MLflow: A system to accelerate the machine learning lifecycle</article-title>
      <source>Proceedings of the fourth international workshop on data management for end-to-end machine learning</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <isbn>9781450380232</isbn>
      <uri>https://doi.org/10.1145/3399579.3399867</uri>
      <pub-id pub-id-type="doi">10.1145/3399579.3399867</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-kreuzberger_2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kreuzberger</surname><given-names>D.</given-names></name>
        <name><surname>Kühl</surname><given-names>N.</given-names></name>
        <name><surname>Hirschl</surname><given-names>S.</given-names></name>
      </person-group>
      <article-title>Machine learning operations (mlops): Overview, definition, and architecture</article-title>
      <source>IEEE Access</source>
      <year iso-8601-date="2023">2023</year>
      <volume>11</volume>
      <issue></issue>
      <pub-id pub-id-type="doi">10.1109/ACCESS.2023.3262138</pub-id>
      <fpage>31866</fpage>
      <lpage>31879</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
