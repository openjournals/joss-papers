<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7626</article-id>
<article-id pub-id-type="doi">10.21105/joss.07626</article-id>
<title-group>
<article-title>AutoEmulate: A Python package for semi-automated
emulation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4030-3543</contrib-id>
<name>
<surname>Stoffel</surname>
<given-names>Martin A.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3144-4838</contrib-id>
<name>
<surname>Li</surname>
<given-names>Bryan M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2014-332X</contrib-id>
<name>
<surname>Westerling</surname>
<given-names>Kalle</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9708-7058</contrib-id>
<name>
<surname>Arana</surname>
<given-names>Sophie</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6003-0178</contrib-id>
<name>
<surname>Balmus</surname>
<given-names>Max</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8499-0720</contrib-id>
<name>
<surname>Daub</surname>
<given-names>Eric</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4612-6982</contrib-id>
<name>
<surname>Niederer</surname>
<given-names>Steve</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>The Alan Turing Institute, London, United
Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>University of Edinburgh, Edinburgh, United
Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Imperial College London, London, United
Kingdom</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-11-28">
<day>28</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>107</issue>
<fpage>7626</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Surrogate modelling</kwd>
<kwd>Emulation</kwd>
<kwd>Simulation</kwd>
<kwd>Machine Learning</kwd>
<kwd>Gaussian Processes</kwd>
<kwd>Neural Processes</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Simulations are ubiquitous in research and application, but are
  often too slow and computationally expensive to deeply explore the
  underlying system. One solution is to create efficient emulators (also
  surrogate- or meta-models) to approximate simulations, but this
  requires substantial expertise. Here, we present AutoEmulate, a
  low-code, AutoML-style python package for emulation. AutoEmulate makes
  it easy to fit and compare emulators, abstracting away the need for
  extensive machine learning (ML) experimentation. The package includes
  a range of emulators, from Gaussian Processes, Support Vector Machines
  and Gradient Boosting Models to novel, experimental deep learning
  emulators such as Neural Processes
  (<xref alt="Garnelo et al., 2018" rid="ref-garnelo_conditional_2018" ref-type="bibr">Garnelo
  et al., 2018</xref>). It also implements global sensitivity analysis
  as a common emulator application, which quantifies the relative
  contribution of different inputs to the output variance. Through
  community feedback and collaboration, we aim for AutoEmulate to evolve
  into an end-to-end tool for most emulation problems.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>To understand complex real-world systems, researchers and engineers
  often construct computer simulations. These can be computationally
  expensive and take minutes, hours or even days to run. For tasks like
  optimisation, sensitivity analysis or uncertainty quantification where
  thousands or even millions of runs are needed, a solution has long
  been to approximate simulations with efficient emulators, which can be
  orders of magnitudes faster
  (<xref alt="Forrester &amp; Keane, 2009" rid="ref-forrester_recent_2009" ref-type="bibr">Forrester
  &amp; Keane, 2009</xref>;
  <xref alt="Kudela &amp; Matousek, 2022" rid="ref-kudela_recent_2022" ref-type="bibr">Kudela
  &amp; Matousek, 2022</xref>). Emulation is becoming increasingly
  widespread, ranging from engineering
  (<xref alt="Yondo et al., 2018" rid="ref-yondo_review_2018" ref-type="bibr">Yondo
  et al., 2018</xref>), architecture
  (<xref alt="Westermann &amp; Evins, 2019" rid="ref-westermann_surrogate_2019" ref-type="bibr">Westermann
  &amp; Evins, 2019</xref>), biomedical
  (<xref alt="Strocchi et al., 2023" rid="ref-strocchi_cell_2023" ref-type="bibr">Strocchi
  et al., 2023</xref>) and climate science
  (<xref alt="Bounceur et al., 2015" rid="ref-bounceur_global_2015" ref-type="bibr">Bounceur
  et al., 2015</xref>), to agent-based models
  (<xref alt="Angione et al., 2022" rid="ref-angione_using_2022" ref-type="bibr">Angione
  et al., 2022</xref>).</p>
  <p>A typical emulation pipeline involves three steps: 1. Evaluating
  the simulation at a small, strategically chosen set of inputs using
  techniques such as Latin Hypercube Sampling
  (<xref alt="McKay et al., 1979" rid="ref-mckay_comparison_1979" ref-type="bibr">McKay
  et al., 1979</xref>) to create a representative dataset, 2.
  constructing a high-accuracy emulator using that dataset, which
  involves model selection, hyperparameter optimisation and evaluation
  and 3. applying the emulator to tasks such as prediction, sensitivity
  analysis, or optimisation. A key challenge is the emulator
  construction, which requires machine learning expertise and
  familiarity with an evolving ecosystem of models and tools - creating
  a significant barrier for researchers focused on studying the
  underlying system rather than building emulators.</p>
  <p>AutoEmulate automates emulator building, with the goal to
  eventually streamline the whole emulation pipeline. For people new to
  ML, AutoEmulate compares, optimises and evaluates a range of models to
  create an efficient emulator for their simulation in just a few lines
  of code. For experienced surrogate modellers, AutoEmulate provides a
  reference set of cutting-edge emulators to quickly benchmark new
  models against. The package includes classic emulators such as Radial
  Basis Functions and Gaussian Processes, established ML models like
  Gradient Boosting and Support Vector Machines, as well as experimental
  deep learning emulators such as
  <ext-link ext-link-type="uri" xlink:href="https://yanndubs.github.io/Neural-Process-Family/text/Intro.html">Conditional
  Neural Processes</ext-link>
  (<xref alt="Garnelo et al., 2018" rid="ref-garnelo_conditional_2018" ref-type="bibr">Garnelo
  et al., 2018</xref>). AutoEmulate is built to be extensible. Emulators
  follow the popular
  <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/1.5/developers/develop.html#rolling-your-own-estimator">scikit-learn
  estimator template</ext-link> and PyTorch
  (<xref alt="Paszke et al., 2019" rid="ref-paszke_pytorch_2019" ref-type="bibr">Paszke
  et al., 2019</xref>) deep learning models are supported with little
  overhead using a
  <ext-link ext-link-type="uri" xlink:href="https://skorch.readthedocs.io/en/stable/">skorch</ext-link>
  (<xref alt="Tietz et al., 2017" rid="ref-tietz_skorch_2017" ref-type="bibr">Tietz
  et al., 2017</xref>) interface.</p>
  <p>AutoEmulate fills a gap in the current landscape of surrogate
  modeling tools as itâ€™s both highly accessible for newcomers while
  providing cutting-edge emulators for experienced surrogate modelers.
  In contrast, existing libraries either focus on lower level
  implementations of specific models, like GPflow
  (<xref alt="Matthews et al., 2017" rid="ref-matthews_gpflow_2017" ref-type="bibr">Matthews
  et al., 2017</xref>) and GPytorch
  (<xref alt="Gardner et al., 2018" rid="ref-gardner_gpytorch_2018" ref-type="bibr">Gardner
  et al., 2018</xref>), or provide multiple emulators and applications
  but require to manually pre-process data, compare emulators and
  optimise hyperparameters like SMT in Python
  (<xref alt="Saves et al., 2024" rid="ref-saves_smt_2024" ref-type="bibr">Saves
  et al., 2024</xref>) or
  <ext-link ext-link-type="uri" xlink:href="https://docs.sciml.ai/Surrogates/latest/">Surrogates.jl</ext-link>
  in Julia.</p>
</sec>
<sec id="pipeline">
  <title>Pipeline</title>
  <p>The inputs for AutoEmulate are <monospace>X</monospace> and
  <monospace>y</monospace>, where <monospace>X</monospace> is a 2D array
  (e.g.Â numpy-array, Pandas DataFrame) containing simulation parameters
  in columns and their values in rows, and <monospace>y</monospace> is
  an array containing the corresponding simulation outputs. A dataset
  <monospace>X</monospace>, <monospace>y</monospace> is usually obtained
  by constructing a set of parameters <monospace>X</monospace> using
  sampling techniques like Latin Hypercube Sampling
  (<xref alt="McKay et al., 1979" rid="ref-mckay_comparison_1979" ref-type="bibr">McKay
  et al., 1979</xref>) and evaluating the simulation on these inputs to
  obtain outputs <monospace>y</monospace>. With <monospace>X</monospace>
  and <monospace>y</monospace>, we can create an emulator with
  AutoEmulate in just a few lines of code.</p>
  <code language="python">from autoemulate.compare import AutoEmulate

ae = AutoEmulate()
ae.setup(X, y)                            # customise pipeline
ae.compare()                              # runs the pipeline</code>
  <p>Under the hood, AutoEmulate runs a complete ML pipeline. It splits
  the data into training and test sets, standardises inputs, fits a set
  of user-specified emulators, compares them using cross-validation and
  optionally optimises hyperparameters using pre-defined search spaces.
  All these steps can be customised in <monospace>setup()</monospace>.
  After running <monospace>compare()</monospace>, the cross-validation
  results can be visualised and summarised.</p>
  <code language="python">ae.plot_cv()                              # visualise results
ae.summarise_cv()                         # cv scores for each model</code>
  <table-wrap>
    <caption>
      <p>Average cross-validation scores</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th>Model</th>
          <th>Short Name</th>
          <th>RMSE</th>
          <th>RÂ²</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Gaussian Process</td>
          <td>gp</td>
          <td>0.1027</td>
          <td>0.9851</td>
        </tr>
        <tr>
          <td>Random Forest</td>
          <td>rf</td>
          <td>0.1511</td>
          <td>0.9677</td>
        </tr>
        <tr>
          <td>Gradient Boosting</td>
          <td>gb</td>
          <td>0.1566</td>
          <td>0.9642</td>
        </tr>
        <tr>
          <td>Conditional Neural Process</td>
          <td>cnp</td>
          <td>0.1915</td>
          <td>0.9465</td>
        </tr>
        <tr>
          <td>Radial Basis Functions</td>
          <td>rbf</td>
          <td>0.3518</td>
          <td>0.7670</td>
        </tr>
        <tr>
          <td>Support Vector Machines</td>
          <td>svm</td>
          <td>0.4924</td>
          <td>0.6635</td>
        </tr>
        <tr>
          <td>LightGBM</td>
          <td>lgbm</td>
          <td>0.6044</td>
          <td>0.4930</td>
        </tr>
        <tr>
          <td>Second Order Polynomial</td>
          <td>sop</td>
          <td>0.8378</td>
          <td>0.0297</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>After comparing cross-validation metrics and plots, an emulator can
  be selected and evaluated on the held-out test set (defaults to 20% of
  the data).</p>
  <code language="python">emulator = ae.get_model(&quot;GaussianProcess&quot;) # get fitted emulator
ae.evaluate(emulator)                      # calculate test set scores
ae.plot_eval(emulator, input_index=[0, 1]) # plot predictions</code>
  <fig>
    <caption><p>Test set predictions</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="eval_2.png" />
  </fig>
  <p>Finally, the emulator can be refitted on the combined training and
  test set data before applying it. Itâ€™s now ready to be used as an
  efficient replacement for the original simulation, being able to
  generate tens of thousands of new data points in negligible time using
  <monospace>predict()</monospace>. Lastly, we implemented global
  sensitivity analysis, which requires a large number of samples from
  the emulator to quantify how each simulation parameter and their
  interactions contribute to the output variance.</p>
  <code language="python">emulator = ae.refit(emulator)               # refit using full data
emulator.predict(X)                         # emulate!
ae.sensitivity_analysis(emulator)           # global SA with Sobol indices</code>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank the Turing Research and Innovation Cluster in Digital
  Twins for supporting this work. We also thank Keith Worden, Ieva
  Kazlauskaite, Rosie Williams, Robert Arthern, Peter Yatsyshin,
  Christopher Burr and James Byrne for discussions and Marina Strocci,
  Zack Xuereb Conti, Richard Wilkinson for discussions and providing
  datasets.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-garnelo_conditional_2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Garnelo</surname><given-names>Marta</given-names></name>
        <name><surname>Rosenbaum</surname><given-names>Dan</given-names></name>
        <name><surname>Maddison</surname><given-names>Chris J.</given-names></name>
        <name><surname>Ramalho</surname><given-names>Tiago</given-names></name>
        <name><surname>Saxton</surname><given-names>David</given-names></name>
        <name><surname>Shanahan</surname><given-names>Murray</given-names></name>
        <name><surname>Teh</surname><given-names>Yee Whye</given-names></name>
        <name><surname>Rezende</surname><given-names>Danilo J.</given-names></name>
        <name><surname>Eslami</surname><given-names>S. M. Ali</given-names></name>
      </person-group>
      <article-title>Conditional Neural Processes</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2018-07">2018</year><month>07</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-09-16">2024</year><month>09</month><day>16</day></date-in-citation>
      <uri>http://arxiv.org/abs/1807.01613</uri>
    </element-citation>
  </ref>
  <ref id="ref-kudela_recent_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kudela</surname><given-names>Jakub</given-names></name>
        <name><surname>Matousek</surname><given-names>Radomil</given-names></name>
      </person-group>
      <article-title>Recent advances and applications of surrogate models for finite element method computations: A review</article-title>
      <source>Soft Computing</source>
      <year iso-8601-date="2022-12">2022</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-06">2024</year><month>11</month><day>06</day></date-in-citation>
      <volume>26</volume>
      <issue>24</issue>
      <issn>1433-7479</issn>
      <uri>https://doi.org/10.1007/s00500-022-07362-8</uri>
      <pub-id pub-id-type="doi">10.1007/s00500-022-07362-8</pub-id>
      <fpage>13709</fpage>
      <lpage>13733</lpage>
    </element-citation>
  </ref>
  <ref id="ref-forrester_recent_2009">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Forrester</surname><given-names>Alexander I. J.</given-names></name>
        <name><surname>Keane</surname><given-names>Andy J.</given-names></name>
      </person-group>
      <article-title>Recent advances in surrogate-based optimization</article-title>
      <source>Progress in Aerospace Sciences</source>
      <year iso-8601-date="2009-01">2009</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-06">2024</year><month>11</month><day>06</day></date-in-citation>
      <volume>45</volume>
      <issue>1</issue>
      <issn>0376-0421</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0376042108000766</uri>
      <pub-id pub-id-type="doi">10.1016/j.paerosci.2008.11.001</pub-id>
      <fpage>50</fpage>
      <lpage>79</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mckay_comparison_1979">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>McKay</surname><given-names>M. D.</given-names></name>
        <name><surname>Beckman</surname><given-names>R. J.</given-names></name>
        <name><surname>Conover</surname><given-names>W. J.</given-names></name>
      </person-group>
      <article-title>A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code</article-title>
      <source>Technometrics</source>
      <year iso-8601-date="1979">1979</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-08">2024</year><month>11</month><day>08</day></date-in-citation>
      <volume>21</volume>
      <issue>2</issue>
      <issn>0040-1706</issn>
      <uri>https://www.jstor.org/stable/1268522</uri>
      <pub-id pub-id-type="doi">10.2307/1268522</pub-id>
      <fpage>239</fpage>
      <lpage>245</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gardner_gpytorch_2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gardner</surname><given-names>Jacob</given-names></name>
        <name><surname>Pleiss</surname><given-names>Geoff</given-names></name>
        <name><surname>Weinberger</surname><given-names>Kilian Q.</given-names></name>
        <name><surname>Bindel</surname><given-names>David</given-names></name>
        <name><surname>Wilson</surname><given-names>Andrew G.</given-names></name>
      </person-group>
      <article-title>Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2018">2018</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>31</volume>
      <uri>https://proceedings.neurips.cc/paper/2018/hash/27e8e17134dd7083b050476733207ea1-Abstract.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-matthews_gpflow_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Matthews</surname><given-names>Alexander G. de G.</given-names></name>
        <name><surname>Van Der Wilk</surname><given-names>Mark</given-names></name>
        <name><surname>Nickson</surname><given-names>Tom</given-names></name>
        <name><surname>Fujii</surname><given-names>Keisuke</given-names></name>
        <name><surname>Boukouvalas</surname><given-names>Alexis</given-names></name>
        <name><surname>Le</surname><given-names>Pablo</given-names></name>
        <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
        <name><surname>Hensman</surname><given-names>James</given-names></name>
      </person-group>
      <article-title>GPflow: A Gaussian process library using TensorFlow</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2017">2017</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>18</volume>
      <issue>40</issue>
      <uri>https://www.jmlr.org/papers/v18/16-537.html</uri>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-paszke_pytorch_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
      </person-group>
      <article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2019">2019</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-29">2024</year><month>11</month><day>29</day></date-in-citation>
      <volume>32</volume>
      <uri>https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-tietz_skorch_2017">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Tietz</surname><given-names>Marian</given-names></name>
        <name><surname>Fan</surname><given-names>Thomas J.</given-names></name>
        <name><surname>Nouri</surname><given-names>Daniel</given-names></name>
        <name><surname>Bossan</surname><given-names>Benjamin</given-names></name>
        <string-name>skorch Developers</string-name>
      </person-group>
      <source>Skorch: A scikit-learn compatible neural network library that wraps PyTorch</source>
      <year iso-8601-date="2017-07">2017</year><month>07</month>
      <uri>https://skorch.readthedocs.io/en/stable/</uri>
    </element-citation>
  </ref>
  <ref id="ref-strocchi_cell_2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Strocchi</surname><given-names>Marina</given-names></name>
        <name><surname>Longobardi</surname><given-names>Stefano</given-names></name>
        <name><surname>Augustin</surname><given-names>Christoph M.</given-names></name>
        <name><surname>Gsell</surname><given-names>Matthias A. F.</given-names></name>
        <name><surname>Petras</surname><given-names>Argyrios</given-names></name>
        <name><surname>Rinaldi</surname><given-names>Christopher A.</given-names></name>
        <name><surname>Vigmond</surname><given-names>Edward J.</given-names></name>
        <name><surname>Plank</surname><given-names>Gernot</given-names></name>
        <name><surname>Oates</surname><given-names>Chris J.</given-names></name>
        <name><surname>Wilkinson</surname><given-names>Richard D.</given-names></name>
        <name><surname>Niederer</surname><given-names>Steven A.</given-names></name>
      </person-group>
      <article-title>Cell to whole organ global sensitivity analysis on a four-chamber heart electromechanics model using Gaussian processes emulators</article-title>
      <source>PLOS Computational Biology</source>
      <year iso-8601-date="2023-06">2023</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>19</volume>
      <issue>6</issue>
      <issn>1553-7358</issn>
      <uri>https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011257</uri>
      <pub-id pub-id-type="doi">10.1371/journal.pcbi.1011257</pub-id>
      <fpage>e1011257</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-yondo_review_2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yondo</surname><given-names>Raul</given-names></name>
        <name><surname>AndrÃ©s</surname><given-names>Esther</given-names></name>
        <name><surname>Valero</surname><given-names>Eusebio</given-names></name>
      </person-group>
      <article-title>A review on design of experiments and surrogate models in aircraft real-time and many-query aerodynamic analyses</article-title>
      <source>Progress in Aerospace Sciences</source>
      <year iso-8601-date="2018-01">2018</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>96</volume>
      <issn>0376-0421</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0376042117300611</uri>
      <pub-id pub-id-type="doi">10.1016/j.paerosci.2017.11.003</pub-id>
      <fpage>23</fpage>
      <lpage>61</lpage>
    </element-citation>
  </ref>
  <ref id="ref-saves_smt_2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Saves</surname><given-names>Paul</given-names></name>
        <name><surname>Lafage</surname><given-names>RÃ©mi</given-names></name>
        <name><surname>Bartoli</surname><given-names>Nathalie</given-names></name>
        <name><surname>Diouane</surname><given-names>Youssef</given-names></name>
        <name><surname>Bussemaker</surname><given-names>Jasper</given-names></name>
        <name><surname>Lefebvre</surname><given-names>Thierry</given-names></name>
        <name><surname>Hwang</surname><given-names>John T.</given-names></name>
        <name><surname>Morlier</surname><given-names>Joseph</given-names></name>
        <name><surname>Martins</surname><given-names>Joaquim R. R. A.</given-names></name>
      </person-group>
      <article-title>SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes</article-title>
      <source>Advances in Engineering Software</source>
      <year iso-8601-date="2024-02">2024</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-12-02">2024</year><month>12</month><day>02</day></date-in-citation>
      <volume>188</volume>
      <issn>0965-9978</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S096599782300162X</uri>
      <pub-id pub-id-type="doi">10.1016/j.advengsoft.2023.103571</pub-id>
      <fpage>103571</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-westermann_surrogate_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Westermann</surname><given-names>Paul</given-names></name>
        <name><surname>Evins</surname><given-names>Ralph</given-names></name>
      </person-group>
      <article-title>Surrogate modelling for sustainable building design â€“ A review</article-title>
      <source>Energy and Buildings</source>
      <year iso-8601-date="2019-09">2019</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-12-02">2024</year><month>12</month><day>02</day></date-in-citation>
      <volume>198</volume>
      <issn>0378-7788</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0378778819302877</uri>
      <pub-id pub-id-type="doi">10.1016/j.enbuild.2019.05.057</pub-id>
      <fpage>170</fpage>
      <lpage>186</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bounceur_global_2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bounceur</surname><given-names>N.</given-names></name>
        <name><surname>Crucifix</surname><given-names>M.</given-names></name>
        <name><surname>Wilkinson</surname><given-names>R. D.</given-names></name>
      </person-group>
      <article-title>Global sensitivity analysis of the climateâ€“vegetation system to astronomical forcing: An emulator-based approach</article-title>
      <source>Earth System Dynamics</source>
      <year iso-8601-date="2015-05">2015</year><month>05</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>6</volume>
      <issue>1</issue>
      <issn>2190-4979</issn>
      <uri>https://esd.copernicus.org/articles/6/205/2015/</uri>
      <pub-id pub-id-type="doi">10.5194/esd-6-205-2015</pub-id>
      <fpage>205</fpage>
      <lpage>224</lpage>
    </element-citation>
  </ref>
  <ref id="ref-angione_using_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Angione</surname><given-names>Claudio</given-names></name>
        <name><surname>Silverman</surname><given-names>Eric</given-names></name>
        <name><surname>Yaneske</surname><given-names>Elisabeth</given-names></name>
      </person-group>
      <article-title>Using machine learning as a surrogate model for agent-based simulations</article-title>
      <source>PLOS ONE</source>
      <year iso-8601-date="2022-02">2022</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-18">2024</year><month>11</month><day>18</day></date-in-citation>
      <volume>17</volume>
      <issue>2</issue>
      <issn>1932-6203</issn>
      <uri>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0263150</uri>
      <pub-id pub-id-type="doi">10.1371/journal.pone.0263150</pub-id>
      <fpage>e0263150</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
