<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4061</article-id>
<article-id pub-id-type="doi">10.21105/joss.04061</article-id>
<title-group>
<article-title>The AutoActive Research Environment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Albrektsen</surname>
<given-names>Sigurd</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rasmussen</surname>
<given-names>Kasper Gade Bøtker</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liverud</surname>
<given-names>Anders E.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dalgard</surname>
<given-names>Steffen</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Høgenes</surname>
<given-names>Jakob</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jahren</surname>
<given-names>Silje Ekroll</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kocbach</surname>
<given-names>Jan</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Seeberg</surname>
<given-names>Trine M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Smart Sensor Systems, SINTEF Digital, Trondheim,
Norway</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Centre for Elite Sports Research, Department of
Neuromedicine and Movement Science, Norwegian University of Science and
Technology, Trondheim, Norway</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-09-28">
<day>28</day>
<month>9</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>72</issue>
<fpage>4061</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Visualising sensor data and videos</kwd>
<kwd>Synchronizing sensor data and videos</kwd>
<kwd>Organising data</kwd>
<kwd>Python toolbox</kwd>
<kwd>Matlab toolbox</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>There is an ever-growing variety of biomedical sensors and
  wearables that aim to monitor activity, biomarkers, and vital signs.
  However, to fully understand the physical and physiological factors of
  the underlying processes, multiple sensors are often needed in
  combination with videos. Software for combining, synchronizing,
  organising and processing sensor data from multiple sensors and videos
  is therefore essential. Even though multiple open-source solutions
  like Pyomeca
  (<xref alt="Martinez et al., 2020" rid="ref-Martinez2020" ref-type="bibr">Martinez
  et al., 2020</xref>) and ALPS
  (<xref alt="Musmann et al., 2020" rid="ref-Musmann2020" ref-type="bibr">Musmann
  et al., 2020</xref>) exist, existing open source software solutions
  are limited. None provide the possibility to combine sensor data and
  videos, few provide tools for synchronising sensors, and none provide
  tools for synchronising sensors with videos. Furthermore, many
  solutions rely on cloud storage, which is often unacceptable in
  biomedical research. There also exist solutions which are not limited
  in functionality and solve many of the same problems as ARE, such as
  SensiML Analytics Toolkit
  (<xref alt="SensiML, cited Jan 2022" rid="ref-SensiML" ref-type="bibr">SensiML,
  cited Jan 2022</xref>) and Pasco Capstone Software
  (<xref alt="scientific, cited Jan 2022" rid="ref-PascoSoftware" ref-type="bibr">scientific,
  cited Jan 2022</xref>), but these are not open source. To meet these
  limitations, we have developed the AutoActive Research Environment
  (ARE). The idea of ARE is to create a generic open source
  methodological framework, especially but not exlusively for the
  biomedical and sport domains, supporting a wide range of sensors and
  tools that aid the development, optimization, and evaluation of
  algorithms.</p>
</sec>
<sec id="summary">
  <title>Summary</title>
  <p>ARE consists of three different software modules;
  ActivityPresenter, a Matlab toolbox, and a Python toolbox.
  ActivityPresenter is created to simplify the process of visualising,
  synchronising, and organising data, such as sensor data and videos
  from multiple sources, while the Matlab and Python toolboxes allow
  researchers to easily process data. Furthermore, a file format called
  AutoActiveZip (aaz) was created to store data and metadata in an
  organized manner. This format is a structured archive which contains
  immutable data structures and where the information within can be
  accessed without the use of temporary files that needs to be cleaned
  up. This ensures that sensitive data are not inadvertently left in
  temporary folders in case of program failure. The format allows the
  strengths of ActivityPresenter, such as synchronising data from
  multiple sources, and visualising videos and sensor data side by side
  to be combined with algorithms developed in Matlab and Python.</p>
</sec>
<sec id="overview-of-the-autoactive-research-environment">
  <title>Overview of the AutoActive Research Environment</title>
  <sec id="activitypresenter">
    <title>ActivityPresenter</title>
    <p>ActivityPresenter is an easy-to-use software with a graphical
    user interface that can visualise, synchronise, and organise data
    from sensors and cameras. It is developed using the Xamarin
    framework which simplifies the task of supporting multiple operating
    systems, as almost all the code for both the GUI and data handling
    can be shared for all targeted platforms. An example of
    ActivityPresenter can be seen in
    <xref alt="Figure 1" rid="figU003AActivityPresenter">Figure 1</xref>
    where we visualise synchronised video with gyroscope and heart rate
    data.</p>
    <fig>
      <caption><p>Example of ActivityPresenter.
      <styled-content id="figU003AActivityPresenter"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="figures/ActivityPresenter.PNG" xlink:title="" />
    </fig>
    <p>ActivityPresenter makes it possible to import data from an aaz
    file, files generated by sensors such as the Physiolog 5 sensor
    (Gait Up SA, Lausanne, Switzerland), Catapult Optimeye S5 (Catapult
    Sports, Melbourne, Australia) and tcx files from Garmin (Garmin
    International Inc, Kansas, USA) as well as common data types such as
    csv and xlsx and all video formats acceptable by Microsoft Windows.
    Furthermore, it is easy to extend accepted file types as the
    architecture is plugin-based. The application architecture can be
    seen in
    <xref alt="Figure 2" rid="figU003AArchitecture">Figure 2</xref>.
    Data can be loaded from an aaz file or from a custom data importer
    onto the databus. Data on the databus can be used to create tree
    views to get an overview of the datasets, create figures to view
    data, or synchronise data coming from different sources. When the
    data has been synchronised, the changes are written back to the
    databus. The data on the databus can also be reorganised and written
    to a new aaz file. When data is made available on the databus, data
    is not necessarily loaded into memory. If data comes from an aaz
    file, data is first read into memory when accessed. This typically
    happens when the data is selected from the data tree view for
    visualization. Hereby, we minimise the memory footprint of
    ActivityPresenter and make it possible to view parts of large
    sessions on devices with limited resources.</p>
    <fig>
      <caption><p>Architecture of ActivityPresenter.
      <styled-content id="figU003AArchitecture"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="figures/Architecture.PNG" xlink:title="" />
    </fig>
  </sec>
  <sec id="data-handling">
    <title>Data Handling</title>
    <sec id="session">
      <title>Session</title>
      <p>The concept of sessions is key to how we handle and store data
      in ARE; they are the root containers of datasets. A session
      represents an activity bounded in time and space and stores the
      information about the context of the activity, and the data
      generated during that activity. When a session is saved, it
      becomes immutable and is assigned a unique identifier. This allow
      sessions to be based on previous sessions, and enables
      traceability and reproducibility as analysed information is
      referenced to the session where the data for that analysis was
      stored. It also allows referencing of large files, such as
      high-quality video captures during an activity, without
      duplicating the files.</p>
    </sec>
    <sec id="autoactivezip-file">
      <title>AutoActiveZip File</title>
      <p>An AutoActiveZip (aaz) file is an uncompressed zip archive that
      contains a set of sessions. All information inside the archive is
      organized into directories like a file system. By using the ZIP
      archive file format, we can store multiple datasets in a single
      file, store necessary metadata to describe the data, but most
      importantly we can compress data in a binary format suitable for
      different data types. In ARE sensor data is stored in parquet
      files, while videos are stored in their original format, as they
      are already compressed. By using the parquet format instead of a
      common data format such as csv we reduce storage requirements on
      larger files. The necessary metadata is stored in a json file
      within the archive. An example of the structure of an aaz-file can
      be seen in
      <xref alt="Figure 3" rid="figU003AAazFile">Figure 3</xref> where a
      file named “GoPro_openpifpaf.aaz” is described. An aaz file can
      contain one to many sessions, in this case there is only one
      session. The session is identified with a uuid4 number,
      “a9ee0260-c8c6-4f87-b00c-bb25a7772885” and is just a folder.
      Inside the session folder two more folders exist, a folder named
      “data” and a folder named “video”, and a json file named
      “AUTOACTIVE_SESSION.json”. The purpose of the json file is to
      store necessary metadata. The folder named data contains a parquet
      file named “video_features.3ded455b-6567-440f-8f87-effc6549ed05”.
      The other folder contains a video named
      “GoPro1_inne.d84020b3-f047-4026-96df-51ce987d747e”. Although the
      folders only contain one file in the example, a folder can
      potentially contain multiple different files.</p>
      <fig>
        <caption><p>Structure of the AutoActive Zip file
        <styled-content id="figU003AAazFile"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="figures/AazFile.PNG" xlink:title="" />
      </fig>
    </sec>
    <sec id="json-file">
      <title>Json file</title>
      <p>Each session in an aaz file contains a root json file which
      contains important metadata used when reading data from the aaz
      file into native C#, Matlab and Python classes. An example of the
      structure of a json file can be seen in
      <xref alt="Figure 4" rid="figU003AJsonFile">Figure 4</xref>. The
      json file corresponds to the zip file in
      <xref alt="Figure 3" rid="figU003AAazFile">Figure 3</xref>. Each
      part of the json file contains a meta field and a user field. The
      meta field contains only data not presented to the user, while the
      user field contains metadata visible and editable by user or
      nested datasets in the form of other data objects. The first meta
      field seen in
      <xref alt="Figure 4" rid="figU003AJsonFile">Figure 4</xref>
      describes the session object while the user field contains another
      folder named “Data” where the data-table and video is defined.</p>
      <fig>
        <caption><p>Structure of the json file inside the aaz file
        <styled-content id="figU003AJsonFile"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="figures/JsonFile.PNG" xlink:title="" />
      </fig>
    </sec>
  </sec>
  <sec id="matlab-and-python-toolboxes">
    <title>Matlab and Python toolboxes</title>
    <p>The Matlab and Python toolboxes consist of a reader and writer
    class which reads and writes AutoActiveZip files. The Matlab toolbox
    also consists of classes which makes it easy to create aaz
    dataobjects directly from e.g. Physiolog 5 and tcx files from
    Garmin. Furthermore, the libraries consist of a set of classes
    storing sensor data and videos. The data classes all inherit from
    the dataobject class. The dataobject class specifies all
    transformations needed for converting the native Matlab and Python
    formats to and from the AutoActiveZip file. All dataobject
    sub-classes in Matlab and Python are identified by a type string.
    The type string is also stored in the AutoActiveZip File in the json
    file and can be seen in the meta sections in
    <xref alt="Figure 4" rid="figU003AJsonFile">Figure 4</xref>. This
    makes it possible to load a session from the AutoActiveZip into
    specific data classes.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The AutoActive Research platform was developed at SINTEF as a part
  of the AutoActive, project financed by the Norwegian Research Council
  (no. 270791), with support from the SILENSE ARTEMIS project (no.
  737487) and internal funding.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Martinez2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Martinez</surname><given-names>Romain</given-names></name>
        <name><surname>Michaud</surname><given-names>Benjamin</given-names></name>
        <name><surname>Begon</surname><given-names>Mickael</given-names></name>
      </person-group>
      <article-title>‘Pyomeca‘: An open-source framework for biomechanical analysis</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>53</issue>
      <uri>https://doi.org/10.21105/joss.02431</uri>
      <pub-id pub-id-type="doi">10.21105/joss.02431</pub-id>
      <fpage>2431</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Musmann2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Musmann</surname><given-names>F.</given-names></name>
        <name><surname>Sasso</surname><given-names>A.</given-names></name>
        <name><surname>Arnrich</surname><given-names>B.</given-names></name>
      </person-group>
      <article-title>ALPS: A web platform for analysing multimodal sensor data in the context of digital health</article-title>
      <source>2020 IEEE international conference on healthcare informatics (ICHI)</source>
      <publisher-name>IEEE Computer Society</publisher-name>
      <publisher-loc>Los Alamitos, CA, USA</publisher-loc>
      <year iso-8601-date="2020-12">2020</year><month>12</month>
      <volume></volume>
      <issn></issn>
      <uri>https://doi.ieeecomputersociety.org/10.1109/ICHI48887.2020.9374371</uri>
      <pub-id pub-id-type="doi">10.1109/ICHI48887.2020.9374371</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PascoSoftware">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>scientific</surname><given-names>PASCO</given-names></name>
      </person-group>
      <article-title>PASCO capstone software</article-title>
      <uri>https://www.pasco.com/products/software/capstonea</uri>
    </element-citation>
  </ref>
  <ref id="ref-SensiML">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>SensiML</surname></name>
      </person-group>
      <article-title>SensiML analytics toolkit</article-title>
      <uri>https://sensiml.com/</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
