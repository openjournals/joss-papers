<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4634</article-id>
<article-id pub-id-type="doi">10.21105/joss.04634</article-id>
<title-group>
<article-title>pocoMC: A Python package for accelerated Bayesian
inference in astronomy and cosmology</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">0000-0001-9489-4612</contrib-id>
<name>
<surname>Karamanis</surname>
<given-names>Minas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6882-627X</contrib-id>
<name>
<surname>Nabergoj</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0467-5438</contrib-id>
<name>
<surname>Beutler</surname>
<given-names>Florian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-1168-8299</contrib-id>
<name>
<surname>Peacock</surname>
<given-names>John A.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2262-356X</contrib-id>
<name>
<surname>Seljak</surname>
<given-names>Uro≈°</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institute for Astronomy, University of Edinburgh, Royal
Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Faculty of Computer and Information Science, University of
Ljubljana, Veƒçna pot 113, 1000 Ljubljana, Slovenia</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Physics Department, University of California and Lawrence
Berkeley National Laboratory Berkeley, CA 94720, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-07-12">
<day>12</day>
<month>7</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>79</issue>
<fpage>4634</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>astronomy</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>pocoMC</monospace> is a Python package for accelerated
  Bayesian inference in astronomy and cosmology. The code is designed to
  sample efficiently from posterior distributions with non-trivial
  geometry, including strong multimodality and non-linearity. To this
  end, <monospace>pocoMC</monospace> relies on the Preconditioned Monte
  Carlo algorithm which utilises a Normalising Flow to decorrelate the
  parameters of the posterior. It facilitates both tasks of parameter
  estimation and model comparison, focusing especially on
  computationally expensive applications. It allows fitting arbitrary
  models defined as a log-likelihood function and a log-prior
  probability density function in Python. Compared to popular
  alternatives (e.g. nested sampling) <monospace>pocoMC</monospace> can
  speed up the sampling procedure by orders of magnitude, cutting down
  the computational cost substantially. Finally, parallelisation to
  computing clusters manifests linear scaling.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Over the past few decades, the volume of astronomical and
  cosmological data has increased substantially. At the same time,
  theoretical and phenomenological models in these fields have grown
  even more complex. As a response to that, a number of methods aiming
  at efficient Bayesian computation have been developed with the sole
  task of comparing those models to the available data
  (<xref alt="Sharma, 2017" rid="ref-sharma2017markov" ref-type="bibr">Sharma,
  2017</xref>;
  <xref alt="Trotta, 2017" rid="ref-trotta2017bayesian" ref-type="bibr">Trotta,
  2017</xref>). In the Bayesian context, scientific inference proceeds
  through the use of Bayes‚Äô theorem:
  <named-content id="eqU003Abayes" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
  \mathcal{P}(\theta) = \frac{\mathcal{L}(\theta)\pi(\theta)}{\mathcal{Z}}]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>‚Ñí</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>œÄ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mstyle mathvariant="script"><mml:mi>ùíµ</mml:mi></mml:mstyle></mml:mfrac></mml:mrow></mml:math></alternatives></disp-formula></named-content>
  where the posterior <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{P}(\theta)\equiv p(\theta\vert d,\mathcal{M})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>‚â°</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ≥</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is the probability of the parameters <inline-formula><alternatives>
  <tex-math><![CDATA[\theta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ∏</mml:mi></mml:math></alternatives></inline-formula>
  given the data <inline-formula><alternatives>
  <tex-math><![CDATA[d]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>d</mml:mi></mml:math></alternatives></inline-formula>
  and the model <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{M}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>‚Ñ≥</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>.
  The other components of this equation are: the likelihood function
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{L}(\theta)\equiv p(d\vert \theta,\mathcal{M})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>‚Ñí</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>‚â°</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ≥</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  the prior <inline-formula><alternatives>
  <tex-math><![CDATA[\pi(\theta) \equiv p(\theta\vert \mathcal{M})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>œÄ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>‚â°</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ≥</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  and the model evidence <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{Z}=p(d\vert \mathcal{M})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>ùíµ</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ≥</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  The prior and the likelihood are usually provided as input in this
  equation and one seeks to estimate the posterior and the evidence.
  Knowledge of the posterior, in the form of samples, is paramount for
  the task of parameter estimation whereas the ratio of model evidences
  yields the Bayes factor which is the cornerstone of Bayesian model
  comparison.</p>
  <p>Markov chain Monte Carlo (MCMC) has been established as the
  standard tool for Bayesian computation in astronomy and cosmology,
  either as a standalone algorithm or as part of another method (e.g.,
  nested sampling,
  <xref alt="Skilling, 2006" rid="ref-skilling2006nested" ref-type="bibr">Skilling,
  2006</xref>). However, as MCMC relies on the local exploration of the
  posterior, the presence of a non-linear correlation between parameters
  and multimodality can at best hinder its performance and at worst
  violate its theoretical guarantees of convergence (i.e.¬†ergodicity).
  Usually, those challenges are partially addressed by reparameterising
  the model using a common change-of-variables parameter transformation.
  However, guessing the right kind of reparameterisation <italic>a
  priori</italic> is not trivial as it often requires a deep knowledge
  of the physical model and its symmetries. These problems are usually
  complicated further by the substantial computational cost of
  evaluating astronomical and cosmological models.
  <monospace>pocoMC</monospace> is designed to tackle exactly these
  kinds of difficulties by automatically reparameterising the model such
  that the parameters of the model are approximately uncorrelated and
  standard techniques can be applied. As a result,
  <monospace>pocoMC</monospace> produces both samples from the posterior
  distribution and an unbiased estimate of the model evidence thus
  facilitating both scientific tasks with excellent efficiency and
  robustness. Compared to popular alternatives such as nested sampling,
  <monospace>pocoMC</monospace> can reduce the computational cost, and
  thus, the total run time of the analysis by orders of magnitude, in
  both artificial and realistic applications
  (<xref alt="Karamanis et al., 2022" rid="ref-karamanis2022accelerating" ref-type="bibr">Karamanis
  et al., 2022</xref>). Finally, the code is well-tested and is
  currently used for research work in the field of gravitational wave
  parameter estimation
  (<xref alt="Vretinaris et al., 2022" rid="ref-vretinaris2022postmerger" ref-type="bibr">Vretinaris
  et al., 2022</xref>).</p>
</sec>
<sec id="method">
  <title>Method</title>
  <p><monospace>pocoMC</monospace> implements the Preconditioned Monte
  Carlo (PMC) algorithm. PMC combines the popular Sequential Monte Carlo
  (SMC,
  <xref alt="Del Moral et al., 2006" rid="ref-del2006sequential" ref-type="bibr">Del
  Moral et al., 2006</xref>) method with a Normalising Flow (NF,
  <xref alt="Papamakarios et al., 2021" rid="ref-papamakarios2021normalizing" ref-type="bibr">Papamakarios
  et al., 2021</xref>). The latter works as a preconditioner for the
  target distribution of the former. As SMC evolves a population of
  particles, starting from the prior distribution and gradually
  approaching the posterior distribution, the NF transforms the
  parameters of the target distribution such that any correlation
  between parameters or presence of multimodality is removed. The effect
  of this bijective transformation is the substantial rise in the
  sampling efficiency of the algorithm as the particles are allowed to
  sample freely from the target without being hindered by its
  locally-curved geometry. The method is explained in detail in the
  accompanying publication
  (<xref alt="Karamanis et al., 2022" rid="ref-karamanis2022accelerating" ref-type="bibr">Karamanis
  et al., 2022</xref>), and we provide only a summary here. NFs have
  been used extensively to accelerate various sampling algorithms,
  including Hamiltonian Monte Carlo
  (<xref alt="Hoffman et al., 2019" rid="ref-hoffman2019neutra" ref-type="bibr">Hoffman
  et al., 2019</xref>), Metropolis adjusted Langevin algorithm
  (<xref alt="Gabri√© et al., 2022a" rid="ref-gabrie2021efficient" ref-type="bibr">Gabri√©
  et al., 2022a</xref>), adaptive Independence Metropolis-Hastings
  (<xref alt="Brofos et al., 2022" rid="ref-brofos2022adaptation" ref-type="bibr">Brofos
  et al., 2022</xref>), adaptive MCMC
  (<xref alt="Gabri√© et al., 2022b" rid="ref-gabrie2022adaptive" ref-type="bibr">Gabri√©
  et al., 2022b</xref>), and nested sampling
  (<xref alt="Moss, 2020" rid="ref-moss2020accelerated" ref-type="bibr">Moss,
  2020</xref>).</p>
  <sec id="sequential-monte-carlo">
    <title>Sequential Monte Carlo</title>
    <p>The basic idea of basic SMC is to sample from the posterior
    distribution <inline-formula><alternatives>
    <tex-math><![CDATA[\mathcal{P}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    by first defining a path of intermediate distributions starting from
    the prior <inline-formula><alternatives>
    <tex-math><![CDATA[\pi(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>œÄ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    In the case of <monospace>pocoMC</monospace> the path has the form:
    <named-content id="eqU003Apath" content-type="equation"><disp-formula><alternatives>
    <tex-math><![CDATA[
    p_{t}(\theta) = \pi(\theta)^{1-\beta_{t}} \mathcal{P}(\theta)^{\beta_{t}}]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>œÄ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:msub><mml:mi>Œ≤</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math></alternatives></disp-formula></named-content>
    where <inline-formula><alternatives>
    <tex-math><![CDATA[0=\beta_{1}<\beta_{2}<\dots<\beta_{T}=1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>‚Ä¶</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    Starting from the prior, each distribution with density
    <inline-formula><alternatives>
    <tex-math><![CDATA[p_{t}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    is sampled in turn using a collection of particles propagated by a
    number of MCMC steps. Before MCMC sampling, the particles are
    re-weighted using importance sampling and then re-sampled to account
    for the transition from <inline-formula><alternatives>
    <tex-math><![CDATA[p_{t}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    to <inline-formula><alternatives>
    <tex-math><![CDATA[p_{t+1}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    <monospace>pocoMC</monospace> utilises the importance weights of
    this step to define an estimator for the effective sample size (ESS)
    of the population of particles. Maintaining a fixed value of ESS
    during the run allows <monospace>pocoMC</monospace> to adaptively
    specify the <inline-formula><alternatives>
    <tex-math><![CDATA[\beta_{t}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œ≤</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    schedule.</p>
  </sec>
  <sec id="preconditioned-monte-carlo">
    <title>Preconditioned Monte Carlo</title>
    <p>In vanilla SMC, standard MCMC methods (e.g.¬†Metropolis-Hastings)
    are used to update the positions of the particles during each
    iteration. This however can become highly inefficient if the
    distribution <inline-formula><alternatives>
    <tex-math><![CDATA[p_{t}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    is characterised by a non-trivial geometry.
    <monospace>pocoMC</monospace>, which is based on PMC, utilises a NF
    to learn an invertible transformation that simplifies the geometry
    of the distribution by mapping <inline-formula><alternatives>
    <tex-math><![CDATA[p_{t}(\theta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ∏</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    into a zero-mean unit-variance normal distribution. Sampling then
    proceeds in the latent space in which correlations are substantially
    reduced. The positions of the particles are transformed back to the
    original parameter space at the end of each iteration. This way, PMC
    and <monospace>pocoMC</monospace> can sample from very challenging
    posteriors very efficiently using simple Metropolis-Hastings updates
    in the preconditioned/uncorrelated latent space.</p>
  </sec>
</sec>
<sec id="features">
  <title>Features</title>
  <list list-type="bullet">
    <list-item>
      <p>User-friendly black-box API: only the log-likelihood, log-prior
      and some prior samples required from the user.</p>
    </list-item>
    <list-item>
      <p>The default configuration sufficient for most applications: no
      tuning is required but is possible for experienced users.</p>
    </list-item>
    <list-item>
      <p>Comprehensive plotting tools: posterior corner, trace, and run
      plots are all supported.</p>
    </list-item>
    <list-item>
      <p>Model evidence estimation using Gaussianized Bridge Sampling
      (<xref alt="Jia &amp; Seljak, 2020" rid="ref-jia2020normalizing" ref-type="bibr">Jia
      &amp; Seljak, 2020</xref>).</p>
    </list-item>
    <list-item>
      <p>Support for both MAF and RealNVP normalising flows with added
      regularisation
      (<xref alt="Dinh et al., 2016" rid="ref-dinh2016density" ref-type="bibr">Dinh
      et al., 2016</xref>;
      <xref alt="Papamakarios et al., 2017" rid="ref-papamakarios2017masked" ref-type="bibr">Papamakarios
      et al., 2017</xref>).</p>
    </list-item>
    <list-item>
      <p>Straightforward parallelisation using MPI or
      multiprocessing.</p>
    </list-item>
    <list-item>
      <p>Well-tested and documented: continuous integration, unit tests,
      a wide range of examples, and
      <ext-link ext-link-type="uri" xlink:href="https://pocomc.readthedocs.io/">extensive
      documentation</ext-link>.</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>MK would like to thank Jamie Donald-McCann and Richard Grumitt for
  providing constructive comments and George Vretinaris for feedback on
  an early version of the code. This project has received funding from
  the European Research Council (ERC) under the European Union‚Äôs Horizon
  2020 research and innovation program (grant agreement 853291), and
  from the U.S. Department of Energy, Office of Science, Office of
  Advanced Scientific Computing Research under Contract
  No.¬†DE-AC02-05CH11231 at Lawrence Berkeley National Laboratory to
  enable research for Data-intensive Machine Learning and Analysis. FB
  is a University Research Fellow.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-karamanis2022accelerating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Karamanis</surname><given-names>Minas</given-names></name>
        <name><surname>Beutler</surname><given-names>Florian</given-names></name>
        <name><surname>Peacock</surname><given-names>John A</given-names></name>
        <name><surname>Nabergoj</surname><given-names>David</given-names></name>
        <name><surname>Seljak</surname><given-names>Uro≈°</given-names></name>
      </person-group>
      <article-title>Accelerating astronomical and cosmological inference with preconditioned Monte Carlo</article-title>
      <source>Mon. Not. R. Astron Soc.</source>
      <publisher-name>Oxford University Press (OUP)</publisher-name>
      <year iso-8601-date="2022-08">2022</year><month>08</month>
      <volume>516</volume>
      <issue>2</issue>
      <issn>0035-8711</issn>
      <uri>https://doi.org/10.1093/mnras/stac2272</uri>
      <pub-id pub-id-type="doi">10.1093/mnras/stac2272</pub-id>
      <fpage>1644</fpage>
      <lpage>1653</lpage>
    </element-citation>
  </ref>
  <ref id="ref-trotta2017bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Trotta</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Bayesian methods in cosmology</article-title>
      <source>arXiv e-prints</source>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <uri>https://arxiv.org/abs/1701.01467</uri>
      <fpage>arXiv:1701.01467</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-sharma2017markov">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sharma</surname><given-names>Sanjib</given-names></name>
      </person-group>
      <article-title>Markov chain Monte Carlo methods for Bayesian data analysis in astronomy</article-title>
      <source>Annu. Rev. Astron. Astr.</source>
      <publisher-name>Annual Reviews</publisher-name>
      <year iso-8601-date="2017-08">2017</year><month>08</month>
      <volume>55</volume>
      <issue>1</issue>
      <issn>0066-4146</issn>
      <uri>https://doi.org/10.1146/annurev-astro-082214-122339</uri>
      <pub-id pub-id-type="doi">10.1146/annurev-astro-082214-122339</pub-id>
      <fpage>213</fpage>
      <lpage>259</lpage>
    </element-citation>
  </ref>
  <ref id="ref-skilling2006nested">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Skilling</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Nested sampling for general Bayesian computation</article-title>
      <source>Bayesian Anal.</source>
      <publisher-name>Institute of Mathematical Statistics</publisher-name>
      <year iso-8601-date="2006-12">2006</year><month>12</month>
      <volume>1</volume>
      <issue>4</issue>
      <issn>1936-0975</issn>
      <uri>https://doi.org/10.1214/06-ba127</uri>
      <pub-id pub-id-type="doi">10.1214/06-ba127</pub-id>
      <fpage>833</fpage>
      <lpage>859</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dinh2016density">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dinh</surname><given-names>Laurent</given-names></name>
        <name><surname>Sohl-Dickstein</surname><given-names>Jascha</given-names></name>
        <name><surname>Bengio</surname><given-names>Samy</given-names></name>
      </person-group>
      <article-title>Density estimation using Real NVP</article-title>
      <source>arXiv e-prints</source>
      <year iso-8601-date="2016-05">2016</year><month>05</month>
      <uri>https://arxiv.org/abs/1605.08803</uri>
      <fpage>arXiv:1605.08803</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2017masked">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Pavlakou</surname><given-names>Theo</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Masked autoregressive flow for density estimation</article-title>
      <source>Adv Neural Inf Process Syst</source>
      <year iso-8601-date="2017">2017</year>
      <volume>30</volume>
    </element-citation>
  </ref>
  <ref id="ref-del2006sequential">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Del Moral</surname><given-names>Pierre</given-names></name>
        <name><surname>Doucet</surname><given-names>Arnaud</given-names></name>
        <name><surname>Jasra</surname><given-names>Ajay</given-names></name>
      </person-group>
      <article-title>Sequential Monte Carlo samplers</article-title>
      <source>J. R. Stat. Soc. B</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2006-06">2006</year><month>06</month>
      <volume>68</volume>
      <issue>3</issue>
      <issn>1369-7412</issn>
      <uri>https://doi.org/10.1111/j.1467-9868.2006.00553.x</uri>
      <pub-id pub-id-type="doi">10.1111/j.1467-9868.2006.00553.x</pub-id>
      <fpage>411</fpage>
      <lpage>436</lpage>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2021normalizing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Nalisnick</surname><given-names>Eric T</given-names></name>
        <name><surname>Rezende</surname><given-names>Danilo Jimenez</given-names></name>
        <name><surname>Mohamed</surname><given-names>Shakir</given-names></name>
        <name><surname>Lakshminarayanan</surname><given-names>Balaji</given-names></name>
      </person-group>
      <article-title>Normalizing flows for probabilistic modeling and inference.</article-title>
      <source>J. Mach. Learn. Res.</source>
      <year iso-8601-date="2021">2021</year>
      <volume>22</volume>
      <issue>57</issue>
      <fpage>1</fpage>
      <lpage>64</lpage>
    </element-citation>
  </ref>
  <ref id="ref-vretinaris2022postmerger">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Vretinaris</surname><given-names>George</given-names></name>
        <name><surname>Vretinaris</surname><given-names>Stamatis</given-names></name>
        <name><surname>Mermigkas</surname><given-names>Christos</given-names></name>
        <name><surname>Karamanis</surname><given-names>Minas</given-names></name>
        <name><surname>Stergioulas</surname><given-names>Nikolaos</given-names></name>
      </person-group>
      <article-title>Robust and fast parameter estimation of gravitational waves from neutron star merger remnants</article-title>
      <source>in prep</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-jia2020normalizing">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Jia</surname><given-names>He</given-names></name>
        <name><surname>Seljak</surname><given-names>Uros</given-names></name>
      </person-group>
      <article-title>Normalizing constant estimation with gaussianized bridge sampling</article-title>
      <source>Symposium on advances in approximate bayesian inference</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <fpage>1</fpage>
      <lpage>14</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hoffman2019neutra">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hoffman</surname><given-names>Matthew</given-names></name>
        <name><surname>Sountsov</surname><given-names>Pavel</given-names></name>
        <name><surname>Dillon</surname><given-names>Joshua V.</given-names></name>
        <name><surname>Langmore</surname><given-names>Ian</given-names></name>
        <name><surname>Tran</surname><given-names>Dustin</given-names></name>
        <name><surname>Vasudevan</surname><given-names>Srinivas</given-names></name>
      </person-group>
      <article-title>NeuTra-lizing bad geometry in Hamiltonian Monte Carlo using neural transport</article-title>
      <source>arXiv e-prints</source>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <uri>https://arxiv.org/abs/1903.03704</uri>
      <fpage>arXiv:1903.03704</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gabrie2021efficient">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gabri√©</surname><given-names>Marylou</given-names></name>
        <name><surname>Rotskoff</surname><given-names>Grant M.</given-names></name>
        <name><surname>Vanden-Eijnden</surname><given-names>Eric</given-names></name>
      </person-group>
      <article-title>Adaptive Monte Carlo augmented with normalizing flows</article-title>
      <source>Proc. Natl. Acad. Sci.</source>
      <publisher-name>Proceedings of the National Academy of Sciences</publisher-name>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <volume>119</volume>
      <issue>10</issue>
      <issn>0027-8424</issn>
      <uri>https://doi.org/10.1073/pnas.2109420119</uri>
      <pub-id pub-id-type="doi">10.1073/pnas.2109420119</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-brofos2022adaptation">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Brofos</surname><given-names>James</given-names></name>
        <name><surname>Gabri√©</surname><given-names>Marylou</given-names></name>
        <name><surname>Brubaker</surname><given-names>Marcus A</given-names></name>
        <name><surname>Lederman</surname><given-names>Roy R</given-names></name>
      </person-group>
      <article-title>Adaptation of the independent Metropolis-Hastings sampler with normalizing flow proposals</article-title>
      <source>International conference on artificial intelligence and statistics</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <fpage>5949</fpage>
      <lpage>5986</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gabrie2022adaptive">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gabri√©</surname><given-names>Marylou</given-names></name>
        <name><surname>Rotskoff</surname><given-names>Grant M.</given-names></name>
        <name><surname>Vanden-Eijnden</surname><given-names>Eric</given-names></name>
      </person-group>
      <article-title>Adaptive Monte Carlo augmented with normalizing flows</article-title>
      <source>Proc. Natl. Acad. Sci.</source>
      <publisher-name>Proceedings of the National Academy of Sciences</publisher-name>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <volume>119</volume>
      <issue>10</issue>
      <issn>0027-8424</issn>
      <uri>https://doi.org/10.1073/pnas.2109420119</uri>
      <pub-id pub-id-type="doi">10.1073/pnas.2109420119</pub-id>
      <fpage>e2109420119</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-moss2020accelerated">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Moss</surname><given-names>Adam</given-names></name>
      </person-group>
      <article-title>Accelerated Bayesian inference using deep learning</article-title>
      <source>Mon. Not. R. Astron Soc.</source>
      <publisher-name>Oxford University Press (OUP)</publisher-name>
      <year iso-8601-date="2020-05">2020</year><month>05</month>
      <volume>496</volume>
      <issue>1</issue>
      <issn>0035-8711</issn>
      <uri>https://doi.org/10.1093/mnras/staa1469</uri>
      <pub-id pub-id-type="doi">10.1093/mnras/staa1469</pub-id>
      <fpage>328</fpage>
      <lpage>338</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
