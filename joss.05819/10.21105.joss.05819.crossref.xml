<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20240124T161531-8b74bb1b92a8a4e9142758965f06582f1a5bc080</doi_batch_id>
    <timestamp>20240124161531</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>01</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>93</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>SonoUno development: a User-Centered Sonification
software for data analysis</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Johanna</given_name>
            <surname>Casado</surname>
            <ORCID>https://orcid.org/0000-0001-9528-5034</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Gonzalo</given_name>
            <surname>de la Vega</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Beatriz</given_name>
            <surname>García</surname>
            <ORCID>https://orcid.org/0000-0003-0919-2734</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>01</month>
          <day>24</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>5819</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.05819</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.10303871</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/5819</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.05819</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.05819</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.05819.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="wandatesis2013">
            <article_title>Sound for the exploration of space physics
data</article_title>
            <author>Díaz-Merced</author>
            <journal_title>University of glasgow</journal_title>
            <cYear>2013</cYear>
            <unstructured_citation>Díaz-Merced, W. L. (2013). Sound for
the exploration of space physics data. University of
Glasgow.</unstructured_citation>
          </citation>
          <citation key="wanda2019">
            <article_title>A user centred inclusive web framework for
astronomy</article_title>
            <author>Díaz-Merced</author>
            <journal_title>Proceedings of the international astronomical
union</journal_title>
            <doi>10.1017/S1743921321000272</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Díaz-Merced, W., Walker-Holmes, M.,
Hettlage, C., Green, P., Casado, J., &amp; García, B. (2019). A user
centred inclusive web framework for astronomy. Proceedings of the
International Astronomical Union, 421–422.
https://doi.org/10.1017/S1743921321000272</unstructured_citation>
          </citation>
          <citation key="bardellietal2021">
            <article_title>A sonification of the zCOSMOS galaxy
dataset</article_title>
            <author>Bardelli</author>
            <journal_title>In international conference on human-computer
interaction</journal_title>
            <doi>10.1007/978-3-030-77411-0_12</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Bardelli, S., Ferretti, C., Ludovico,
L. A., Presti, G., &amp; Rinaldi, M. (2021). A sonification of the
zCOSMOS galaxy dataset. In International Conference on Human-Computer
Interaction, 171–188.
https://doi.org/10.1007/978-3-030-77411-0_12</unstructured_citation>
          </citation>
          <citation key="lightsound2020">
            <article_title>LightSound: A sonification tool for observing
solar eclipses</article_title>
            <author>Bieryla</author>
            <journal_title>In american astronomical society meeting
abstracts# 235</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Bieryla, A., Hyman, S., &amp; Davis,
D. (2020). LightSound: A sonification tool for observing solar eclipses.
In American Astronomical Society Meeting Abstracts# 235,
203–204.</unstructured_citation>
          </citation>
          <citation key="henriquesetal2014">
            <article_title>See-through-sound: Transforming images into
sonic representations to help the blind</article_title>
            <author>Henriques</author>
            <journal_title>Journal of Information Technology Research
(JITR)</journal_title>
            <issue>1</issue>
            <volume>7</volume>
            <doi>10.4018/jitr.2014010105</doi>
            <cYear>2014</cYear>
            <unstructured_citation>Henriques, J. T., Cavaco, S., &amp;
Correia, N. (2014). See-through-sound: Transforming images into sonic
representations to help the blind. Journal of Information Technology
Research (JITR), 7(1), 59–77.
https://doi.org/10.4018/jitr.2014010105</unstructured_citation>
          </citation>
          <citation key="AU2023">
            <article_title>The audible universe workshop: An
interdisciplinary approach to the design and evaluation of tools for
astronomical data sonification</article_title>
            <author>Misdariis</author>
            <journal_title>Presented at the 28th international
conference on auditory displays (ICAD 2023) - sonification for the
masses, norrköping, sweden, 26–30 june 2023</journal_title>
            <doi>10.21785/icad2023.2124</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Misdariis, N., Pauletto, S., Bonne,
N., Harrison, C., Meredith, K., &amp; Zanella, A. (2023). The audible
universe workshop: An interdisciplinary approach to the design and
evaluation of tools for astronomical data sonification. Presented at the
28th International Conference on Auditory Displays (ICAD 2023) -
Sonification for the Masses, Norrköping, Sweden, 26–30 June 2023.
https://doi.org/10.21785/icad2023.2124</unstructured_citation>
          </citation>
          <citation key="laurentizetal2021">
            <article_title>R scuti: Creative star data
visualization</article_title>
            <author>Laurentiz</author>
            <journal_title>International Journal of Creative Interfaces
and Computer Graphics (IJCICG)</journal_title>
            <issue>1</issue>
            <volume>12</volume>
            <doi>10.4018/IJCICG.2021010102</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Laurentiz, S., Bergantini, L. P.,
Venancio, S., Mayer, B., Carvalho, M. A., Vargas, D., Perissinotto, P.
M., &amp; Policarpo, C. (2021). R scuti: Creative star data
visualization. International Journal of Creative Interfaces and Computer
Graphics (IJCICG), 12(1), 13–26.
https://doi.org/10.4018/IJCICG.2021010102</unstructured_citation>
          </citation>
          <citation key="reynagaetal2020">
            <article_title>Strategies and technology aids for teaching
science to blind and visually impaired students</article_title>
            <author>Reynaga-Peña</author>
            <journal_title>In User-Centered Software Development for the
Blind and Visually Impaired: Emerging Research and
Opportunities</journal_title>
            <doi>10.4018/978-1-5225-8539-8.ch002</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Reynaga-Peña, C. G., &amp; Carmen
López-Suero, C. del. (2020). Strategies and technology aids for teaching
science to blind and visually impaired students. In User-Centered
Software Development for the Blind and Visually Impaired: Emerging
Research and Opportunities, 26–37.
https://doi.org/10.4018/978-1-5225-8539-8.ch002</unstructured_citation>
          </citation>
          <citation key="andreopoulouYgoudarzi2021">
            <article_title>SONIFICATION FIRST: THE ROLE OF ICAD IN THE
ADVANCEMENT OF SONIFICATION-RELATED RESEARCH</article_title>
            <author>Andreopoulou</author>
            <journal_title>In the 26th international conference on
auditory display (ICAD), virtual conference</journal_title>
            <doi>10.21785/icad2021.031</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Andreopoulou, A., &amp; Goudarzi, V.
(2021). SONIFICATION FIRST: THE ROLE OF ICAD IN THE ADVANCEMENT OF
SONIFICATION-RELATED RESEARCH. In the 26th International Conference on
Auditory Display (ICAD), Virtual Conference.
https://doi.org/10.21785/icad2021.031</unstructured_citation>
          </citation>
          <citation key="ise2a2017">
            <article_title>Evolving from xSonify: A new digital platform
for sonorization</article_title>
            <author>García</author>
            <journal_title>EPJ web of conferences</journal_title>
            <volume>200</volume>
            <doi>10.1051/epjconf/201920001013</doi>
            <cYear>2019</cYear>
            <unstructured_citation>García, B., Díaz-Merced, W., Casado,
J., &amp; Cancio, A. (2019). Evolving from xSonify: A new digital
platform for sonorization. EPJ Web of Conferences, 200, 01013.
https://doi.org/10.1051/epjconf/201920001013</unstructured_citation>
          </citation>
          <citation key="ijskd2022">
            <article_title>Sonification as a tool for data analysis:
Usability and compliance evaluation study</article_title>
            <author>Casado</author>
            <journal_title>International Journal of Sociotechnology and
Knowledge Development IJSKD</journal_title>
            <issue>1</issue>
            <volume>14</volume>
            <doi>10.4018/IJSKD.299048</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Casado, J., Díaz-Merced, W., García,
B., Schneps, M., Kolemberg, K., Rychtarikova, M., &amp; Roozen, N. B.
(2022). Sonification as a tool for data analysis: Usability and
compliance evaluation study. International Journal of Sociotechnology
and Knowledge Development IJSKD, 14(1), 1–27.
https://doi.org/10.4018/IJSKD.299048</unstructured_citation>
          </citation>
          <citation key="casadoetal2019">
            <article_title>Analysis of astronomical data through
sonification: Reaching more inclusion for visually disable
scientists</article_title>
            <author>Casado</author>
            <journal_title>Proceedings of the international astronomical
union, (S358)</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Casado, J., García, B., &amp;
Díaz-Merced, W. L. (2019). Analysis of astronomical data through
sonification: Reaching more inclusion for visually disable scientists.
Proceedings of the International Astronomical Union,
(S358).</unstructured_citation>
          </citation>
          <citation key="casadoFG2022">
            <article_title>A new approach to sonification of
astrophysical data: The user centred design of SonoUno</article_title>
            <author>Casado</author>
            <journal_title>American Journal of Astronomy and
Astrophysics</journal_title>
            <issue>4</issue>
            <volume>9</volume>
            <doi>10.11648/j.ajaa.20210904.11</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Casado, J., García, B., Gandhi, P.,
&amp; Díaz-Merced, W. (2022). A new approach to sonification of
astrophysical data: The user centred design of SonoUno. American Journal
of Astronomy and Astrophysics, 9(4), 42–51.
https://doi.org/10.11648/j.ajaa.20210904.11</unstructured_citation>
          </citation>
          <citation key="zanella2022">
            <article_title>Sonification and sound design for astronomy
research, education and public engagement</article_title>
            <author>Zanella</author>
            <journal_title>Nature Astronomy</journal_title>
            <doi>10.1038/s41550-022-01721-z</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Zanella, A., Harrison, C. M., Lenzi,
S., Cooke, J., Damsma, P., &amp; Fleming, S. W. (2022). Sonification and
sound design for astronomy research, education and public engagement.
Nature Astronomy, 1–8.
https://doi.org/10.1038/s41550-022-01721-z</unstructured_citation>
          </citation>
          <citation key="strauss2021">
            <article_title>Audio universe tour of the solar system:
Using sound to make the universe more accessible</article_title>
            <author>Harrison</author>
            <journal_title>Astronomy and Geophysics</journal_title>
            <issue>2</issue>
            <volume>63</volume>
            <doi>10.1093/astrogeo/atac027</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Harrison, C., Trayford, J., Harrison,
L., &amp; Bonne, N. (2021). Audio universe tour of the solar system:
Using sound to make the universe more accessible. Astronomy and
Geophysics, 63(2), 2.38–2.40.
https://doi.org/10.1093/astrogeo/atac027</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
