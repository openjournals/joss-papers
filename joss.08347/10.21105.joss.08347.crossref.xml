<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20251223221505-1810ce7bfaf6c38404ed373a93b6b5c0aa72fa0d</doi_batch_id>
    <timestamp>20251223221505</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>12</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>116</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>SBGM: Score-Based Generative Models in JAX.</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Jed</given_name>
            <surname>Homer</surname>
            <affiliations>
              <institution><institution_name>University Observatory, Faculty for Physics, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, München, Deutschland.</institution_name><institution_id type="ror">https://ror.org/00hx57361</institution_id></institution>
              <institution><institution_name>Munich Center for Machine Learning.</institution_name><institution_id type="ror">https://ror.org/00hx57361</institution_id></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0002-0985-1437</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>12</month>
          <day>23</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>8347</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.08347</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.17807012</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/8347</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.08347</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.08347</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.08347.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="diffusion">
            <article_title>Deep unsupervised learning using nonequilibrium thermodynamics</article_title>
            <author>Sohl-Dickstein</author>
            <cYear>2015</cYear>
            <unstructured_citation>Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., &amp; Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. https://arxiv.org/abs/1503.03585</unstructured_citation>
          </citation>
          <citation key="ddpm">
            <article_title>Denoising diffusion probabilistic models</article_title>
            <author>Ho</author>
            <cYear>2020</cYear>
            <unstructured_citation>Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models. https://arxiv.org/abs/2006.11239</unstructured_citation>
          </citation>
          <citation key="sbi">
            <article_title>The frontier of simulation-based inference</article_title>
            <author>Cranmer</author>
            <journal_title>Proceedings of the National Academy of Sciences</journal_title>
            <issue>48</issue>
            <volume>117</volume>
            <doi>10.1073/pnas.1912789117</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Cranmer, K., Brehmer, J., &amp; Louppe, G. (2020). The frontier of simulation-based inference. Proceedings of the National Academy of Sciences, 117(48), 30055–30062. https://doi.org/10.1073/pnas.1912789117</unstructured_citation>
          </citation>
          <citation key="field_level_inference">
            <article_title>Bayesian field-level inference of primordial non-gaussianity using next-generation galaxy surveys</article_title>
            <author>Andrews</author>
            <journal_title>Monthly Notices of the Royal Astronomical Society</journal_title>
            <issue>4</issue>
            <volume>520</volume>
            <doi>10.1093/mnras/stad432</doi>
            <issn>1365-2966</issn>
            <cYear>2023</cYear>
            <unstructured_citation>Andrews, A., Jasche, J., Lavaux, G., &amp; Schmidt, F. (2023). Bayesian field-level inference of primordial non-gaussianity using next-generation galaxy surveys. Monthly Notices of the Royal Astronomical Society, 520(4), 5746–5763. https://doi.org/10.1093/mnras/stad432</unstructured_citation>
          </citation>
          <citation key="Feng2023">
            <article_title>Score-based diffusion models as principled priors for inverse imaging</article_title>
            <author>Feng</author>
            <cYear>2023</cYear>
            <unstructured_citation>Feng, B. T., Smith, J., Rubinstein, M., Chang, H., Bouman, K. L., &amp; Freeman, W. T. (2023). Score-based diffusion models as principled priors for inverse imaging. https://arxiv.org/abs/2304.11751</unstructured_citation>
          </citation>
          <citation key="Feng2024">
            <article_title>Variational bayesian imaging with an efficient surrogate score-based prior</article_title>
            <author>Feng</author>
            <cYear>2024</cYear>
            <unstructured_citation>Feng, B. T., &amp; Bouman, K. L. (2024). Variational bayesian imaging with an efficient surrogate score-based prior. https://arxiv.org/abs/2309.01949</unstructured_citation>
          </citation>
          <citation key="inverse_problem_medical">
            <article_title>Solving inverse problems in medical imaging with score-based generative models</article_title>
            <author>Song</author>
            <cYear>2022</cYear>
            <unstructured_citation>Song, Y., Shen, L., Xing, L., &amp; Ermon, S. (2022). Solving inverse problems in medical imaging with score-based generative models. https://arxiv.org/abs/2111.08005</unstructured_citation>
          </citation>
          <citation key="conditional_diffusion">
            <article_title>Conditional image generation with score-based diffusion models</article_title>
            <author>Batzolis</author>
            <cYear>2021</cYear>
            <unstructured_citation>Batzolis, G., Stanczuk, J., Schönlieb, C.-B., &amp; Etmann, C. (2021). Conditional image generation with score-based diffusion models. https://arxiv.org/abs/2111.13606</unstructured_citation>
          </citation>
          <citation key="kidger">
            <article_title>On neural differential equations</article_title>
            <author>Kidger</author>
            <cYear>2022</cYear>
            <unstructured_citation>Kidger, P. (2022). On neural differential equations. https://arxiv.org/abs/2202.02435</unstructured_citation>
          </citation>
          <citation key="sde">
            <article_title>Score-based generative modeling through stochastic differential equations</article_title>
            <author>Song</author>
            <cYear>2021</cYear>
            <unstructured_citation>Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., &amp; Poole, B. (2021). Score-based generative modeling through stochastic differential equations. https://arxiv.org/abs/2011.13456</unstructured_citation>
          </citation>
          <citation key="sde_ml">
            <article_title>Maximum likelihood training of score-based diffusion models</article_title>
            <author>Song</author>
            <cYear>2021</cYear>
            <unstructured_citation>Song, Y., Durkan, C., Murray, I., &amp; Ermon, S. (2021). Maximum likelihood training of score-based diffusion models. https://arxiv.org/abs/2101.09258</unstructured_citation>
          </citation>
          <citation key="ffjord">
            <article_title>FFJORD: Free-form continuous dynamics for scalable reversible generative models</article_title>
            <author>Grathwohl</author>
            <cYear>2018</cYear>
            <unstructured_citation>Grathwohl, W., Chen, R. T. Q., Bettencourt, J., Sutskever, I., &amp; Duvenaud, D. (2018). FFJORD: Free-form continuous dynamics for scalable reversible generative models. https://arxiv.org/abs/1810.01367</unstructured_citation>
          </citation>
          <citation key="neuralodes">
            <article_title>Neural ordinary differential equations</article_title>
            <author>Chen</author>
            <cYear>2019</cYear>
            <unstructured_citation>Chen, R. T. Q., Rubanova, Y., Bettencourt, J., &amp; Duvenaud, D. (2019). Neural ordinary differential equations. https://arxiv.org/abs/1806.07366</unstructured_citation>
          </citation>
          <citation key="blinddiffusion">
            <article_title>Parallel diffusion models of operator and image for blind inverse problems</article_title>
            <author>Chung</author>
            <cYear>2022</cYear>
            <unstructured_citation>Chung, H., Kim, J., Kim, S., &amp; Ye, J. C. (2022). Parallel diffusion models of operator and image for blind inverse problems. https://arxiv.org/abs/2211.10656</unstructured_citation>
          </citation>
          <citation key="ambientdiffusion">
            <article_title>Consistent diffusion meets tweedie: Training exact ambient diffusion models with noisy data</article_title>
            <author>Daras</author>
            <cYear>2024</cYear>
            <unstructured_citation>Daras, G., Dimakis, A. G., &amp; Daskalakis, C. (2024). Consistent diffusion meets tweedie: Training exact ambient diffusion models with noisy data. https://arxiv.org/abs/2404.10177</unstructured_citation>
          </citation>
          <citation key="emulating">
            <article_title>&lt;Scp&gt;CosmoPower&lt;/scp&gt;: Emulating cosmological power spectra for accelerated bayesian inference from next-generation surveys</article_title>
            <author>Spurio Mancini</author>
            <journal_title>Monthly Notices of the Royal Astronomical Society</journal_title>
            <issue>2</issue>
            <volume>511</volume>
            <doi>10.1093/mnras/stac064</doi>
            <issn>1365-2966</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Spurio Mancini, A., Piras, D., Alsing, J., Joachimi, B., &amp; Hobson, M. P. (2022). &lt;Scp&gt;CosmoPower&lt;/scp&gt;: Emulating cosmological power spectra for accelerated bayesian inference from next-generation surveys. Monthly Notices of the Royal Astronomical Society, 511(2), 1771–1788. https://doi.org/10.1093/mnras/stac064</unstructured_citation>
          </citation>
          <citation key="jax">
            <article_title>JAX: Composable transformations of Python+NumPy programs</article_title>
            <author>Bradbury</author>
            <cYear>2018</cYear>
            <unstructured_citation>Bradbury, J., Frostig, R., Hawkins, P., Johnson, M. J., Leary, C., Maclaurin, D., Necula, G., Paszke, A., VanderPlas, J., Wanderman-Milne, S., &amp; Zhang, Q. (2018). JAX: Composable transformations of Python+NumPy programs (Version 0.3.13). http://github.com/jax-ml/jax</unstructured_citation>
          </citation>
          <citation key="equinox">
            <article_title>Equinox: Neural networks in JAX via callable PyTrees and filtered transformations</article_title>
            <author>Kidger</author>
            <journal_title>Differentiable Programming workshop at Neural Information Processing Systems 2021</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Kidger, P., &amp; Garcia, C. (2021). Equinox: Neural networks in JAX via callable PyTrees and filtered transformations. Differentiable Programming Workshop at Neural Information Processing Systems 2021.</unstructured_citation>
          </citation>
          <citation key="optax">
            <article_title>The DeepMind JAX Ecosystem</article_title>
            <author>DeepMind</author>
            <cYear>2020</cYear>
            <unstructured_citation>DeepMind, Babuschkin, I., Baumli, K., Bell, A., Bhupatiraju, S., Bruce, J., Buchlovsky, P., Budden, D., Cai, T., Clark, A., Danihelka, I., Dedieu, A., Fantacci, C., Godwin, J., Jones, C., Hemsley, R., Hennigan, T., Hessel, M., Hou, S., … Viola, F. (2020). The DeepMind JAX Ecosystem. http://github.com/google-deepmind</unstructured_citation>
          </citation>
          <citation key="resnet">
            <article_title>Deep residual learning for image recognition</article_title>
            <author>He</author>
            <cYear>2015</cYear>
            <unstructured_citation>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2015). Deep residual learning for image recognition. https://arxiv.org/abs/1512.03385</unstructured_citation>
          </citation>
          <citation key="unet">
            <article_title>U-net: Convolutional networks for biomedical image segmentation</article_title>
            <author>Ronneberger</author>
            <cYear>2015</cYear>
            <unstructured_citation>Ronneberger, O., Fischer, P., &amp; Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. https://arxiv.org/abs/1505.04597</unstructured_citation>
          </citation>
          <citation key="ldms">
            <article_title>High-resolution image synthesis with latent diffusion models</article_title>
            <author>Rombach</author>
            <cYear>2022</cYear>
            <unstructured_citation>Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (2022). High-resolution image synthesis with latent diffusion models. https://arxiv.org/abs/2112.10752</unstructured_citation>
          </citation>
          <citation key="dits">
            <article_title>Scalable diffusion models with transformers</article_title>
            <author>Peebles</author>
            <cYear>2023</cYear>
            <unstructured_citation>Peebles, W., &amp; Xie, S. (2023). Scalable diffusion models with transformers. https://arxiv.org/abs/2212.09748</unstructured_citation>
          </citation>
          <citation key="gans">
            <article_title>Generative adversarial networks</article_title>
            <author>Goodfellow</author>
            <cYear>2014</cYear>
            <unstructured_citation>Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &amp; Bengio, Y. (2014). Generative adversarial networks. https://arxiv.org/abs/1406.2661</unstructured_citation>
          </citation>
          <citation key="vaes">
            <article_title>Auto-encoding variational bayes</article_title>
            <author>Kingma</author>
            <cYear>2022</cYear>
            <unstructured_citation>Kingma, D. P., &amp; Welling, M. (2022). Auto-encoding variational bayes. https://arxiv.org/abs/1312.6114</unstructured_citation>
          </citation>
          <citation key="flows">
            <article_title>Normalizing flows for probabilistic modeling and inference</article_title>
            <author>Papamakarios</author>
            <cYear>2021</cYear>
            <unstructured_citation>Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., &amp; Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. https://arxiv.org/abs/1912.02762</unstructured_citation>
          </citation>
          <citation key="blackjax">
            <article_title>BlackJAX: Composable Bayesian inference in JAX</article_title>
            <author>Cabezas</author>
            <cYear>2024</cYear>
            <unstructured_citation>Cabezas, A., Corenflos, A., Lao, J., &amp; Louf, R. (2024). BlackJAX: Composable Bayesian inference in JAX. https://arxiv.org/abs/2402.10797</unstructured_citation>
          </citation>
          <citation key="Remy">
            <article_title>Probabilistic mass-mapping with neural score estimation</article_title>
            <author>Remy</author>
            <journal_title>Astronomy &amp;amp; Astrophysics</journal_title>
            <volume>672</volume>
            <doi>10.1051/0004-6361/202243054</doi>
            <issn>1432-0746</issn>
            <cYear>2023</cYear>
            <unstructured_citation>Remy, B., Lanusse, F., Jeffrey, N., Liu, J., Starck, J.-L., Osato, K., &amp; Schrabback, T. (2023). Probabilistic mass-mapping with neural score estimation. Astronomy &amp;Amp; Astrophysics, 672, A51. https://doi.org/10.1051/0004-6361/202243054</unstructured_citation>
          </citation>
          <citation key="vdms">
            <article_title>Variational diffusion models</article_title>
            <author>Kingma</author>
            <cYear>2023</cYear>
            <unstructured_citation>Kingma, D. P., Salimans, T., Poole, B., &amp; Ho, J. (2023). Variational diffusion models. https://arxiv.org/abs/2107.00630</unstructured_citation>
          </citation>
          <citation key="mixer">
            <article_title>MLP-mixer: An all-MLP architecture for vision</article_title>
            <author>Tolstikhin</author>
            <cYear>2021</cYear>
            <unstructured_citation>Tolstikhin, I., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., Yung, J., Steiner, A., Keysers, D., Uszkoreit, J., Lucic, M., &amp; Dosovitskiy, A. (2021). MLP-mixer: An all-MLP architecture for vision. https://arxiv.org/abs/2105.01601</unstructured_citation>
          </citation>
          <citation key="score_matching">
            <article_title>Estimation of non-normalized statistical models by score matching</article_title>
            <author>Hyvärinen</author>
            <journal_title>Journal of Machine Learning Research</journal_title>
            <issue>24</issue>
            <volume>6</volume>
            <cYear>2005</cYear>
            <unstructured_citation>Hyvärinen, A. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research, 6(24), 695–709. http://jmlr.org/papers/v6/hyvarinen05a.html</unstructured_citation>
          </citation>
          <citation key="score_matching2">
            <article_title>A connection between score matching and denoising autoencoders</article_title>
            <author>Vincent</author>
            <journal_title>Neural Computation</journal_title>
            <issue>7</issue>
            <volume>23</volume>
            <doi>10.1162/NECO_a_00142</doi>
            <issn>0899-7667</issn>
            <cYear>2011</cYear>
            <unstructured_citation>Vincent, P. (2011). A connection between score matching and denoising autoencoders. Neural Computation, 23(7), 1661–1674. https://doi.org/10.1162/NECO_a_00142</unstructured_citation>
          </citation>
          <citation key="azula">
            <article_title>Azula: Diffusion models in PyTorch</article_title>
            <author>Rozet</author>
            <cYear>2024</cYear>
            <unstructured_citation>Rozet, F. (2024). Azula: Diffusion models in PyTorch (Version 0.2.04). https://github.com/probabilists/azula</unstructured_citation>
          </citation>
          <citation key="dit">
            <article_title>Scalable diffusion models with transformers</article_title>
            <author>Peebles</author>
            <cYear>2023</cYear>
            <unstructured_citation>Peebles, W., &amp; Xie, S. (2023). Scalable diffusion models with transformers. https://arxiv.org/abs/2212.09748</unstructured_citation>
          </citation>
          <citation key="Hutchinson">
            <article_title>A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines</article_title>
            <author>Hutchinson</author>
            <journal_title>Communications in Statistics - Simulation and Computation</journal_title>
            <issue>2</issue>
            <volume>19</volume>
            <doi>10.1080/03610919008812866</doi>
            <cYear>1990</cYear>
            <unstructured_citation>Hutchinson, M. F. (1990). A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines. Communications in Statistics - Simulation and Computation, 19(2), 433–450. https://doi.org/10.1080/03610919008812866</unstructured_citation>
          </citation>
          <citation key="lipman2023flowmatchinggenerativemodeling">
            <article_title>Flow matching for generative modeling</article_title>
            <author>Lipman</author>
            <cYear>2023</cYear>
            <unstructured_citation>Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., &amp; Le, M. (2023). Flow matching for generative modeling. https://arxiv.org/abs/2210.02747</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
