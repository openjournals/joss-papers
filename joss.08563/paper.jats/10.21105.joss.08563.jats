<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8563</article-id>
<article-id pub-id-type="doi">10.21105/joss.08563</article-id>
<title-group>
<article-title>VSMOD: A Vessel Segmentation and MODelization plugin for
3D Slicer</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1008-3009</contrib-id>
<name>
<surname>des Ligneris</surname>
<given-names>Morgane</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Husak</surname>
<given-names>Gabriel</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Aillet</surname>
<given-names>Azéline</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5844-2536</contrib-id>
<name>
<surname>Dollé</surname>
<given-names>Guillaume</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4570-0994</contrib-id>
<name>
<surname>Frindel</surname>
<given-names>Carole</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9918-3761</contrib-id>
<name>
<surname>Merveille</surname>
<given-names>Odyssée</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Univ Lyon, INSA‐Lyon, Université Claude Bernard Lyon 1,
UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1294, Lyon,
France.</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>EPITA Research Laboratory (LRE), Le Kremlin-Bicêtre,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Université de Reims Champagne-Ardenne, CNRS, LMR UMR 9008,
Reims</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>IUF, Institut Universitaire de France, Paris</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<volume>10</volume>
<issue>113</issue>
<fpage>8563</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>3D Slicer plugin</kwd>
<kwd>medical imaging</kwd>
<kwd>image segmentation</kwd>
<kwd>annotation</kwd>
<kwd>pulmonar vascular tree</kwd>
<kwd>graph</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The volumetric annotation of vessels in medical images is a
  challenging and time-consuming task that typically requires extensive
  expert manual work. <italic>VSMOD</italic> is a free, user-friendly
  plugin for 3D Slicer
  (<xref alt="Fedorov et al., 2012" rid="ref-fedorov2012" ref-type="bibr">Fedorov
  et al., 2012</xref>) designed to simplify and streamline the vascular
  annotation process. <italic>VSMOD</italic> offers a semi-automatic
  two-step segmentation approach, that combines RANSAC-based centerline
  detection
  (<xref alt="Yureidini et al., 2012" rid="ref-yureidini2012" ref-type="bibr">Yureidini
  et al., 2012</xref>) and a region growing approach with automatic seed
  selection to accelerate vessel annotation. Users can interactively
  generate vessel centerlines by placing two points – one marking the
  vessel’s starting location, and the other indicating its initial
  direction thereby defining a branch. Additional branches are created
  by tracking a new branch near existing ones. From these centerlines, a
  vascular tree graph is automatically constructed and can be exported
  as a NetworkX graph
  (<xref alt="Hagberg et al., 2008" rid="ref-hagberg2008" ref-type="bibr">Hagberg
  et al., 2008</xref>), facilitating efficient data storage and external
  manipulation. Finally, a region growing segmentation is applied using
  seeds automatically derived from the centerlines.</p>
  <p>Initially designed for pulmonary artery annotation,
  <italic>VSMOD</italic>’s methodology is adaptable to various vascular
  structures across different organs (e.g., brain, liver). This plugin
  significantly reduces the time required to obtain complete volumetric
  vessel segmentation. Moreover, it generates fully connected vascular
  trees with precise topology, which is nearly impossible to achieve
  with conventional annotation tools.</p>
  <p><italic>VSMOD</italic> enables users to create accurate and
  topologically consistent vascular network annotations, facilitating
  large-scale supervised machine-learning dataset generation for
  vascular segmentation. Future developments will focus on improving the
  segmentation step using deep learning-based approaches and further
  assessing the framework’s generalizability across diverse vascular
  segmentation tasks. The plugin is available at this
  <ext-link ext-link-type="uri" xlink:href="https://github.com/omerveille/VSMOD">Github
  Repo</ext-link>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Accurate annotation of vascular networks in medical imaging remains
  a critical challenge and is essential to develop accurate deep
  learning-based segmentation models. Current segmentation models still
  struggle with preserving the connectivity of complex vascular networks
  (<xref alt="Carneiro-Esteves et al., 2025" rid="ref-esteves2025" ref-type="bibr">Carneiro-Esteves
  et al., 2025</xref>;
  <xref alt="Keshwani et al., 2020" rid="ref-Keshwani2020" ref-type="bibr">Keshwani
  et al., 2020</xref>;
  <xref alt="Rougé et al., 2024" rid="ref-rouge2024" ref-type="bibr">Rougé
  et al., 2024</xref>) which is crucial for downstream tasks such as
  flow dynamic simulations. Improving the quality and precision of
  annotated datasets is crucial for training more effective models.
  However, traditional manual annotation methods are extremely
  time-consuming and subject to inter-observer variability creating
  important concept shifts in the annotation, ultimately leading to
  lower model performance
  (<xref alt="Rougé et al., 2025" rid="ref-rouge2025" ref-type="bibr">Rougé
  et al., 2025</xref>).</p>
  <p>Existing vessel annotation tools have notable limitations.
  Traditional paint and brush tools in image analysis software such as
  <italic>3D Slicer</italic><xref ref-type="fn" rid="fn1">1</xref>
  (<xref alt="Pinter et al., 2019" rid="ref-pinter2019" ref-type="bibr">Pinter
  et al., 2019</xref>) or
  <italic>ImageJ</italic><xref ref-type="fn" rid="fn2">2</xref> required
  slice-by-slice pixel-level annotation, making the process extremely
  laborious and often resulting in disconnected segmentations. Tubular
  shape prior tools have been proposed, such as the <italic>Draw
  Tube</italic> tool from the SlicerSegmentEditorExtraEffects
  extension<xref ref-type="fn" rid="fn3">3</xref>. However, this method
  requires manually drawing each vessel separately, and its fixed
  tubular shape is poorly suited for real vessels, which exhibit
  tortuosity and variable radii. Additionally, constructing a fully
  connected vascular tree remains particularly challenging.</p>
  <p>Recently, Lamy <italic>et al.</italic> proposed the
  <italic>RVXLiverSegmentation</italic> plugin
  (<xref alt="Lamy et al., 2022" rid="ref-lamy2022" ref-type="bibr">Lamy
  et al., 2022</xref>) for 3D Slicer to segment vascular networks of the
  liver. This tool enables fast and accurate vascular segmentation by
  requiring users to place predetermined points at branching nodes.
  However, it is designed specifically for the vasculature of the liver
  and is not applicable to other organs. <italic>VSMOD</italic> is
  designed to overcome these limitations by providing a user-friendly
  plugin for efficiently generating accurate and topologically correct
  vascular segmentations.</p>
</sec>
<sec id="overview-of-vsmod">
  <title>Overview of VSMOD</title>
  <p><italic>VSMOD</italic> integrates two complementary modules
  (cf. Fig.
  <xref alt="[fig:vessel_example]" rid="figU003Avessel_example">[fig:vessel_example]</xref>).
  First, the <bold>centerline module</bold> uses a RANSAC centerline
  tracking algorithm to create a graph model of the vascular network,
  ensuring that parent-child relationships between vessels are
  preserved, and providing precise geometry and radius estimation. Then,
  the <bold>segmentation module</bold> automatically generates seeds to
  initialize a region growing segmentation yielding a completely
  connected vascular segmentation.</p>
  <fig>
    <caption><p>Example of the annotation process on pulmonary arteries.
    From left to right: a) Centerlines detected using the RANSAC-based
    algorithm. b) 3D visualization of automatically placed seeds for
    region-growing. c) The final vessel
    segmentation.<styled-content id="figU003Avessel_example"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="vessel_example.png" />
  </fig>
  <sec id="centerline-module">
    <title>Centerline Module</title>
    <fig>
      <caption><p>Example of the centerline module interface. Green dots
      represent user-selected points, while blue and pink lines indicate
      centerlines detected by the RANSAC algorithm. The bottom-left
      panel displays the vascular graph, where the b1 branch splits into
      b2 and
      b3.<styled-content id="figU003Acenterline_tab"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="centerline_tab.png" />
    </fig>
    <p>The first module of <italic>VSMOD</italic> extracts vessel
    centerlines (cf. Fig.
    <xref alt="[fig:centerline_tab]" rid="figU003Acenterline_tab">[fig:centerline_tab]</xref>).
    Users begin by placing starting and directional points to define the
    initial vessel path. Then, the RANSAC algorithm
    (<xref alt="Yureidini et al., 2012" rid="ref-yureidini2012" ref-type="bibr">Yureidini
    et al., 2012</xref>) iteratively tracks points along the vessel
    centerline. At vessel intersections, the algorithm randomly selects
    a branch and continues tracking until it reaches the end of the
    vessel. To annotate additional vessels, the user selects two new
    points near an existing centerline. The algorithm then automatically
    detects the new branch and connects it to the previously identified
    centerlines. An estimate of the diameter of the vessel at the
    beginning of the vessel has to be set when launching the algorithm
    for the first time. This is the only parameter that is required. The
    other RANSAC algorithm parameters can be set manually by the user
    for a fine user control, but good default values are provided.</p>
    <p>Additionally, this module enables users to export and load a
    vascular network as a NetworkX graph
    (<xref alt="Hagberg et al., 2008" rid="ref-hagberg2008" ref-type="bibr">Hagberg
    et al., 2008</xref>) in JSON format. This feature allows for pausing
    and resuming the annotation process while preserving the vessel
    hierarchy and structural relationships for further computational
    analysis.</p>
  </sec>
  <sec id="segmentation-module">
    <title>Segmentation Module</title>
    <fig>
      <caption><p>Example of the segmentation module interface with
      automatically generated seed points on a patient’s axial view. The
      automatic seeds are displayed in different colors inside the
      vessels (pink, purple and green) and surrounded by the yellow
      border to constrain the region growing
      process.<styled-content id="figU003Asegmentation_tab"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="segmentation_tab.png" />
    </fig>
    <p>The second module of <italic>VSMOD</italic> transforms the
    extracted centerline data into a volumic vessel segmentation
    (cf. Fig.
    <xref alt="[fig:segmentation_tab]" rid="figU003Asegmentation_tab">[fig:segmentation_tab]</xref>).
    This process leverages the “Grow from seeds” region growing
    segmentation tools from 3D Slicer
    (<xref alt="Zhu et al., 2014" rid="ref-zhu2014" ref-type="bibr">Zhu
    et al., 2014</xref>) to refine and expand the segmentation. The
    process begins with the automatic generation of seed points along
    the detected centerline. The seed size is determined by the radius
    estimations obtained from the previous step. These seeds serve as
    anchor points, guiding the segmentation along the vessel path. The
    background seeds are produced by applying dilation and subtraction
    operations, to create a raw boundary outside the vessels. This
    ensures that the region-growing process remains confined within the
    vascular structure and does not extend into surrounding tissues. The
    distance between the edge of the vessel and the outside boundary is
    a parameter that can be adjusted by the user.</p>
  </sec>
</sec>
<sec id="results">
  <title>Results</title>
  <sec id="reduction-of-the-annotation-time">
    <title>Reduction of the annotation time</title>
    <p>In this section we compare the time to annotate a complete
    pulmonary vascular network from a computed tomography pulmonary
    angiography (CTPA).</p>
    <p>Ten CTPA images were extensively annotated with the
    <italic>VSMOD</italic> plugin by an expert who reported an average
    time of 3 hours and 35 minutes per image to annotate the complete
    vascular network (269 vessels on average per image).</p>
    <p>Most of this time was spent in the centerline module, where users
    manually place vessel start and directional points. Additional time
    was dedicated to refining seed placement around embolized regions,
    which required extra attention due to their complexity.</p>
    <p>Extensive manual annotation of the vascular network using
    traditional tools was impractical due to the significant time
    required. Instead, two experts annotated several individual vessels
    representative of the network’s complexity using the available tools
    in 3D Slicer. The annotation process took an average of four minutes
    and 46 sec per vessel, which would equate to approximately 21 hours
    22 minutes per image for a complete vascular network.
    <italic>VSMOD</italic> reduces annotation time by 80% (cf. Table
    <xref alt="1" rid="tableU003Asegmentation_comparison">1</xref>).</p>
    <p>Beyond efficiency gains, <italic>VSMOD</italic> offers additional
    advantages by automatically generating a hierarchical vessel tree,
    providing centerline data, radius estimations, and graph
    connectivity information – critical components for downstream
    vascular analysis.</p>
    <table-wrap>
      <caption>
        <p>Comparison of average segmentation times per patient
        calculated on data with an average of 269 vessels
        <styled-content id="tableU003Asegmentation_comparison"></styled-content></p>
      </caption>
      <table>
        <thead>
          <tr>
            <th align="center">Annotation method</th>
            <th align="center">Time per vessel</th>
            <th align="center">Total time per patient</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">Manual</td>
            <td align="center">4m46s</td>
            <td align="center">21h22m52s</td>
          </tr>
          <tr>
            <td align="center"><italic>VSMOD</italic></td>
            <td align="center">48s</td>
            <td align="center">3h35min12s</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec id="plugin-usage-on-different-vascular-networks">
    <title>Plugin usage on different vascular networks</title>
    <p><italic>VSMOD</italic> is not restricted to the vascular network
    of a specific organ. Its algorithms are generic and rely solely on
    the assumption of vessel geometry-tube-like structures with
    curvature. Extensive testing was conducted on the pulmonary vascular
    network, as discussed in the previous section. Additionally, the
    plugin was tested on the brain vascular network using magnetic
    resonance angiography (MRA). Despite the significant geometric
    differences between pulmonary and cerebral vessels,
    <italic>VSMOD</italic> was also able to segment these vessels, as
    illustrated in Fig.
    <xref alt="[fig:brain_example]" rid="figU003Abrain_example">[fig:brain_example]</xref>.</p>
    <fig>
      <caption><p>Example of the annotation process on brain vessels.
      From left to right: a) Centerlines detected using the RANSAC-based
      algorithm. b) 3D visualization of automatically placed seeds for
      region-growing. c) The final vessel
      segmentation.<styled-content id="figU003Abrain_example"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="brain_example.png" />
    </fig>
    <p>In conclusion, <italic>VSMOD</italic> provides a user-friendly
    framework for generating vascular network segmentation annotations.
    By automating the most labor-intensive aspects of vascular
    segmentation, this module significantly reduces manual effort while
    still allowing users to fine-tune the results as needed.</p>
    <p>Future work will focus on optimizing RANSAC parameters by
    introducing anatomy-specific default settings for different types of
    vessels. This would minimize the need for manual fine-tuning,
    improving usability and adaptability. Additionally, integrating deep
    learning models could further enhance segmentation accuracy and
    reduce manual intervention, particularly in the segmentation
    module.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The vascular graph modeling is inspired by the hierarchical vessel
  organization proposed in <italic>RVXLiverSegmentation</italic>
  (<xref alt="Lamy et al., 2022" rid="ref-lamy2022" ref-type="bibr">Lamy
  et al., 2022</xref>).</p>
  <p>This work was founded by the French ANR through the PERSEVERE and
  PreSPIN projects (ANR-22-CE45-0018, ANR-20-CE45-0011). This work was
  also performed within the framework of the LABEX PRIMES
  (ANR-11-LABX-0063).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-fedorov2012">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fedorov</surname><given-names>Andriy</given-names></name>
        <name><surname>Beichel</surname><given-names>Reinhard</given-names></name>
        <name><surname>Kalpathy-Cramer</surname><given-names>Jayashree</given-names></name>
        <name><surname>Finet</surname><given-names>Julien</given-names></name>
        <name><surname>Fillion-Robin</surname><given-names>Jean-Christophe</given-names></name>
        <name><surname>Pujol</surname><given-names>Sonia</given-names></name>
        <name><surname>Bauer</surname><given-names>Christian</given-names></name>
        <name><surname>Jennings</surname><given-names>Dominique</given-names></name>
        <name><surname>Fennessy</surname><given-names>Fiona</given-names></name>
        <name><surname>Sonka</surname><given-names>Milan</given-names></name>
        <name><surname>Buatti</surname><given-names>John</given-names></name>
        <name><surname>Aylward</surname><given-names>Stephen</given-names></name>
        <name><surname>Miller</surname><given-names>James V.</given-names></name>
        <name><surname>Pieper</surname><given-names>Steve</given-names></name>
        <name><surname>Kikinis</surname><given-names>Ron</given-names></name>
      </person-group>
      <article-title>3D Slicer as an image computing platform for the Quantitative Imaging Network</article-title>
      <source>Magnetic Resonance Imaging</source>
      <year iso-8601-date="2012-11-01">2012</year><month>11</month><day>01</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-24">2025</year><month>01</month><day>24</day></date-in-citation>
      <volume>30</volume>
      <issue>9</issue>
      <issn>0730-725X</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0730725X12001816</uri>
      <pub-id pub-id-type="doi">10.1016/j.mri.2012.05.001</pub-id>
      <fpage>1323</fpage>
      <lpage>1341</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hagberg2008">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hagberg</surname><given-names>Aric A.</given-names></name>
        <name><surname>Schult</surname><given-names>Daniel A.</given-names></name>
        <name><surname>Swart</surname><given-names>Pieter J.</given-names></name>
      </person-group>
      <article-title>Exploring Network Structure, Dynamics, and Function using NetworkX</article-title>
      <source>scipy</source>
      <year iso-8601-date="2008-05-06">2008</year><month>05</month><day>06</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-27">2025</year><month>01</month><day>27</day></date-in-citation>
      <uri>https://proceedings.scipy.org/articles/TCWV9851</uri>
      <pub-id pub-id-type="doi">10.25080/TCWV9851</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lamy2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lamy</surname><given-names>Jonas</given-names></name>
        <name><surname>Pelletier</surname><given-names>Thibault</given-names></name>
        <name><surname>Lienemann</surname><given-names>Guillaume</given-names></name>
        <name><surname>Magnin</surname><given-names>Benoît</given-names></name>
        <name><surname>Kerautret</surname><given-names>Bertrand</given-names></name>
        <name><surname>Passat</surname><given-names>Nicolas</given-names></name>
        <name><surname>Finet</surname><given-names>Julien</given-names></name>
        <name><surname>Vacavant</surname><given-names>Antoine</given-names></name>
      </person-group>
      <article-title>The 3D Slicer RVXLiverSegmentation plug-in for interactive liver anatomy reconstruction from medical images</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2022-05-05">2022</year><month>05</month><day>05</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-20">2025</year><month>01</month><day>20</day></date-in-citation>
      <volume>7</volume>
      <issue>73</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.03920</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03920</pub-id>
      <fpage>3920</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-pinter2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pinter</surname><given-names>Csaba</given-names></name>
        <name><surname>Lasso</surname><given-names>Andras</given-names></name>
        <name><surname>Fichtinger</surname><given-names>Gabor</given-names></name>
      </person-group>
      <article-title>Polymorph segmentation representation for medical image computing</article-title>
      <source>Computer Methods and Programs in Biomedicine</source>
      <year iso-8601-date="2019-04-01">2019</year><month>04</month><day>01</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-27">2025</year><month>01</month><day>27</day></date-in-citation>
      <volume>171</volume>
      <issn>0169-2607</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0169260718313038</uri>
      <pub-id pub-id-type="doi">10.1016/j.cmpb.2019.02.011</pub-id>
      <fpage>19</fpage>
      <lpage>26</lpage>
    </element-citation>
  </ref>
  <ref id="ref-yureidini2012">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Yureidini</surname><given-names>Ahmed</given-names></name>
        <name><surname>Kerrien</surname><given-names>Erwan</given-names></name>
        <name><surname>Cotin</surname><given-names>Stéphane</given-names></name>
      </person-group>
      <article-title>Robust RANSAC-based blood vessel segmentation</article-title>
      <source>Medical Imaging 2012: Image Processing</source>
      <publisher-name>SPIE</publisher-name>
      <year iso-8601-date="2012-02-14">2012</year><month>02</month><day>14</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-01-27">2025</year><month>01</month><day>27</day></date-in-citation>
      <volume>8314</volume>
      <uri>https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8314/83141M/Robust-RANSAC-based-blood-vessel-segmentation/10.1117/12.911670.full</uri>
      <pub-id pub-id-type="doi">10.1117/12.911670</pub-id>
      <fpage>474</fpage>
      <lpage>481</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhu2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhu</surname><given-names>Linagjia</given-names></name>
        <name><surname>Kolesov</surname><given-names>Ivan</given-names></name>
        <name><surname>Gao</surname><given-names>Yi</given-names></name>
        <name><surname>Kikinis</surname><given-names>Ron</given-names></name>
        <name><surname>Tannenbaum</surname><given-names>Allen</given-names></name>
      </person-group>
      <article-title>An Eﬀective Interactive Medical Image Segmentation Method Using Fast GrowCut</article-title>
      <source>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), Interactive Medical Image Computing Workshop</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-rouge2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rougé</surname><given-names>Pierre</given-names></name>
        <name><surname>Conze</surname><given-names>Pierre-Henri</given-names></name>
        <name><surname>Passat</surname><given-names>Nicolas</given-names></name>
        <name><surname>Merveille</surname><given-names>Odyssée</given-names></name>
      </person-group>
      <article-title>Guidelines for cerebrovascular segmentation: Managing imperfect annotations in the context of semi-supervised learning</article-title>
      <source>Computerized Medical Imaging and Graphics</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-03-24">2025</year><month>03</month><day>24</day></date-in-citation>
      <volume>119</volume>
      <uri>https://hal.science/hal-04819764</uri>
      <pub-id pub-id-type="doi">10.1016/j.compmedimag.2024.102474</pub-id>
      <fpage>102474</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-esteves2025">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Carneiro-Esteves</surname><given-names>Sophie</given-names></name>
        <name><surname>Vacavant</surname><given-names>Antoine</given-names></name>
        <name><surname>Merveille</surname><given-names>Odyssée</given-names></name>
      </person-group>
      <article-title>Restoring connectivity in vascular segmentations using a learned post-processing model</article-title>
      <source>Topology- and graph-informed imaging informatics</source>
      <person-group person-group-type="editor">
        <name><surname>Chen</surname><given-names>Chao</given-names></name>
        <name><surname>Singh</surname><given-names>Yash</given-names></name>
        <name><surname>Hu</surname><given-names>Xiaoling</given-names></name>
      </person-group>
      <publisher-name>Springer Nature Switzerland</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2025">2025</year>
      <isbn>978-3-031-73967-5</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-031-73967-5_6</pub-id>
      <fpage>55</fpage>
      <lpage>65</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rouge2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rougé</surname><given-names>Pierre</given-names></name>
        <name><surname>Passat</surname><given-names>Nicolas</given-names></name>
        <name><surname>Merveille</surname><given-names>Odyssée</given-names></name>
      </person-group>
      <article-title>Topology aware multitask cascaded u-net for cerebrovascular segmentation</article-title>
      <source>PLOS ONE</source>
      <publisher-name>Public Library of Science</publisher-name>
      <year iso-8601-date="2024-12">2024</year><month>12</month>
      <volume>19</volume>
      <issue>12</issue>
      <uri>https://doi.org/10.1371/journal.pone.0311439</uri>
      <pub-id pub-id-type="doi">10.1371/journal.pone.0311439</pub-id>
      <fpage>1</fpage>
      <lpage>20</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Keshwani2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Keshwani</surname><given-names>Deepak</given-names></name>
        <name><surname>Kitamura</surname><given-names>Yoshiro</given-names></name>
        <name><surname>Ihara</surname><given-names>Satoshi</given-names></name>
        <name><surname>Iizuka</surname><given-names>Satoshi</given-names></name>
        <name><surname>Simo-Serra</surname><given-names>Edgar</given-names></name>
      </person-group>
      <article-title>TopNet: Topology preserving metric learning for vessel tree reconstruction and labelling</article-title>
      <source>Medical image computing and computer assisted intervention – MICCAI 2020</source>
      <person-group person-group-type="editor">
        <name><surname>Martel</surname><given-names>Anne L.</given-names></name>
        <name><surname>Abolmaesumi</surname><given-names>Purang</given-names></name>
        <name><surname>Stoyanov</surname><given-names>Danail</given-names></name>
        <name><surname>Mateus</surname><given-names>Diana</given-names></name>
        <name><surname>Zuluaga</surname><given-names>Maria A.</given-names></name>
        <name><surname>Zhou</surname><given-names>S. Kevin</given-names></name>
        <name><surname>Racoceanu</surname><given-names>Daniel</given-names></name>
        <name><surname>Joskowicz</surname><given-names>Leo</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <isbn>978-3-030-59725-2</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-59725-2_2</pub-id>
      <fpage>14</fpage>
      <lpage>23</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p><ext-link ext-link-type="uri" xlink:href="https://www.slicer.org/">https://www.slicer.org/</ext-link></p>
  </fn>
  <fn id="fn2">
    <label>2</label><p><ext-link ext-link-type="uri" xlink:href="https://imagej.net/ij/">https://imagej.net/ij/</ext-link></p>
  </fn>
  <fn id="fn3">
    <label>3</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/lassoan/SlicerSegmentEditorExtraEffects">https://github.com/lassoan/SlicerSegmentEditorExtraEffects</ext-link></p>
  </fn>
</fn-group>
</back>
</article>
