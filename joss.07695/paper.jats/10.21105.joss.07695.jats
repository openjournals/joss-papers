<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7695</article-id>
<article-id pub-id-type="doi">10.21105/joss.07695</article-id>
<title-group>
<article-title>Cost-Effective Big Data Orchestration Using Dagster: A
Multi-Platform Approach</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6662-464X</contrib-id>
<name>
<surname>Picatto</surname>
<given-names>Hernan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8684-1163</contrib-id>
<name>
<surname>Heiler</surname>
<given-names>Georg</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Klimek</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Supply Chain Intelligence Institute Austria,
Austria</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Complexity Science Hub Vienna, Austria</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Institute of the Science of Complex Systems, Center for
Medical Data Science CeDAS, Medical University of Vienna,
Austria</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Division of Insurance Medicine, Department of Clinical
Neuroscience, Karolinska Institutet, Sweden</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-09-16">
<day>16</day>
<month>9</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>109</issue>
<fpage>7695</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Orchestration</kwd>
<kwd>PaaS</kwd>
<kwd>Apache Spark</kwd>
<kwd>Big Data</kwd>
<kwd>Databricks</kwd>
<kwd>AWS EMR</kwd>
<kwd>Cost Efficiency</kwd>
<kwd>Data Engineering</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The rapid evolution of big data has amplified the need for robust
  and efficient data processing. Spark-based Platform-as-a-Service
  (PaaS) options, like Databricks and Amazon EMR, offer strong
  analytics. But at the cost of high operational expenses and vendor
  lock-in
  (<xref alt="Kumar &amp; Kumar, 2022" rid="ref-kumar" ref-type="bibr">Kumar
  &amp; Kumar, 2022</xref>). Despite being user-friendly, their cost
  structures and opaque pricing can lead to inefficiencies.</p>
  <p>This paper introduces a cost-effective, flexible orchestration
  framework leveraging Dagster
  (<xref alt="Dagster, 2018" rid="ref-dagster" ref-type="bibr">Dagster,
  2018</xref>). Our solution reduces reliance on a single PaaS provider.
  It does this by integrating multiple Spark environments. We showcase
  Dagster’s power to boost efficiency. It enforces coding best practices
  and reduce costs. Our implementation showed a 12% speedup over EMR. It
  cut costs by 40% compared to DBR, saving over 300 euros per pipeline
  run. Our framework supports rapid prototyping and testing. This is key
  for continuous development and efficiency. It promotes a sustainable
  model for large-scale data processing.</p>
</sec>
<sec id="statement-of-need-and-relevance">
  <title>Statement of Need and Relevance</title>
  <p>In large-scale data processing, Spark-based PaaS like Databricks
  are user-friendly and powerful. But, they have vendor lock-in and
  unpredictable costs
  (<xref alt="Zaharia et al., 2016" rid="ref-Zaharia" ref-type="bibr">Zaharia
  et al., 2016</xref>). This convenience can lead to inefficient
  resource use, impacting productivity and increasing expenses.</p>
  <p>Our solution uses Dagster’s orchestration to integrate diverse
  Spark environments. This reduces reliance on a single provider. This
  mitigates lock-in risks, cuts costs, and promotes best coding
  practices. This boosts productivity by rapidly prototyping on smaller
  datasets. It cuts costs by optimizing resource use, without
  sacrificing performance. This approach is vital for organizations
  seeking agile, scalable, and cost-effective data operations.</p>
  <p>Also, this approach ensures consistency across development stages.
  It helps verify and replicate results, which is critical in scientific
  research. Using a tool like Dagster, researchers can create better
  workflows. It will foster a collaborative scientific environment.
  Their methods will be as open as their findings.</p>
  <p>While data pipeline research is growing, existing works focus on
  different aspects. Anil et al.
  (<xref alt="Mathew et al., 2024" rid="ref-Anil" ref-type="bibr">Mathew
  et al., 2024</xref>) emphasize optimizing big data processing. Use
  energy-efficient scheduling to reduce consumption and latency in data
  centers. Daw et al.
  (<xref alt="Daw et al., 2021" rid="ref-Daw" ref-type="bibr">Daw et
  al., 2021</xref>) explore using predictive analytics to automate
  resource scaling in cloud environments. This aims to optimize cost and
  performance. Our multi-cloud strategy leverages open orchestration
  tools like Dagster. This approach bridges existing gaps, deftly
  managing data tasks across diverse PaaS.</p>
</sec>
<sec id="relevance">
  <title>Relevance</title>
  <p>The proposed framework improves reproducibility by centralizing
  metadata management and standardizing orchestration across diverse
  environments. This in turn reduces infrastructure complexity and aids
  in consistently replicating experiments, supporting reliable research.
  Notwithstanding the mounting interest in data pipelines, authors such
  as Mathew et al. (2024) concentrate on the optimisation of big data
  processing through sophisticated scheduling techniques that minimise
  energy consumption and latency. While their work also aims to optimise
  resource utilisation in data centres, its core emphasis is on the
  algorithmic enhancement of scheduling mechanisms, rather than on
  orchestration across different PaaS solutions or on the promotion of
  coding practices within data pipelines. In their 2021 paper, Daw et
  al. (<xref alt="2021" rid="ref-Daw" ref-type="bibr">2021</xref>)
  examine the creation of a framework for automated scaling of resources
  in cloud environments. Their work focuses on aspects of resource
  allocation based on predictive analytics, with the goal of optimising
  operational costs and performance. In contrast to the work presented
  here, these approaches do not address the integration of multiple
  cloud platforms or the orchestration of data processing tasks using
  open tools.</p>
</sec>
<sec id="architecture-model">
  <title>Architecture Model</title>
  <p>We use Dagster, an open-source data orchestrator, in our framework.
  It builds, operates, and monitors data pipelines next to aligning with
  our cost and performance optimizations. That this pipeline can also
  significantly reduce resource use has been previously reported, see
  Heiler &amp; Picatto
  (<xref alt="2024" rid="ref-Heiler" ref-type="bibr">2024</xref>):</p>
  <p>More specifically, we aimed to create a cloud-based management
  system offering</p>
  <list list-type="bullet">
    <list-item>
      <p>Dynamic resource deployment with automatic scaling</p>
    </list-item>
    <list-item>
      <p>Virtual machine and network configuration management</p>
    </list-item>
    <list-item>
      <p>Comprehensive deployment and execution monitoring</p>
    </list-item>
  </list>
  <p>To achieve these capabilities, several modifications to Dagster
  default clients were necessary.</p>
  <fig>
    <caption><p>Diagram orchestrator
    behavior.<styled-content id="figU003Adiagram"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="./static/pipeline_diagram.png" />
  </fig>
  <p>Our framework’s core components, depicted in Figure
  <xref alt="[fig:diagram]" rid="figU003Adiagram">[fig:diagram]</xref>,
  include:</p>
  <list list-type="order">
    <list-item>
      <p><bold>Dagster Context Injector:</bold> It manages general and
      job-specific settings. They are vital for efficient resource use
      and task segmentation.</p>
    </list-item>
    <list-item>
      <p><bold>Message Reader Improvements:</bold> It boosts telemetry
      support. It captures and processes messages for real-time
      monitoring and debugging.</p>
    </list-item>
    <list-item>
      <p><bold>Cloud Client Innovations:</bold> Introduces a generic
      cloud client for managing Dagster on various platforms, ensuring
      seamless AWS integration and secure environment customization.</p>
    </list-item>
    <list-item>
      <p><bold>Automation and Integration:</bold> Automates job
      definition uploads with the Databricks REST API and Boto3 clients.
      It streamlines setup and environment bootstrapping.</p>
    </list-item>
    <list-item>
      <p><bold>Dynamic Factory for Cloud Client Management:</bold> It
      picks the best execution environments based on changing needs or
      preferences.</p>
    </list-item>
  </list>
  <p>These changes aim at creating a user-friendly interface that
  shields users from the complexities of cloud resource management. This
  shielding significantly reduces overhead and lets organizations focus
  on strategic goals. To minimize inconsistencies and configuration
  issues, we further dockerized the implementation to ensure a
  controlled development and production environment, facilitating
  reliability and replicability in production.</p>
  <sec id="example-use-case-mining-web-based-interfirm-networks-from-common-crawl">
    <title>Example Use Case: Mining web-based interfirm networks from
    Common Crawl</title>
    <p>We show our framework by making a web-based map of company
    ecosystems, as
    (<xref alt="Kinne &amp; Axenbeck, 2020" rid="ref-kinne" ref-type="bibr">Kinne
    &amp; Axenbeck, 2020</xref>). The research aim in such works is to
    find relationships between companies. To this end company websites
    are searched for hyperlinks to other company websites, often
    revealing collaborative innovation efforts.</p>
    <sec id="datasets">
      <title>Datasets</title>
      <list list-type="bullet">
        <list-item>
          <p>Common Crawl CC-MAIN: This dataset comprises WARC (Web
          ARChive) files containing raw web crawl data, and WAT files
          storing computed metadata.</p>
        </list-item>
        <list-item>
          <p>Seed Nodes: A subset of URLs (e.g., langing pages of
          company websites) identified as starting points for our
          analysis. These nodes are processed to ensure they are
          relevant and free of common problems.</p>
        </list-item>
      </list>
    </sec>
    <sec id="pipeline-breakdown">
      <title>Pipeline Breakdown</title>
      <p>Existing data extraction methods only work on text or graph
      data. However, to understand which kind of collaborations
      companies are forming, our use case requires the extraction of
      both text and graph data simultaneously. We therefore developed a
      custom data extraction method as follows. Our pipeline consists of
      four key assets:</p>
      <list list-type="order">
        <list-item>
          <p><bold>NodesOnly</bold>: Extracts and preprocesses seed node
          information.</p>
        </list-item>
        <list-item>
          <p><bold>Edges</bold>: Extracts HTML content and hyperlinks
          from seed node URLs</p>
        </list-item>
        <list-item>
          <p><bold>Graph</bold>: Constructs a hyperlink graph by
          combining nodes and edges</p>
        </list-item>
        <list-item>
          <p><bold>GraphAggr</bold>: Aggregates the graph to the domain
          level for broader analysis</p>
        </list-item>
      </list>
      <fig>
        <caption><p>Detailed dagster pipeline showcasing how execution
        environments can be chosen as needed between local, EMR and
        DBR.<styled-content id="figU003ApipleineDagster"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="./static/pass-implementation-detail-in-action.png" />
      </fig>
      <p>Figure
      <xref alt="[fig:pipleineDagster]" rid="figU003ApipleineDagster">[fig:pipleineDagster]</xref>
      hows assets that prove our framework’s adaptability and
      efficiency. The framework can handle diverse computing needs
      across various platforms. Data partitioning occurs along two
      dimensions: time and domain. The temporal partitioning matches the
      Common Craw<xref ref-type="fn" rid="fn1">1</xref> dataset. It
      streamlines data management and access. Domain-based partitioning,
      on the other hand, enables parallel processing of different
      research queries. This approach allows varied filtering in data
      analysis. It optimizes resources and enables task submission to
      the best platforms.</p>
    </sec>
  </sec>
  <sec id="further-details">
    <title>Further Details</title>
    <p>For detailed information on the implementation challenges
    encountered during the development of our framework, please refer to
    <ext-link ext-link-type="uri" xlink:href="appendix_1.md">Appendix
    1</ext-link>.</p>
    <p>For a comprehensive comparison of the platforms used in our
    study, please refer to
    <ext-link ext-link-type="uri" xlink:href="appendix_2.md">Appendix
    2</ext-link>.</p>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>This research was supported by
  <ext-link ext-link-type="uri" xlink:href="https://ascii.ac.at/">Supply
  Chain Intelligence Institute Austria (ASCII)</ext-link>.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-dagster">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Dagster</surname></name>
      </person-group>
      <article-title>Dagster | cloud-native orchestration of data pipelines</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <uri>https://github.com/dagster-io/dagster</uri>
    </element-citation>
  </ref>
  <ref id="ref-Anil">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mathew</surname><given-names>Anil</given-names></name>
        <name><surname>Andrikopoulos</surname><given-names>Vasilios</given-names></name>
        <name><surname>Blaauw</surname><given-names>Frank J.</given-names></name>
        <name><surname>Karastoyanova</surname><given-names>Dimka</given-names></name>
      </person-group>
      <article-title>Pattern-based serverless data processing pipelines for function-as-a-service orchestration systems</article-title>
      <source>Future Generation Computer Systems</source>
      <year iso-8601-date="2024">2024</year>
      <volume>154</volume>
      <issn>0167-739X</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0167739X23004855</uri>
      <pub-id pub-id-type="doi">10.1016/j.future.2023.12.026</pub-id>
      <fpage>87</fpage>
      <lpage>100</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Zaharia">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zaharia</surname><given-names>Matei</given-names></name>
        <name><surname>Xin</surname><given-names>Reynold S.</given-names></name>
        <name><surname>Wendell</surname><given-names>Patrick</given-names></name>
        <name><surname>Das</surname><given-names>Tathagata</given-names></name>
        <name><surname>Armbrust</surname><given-names>Michael</given-names></name>
        <name><surname>Dave</surname><given-names>Ankur</given-names></name>
        <name><surname>Meng</surname><given-names>Xiangrui</given-names></name>
        <name><surname>Rosen</surname><given-names>Josh</given-names></name>
        <name><surname>Venkataraman</surname><given-names>Shivaram</given-names></name>
        <name><surname>Franklin</surname><given-names>Michael J.</given-names></name>
        <name><surname>Ghodsi</surname><given-names>Ali</given-names></name>
        <name><surname>Gonzalez</surname><given-names>Joseph</given-names></name>
        <name><surname>Shenker</surname><given-names>Scott</given-names></name>
        <name><surname>Stoica</surname><given-names>Ion</given-names></name>
      </person-group>
      <article-title>Apache spark: A unified engine for big data processing</article-title>
      <source>Commun. ACM</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2016-10">2016</year><month>10</month>
      <volume>59</volume>
      <issue>11</issue>
      <issn>0001-0782</issn>
      <uri>https://doi.org/10.1145/2934664</uri>
      <pub-id pub-id-type="doi">10.1145/2934664</pub-id>
      <fpage>56</fpage>
      <lpage>65</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Daw">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Daw</surname><given-names>Nilanjan</given-names></name>
        <name><surname>Bellur</surname><given-names>Umesh</given-names></name>
        <name><surname>Kulkarni</surname><given-names>Purushottam</given-names></name>
      </person-group>
      <article-title>Speedo: Fast dispatch and orchestration of serverless workflows</article-title>
      <source>Proceedings of the ACM symposium on cloud computing</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <isbn>9781450386388</isbn>
      <uri>https://doi.org/10.1145/3472883.3486982</uri>
      <pub-id pub-id-type="doi">10.1145/3472883.3486982</pub-id>
      <fpage>585</fpage>
      <lpage>599</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Heiler">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heiler</surname><given-names>Georg</given-names></name>
        <name><surname>Picatto</surname><given-names>Hernan</given-names></name>
      </person-group>
      <article-title>Cost efficient alternative to databricks lock-in</article-title>
      <year iso-8601-date="2024-05">2024</year><month>05</month>
      <uri>https://georgheiler.com/2024/06/21/cost-efficient-alternative-to-databricks-lock-in/</uri>
    </element-citation>
  </ref>
  <ref id="ref-kinne">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kinne</surname><given-names>Jan</given-names></name>
        <name><surname>Axenbeck</surname><given-names>Janna</given-names></name>
      </person-group>
      <article-title>Web mining for innovation ecosystem mapping: A framework and a large-scale pilot study</article-title>
      <source>Scientometrics</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>125</volume>
      <issue>3</issue>
      <uri>https://doi.org/10.1007/s11192-020-03726-9</uri>
      <pub-id pub-id-type="doi">10.1007/s11192-020-03726-9</pub-id>
      <fpage>2011</fpage>
      <lpage>2041</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kumar">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kumar</surname><given-names>Purushottam</given-names></name>
        <name><surname>Kumar</surname><given-names>Prakash</given-names></name>
      </person-group>
      <article-title>Vendor lock-in situation and threats in cloud computing</article-title>
      <source>International Journal of Innovative Science and Research Technology</source>
      <publisher-name>IJISRT</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>7</volume>
      <issue>9</issue>
      <issn>2456-2165</issn>
      <uri>https://ijisrt.com/assets/upload/files/IJISRT22SEP948.pdf</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.7196590</pub-id>
      <fpage>1437</fpage>
      <lpage>1441</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>Common Crawl was accessed between October 2023
    and March 2024 from
    <ext-link ext-link-type="uri" xlink:href="https://registry.opendata.aws/commoncrawl">Common
    Crawl</ext-link>.</p>
  </fn>
</fn-group>
</back>
</article>
