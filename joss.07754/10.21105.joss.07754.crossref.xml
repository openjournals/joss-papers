<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20250409123305-f087c7ccb1048c417269b1fce94807e591ea37ef</doi_batch_id>
    <timestamp>20250409123305</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>04</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>108</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>sbi reloaded: a toolkit for simulation-based inference workflows</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Jan</given_name>
            <surname>Boelts</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
              <institution><institution_name>TransferLab, appliedAI Institute for Europe</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Michael</given_name>
            <surname>Deistler</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Manuel</given_name>
            <surname>Gloeckler</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Álvaro</given_name>
            <surname>Tejero-Cantero</surname>
            <affiliations>
              <institution><institution_name>TransferLab, appliedAI Institute for Europe</institution_name></institution>
              <institution><institution_name>ML Colab, Cluster ML in Science, University of Tübingen</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jan-Matthis</given_name>
            <surname>Lueckmann</surname>
            <affiliations>
              <institution><institution_name>Google Research</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Guy</given_name>
            <surname>Moss</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Peter</given_name>
            <surname>Steinbach</surname>
            <affiliations>
              <institution><institution_name>Helmholtz-Zentrum Dresden-Rossendorf</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Thomas</given_name>
            <surname>Moreau</surname>
            <affiliations>
              <institution><institution_name>Université Paris-Saclay, INRIA, CEA, Palaiseau, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Fabio</given_name>
            <surname>Muratore</surname>
            <affiliations>
              <institution><institution_name>Robert Bosch GmbH</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Julia</given_name>
            <surname>Linhart</surname>
            <affiliations>
              <institution><institution_name>Université Paris-Saclay, INRIA, CEA, Palaiseau, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Conor</given_name>
            <surname>Durkan</surname>
            <affiliations>
              <institution><institution_name>School of Informatics, University of Edinburgh</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Julius</given_name>
            <surname>Vetter</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Benjamin Kurt</given_name>
            <surname>Miller</surname>
            <affiliations>
              <institution><institution_name>University of Amsterdam</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Maternus</given_name>
            <surname>Herold</surname>
            <affiliations>
              <institution><institution_name>TransferLab, appliedAI Institute for Europe</institution_name></institution>
              <institution><institution_name>Research and Innovation Center, BMW Group</institution_name></institution>
              <institution><institution_name>Institute for Applied Mathematics and Scientific Computing, University of the Bundeswehr Munich, Germany</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Abolfazl</given_name>
            <surname>Ziaeemehr</surname>
            <affiliations>
              <institution><institution_name>Aix Marseille, INSERM, INS, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Matthijs</given_name>
            <surname>Pals</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Theo</given_name>
            <surname>Gruner</surname>
            <affiliations>
              <institution><institution_name>TU Darmstadt, hessian.AI, Germany</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Sebastian</given_name>
            <surname>Bischoff</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
              <institution><institution_name>University Hospital Tübingen and M3 Research Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Nastya</given_name>
            <surname>Krouglova</surname>
            <affiliations>
              <institution><institution_name>Faculty of Science, B-3000, KU Leuven, Belgium</institution_name></institution>
              <institution><institution_name>VIB-Neuroelectronics Research Flanders (NERF) and imec, Belgium</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Richard</given_name>
            <surname>Gao</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Janne K</given_name>
            <surname>Lappalainen</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Bálint</given_name>
            <surname>Mucsányi</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
              <institution><institution_name>Methods of Machine Learning, University of Tübingen</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Felix</given_name>
            <surname>Pei</surname>
            <affiliations>
              <institution><institution_name>Neuroscience Institute, Carnegie Mellon University</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Auguste</given_name>
            <surname>Schulz</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Zinovia</given_name>
            <surname>Stefanidi</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Pedro</given_name>
            <surname>Rodrigues</surname>
            <affiliations>
              <institution><institution_name>Université Grenoble Alpes, INRIA, CNRS, Grenoble INP, LJK, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Cornelius</given_name>
            <surname>Schröder</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Faried Abu</given_name>
            <surname>Zaid</surname>
            <affiliations>
              <institution><institution_name>TransferLab, appliedAI Institute for Europe</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jonas</given_name>
            <surname>Beck</surname>
            <affiliations>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
              <institution><institution_name>Hertie Institute for AI in Brain Health, University of Tübingen</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jaivardhan</given_name>
            <surname>Kapoor</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>David S.</given_name>
            <surname>Greenberg</surname>
            <affiliations>
              <institution><institution_name>Institute of Coastal Systems - Analysis and Modeling</institution_name></institution>
              <institution><institution_name>Helmholtz AI</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Pedro J.</given_name>
            <surname>Gonçalves</surname>
            <affiliations>
              <institution><institution_name>VIB-Neuroelectronics Research Flanders (NERF) and imec, Belgium</institution_name></institution>
              <institution><institution_name>Departments of Computer Science Electrical Engineering, KU Leuven, Belgium</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jakob H.</given_name>
            <surname>Macke</surname>
            <affiliations>
              <institution><institution_name>Machine Learning in Science, University of Tübingen</institution_name></institution>
              <institution><institution_name>Tübingen AI Center</institution_name></institution>
              <institution><institution_name>Department Empirical Inference, Max Planck Institute for Intelligent Systems, Tübingen</institution_name></institution>
            </affiliations>
          </person_name>
        </contributors>
        <publication_date>
          <month>04</month>
          <day>08</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>7754</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.07754</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.15034786</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/7754</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.07754</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.07754</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.07754.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="nflows-repo">
            <article_title>Nflows: Normalizing flows in PyTorch</article_title>
            <author>Durkan</author>
            <journal_title>GitHub repository</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Durkan, C., Bekasov, A., Papamakarios, G., &amp; Murray, I. (2019). Nflows: Normalizing flows in PyTorch. In GitHub repository. https://github.com/bayesiains/nflows; GitHub.</unstructured_citation>
          </citation>
          <citation key="zuko-repo">
            <article_title>Zuko - normalizing flows in PyTorch</article_title>
            <author>Rozet</author>
            <journal_title>GitHub repository</journal_title>
            <cYear>2023</cYear>
            <unstructured_citation>Rozet, F. (2023). Zuko - normalizing flows in PyTorch. In GitHub repository. https://github.com/probabilists/zuko; GitHub.</unstructured_citation>
          </citation>
          <citation key="bingham2019pyro">
            <article_title>Pyro: Deep universal probabilistic programming</article_title>
            <author>Bingham</author>
            <journal_title>J. Mach. Learn. Res.</journal_title>
            <volume>20</volume>
            <doi>10.48550/arXiv.1810.09538</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Bingham, E., Chen, J. P., Jankowiak, M., Obermeyer, F., Pradhan, N., Karaletsos, T., Singh, R., Szerlip, P. A., Horsfall, P., &amp; Goodman, N. D. (2019). Pyro: Deep universal probabilistic programming. J. Mach. Learn. Res., 20, 28:1–28:6. https://doi.org/10.48550/arXiv.1810.09538</unstructured_citation>
          </citation>
          <citation key="abril2023pymc">
            <article_title>PyMC: A modern, and comprehensive probabilistic programming framework in Python</article_title>
            <author>Abril-Pla</author>
            <journal_title>PeerJ Computer Science</journal_title>
            <volume>9</volume>
            <doi>10.7717/peerj-cs.1516</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Abril-Pla, O., Andreani, V., Carroll, C., Dong, L., Fonnesbeck, C. J., Kochurov, M., Kumar, R., Lao, J., Luhmann, C. C., Martin, O. A., &amp; others. (2023). PyMC: A modern, and comprehensive probabilistic programming framework in Python. PeerJ Computer Science, 9, e1516. https://doi.org/10.7717/peerj-cs.1516</unstructured_citation>
          </citation>
          <citation key="joblib">
            <article_title>Joblib</article_title>
            <author>Varoquaux</author>
            <journal_title>GitHub repository</journal_title>
            <cYear>2008</cYear>
            <unstructured_citation>Varoquaux, G. (2008). Joblib. In GitHub repository. https://github.com/joblib/joblib; GitHub.</unstructured_citation>
          </citation>
          <citation key="sisson2018_chapter1">
            <article_title>Overview of ABC</article_title>
            <author>Sisson</author>
            <journal_title>Handbook of approximate bayesian computation</journal_title>
            <doi>10.1201/9781315117195</doi>
            <isbn>9781439881507</isbn>
            <cYear>2018</cYear>
            <unstructured_citation>Sisson, S. A., Y., F., &amp; A., B. M. (2018). Overview of ABC. In Handbook of approximate bayesian computation. CRC Press, Taylor &amp; Francis Group. https://doi.org/10.1201/9781315117195</unstructured_citation>
          </citation>
          <citation key="papamakarios2016fast">
            <article_title>Fast \varepsilon-free inference of simulation models with Bayesian conditional density estimation</article_title>
            <author>Papamakarios</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>29</volume>
            <doi>10.48550/arXiv.1605.06376</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Papamakarios, G., &amp; Murray, I. (2016). Fast \varepsilon-free inference of simulation models with Bayesian conditional density estimation. Advances in Neural Information Processing Systems, 29. https://doi.org/10.48550/arXiv.1605.06376</unstructured_citation>
          </citation>
          <citation key="papamakarios2021normalizing">
            <article_title>Normalizing flows for probabilistic modeling and inference</article_title>
            <author>Papamakarios</author>
            <journal_title>Journal of Machine Learning Research</journal_title>
            <issue>57</issue>
            <volume>22</volume>
            <doi>10.48550/arXiv.1912.02762</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., &amp; Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. Journal of Machine Learning Research, 22(57), 1–64. https://doi.org/10.48550/arXiv.1912.02762</unstructured_citation>
          </citation>
          <citation key="papamakarios2019sequential">
            <article_title>Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows</article_title>
            <author>Papamakarios</author>
            <journal_title>The 22nd international conference on artificial intelligence and statistics</journal_title>
            <doi>10.48550/arXiv.1805.07226</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Papamakarios, G., Sterratt, D., &amp; Murray, I. (2019). Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows. The 22nd International Conference on Artificial Intelligence and Statistics, 837–848. https://doi.org/10.48550/arXiv.1805.07226</unstructured_citation>
          </citation>
          <citation key="greenberg2019automatic">
            <article_title>Automatic posterior transformation for likelihood-free inference</article_title>
            <author>Greenberg</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.1905.07488</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Greenberg, D., Nonnenmacher, M., &amp; Macke, J. (2019). Automatic posterior transformation for likelihood-free inference. International Conference on Machine Learning, 2404–2414. https://doi.org/10.48550/arXiv.1905.07488</unstructured_citation>
          </citation>
          <citation key="tejerocantero2020sbi">
            <article_title>Sbi: A toolkit for simulation-based inference</article_title>
            <author>Tejero-Cantero</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>52</issue>
            <volume>5</volume>
            <doi>10.21105/joss.02505</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Tejero-Cantero, A., Boelts, J., Deistler, M., Lueckmann, J.-M., Durkan, C., Gonçalves, P. J., Greenberg, D. S., &amp; Macke, J. H. (2020). Sbi: A toolkit for simulation-based inference. Journal of Open Source Software, 5(52), 2505. https://doi.org/10.21105/joss.02505</unstructured_citation>
          </citation>
          <citation key="hermans2020likelihood">
            <article_title>Likelihood-free MCMC with amortized approximate ratio estimators</article_title>
            <author>Hermans</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.1903.04057</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Hermans, J., Begy, V., &amp; Louppe, G. (2020). Likelihood-free MCMC with amortized approximate ratio estimators. International Conference on Machine Learning, 4239–4248. https://doi.org/10.48550/arXiv.1903.04057</unstructured_citation>
          </citation>
          <citation key="Bishop_94">
            <article_title>Mixture density networks</article_title>
            <author>Bishop</author>
            <journal_title>Technical Report. Aston University, Birmingham</journal_title>
            <cYear>1994</cYear>
            <unstructured_citation>Bishop, C. M. (1994). Mixture density networks. Technical Report. Aston University, Birmingham.</unstructured_citation>
          </citation>
          <citation key="talts2018validating">
            <article_title>Validating Bayesian inference algorithms with simulation-based calibration</article_title>
            <author>Talts</author>
            <journal_title>arXiv preprint arXiv:1804.06788</journal_title>
            <doi>10.48550/arXiv.1804.06788</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Talts, S., Betancourt, M., Simpson, D., Vehtari, A., &amp; Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. arXiv Preprint arXiv:1804.06788. https://doi.org/10.48550/arXiv.1804.06788</unstructured_citation>
          </citation>
          <citation key="boelts2022flexible">
            <article_title>Flexible and efficient simulation-based inference for models of decision-making</article_title>
            <author>Boelts</author>
            <journal_title>Elife</journal_title>
            <volume>11</volume>
            <doi>10.7554/eLife.77220</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Boelts, J., Lueckmann, J.-M., Gao, R., &amp; Macke, J. H. (2022). Flexible and efficient simulation-based inference for models of decision-making. Elife, 11, e77220. https://doi.org/10.7554/eLife.77220</unstructured_citation>
          </citation>
          <citation key="deistler2022energy">
            <article_title>Energy-efficient network activity from disparate circuit parameters</article_title>
            <author>Deistler</author>
            <journal_title>Proceedings of the National Academy of Sciences</journal_title>
            <issue>44</issue>
            <volume>119</volume>
            <doi>10.1073/pnas.2207632119</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Deistler, M., Macke, J. H., &amp; Gonçalves, P. J. (2022). Energy-efficient network activity from disparate circuit parameters. Proceedings of the National Academy of Sciences, 119(44), e2207632119. https://doi.org/10.1073/pnas.2207632119</unstructured_citation>
          </citation>
          <citation key="deistler2022truncated">
            <article_title>Truncated proposals for scalable and hassle-free simulation-based inference</article_title>
            <author>Deistler</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <doi>10.48550/arXiv.2210.04815</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Deistler, M., Gonçalves, P. J., &amp; Macke, J. H. (2022). Truncated proposals for scalable and hassle-free simulation-based inference. In A. H. Oh, A. Agarwal, D. Belgrave, &amp; K. Cho (Eds.), Advances in neural information processing systems. https://doi.org/10.48550/arXiv.2210.04815</unstructured_citation>
          </citation>
          <citation key="radev2020bayesflow">
            <article_title>BayesFlow: Learning complex stochastic models with invertible neural networks</article_title>
            <author>Radev</author>
            <journal_title>IEEE transactions on neural networks and learning systems</journal_title>
            <issue>4</issue>
            <volume>33</volume>
            <doi>10.1109/tnnls.2020.3042395</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Radev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., &amp; Köthe, U. (2020). BayesFlow: Learning complex stochastic models with invertible neural networks. IEEE Transactions on Neural Networks and Learning Systems, 33(4), 1452–1466. https://doi.org/10.1109/tnnls.2020.3042395</unstructured_citation>
          </citation>
          <citation key="geffner2023compositional">
            <article_title>Compositional score modeling for simulation-based inference</article_title>
            <author>Geffner</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.2209.14249</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Geffner, T., Papamakarios, G., &amp; Mnih, A. (2023). Compositional score modeling for simulation-based inference. International Conference on Machine Learning, 11098–11116. https://doi.org/10.48550/arXiv.2209.14249</unstructured_citation>
          </citation>
          <citation key="sharrock2022sequential">
            <article_title>Neural score estimation: Likelihood-free inference with conditional score based diffusion models</article_title>
            <author>Simons</author>
            <journal_title>Fifth symposium on advances in approximate bayesian inference</journal_title>
            <doi>10.48550/arXiv.2210.04872</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Simons, J., Sharrock, L., Liu, S., &amp; Beaumont, M. (2023). Neural score estimation: Likelihood-free inference with conditional score based diffusion models. Fifth Symposium on Advances in Approximate Bayesian Inference. https://doi.org/10.48550/arXiv.2210.04872</unstructured_citation>
          </citation>
          <citation key="dax2023flow">
            <article_title>Flow matching for scalable simulation-based inference</article_title>
            <author>Wildberger</author>
            <journal_title>Thirty-seventh conference on neural information processing systems</journal_title>
            <doi>10.48550/arXiv.2305.17161</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Wildberger, J. B., Dax, M., Buchholz, S., Green, S. R., Macke, J. H., &amp; Schölkopf, B. (2023). Flow matching for scalable simulation-based inference. Thirty-Seventh Conference on Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2305.17161</unstructured_citation>
          </citation>
          <citation key="hermans2022crisis">
            <article_title>A crisis in simulation-based inference? Beware, your posterior approximations can be unfaithful</article_title>
            <author>Hermans</author>
            <journal_title>Transactions on Machine Learning Research</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>Hermans, J., Delaunoy, A., Rozet, F., Wehenkel, A., &amp; Louppe, G. (2022). A crisis in simulation-based inference? Beware, your posterior approximations can be unfaithful. Transactions on Machine Learning Research.</unstructured_citation>
          </citation>
          <citation key="groschner2022biophysical">
            <article_title>A biophysical account of multiplication by a single neuron</article_title>
            <author>Groschner</author>
            <journal_title>Nature</journal_title>
            <issue>7899</issue>
            <volume>603</volume>
            <doi>10.1038/s41586-022-04428-3</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Groschner, L. N., Malis, J. G., Zuidinga, B., &amp; Borst, A. (2022). A biophysical account of multiplication by a single neuron. Nature, 603(7899), 119–123. https://doi.org/10.1038/s41586-022-04428-3</unstructured_citation>
          </citation>
          <citation key="bondarenko2023embryo">
            <article_title>Embryo-uterine interaction coordinates mouse embryogenesis during implantation</article_title>
            <author>Bondarenko</author>
            <journal_title>The EMBO Journal</journal_title>
            <issue>17</issue>
            <volume>42</volume>
            <doi>10.15252/embj.2022113280</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Bondarenko, V., Nikolaev, M., Kromm, D., Belousov, R., Wolny, A., Blotenburg, M., Zeller, P., Rezakhani, S., Hugger, J., Uhlmann, V., &amp; others. (2023). Embryo-uterine interaction coordinates mouse embryogenesis during implantation. The EMBO Journal, 42(17), e113280. https://doi.org/10.15252/embj.2022113280</unstructured_citation>
          </citation>
          <citation key="confavreux2023meta">
            <article_title>Meta-learning families of plasticity rules in recurrent spiking networks using simulation-based inference</article_title>
            <author>Confavreux</author>
            <journal_title>Advances in Neural Information Processing Systems</journal_title>
            <volume>36</volume>
            <cYear>2023</cYear>
            <unstructured_citation>Confavreux, B., Ramesh, P., Gonçalves, P. J., Macke, J. H., &amp; Vogels, T. (2023). Meta-learning families of plasticity rules in recurrent spiking networks using simulation-based inference. Advances in Neural Information Processing Systems, 36, 13545–13558.</unstructured_citation>
          </citation>
          <citation key="myers2024disinhibition">
            <article_title>Disinhibition by VIP interneurons is orthogonal to cross-modal attentional modulation in primary visual cortex</article_title>
            <author>Myers-Joseph</author>
            <journal_title>Neuron</journal_title>
            <issue>4</issue>
            <volume>112</volume>
            <doi>10.1016/j.neuron.2023.11.006</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Myers-Joseph, D., Wilmes, K. A., Fernandez-Otero, M., Clopath, C., &amp; Khan, A. G. (2024). Disinhibition by VIP interneurons is orthogonal to cross-modal attentional modulation in primary visual cortex. Neuron, 112(4), 628–645. https://doi.org/10.1016/j.neuron.2023.11.006</unstructured_citation>
          </citation>
          <citation key="avecilla2022neural">
            <article_title>Neural networks enable efficient and accurate simulation-based inference of evolutionary parameters from adaptation dynamics</article_title>
            <author>Avecilla</author>
            <journal_title>PLoS biology</journal_title>
            <issue>5</issue>
            <volume>20</volume>
            <doi>10.1371/journal.pbio.3001633</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Avecilla, G., Chuong, J. N., Li, F., Sherlock, G., Gresham, D., &amp; Ram, Y. (2022). Neural networks enable efficient and accurate simulation-based inference of evolutionary parameters from adaptation dynamics. PLoS Biology, 20(5), e3001633. https://doi.org/10.1371/journal.pbio.3001633</unstructured_citation>
          </citation>
          <citation key="gloecklervariational">
            <article_title>Variational methods for simulation-based inference</article_title>
            <author>Gloeckler</author>
            <journal_title>International conference on learning representations</journal_title>
            <doi>10.48550/arXiv.2203.04176</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Gloeckler, M., Deistler, M., &amp; Macke, J. H. (2022). Variational methods for simulation-based inference. International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2203.04176</unstructured_citation>
          </citation>
          <citation key="lowet2023theta">
            <article_title>Theta and gamma rhythmic coding through two spike output modes in the hippocampus during spatial navigation</article_title>
            <author>Lowet</author>
            <journal_title>Cell reports</journal_title>
            <issue>8</issue>
            <volume>42</volume>
            <doi>10.1016/j.celrep.2023.112906</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Lowet, E., Sheehan, D. J., Chialva, U., Pena, R. D. O., Mount, R. A., Xiao, S., Zhou, S. L., Tseng, H., Gritton, H., Shroff, S., &amp; others. (2023). Theta and gamma rhythmic coding through two spike output modes in the hippocampus during spatial navigation. Cell Reports, 42(8). https://doi.org/10.1016/j.celrep.2023.112906</unstructured_citation>
          </citation>
          <citation key="mishra2022neural">
            <article_title>Neural simulation-based inference approach for characterizing the galactic center \gamma-ray excess</article_title>
            <author>Mishra-Sharma</author>
            <journal_title>Physical Review D</journal_title>
            <issue>6</issue>
            <volume>105</volume>
            <doi>10.1103/PhysRevD.105.063017</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Mishra-Sharma, S., &amp; Cranmer, K. (2022). Neural simulation-based inference approach for characterizing the galactic center \gamma-ray excess. Physical Review D, 105(6), 063017. https://doi.org/10.1103/PhysRevD.105.063017</unstructured_citation>
          </citation>
          <citation key="dyer2022black">
            <article_title>Black-box Bayesian inference for economic agent-based models</article_title>
            <author>Dyer</author>
            <journal_title>arXiv preprint arXiv:2202.00625</journal_title>
            <doi>10.48550/arXiv.2202.00625</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Dyer, J., Cannon, P., Farmer, J. D., &amp; Schmon, S. (2022). Black-box Bayesian inference for economic agent-based models. arXiv Preprint arXiv:2202.00625. https://doi.org/10.48550/arXiv.2202.00625</unstructured_citation>
          </citation>
          <citation key="hahn2022accelerated">
            <article_title>Accelerated Bayesian SED modeling using amortized neural posterior estimation</article_title>
            <author>Hahn</author>
            <journal_title>The Astrophysical Journal</journal_title>
            <issue>1</issue>
            <volume>938</volume>
            <doi>10.3847/1538-4357/ac7b84</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Hahn, C., &amp; Melchior, P. (2022). Accelerated Bayesian SED modeling using amortized neural posterior estimation. The Astrophysical Journal, 938(1), 11. https://doi.org/10.3847/1538-4357/ac7b84</unstructured_citation>
          </citation>
          <citation key="lemos2024field">
            <article_title>Field-level simulation-based inference of galaxy clustering with convolutional neural networks</article_title>
            <author>Lemos</author>
            <journal_title>Physical Review D</journal_title>
            <issue>8</issue>
            <volume>109</volume>
            <doi>10.1103/physrevd.109.083536</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Lemos, P., Parker, L., Hahn, C., Ho, S., Eickenberg, M., Hou, J., Massara, E., Modi, C., Dizgah, A. M., Blancard, B. R.-S., &amp; others. (2024). Field-level simulation-based inference of galaxy clustering with convolutional neural networks. Physical Review D, 109(8), 083536. https://doi.org/10.1103/physrevd.109.083536</unstructured_citation>
          </citation>
          <citation key="muratore2022neural">
            <article_title>Neural posterior domain randomization</article_title>
            <author>Muratore</author>
            <journal_title>Conference on robot learning</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>Muratore, F., Gruner, T., Wiese, F., Belousov, B., Gienger, M., &amp; Peters, J. (2022). Neural posterior domain randomization. Conference on Robot Learning, 1532–1542.</unstructured_citation>
          </citation>
          <citation key="rossler2023skewed">
            <article_title>Skewed distribution of spines is independent of presynaptic transmitter release and synaptic plasticity, and emerges early during adult neurogenesis</article_title>
            <author>Rößler</author>
            <journal_title>Open Biology</journal_title>
            <issue>8</issue>
            <volume>13</volume>
            <doi>10.1098/rsob.230063</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Rößler, N., Jungenitz, T., Sigler, A., Bird, A., Mittag, M., Rhee, J. S., Deller, T., Cuntz, H., Brose, N., Schwarzacher, S. W., &amp; others. (2023). Skewed distribution of spines is independent of presynaptic transmitter release and synaptic plasticity, and emerges early during adult neurogenesis. Open Biology, 13(8), 230063. https://doi.org/10.1098/rsob.230063</unstructured_citation>
          </citation>
          <citation key="gloeckler2023adversarial">
            <article_title>Adversarial robustness of amortized Bayesian inference</article_title>
            <author>Gloeckler</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.2305.14984</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Gloeckler, M., Deistler, M., &amp; Macke, J. H. (2023). Adversarial robustness of amortized Bayesian inference. International Conference on Machine Learning, 11493–11524. https://doi.org/10.48550/arXiv.2305.14984</unstructured_citation>
          </citation>
          <citation key="dyer2022calibrating">
            <article_title>Calibrating agent-based models to microdata with graph neural networks</article_title>
            <author>Dyer</author>
            <journal_title>ICML 2022 workshop AI for agent-based modelling</journal_title>
            <doi>10.48550/arXiv.2206.07570</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Dyer, J., Cannon, P., Farmer, J. D., &amp; Schmon, S. M. (2022). Calibrating agent-based models to microdata with graph neural networks. ICML 2022 Workshop AI for Agent-Based Modelling. https://doi.org/10.48550/arXiv.2206.07570</unstructured_citation>
          </citation>
          <citation key="wiqvist2021sequential">
            <article_title>Sequential neural posterior and likelihood approximation</article_title>
            <author>Wiqvist</author>
            <journal_title>arXiv preprint arXiv:2102.06522</journal_title>
            <doi>10.48550/arXiv.2102.06522</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Wiqvist, S., Frellsen, J., &amp; Picchini, U. (2021). Sequential neural posterior and likelihood approximation. arXiv Preprint arXiv:2102.06522. https://doi.org/10.48550/arXiv.2102.06522</unstructured_citation>
          </citation>
          <citation key="jin2023bayesian">
            <article_title>Bayesian inference of a spectral graph model for brain oscillations</article_title>
            <author>Jin</author>
            <journal_title>NeuroImage</journal_title>
            <volume>279</volume>
            <doi>10.1016/j.neuroimage.2023.120278</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Jin, H., Verma, P., Jiang, F., Nagarajan, S. S., &amp; Raj, A. (2023). Bayesian inference of a spectral graph model for brain oscillations. NeuroImage, 279, 120278. https://doi.org/10.1016/j.neuroimage.2023.120278</unstructured_citation>
          </citation>
          <citation key="spurio2023bayesian">
            <article_title>Bayesian model comparison for simulation-based inference</article_title>
            <author>Spurio Mancini</author>
            <journal_title>RAS Techniques and Instruments</journal_title>
            <issue>1</issue>
            <volume>2</volume>
            <doi>10.1093/rasti/rzad051</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Spurio Mancini, A., Docherty, M., Price, M., &amp; McEwen, J. (2023). Bayesian model comparison for simulation-based inference. RAS Techniques and Instruments, 2(1), 710–722. https://doi.org/10.1093/rasti/rzad051</unstructured_citation>
          </citation>
          <citation key="boelts2023simulation">
            <article_title>Simulation-based inference for efficient identification of generative models in computational connectomics</article_title>
            <author>Boelts</author>
            <journal_title>PLOS Computational Biology</journal_title>
            <issue>9</issue>
            <volume>19</volume>
            <doi>10.1101/2023.01.31.526269</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Boelts, J., Harth, P., Gao, R., Udvary, D., Yáñez, F., Baum, D., Hege, H.-C., Oberlaender, M., &amp; Macke, J. H. (2023). Simulation-based inference for efficient identification of generative models in computational connectomics. PLOS Computational Biology, 19(9), e1011406. https://doi.org/10.1101/2023.01.31.526269</unstructured_citation>
          </citation>
          <citation key="dirmeier2023simulation">
            <article_title>Simulation-based inference using surjective sequential neural likelihood estimation</article_title>
            <author>Dirmeier</author>
            <journal_title>arXiv preprint</journal_title>
            <doi>10.48550/arXiv.2308.01054</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Dirmeier, S., Albert, C., &amp; Perez-Cruz, F. (2023). Simulation-based inference using surjective sequential neural likelihood estimation. arXiv Preprint. https://doi.org/10.48550/arXiv.2308.01054</unstructured_citation>
          </citation>
          <citation key="linhart2024c2st">
            <article_title>L-c2st: Local diagnostics for posterior approximations in simulation-based inference</article_title>
            <author>Linhart</author>
            <journal_title>Advances in Neural Information Processing Systems</journal_title>
            <volume>36</volume>
            <doi>10.48550/arXiv.2306.03580</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Linhart, J., Gramfort, A., &amp; Rodrigues, P. (2024). L-c2st: Local diagnostics for posterior approximations in simulation-based inference. Advances in Neural Information Processing Systems, 36. https://doi.org/10.48550/arXiv.2306.03580</unstructured_citation>
          </citation>
          <citation key="lemos2023sampling">
            <article_title>Sampling-based accuracy testing of posterior estimators for general inference</article_title>
            <author>Lemos</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.2302.03026</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Lemos, P., Coogan, A., Hezaveh, Y., &amp; Perreault-Levasseur, L. (2023). Sampling-based accuracy testing of posterior estimators for general inference. International Conference on Machine Learning, 19256–19273. https://doi.org/10.48550/arXiv.2302.03026</unstructured_citation>
          </citation>
          <citation key="song2021scorebased">
            <article_title>Score-based generative modeling through stochastic differential equations</article_title>
            <author>Song</author>
            <journal_title>International conference on learning representations</journal_title>
            <doi>10.48550/arXiv.2011.13456</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., &amp; Poole, B. (2021). Score-based generative modeling through stochastic differential equations. International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2011.13456</unstructured_citation>
          </citation>
          <citation key="gloeckler2024allinone">
            <article_title>All-in-one simulation-based inference</article_title>
            <author>Gloeckler</author>
            <journal_title>Forty-first international conference on machine learning</journal_title>
            <doi>10.48550/arXiv.2404.09636</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Gloeckler, M., Deistler, M., Weilbach, C. D., Wood, F., &amp; Macke, J. H. (2024). All-in-one simulation-based inference. Forty-First International Conference on Machine Learning. https://doi.org/10.48550/arXiv.2404.09636</unstructured_citation>
          </citation>
          <citation key="lipman2023flow">
            <article_title>Flow matching for generative modeling</article_title>
            <author>Lipman</author>
            <journal_title>The eleventh international conference on learning representations</journal_title>
            <doi>10.48550/arXiv.2210.02747</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., &amp; Le, M. (2023). Flow matching for generative modeling. The Eleventh International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2210.02747</unstructured_citation>
          </citation>
          <citation key="arviz_2019">
            <article_title>ArviZ a unified library for exploratory analysis of Bayesian models in Python</article_title>
            <author>Kumar</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>33</issue>
            <volume>4</volume>
            <doi>10.21105/joss.01143</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Kumar, R., Carroll, C., Hartikainen, A., &amp; Martin, O. (2019). ArviZ a unified library for exploratory analysis of Bayesian models in Python. Journal of Open Source Software, 4(33), 1143. https://doi.org/10.21105/joss.01143</unstructured_citation>
          </citation>
          <citation key="rozet_2021_lampe">
            <article_title>LAMPE: Likelihood-free amortized posterior estimation</article_title>
            <author>Rozet</author>
            <journal_title>Statistical Software</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Rozet, F., Delaunoy, A., Miller, B., &amp; others. (2021). LAMPE: Likelihood-free amortized posterior estimation. Statistical Software.</unstructured_citation>
          </citation>
          <citation key="bayesflow_2023_software">
            <article_title>BayesFlow: Amortized Bayesian workflows with neural networks</article_title>
            <author>Radev</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>89</issue>
            <volume>8</volume>
            <doi>10.21105/joss.05702</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Radev, S. T., Schmitt, M., Schumacher, L., Elsemüller, L., Pratz, V., Schälte, Y., Köthe, U., &amp; Bürkner, P.-C. (2023). BayesFlow: Amortized Bayesian workflows with neural networks. Journal of Open Source Software, 8(89), 5702. https://doi.org/10.21105/joss.05702</unstructured_citation>
          </citation>
          <citation key="swyft">
            <article_title>Swyft: A system for scientific simulation-based inference at scale</article_title>
            <author>undark-lab</author>
            <cYear>2023</cYear>
            <unstructured_citation>undark-lab. (2023). Swyft: A system for scientific simulation-based inference at scale. https://github.com/undark-lab/swyft.</unstructured_citation>
          </citation>
          <citation key="dirmeier2024simulationbasedinferencepythonpackage">
            <article_title>Simulation-based inference with the Python package sbijax</article_title>
            <author>Dirmeier</author>
            <cYear>2024</cYear>
            <unstructured_citation>Dirmeier, S., Ulzega, S., Mira, A., &amp; Albert, C. (2024). Simulation-based inference with the Python package sbijax. https://arxiv.org/abs/2409.19435</unstructured_citation>
          </citation>
          <citation key="gao2024deep">
            <article_title>Deep inverse modeling reveals dynamic-dependent invariances in neural circuit mechanisms</article_title>
            <author>Gao</author>
            <journal_title>bioRxiv</journal_title>
            <doi>10.1101/2024.08.21.608969</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Gao, R., Deistler, M., Schulz, A., Gonçalves, P. J., &amp; Macke, J. H. (2024). Deep inverse modeling reveals dynamic-dependent invariances in neural circuit mechanisms. bioRxiv, 2024–2008. https://doi.org/10.1101/2024.08.21.608969</unstructured_citation>
          </citation>
          <citation key="bernaerts2023combined">
            <article_title>Combined statistical-mechanistic modeling links ion channel genes to physiology of cortical neuron types</article_title>
            <author>Bernaerts</author>
            <journal_title>bioRxiv</journal_title>
            <doi>10.1101/2023.03.02.530774</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Bernaerts, Y., Deistler, M., Gonçalves, P. J., Beck, J., Stimberg, M., Scala, F., Tolias, A. S., Macke, J., Kobak, D., &amp; Berens, P. (2023). Combined statistical-mechanistic modeling links ion channel genes to physiology of cortical neuron types. bioRxiv, 2023–2003. https://doi.org/10.1101/2023.03.02.530774</unstructured_citation>
          </citation>
          <citation key="wang2024comprehensive">
            <article_title>A comprehensive guide to simulation-based inference in computational biology</article_title>
            <author>Wang</author>
            <doi>10.2139/ssrn.4982890</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Wang, X., Kelly, R. P., Jenner, A. L., Warne, D. J., &amp; Drovandi, C. (2024). A comprehensive guide to simulation-based inference in computational biology. https://doi.org/10.2139/ssrn.4982890</unstructured_citation>
          </citation>
          <citation key="dingeldein2023simulation">
            <article_title>Simulation-based inference of single-molecule force spectroscopy</article_title>
            <author>Dingeldein</author>
            <journal_title>Machine Learning: Science and Technology</journal_title>
            <issue>2</issue>
            <volume>4</volume>
            <doi>10.1016/j.bpj.2022.11.920</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Dingeldein, L., Cossio, P., &amp; Covino, R. (2023). Simulation-based inference of single-molecule force spectroscopy. Machine Learning: Science and Technology, 4(2), 025009. https://doi.org/10.1016/j.bpj.2022.11.920</unstructured_citation>
          </citation>
          <citation key="hashemi2023amortized">
            <article_title>Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators</article_title>
            <author>Hashemi</author>
            <journal_title>Neural Networks</journal_title>
            <volume>163</volume>
            <doi>10.1016/j.neunet.2023.03.040</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Hashemi, M., Vattikonda, A. N., Jha, J., Sip, V., Woodman, M. M., Bartolomei, F., &amp; Jirsa, V. K. (2023). Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators. Neural Networks, 163, 178–194. https://doi.org/10.1016/j.neunet.2023.03.040</unstructured_citation>
          </citation>
          <citation key="phan2019composable">
            <article_title>Composable effects for flexible and accelerated probabilistic programming in NumPyro</article_title>
            <author>Phan</author>
            <journal_title>arXiv preprint arXiv:1912.11554</journal_title>
            <doi>10.48550/arXiv.1912.11554</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Phan, D., Pradhan, N., &amp; Jankowiak, M. (2019). Composable effects for flexible and accelerated probabilistic programming in NumPyro. arXiv Preprint arXiv:1912.11554. https://doi.org/10.48550/arXiv.1912.11554</unstructured_citation>
          </citation>
          <citation key="gelman2015stan">
            <article_title>Stan: A probabilistic programming language for Bayesian inference and optimization</article_title>
            <author>Gelman</author>
            <journal_title>Journal of Educational and Behavioral Statistics</journal_title>
            <issue>5</issue>
            <volume>40</volume>
            <doi>10.3102/1076998615606113</doi>
            <cYear>2015</cYear>
            <unstructured_citation>Gelman, A., Lee, D., &amp; Guo, J. (2015). Stan: A probabilistic programming language for Bayesian inference and optimization. Journal of Educational and Behavioral Statistics, 40(5), 530–543. https://doi.org/10.3102/1076998615606113</unstructured_citation>
          </citation>
          <citation key="ge2018t">
            <article_title>Turing: A language for flexible probabilistic inference</article_title>
            <author>Ge</author>
            <journal_title>International conference on artificial intelligence and statistics, AISTATS 2018, 9-11 april 2018, playa blanca, lanzarote, canary islands, spain</journal_title>
            <cYear>2018</cYear>
            <unstructured_citation>Ge, H., Xu, K., &amp; Ghahramani, Z. (2018). Turing: A language for flexible probabilistic inference. International Conference on Artificial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands, Spain, 1682–1690. http://proceedings.mlr.press/v84/ge18b.html</unstructured_citation>
          </citation>
          <citation key="quera-bofarull2023">
            <article_title>BlackBIRDS: Black-box inference foR differentiable simulators</article_title>
            <author>Quera-Bofarull</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>89</issue>
            <volume>8</volume>
            <doi>10.21105/joss.05776</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Quera-Bofarull, A., Dyer, J., Calinescu, A., Farmer, J. D., &amp; Wooldridge, M. (2023). BlackBIRDS: Black-box inference foR differentiable simulators. Journal of Open Source Software, 8(89), 5776. https://doi.org/10.21105/joss.05776</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
