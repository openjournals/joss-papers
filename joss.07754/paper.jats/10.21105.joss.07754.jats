<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7754</article-id>
<article-id pub-id-type="doi">10.21105/joss.07754</article-id>
<title-group>
<article-title><monospace>sbi</monospace> reloaded: a toolkit for
simulation-based inference workflows</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<name>
<surname>Boelts</surname>
<given-names>Jan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<name>
<surname>Deistler</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-2"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gloeckler</surname>
<given-names>Manuel</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tejero-Cantero</surname>
<given-names>Álvaro</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lueckmann</surname>
<given-names>Jan-Matthis</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moss</surname>
<given-names>Guy</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Steinbach</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moreau</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Muratore</surname>
<given-names>Fabio</given-names>
</name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Linhart</surname>
<given-names>Julia</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Durkan</surname>
<given-names>Conor</given-names>
</name>
<xref ref-type="aff" rid="aff-9"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vetter</surname>
<given-names>Julius</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Miller</surname>
<given-names>Benjamin Kurt</given-names>
</name>
<xref ref-type="aff" rid="aff-10"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Herold</surname>
<given-names>Maternus</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-11"/>
<xref ref-type="aff" rid="aff-12"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ziaeemehr</surname>
<given-names>Abolfazl</given-names>
</name>
<xref ref-type="aff" rid="aff-13"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pals</surname>
<given-names>Matthijs</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gruner</surname>
<given-names>Theo</given-names>
</name>
<xref ref-type="aff" rid="aff-14"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bischoff</surname>
<given-names>Sebastian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-15"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Krouglova</surname>
<given-names>Nastya</given-names>
</name>
<xref ref-type="aff" rid="aff-16"/>
<xref ref-type="aff" rid="aff-17"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gao</surname>
<given-names>Richard</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lappalainen</surname>
<given-names>Janne K</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mucsányi</surname>
<given-names>Bálint</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-18"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pei</surname>
<given-names>Felix</given-names>
</name>
<xref ref-type="aff" rid="aff-19"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schulz</surname>
<given-names>Auguste</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Stefanidi</surname>
<given-names>Zinovia</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rodrigues</surname>
<given-names>Pedro</given-names>
</name>
<xref ref-type="aff" rid="aff-20"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schröder</surname>
<given-names>Cornelius</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zaid</surname>
<given-names>Faried Abu</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Beck</surname>
<given-names>Jonas</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-21"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kapoor</surname>
<given-names>Jaivardhan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Greenberg</surname>
<given-names>David S.</given-names>
</name>
<xref ref-type="aff" rid="aff-22"/>
<xref ref-type="aff" rid="aff-23"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gonçalves</surname>
<given-names>Pedro J.</given-names>
</name>
<xref ref-type="aff" rid="aff-17"/>
<xref ref-type="aff" rid="aff-24"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Macke</surname>
<given-names>Jakob H.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-25"/>
<xref ref-type="corresp" rid="cor-3"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Machine Learning in Science, University of
Tübingen</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Tübingen AI Center</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>TransferLab, appliedAI Institute for Europe</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>ML Colab, Cluster ML in Science, University of
Tübingen</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Google Research</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Helmholtz-Zentrum Dresden-Rossendorf</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Université Paris-Saclay, INRIA, CEA, Palaiseau,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-8">
<institution-wrap>
<institution>Robert Bosch GmbH</institution>
</institution-wrap>
</aff>
<aff id="aff-9">
<institution-wrap>
<institution>School of Informatics, University of
Edinburgh</institution>
</institution-wrap>
</aff>
<aff id="aff-10">
<institution-wrap>
<institution>University of Amsterdam</institution>
</institution-wrap>
</aff>
<aff id="aff-11">
<institution-wrap>
<institution>Research and Innovation Center, BMW Group</institution>
</institution-wrap>
</aff>
<aff id="aff-12">
<institution-wrap>
<institution>Institute for Applied Mathematics and Scientific Computing,
University of the Bundeswehr Munich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-13">
<institution-wrap>
<institution>Aix Marseille, INSERM, INS, France</institution>
</institution-wrap>
</aff>
<aff id="aff-14">
<institution-wrap>
<institution>TU Darmstadt, hessian.AI, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-15">
<institution-wrap>
<institution>University Hospital Tübingen and M3 Research
Center</institution>
</institution-wrap>
</aff>
<aff id="aff-16">
<institution-wrap>
<institution>Faculty of Science, B-3000, KU Leuven,
Belgium</institution>
</institution-wrap>
</aff>
<aff id="aff-17">
<institution-wrap>
<institution>VIB-Neuroelectronics Research Flanders (NERF) and imec,
Belgium</institution>
</institution-wrap>
</aff>
<aff id="aff-18">
<institution-wrap>
<institution>Methods of Machine Learning, University of
Tübingen</institution>
</institution-wrap>
</aff>
<aff id="aff-19">
<institution-wrap>
<institution>Neuroscience Institute, Carnegie Mellon
University</institution>
</institution-wrap>
</aff>
<aff id="aff-20">
<institution-wrap>
<institution>Université Grenoble Alpes, INRIA, CNRS, Grenoble INP, LJK,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-21">
<institution-wrap>
<institution>Hertie Institute for AI in Brain Health, University of
Tübingen</institution>
</institution-wrap>
</aff>
<aff id="aff-22">
<institution-wrap>
<institution>Institute of Coastal Systems - Analysis and
Modeling</institution>
</institution-wrap>
</aff>
<aff id="aff-23">
<institution-wrap>
<institution>Helmholtz AI</institution>
</institution-wrap>
</aff>
<aff id="aff-24">
<institution-wrap>
<institution>Departments of Computer Science Electrical Engineering, KU
Leuven, Belgium</institution>
</institution-wrap>
</aff>
<aff id="aff-25">
<institution-wrap>
<institution>Department Empirical Inference, Max Planck Institute for
Intelligent Systems, Tübingen</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
<corresp id="cor-2">* E-mail: <email></email></corresp>
<corresp id="cor-3">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-10-16">
<day>16</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>108</issue>
<fpage>7754</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>PyTorch</kwd>
<kwd>Bayesian Inference</kwd>
<kwd>Simulation-Based Inference</kwd>
<kwd>Scientific Discovery</kwd>
<kwd>Conditional Density Estimation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="abstract">
  <title>Abstract</title>
  <p>Scientists and engineers use simulators to model empirically
  observed phenomena. However, tuning the parameters of a simulator to
  ensure its outputs match observed data presents a significant
  challenge. Simulation-based inference (SBI) addresses this by enabling
  Bayesian inference for simulators, identifying parameters that match
  observed data and align with prior knowledge. Unlike traditional
  Bayesian inference, SBI only needs access to simulations from the
  model and does not require evaluations of the likelihood-function. In
  addition, SBI algorithms do not require gradients through the
  simulator, allow for massive parallelization of simulations, and can
  perform inference for different observations without further
  simulations or training, thereby amortizing inference. Over the past
  years, we have developed, maintained, and extended
  <monospace>sbi</monospace>, a PyTorch-based package that implements
  Bayesian SBI algorithms based on neural networks. The
  <monospace>sbi</monospace> toolkit implements a wide range of
  inference methods, neural network architectures, sampling methods, and
  diagnostic tools. In addition, it provides well-tested default
  settings but also offers flexibility to fully customize every step of
  the simulation-based inference workflow. Taken together, the
  <monospace>sbi</monospace> toolkit enables scientists and engineers to
  apply state-of-the-art SBI methods to black-box simulators, opening up
  new possibilities for aligning simulations with empirically observed
  data.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Bayesian inference is a principled approach for determining
  parameters consistent with empirical observations: Given a prior over
  parameters, a forward-model (defining the likelihood), and
  observations, it returns a posterior distribution. The posterior
  distribution captures the entire space of parameters that are
  compatible with the observations and the prior and it quantifies
  parameter uncertainty. When the forward-model is given by a stochastic
  simulator, Bayesian inference can be challenging: (1) the
  forward-model can be slow to evaluate, making algorithms that rely on
  sequential evaluations of the likelihood (such as Markov-Chain
  Monte-Carlo, MCMC) impractical, (2) the simulator can be
  non-differentiable, prohibiting the use of gradient-based MCMC or
  variational inference (VI) methods, and (3) likelihood-evaluations can
  be intractable, meaning that we can only generate samples from the
  model, but not evaluate their likelihoods.</p>
  <p>Recently, simulation-based inference (SBI) algorithms based on
  neural networks have been developed to overcome these limitations
  (<xref alt="Hermans et al., 2020" rid="ref-hermans2020likelihood" ref-type="bibr">Hermans
  et al., 2020</xref>;
  <xref alt="Papamakarios et al., 2019" rid="ref-papamakarios2019sequential" ref-type="bibr">Papamakarios
  et al., 2019</xref>;
  <xref alt="Papamakarios &amp; Murray, 2016" rid="ref-papamakarios2016fast" ref-type="bibr">Papamakarios
  &amp; Murray, 2016</xref>). Unlike classical methods from Approximate
  Bayesian Computation (ABC, Sisson et al.
  (<xref alt="2018" rid="ref-sisson2018_chapter1" ref-type="bibr">2018</xref>)),
  these methods use neural networks to learn the relationship between
  parameters and simulation outputs. Neural SBI algorithms (1) allow for
  massive parallelization of simulations (in contrast to sequential
  evaluations in MCMC methods), (2) do not require gradients through the
  simulator, and (3) do not require evaluations of the likelihood, but
  only samples from the simulator. Finally, many of these algorithms
  allow for <italic>amortized</italic> inference, that is, after a large
  upfront cost of simulating data for the training phase, they can
  return the posterior distribution for any observation without
  requiring further simulations or retraining.</p>
  <p>To aid in the effective application of these algorithms to a wide
  range of problems, we developed the <monospace>sbi</monospace>
  toolkit. <monospace>sbi</monospace> implements a variety of
  state-of-the-art SBI algorithms, offering both high-level interfaces,
  extensive documentation and tutorials for practitioners, as well as
  low-level interfaces for experienced users and SBI researchers (giving
  full control over simulations, the training loop, and the sampling
  procedure). Since the original release of the
  <monospace>sbi</monospace> package
  (<xref alt="Tejero-Cantero et al., 2020" rid="ref-tejerocantero2020sbi" ref-type="bibr">Tejero-Cantero
  et al., 2020</xref>), the community of contributors has expanded
  significantly, resulting in a large number of improvements that have
  made <monospace>sbi</monospace> more flexible, performant, and
  reliable. <monospace>sbi</monospace> now supports a wider range of
  amortized and sequential inference methods, neural network
  architectures (including normalizing flows, flow- and score-matching,
  and various embedding network architectures), samplers (including
  MCMC, variational inference, importance sampling, and rejection
  sampling), diagnostic tools, visualization tools, and a comprehensive
  set of tutorials on how to use these features.</p>
  <p>The <monospace>sbi</monospace> package is already used extensively
  by the machine learning research community
  (<xref alt="Boelts et al., 2022" rid="ref-boelts2022flexible" ref-type="bibr">Boelts
  et al., 2022</xref>;
  <xref alt="Deistler, Gonçalves, et al., 2022" rid="ref-deistler2022truncated" ref-type="bibr">Deistler,
  Gonçalves, et al., 2022</xref>;
  <xref alt="Dirmeier et al., 2023" rid="ref-dirmeier2023simulation" ref-type="bibr">Dirmeier
  et al., 2023</xref>;
  <xref alt="Dyer et al., 2022b" rid="ref-dyer2022calibrating" ref-type="bibr">Dyer
  et al., 2022b</xref>;
  <xref alt="Gloeckler et al., 2023" rid="ref-gloeckler2023adversarial" ref-type="bibr">Gloeckler
  et al., 2023</xref>,
  <xref alt="2022" rid="ref-gloecklervariational" ref-type="bibr">2022</xref>,
  <xref alt="2024" rid="ref-gloeckler2024allinone" ref-type="bibr">2024</xref>;
  <xref alt="Hermans et al., 2022" rid="ref-hermans2022crisis" ref-type="bibr">Hermans
  et al., 2022</xref>;
  <xref alt="Linhart et al., 2024" rid="ref-linhart2024c2st" ref-type="bibr">Linhart
  et al., 2024</xref>;
  <xref alt="Muratore et al., 2022" rid="ref-muratore2022neural" ref-type="bibr">Muratore
  et al., 2022</xref>;
  <xref alt="Spurio Mancini et al., 2023" rid="ref-spurio2023bayesian" ref-type="bibr">Spurio
  Mancini et al., 2023</xref>;
  <xref alt="Wiqvist et al., 2021" rid="ref-wiqvist2021sequential" ref-type="bibr">Wiqvist
  et al., 2021</xref>) but has also fostered the application of SBI in
  various fields of research
  (<xref alt="Avecilla et al., 2022" rid="ref-avecilla2022neural" ref-type="bibr">Avecilla
  et al., 2022</xref>;
  <xref alt="Bernaerts et al., 2023" rid="ref-bernaerts2023combined" ref-type="bibr">Bernaerts
  et al., 2023</xref>;
  <xref alt="Boelts et al., 2023" rid="ref-boelts2023simulation" ref-type="bibr">Boelts
  et al., 2023</xref>;
  <xref alt="Bondarenko et al., 2023" rid="ref-bondarenko2023embryo" ref-type="bibr">Bondarenko
  et al., 2023</xref>;
  <xref alt="Confavreux et al., 2023" rid="ref-confavreux2023meta" ref-type="bibr">Confavreux
  et al., 2023</xref>;
  <xref alt="Deistler, Macke, et al., 2022" rid="ref-deistler2022energy" ref-type="bibr">Deistler,
  Macke, et al., 2022</xref>;
  <xref alt="Dingeldein et al., 2023" rid="ref-dingeldein2023simulation" ref-type="bibr">Dingeldein
  et al., 2023</xref>;
  <xref alt="Dyer et al., 2022a" rid="ref-dyer2022black" ref-type="bibr">Dyer
  et al., 2022a</xref>;
  <xref alt="Gao et al., 2024" rid="ref-gao2024deep" ref-type="bibr">Gao
  et al., 2024</xref>;
  <xref alt="Groschner et al., 2022" rid="ref-groschner2022biophysical" ref-type="bibr">Groschner
  et al., 2022</xref>;
  <xref alt="Hahn &amp; Melchior, 2022" rid="ref-hahn2022accelerated" ref-type="bibr">Hahn
  &amp; Melchior, 2022</xref>;
  <xref alt="Hashemi et al., 2023" rid="ref-hashemi2023amortized" ref-type="bibr">Hashemi
  et al., 2023</xref>;
  <xref alt="Jin et al., 2023" rid="ref-jin2023bayesian" ref-type="bibr">Jin
  et al., 2023</xref>;
  <xref alt="Lemos et al., 2024" rid="ref-lemos2024field" ref-type="bibr">Lemos
  et al., 2024</xref>;
  <xref alt="Lowet et al., 2023" rid="ref-lowet2023theta" ref-type="bibr">Lowet
  et al., 2023</xref>;
  <xref alt="Mishra-Sharma &amp; Cranmer, 2022" rid="ref-mishra2022neural" ref-type="bibr">Mishra-Sharma
  &amp; Cranmer, 2022</xref>;
  <xref alt="Myers-Joseph et al., 2024" rid="ref-myers2024disinhibition" ref-type="bibr">Myers-Joseph
  et al., 2024</xref>;
  <xref alt="Rößler et al., 2023" rid="ref-rossler2023skewed" ref-type="bibr">Rößler
  et al., 2023</xref>;
  <xref alt="Wang et al., 2024" rid="ref-wang2024comprehensive" ref-type="bibr">Wang
  et al., 2024</xref>).</p>
</sec>
<sec id="description">
  <title>Description</title>
  <p><monospace>sbi</monospace> is a flexible and extensive toolkit for
  running simulation-based Bayesian inference workflows.
  <monospace>sbi</monospace> supports any kind of (offline) simulator
  and prior, a wide range of inference methods, neural networks, and
  samplers, as well as diagnostic methods and analysis tools
  (<xref alt="[fig:fig1]" rid="figU003Afig1">[fig:fig1]</xref>).</p>
  <fig>
    <caption><p><bold>Features of the <monospace>sbi</monospace>
    package.</bold> Components that were added since the initial release
    described in Tejero-Cantero et al.
    (<xref alt="2020" rid="ref-tejerocantero2020sbi" ref-type="bibr">2020</xref>)
    are marked in
    red.<styled-content id="figU003Afig1"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="sbi_toolbox.png" />
  </fig>
  <p>A significant challenge in making SBI algorithms accessible to a
  broader community lies in accommodating diverse and complex
  simulators, as well as varying degrees of flexibility in each step of
  the inference process. To address this, <monospace>sbi</monospace>
  provides pre-configured defaults for all inference methods, but also
  allows full customization of every step in the process (including
  simulation, training, sampling, diagnostics and analysis).</p>
  <p><bold>Simulator &amp; prior:</bold> The <monospace>sbi</monospace>
  toolkit requires only simulation parameters and simulated data as
  input, without needing direct access to the simulator itself. However,
  if the simulator can be provided as a Python callable,
  <monospace>sbi</monospace> can optionally parallelize running the
  simulations from a given prior using <monospace>joblib</monospace>
  (<xref alt="Varoquaux, 2008" rid="ref-joblib" ref-type="bibr">Varoquaux,
  2008</xref>). Additionally, <monospace>sbi</monospace> can
  automatically handle failed simulations or missing values, it supports
  both discrete and continuous parameters and observations (or mixtures
  thereof) and it provides utilities to flexibly define priors.</p>
  <p><bold>Methods:</bold> <monospace>sbi</monospace> implements a wide
  range of neural network-based SBI algorithms, among them Neural
  Posterior Estimation (NPE) with various conditional estimators, Neural
  Likelihood Estimation (NLE), and Neural Ratio Estimation (NRE). Each
  of these methods can be run either in an <italic>amortized</italic>
  mode, where the neural network is trained once on a set of
  pre-existing simulation results and then performs inference on
  <italic>any</italic> observation without further simulations or
  retraining, or in a <italic>sequential</italic> mode where inference
  is focused on one observation to improve simulation efficiency with
  active learning, running simulations with parameters likely to have
  resulted in the observation.</p>
  <p><bold>Neural networks and training:</bold>
  <monospace>sbi</monospace> implements a wide variety of
  state-of-the-art conditional density estimators for NPE and NLE,
  including normalizing flows
  (<xref alt="Greenberg et al., 2019" rid="ref-greenberg2019automatic" ref-type="bibr">Greenberg
  et al., 2019</xref>;
  <xref alt="Papamakarios et al., 2021" rid="ref-papamakarios2021normalizing" ref-type="bibr">Papamakarios
  et al., 2021</xref>) (via <monospace>nflows</monospace>
  (<xref alt="Durkan et al., 2019" rid="ref-nflows-repo" ref-type="bibr">Durkan
  et al., 2019</xref>) and <monospace>zuko</monospace>
  (<xref alt="Rozet, 2023" rid="ref-zuko-repo" ref-type="bibr">Rozet,
  2023</xref>)), diffusion models
  (<xref alt="Geffner et al., 2023" rid="ref-geffner2023compositional" ref-type="bibr">Geffner
  et al., 2023</xref>;
  <xref alt="Simons et al., 2023" rid="ref-sharrock2022sequential" ref-type="bibr">Simons
  et al., 2023</xref>;
  <xref alt="Song et al., 2021" rid="ref-song2021scorebased" ref-type="bibr">Song
  et al., 2021</xref>), mixture density networks
  (<xref alt="Bishop, 1994" rid="ref-Bishop_94" ref-type="bibr">Bishop,
  1994</xref>), and flow matching
  (<xref alt="Lipman et al., 2023" rid="ref-lipman2023flow" ref-type="bibr">Lipman
  et al., 2023</xref>;
  <xref alt="Wildberger et al., 2023" rid="ref-dax2023flow" ref-type="bibr">Wildberger
  et al., 2023</xref>) (via <monospace>zuko</monospace>), as well as
  ensembles of any of these networks. <monospace>sbi</monospace> also
  implements a large set of embedding networks that can automatically
  learn summary statistics of (potentially) high-dimensional simulation
  outputs (including multilayer perceptrons, convolutional networks, and
  permutation-invariant networks). The neural networks can be trained
  with a pre-configured training loop with established default values,
  but <monospace>sbi</monospace> also allows full access over the
  training loop when desired.</p>
  <p><bold>Sampling:</bold> For NLE and NRE, <monospace>sbi</monospace>
  implements a large range of samplers, including MCMC (with chains
  vectorized across observations), variational inference, rejection
  sampling, or importance sampling, as well as wrappers to use MCMC
  samplers from Pyro and PyMC
  (<xref alt="Abril-Pla et al., 2023" rid="ref-abril2023pymc" ref-type="bibr">Abril-Pla
  et al., 2023</xref>;
  <xref alt="Bingham et al., 2019" rid="ref-bingham2019pyro" ref-type="bibr">Bingham
  et al., 2019</xref>). <monospace>sbi</monospace> can perform inference
  for single observations or for multiple <italic>i.i.d.</italic>
  observations, and can use importance sampling to correct for potential
  inaccuracies in the posterior if the likelihood is available.</p>
  <p><bold>Diagnostics and analysis:</bold> The
  <monospace>sbi</monospace> toolkit also implements a large set of
  diagnostic tools, such as simulation-based calibration (SBC)
  (<xref alt="Talts et al., 2018" rid="ref-talts2018validating" ref-type="bibr">Talts
  et al., 2018</xref>), expected coverage
  (<xref alt="Deistler, Gonçalves, et al., 2022" rid="ref-deistler2022truncated" ref-type="bibr">Deistler,
  Gonçalves, et al., 2022</xref>;
  <xref alt="Hermans et al., 2022" rid="ref-hermans2022crisis" ref-type="bibr">Hermans
  et al., 2022</xref>), local C2ST
  (<xref alt="Linhart et al., 2024" rid="ref-linhart2024c2st" ref-type="bibr">Linhart
  et al., 2024</xref>), and TARP
  (<xref alt="Lemos et al., 2023" rid="ref-lemos2023sampling" ref-type="bibr">Lemos
  et al., 2023</xref>). Additionally, <monospace>sbi</monospace> offers
  visualization tools for the posterior, including marginal and
  conditional corner plots to visualize high-dimensional distributions,
  calibration plots, and wrappers for Arviz
  (<xref alt="Kumar et al., 2019" rid="ref-arviz_2019" ref-type="bibr">Kumar
  et al., 2019</xref>) diagnostic plots.</p>
  <p>With <monospace>sbi</monospace>, our goal is to advance scientific
  discovery and computational engineering by making Bayesian inference
  accessible to a broad range of models, including those with
  inaccessible likelihoods, and to a broader range of users, including
  both machine learning researchers and domain practitioners. We have
  created an open architecture and embraced community-driven development
  practices to encourage collaboration with other machine learning
  researchers and applied scientists to join us in this long-term
  vision.</p>
</sec>
<sec id="related-software">
  <title>Related software</title>
  <p>Simulation-based inference methods implemented in the
  <monospace>sbi</monospace> package require only access to simulated
  data, which can also be generated offline in other programming
  languages or frameworks. This sets <monospace>sbi</monospace> apart
  from toolboxes for traditional Bayesian inference, such as MCMC-based
  methods
  (<xref alt="Abril-Pla et al., 2023" rid="ref-abril2023pymc" ref-type="bibr">Abril-Pla
  et al., 2023</xref>;
  <xref alt="Bingham et al., 2019" rid="ref-bingham2019pyro" ref-type="bibr">Bingham
  et al., 2019</xref>;
  <xref alt="Gelman et al., 2015" rid="ref-gelman2015stan" ref-type="bibr">Gelman
  et al., 2015</xref>), which rely on likelihood evaluations, and from
  probabilistic programming languages (e.g., Pyro
  (<xref alt="Bingham et al., 2019" rid="ref-bingham2019pyro" ref-type="bibr">Bingham
  et al., 2019</xref>), NumPyro
  (<xref alt="Phan et al., 2019" rid="ref-phan2019composable" ref-type="bibr">Phan
  et al., 2019</xref>), Stan
  (<xref alt="Gelman et al., 2015" rid="ref-gelman2015stan" ref-type="bibr">Gelman
  et al., 2015</xref>), or Turing.jl
  (<xref alt="Ge et al., 2018" rid="ref-ge2018t" ref-type="bibr">Ge et
  al., 2018</xref>)), which typically require the simulator to be
  differentiable and implemented within their respective frameworks
  (<xref alt="Quera-Bofarull et al., 2023" rid="ref-quera-bofarull2023" ref-type="bibr">Quera-Bofarull
  et al., 2023</xref>).</p>
  <p>Since the original release of the <monospace>sbi</monospace>
  package, several other packages that implement neural network-based
  SBI algorithms have emerged. The <monospace>lampe</monospace>
  (<xref alt="Rozet et al., 2021" rid="ref-rozet_2021_lampe" ref-type="bibr">Rozet
  et al., 2021</xref>) package offers neural posterior and neural ratio
  estimation, primarily targeting SBI researchers with a low-level API
  and full flexibility over the training loop. Its development has
  stopped in favor of the <monospace>sbi</monospace> project in July
  2024. The <monospace>BayesFlow</monospace> package
  (<xref alt="Radev et al., 2023" rid="ref-bayesflow_2023_software" ref-type="bibr">Radev
  et al., 2023</xref>) focuses on a set of amortized SBI algorithms
  based on posterior and likelihood estimation that have been developed
  in the respective research labs
  (<xref alt="Radev et al., 2020" rid="ref-radev2020bayesflow" ref-type="bibr">Radev
  et al., 2020</xref>). The <monospace>swyft</monospace> package
  (<xref alt="undark-lab, 2023" rid="ref-swyft" ref-type="bibr">undark-lab,
  2023</xref>) specializes in algorithms based on neural ratio
  estimation. The <monospace>sbijax</monospace> package
  (<xref alt="Dirmeier et al., 2024" rid="ref-dirmeier2024simulationbasedinferencepythonpackage" ref-type="bibr">Dirmeier
  et al., 2024</xref>) implements a set of inference methods in JAX.</p>
</sec>
<sec id="author-contributions">
  <title>Author contributions</title>
  <p>This work represents a collaborative effort with contributions from
  a large and diverse team. Author contributions are categorized as
  follows: Jan Boelts and Michael Deistler are the current maintainers
  and lead developers of the sbi package and contributed equally to this
  work. Manuel Gloeckler, Álvaro Tejero-Cantero, Jan-Matthis Lueckmann,
  and Guy Moss have made substantial and sustained core contributions to
  the codebase and project direction. Peter Steinbach, Thomas Moreau,
  Fabio Muratore, Julia Linhart, and Conor Durkan have made major
  contributions to specific features or aspects of the package. All
  other authors listed have contributed to the sbi package through code,
  documentation, or discussions.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work has been supported by the German Federal Ministry of
  Education and Research (BMBF, projects “Simalesam”, FKZ 01IS21055 A-B
  and “DeepHumanVision”, FKZ: 031L0197B, and the Tübingen AI Center FKZ:
  01IS18039A), the German Research Foundation (DFG) through Germany’s
  Excellence Strategy (EXC-Number 2064/1, PN 390727645) and SFB1233 (PN
  276693517), SFB 1089 (PN 227953431), SPP 2041 (PN 34721065), SPP 2041
  “Computational Connectomics”, SPP 2298-2 (PN 543917411), SFB 1233
  “Robust Vision”, and Germany’s Excellence Strategy EXC-Number
  2064/1/Project number 390727645, the “Certification and Foundations of
  Safe Machine Learning Systems in Healthcare” project funded by the
  Carl Zeiss Foundation, the Else Kröner Fresenius Stiftung (Project
  “ClinbrAIn”), and the European Union (ERC, “DeepCoMechTome”, ref.
  101089288). CD was supported by the EPSRC Centre for Doctoral Training
  in Data Science, funded by the UK Engineering and Physical Sciences
  Research Council (grant EP/L016427/1) and the University of Edinburgh.
  BKM is part of the ELLIS PhD program, receiving travel support from
  the ELISE mobility program which has received funding from the
  European Union’s Horizon 2020 research and innovation programme under
  ELISE grant agreement No 951847. DSG is supported by Helmholtz AI. JL
  is a recipient of the Pierre-Aguilar Scholarship and thankful for the
  funding of the Capital Fund Management (CFM). ANK is supported by an
  FWO grant (G097022N). TG was supported by “Third Wave of AI”, funded
  by the Excellence Program of the Hessian Ministry of Higher Education,
  Science, Research and Art. TM and PLCR were supported from a national
  grant managed by the French National Research Agency (Agence Nationale
  de la Recherche) attributed to the ExaDoST project of the NumPEx PEPR
  program, under the reference ANR-22-EXNU-0004. PS is supported by the
  Helmholtz Association Initiative and Networking Fund through the
  Helmholtz AI platform grant. MD, MG, GM, JV, MP, SB, JKL, AS, ZS, JB
  are members of the International Max Planck Research School for
  Intelligent Systems (IMPRS-IS).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-nflows-repo">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Durkan</surname><given-names>Conor</given-names></name>
        <name><surname>Bekasov</surname><given-names>Artur</given-names></name>
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Nflows: Normalizing flows in PyTorch</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/bayesiains/nflows; GitHub</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-zuko-repo">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Rozet</surname><given-names>François</given-names></name>
      </person-group>
      <article-title>Zuko - normalizing flows in PyTorch</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/probabilists/zuko; GitHub</publisher-name>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-bingham2019pyro">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bingham</surname><given-names>Eli</given-names></name>
        <name><surname>Chen</surname><given-names>Jonathan P.</given-names></name>
        <name><surname>Jankowiak</surname><given-names>Martin</given-names></name>
        <name><surname>Obermeyer</surname><given-names>Fritz</given-names></name>
        <name><surname>Pradhan</surname><given-names>Neeraj</given-names></name>
        <name><surname>Karaletsos</surname><given-names>Theofanis</given-names></name>
        <name><surname>Singh</surname><given-names>Rohit</given-names></name>
        <name><surname>Szerlip</surname><given-names>Paul A.</given-names></name>
        <name><surname>Horsfall</surname><given-names>Paul</given-names></name>
        <name><surname>Goodman</surname><given-names>Noah D.</given-names></name>
      </person-group>
      <article-title>Pyro: Deep universal probabilistic programming</article-title>
      <source>J. Mach. Learn. Res.</source>
      <year iso-8601-date="2019">2019</year>
      <volume>20</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1810.09538</pub-id>
      <fpage>28:1</fpage>
      <lpage>28:6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-abril2023pymc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abril-Pla</surname><given-names>Oriol</given-names></name>
        <name><surname>Andreani</surname><given-names>Virgile</given-names></name>
        <name><surname>Carroll</surname><given-names>Colin</given-names></name>
        <name><surname>Dong</surname><given-names>Larry</given-names></name>
        <name><surname>Fonnesbeck</surname><given-names>Christopher J</given-names></name>
        <name><surname>Kochurov</surname><given-names>Maxim</given-names></name>
        <name><surname>Kumar</surname><given-names>Ravin</given-names></name>
        <name><surname>Lao</surname><given-names>Junpeng</given-names></name>
        <name><surname>Luhmann</surname><given-names>Christian C</given-names></name>
        <name><surname>Martin</surname><given-names>Osvaldo A</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>PyMC: A modern, and comprehensive probabilistic programming framework in Python</article-title>
      <source>PeerJ Computer Science</source>
      <publisher-name>PeerJ Inc.</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>9</volume>
      <pub-id pub-id-type="doi">10.7717/peerj-cs.1516</pub-id>
      <fpage>e1516</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-joblib">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Varoquaux</surname><given-names>Gael</given-names></name>
      </person-group>
      <article-title>Joblib</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/joblib/joblib; GitHub</publisher-name>
      <year iso-8601-date="2008">2008</year>
    </element-citation>
  </ref>
  <ref id="ref-sisson2018_chapter1">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Sisson</surname><given-names>S. A.</given-names></name>
        <name><surname>Y.</surname><given-names>Fan</given-names></name>
        <name><surname>A.</surname><given-names>Beaumont M.</given-names></name>
      </person-group>
      <article-title>Overview of ABC</article-title>
      <source>Handbook of approximate bayesian computation</source>
      <publisher-name>CRC Press, Taylor &amp; Francis Group</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <isbn>9781439881507</isbn>
      <pub-id pub-id-type="doi">10.1201/9781315117195</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2016fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Fast \varepsilon-free inference of simulation models with Bayesian conditional density estimation</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2016">2016</year>
      <volume>29</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1605.06376</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2021normalizing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Nalisnick</surname><given-names>Eric</given-names></name>
        <name><surname>Rezende</surname><given-names>Danilo Jimenez</given-names></name>
        <name><surname>Mohamed</surname><given-names>Shakir</given-names></name>
        <name><surname>Lakshminarayanan</surname><given-names>Balaji</given-names></name>
      </person-group>
      <article-title>Normalizing flows for probabilistic modeling and inference</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2021">2021</year>
      <volume>22</volume>
      <issue>57</issue>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.02762</pub-id>
      <fpage>1</fpage>
      <lpage>64</lpage>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2019sequential">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Sterratt</surname><given-names>David</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows</article-title>
      <source>The 22nd international conference on artificial intelligence and statistics</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1805.07226</pub-id>
      <fpage>837</fpage>
      <lpage>848</lpage>
    </element-citation>
  </ref>
  <ref id="ref-greenberg2019automatic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Greenberg</surname><given-names>David</given-names></name>
        <name><surname>Nonnenmacher</surname><given-names>Marcel</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob</given-names></name>
      </person-group>
      <article-title>Automatic posterior transformation for likelihood-free inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1905.07488</pub-id>
      <fpage>2404</fpage>
      <lpage>2414</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tejerocantero2020sbi">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tejero-Cantero</surname><given-names>Alvaro</given-names></name>
        <name><surname>Boelts</surname><given-names>Jan</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Durkan</surname><given-names>Conor</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Greenberg</surname><given-names>David S.</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Sbi: A toolkit for simulation-based inference</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>52</issue>
      <pub-id pub-id-type="doi">10.21105/joss.02505</pub-id>
      <fpage>2505</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-hermans2020likelihood">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hermans</surname><given-names>Joeri</given-names></name>
        <name><surname>Begy</surname><given-names>Volodimir</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Likelihood-free MCMC with amortized approximate ratio estimators</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1903.04057</pub-id>
      <fpage>4239</fpage>
      <lpage>4248</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Bishop_94">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bishop</surname><given-names>C M</given-names></name>
      </person-group>
      <article-title>Mixture density networks</article-title>
      <source>Technical Report. Aston University, Birmingham</source>
      <year iso-8601-date="1994">1994</year>
    </element-citation>
  </ref>
  <ref id="ref-talts2018validating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Talts</surname><given-names>Sean</given-names></name>
        <name><surname>Betancourt</surname><given-names>Michael</given-names></name>
        <name><surname>Simpson</surname><given-names>Daniel</given-names></name>
        <name><surname>Vehtari</surname><given-names>Aki</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>Validating Bayesian inference algorithms with simulation-based calibration</article-title>
      <source>arXiv preprint arXiv:1804.06788</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1804.06788</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-boelts2022flexible">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Boelts</surname><given-names>Jan</given-names></name>
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Gao</surname><given-names>Richard</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Flexible and efficient simulation-based inference for models of decision-making</article-title>
      <source>Elife</source>
      <publisher-name>eLife Sciences Publications Limited</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>11</volume>
      <pub-id pub-id-type="doi">10.7554/eLife.77220</pub-id>
      <fpage>e77220</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-deistler2022energy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
      </person-group>
      <article-title>Energy-efficient network activity from disparate circuit parameters</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
      <publisher-name>National Acad Sciences</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>119</volume>
      <issue>44</issue>
      <pub-id pub-id-type="doi">10.1073/pnas.2207632119</pub-id>
      <fpage>e2207632119</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-deistler2022truncated">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Truncated proposals for scalable and hassle-free simulation-based inference</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Oh</surname><given-names>Alice H.</given-names></name>
        <name><surname>Agarwal</surname><given-names>Alekh</given-names></name>
        <name><surname>Belgrave</surname><given-names>Danielle</given-names></name>
        <name><surname>Cho</surname><given-names>Kyunghyun</given-names></name>
      </person-group>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2210.04815</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-radev2020bayesflow">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Radev</surname><given-names>Stefan T.</given-names></name>
        <name><surname>Mertens</surname><given-names>Ulf K</given-names></name>
        <name><surname>Voss</surname><given-names>Andreas</given-names></name>
        <name><surname>Ardizzone</surname><given-names>Lynton</given-names></name>
        <name><surname>Köthe</surname><given-names>Ullrich</given-names></name>
      </person-group>
      <article-title>BayesFlow: Learning complex stochastic models with invertible neural networks</article-title>
      <source>IEEE transactions on neural networks and learning systems</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>33</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1109/tnnls.2020.3042395</pub-id>
      <fpage>1452</fpage>
      <lpage>1466</lpage>
    </element-citation>
  </ref>
  <ref id="ref-geffner2023compositional">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Geffner</surname><given-names>Tomas</given-names></name>
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Mnih</surname><given-names>Andriy</given-names></name>
      </person-group>
      <article-title>Compositional score modeling for simulation-based inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2209.14249</pub-id>
      <fpage>11098</fpage>
      <lpage>11116</lpage>
    </element-citation>
  </ref>
  <ref id="ref-sharrock2022sequential">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Simons</surname><given-names>Jack</given-names></name>
        <name><surname>Sharrock</surname><given-names>Louis</given-names></name>
        <name><surname>Liu</surname><given-names>Song</given-names></name>
        <name><surname>Beaumont</surname><given-names>Mark</given-names></name>
      </person-group>
      <article-title>Neural score estimation: Likelihood-free inference with conditional score based diffusion models</article-title>
      <source>Fifth symposium on advances in approximate bayesian inference</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2210.04872</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dax2023flow">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wildberger</surname><given-names>Jonas Bernhard</given-names></name>
        <name><surname>Dax</surname><given-names>Maximilian</given-names></name>
        <name><surname>Buchholz</surname><given-names>Simon</given-names></name>
        <name><surname>Green</surname><given-names>Stephen R</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
        <name><surname>Schölkopf</surname><given-names>Bernhard</given-names></name>
      </person-group>
      <article-title>Flow matching for scalable simulation-based inference</article-title>
      <source>Thirty-seventh conference on neural information processing systems</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2305.17161</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hermans2022crisis">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hermans</surname><given-names>Joeri</given-names></name>
        <name><surname>Delaunoy</surname><given-names>Arnaud</given-names></name>
        <name><surname>Rozet</surname><given-names>François</given-names></name>
        <name><surname>Wehenkel</surname><given-names>Antoine</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>A crisis in simulation-based inference? Beware, your posterior approximations can be unfaithful</article-title>
      <source>Transactions on Machine Learning Research</source>
      <publisher-name>OpenReview, Amherst, United States-Massachusetts</publisher-name>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-groschner2022biophysical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Groschner</surname><given-names>Lukas N</given-names></name>
        <name><surname>Malis</surname><given-names>Jonatan G</given-names></name>
        <name><surname>Zuidinga</surname><given-names>Birte</given-names></name>
        <name><surname>Borst</surname><given-names>Alexander</given-names></name>
      </person-group>
      <article-title>A biophysical account of multiplication by a single neuron</article-title>
      <source>Nature</source>
      <publisher-name>Nature Publishing Group UK London</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>603</volume>
      <issue>7899</issue>
      <pub-id pub-id-type="doi">10.1038/s41586-022-04428-3</pub-id>
      <fpage>119</fpage>
      <lpage>123</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bondarenko2023embryo">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bondarenko</surname><given-names>Vladyslav</given-names></name>
        <name><surname>Nikolaev</surname><given-names>Mikhail</given-names></name>
        <name><surname>Kromm</surname><given-names>Dimitri</given-names></name>
        <name><surname>Belousov</surname><given-names>Roman</given-names></name>
        <name><surname>Wolny</surname><given-names>Adrian</given-names></name>
        <name><surname>Blotenburg</surname><given-names>Marloes</given-names></name>
        <name><surname>Zeller</surname><given-names>Peter</given-names></name>
        <name><surname>Rezakhani</surname><given-names>Saba</given-names></name>
        <name><surname>Hugger</surname><given-names>Johannes</given-names></name>
        <name><surname>Uhlmann</surname><given-names>Virginie</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Embryo-uterine interaction coordinates mouse embryogenesis during implantation</article-title>
      <source>The EMBO Journal</source>
      <year iso-8601-date="2023">2023</year>
      <volume>42</volume>
      <issue>17</issue>
      <pub-id pub-id-type="doi">10.15252/embj.2022113280</pub-id>
      <fpage>e113280</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-confavreux2023meta">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Confavreux</surname><given-names>Basile</given-names></name>
        <name><surname>Ramesh</surname><given-names>Poornima</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
        <name><surname>Vogels</surname><given-names>Tim</given-names></name>
      </person-group>
      <article-title>Meta-learning families of plasticity rules in recurrent spiking networks using simulation-based inference</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2023">2023</year>
      <volume>36</volume>
      <fpage>13545</fpage>
      <lpage>13558</lpage>
    </element-citation>
  </ref>
  <ref id="ref-myers2024disinhibition">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Myers-Joseph</surname><given-names>Dylan</given-names></name>
        <name><surname>Wilmes</surname><given-names>Katharina A</given-names></name>
        <name><surname>Fernandez-Otero</surname><given-names>Marian</given-names></name>
        <name><surname>Clopath</surname><given-names>Claudia</given-names></name>
        <name><surname>Khan</surname><given-names>Adil G</given-names></name>
      </person-group>
      <article-title>Disinhibition by VIP interneurons is orthogonal to cross-modal attentional modulation in primary visual cortex</article-title>
      <source>Neuron</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>112</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1016/j.neuron.2023.11.006</pub-id>
      <fpage>628</fpage>
      <lpage>645</lpage>
    </element-citation>
  </ref>
  <ref id="ref-avecilla2022neural">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Avecilla</surname><given-names>Grace</given-names></name>
        <name><surname>Chuong</surname><given-names>Julie N</given-names></name>
        <name><surname>Li</surname><given-names>Fangfei</given-names></name>
        <name><surname>Sherlock</surname><given-names>Gavin</given-names></name>
        <name><surname>Gresham</surname><given-names>David</given-names></name>
        <name><surname>Ram</surname><given-names>Yoav</given-names></name>
      </person-group>
      <article-title>Neural networks enable efficient and accurate simulation-based inference of evolutionary parameters from adaptation dynamics</article-title>
      <source>PLoS biology</source>
      <publisher-name>Public Library of Science San Francisco, CA USA</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>20</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1371/journal.pbio.3001633</pub-id>
      <fpage>e3001633</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gloecklervariational">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gloeckler</surname><given-names>Manuel</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Variational methods for simulation-based inference</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2203.04176</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lowet2023theta">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lowet</surname><given-names>Eric</given-names></name>
        <name><surname>Sheehan</surname><given-names>Daniel J</given-names></name>
        <name><surname>Chialva</surname><given-names>Ulises</given-names></name>
        <name><surname>Pena</surname><given-names>Rodrigo De Oliveira</given-names></name>
        <name><surname>Mount</surname><given-names>Rebecca A</given-names></name>
        <name><surname>Xiao</surname><given-names>Sheng</given-names></name>
        <name><surname>Zhou</surname><given-names>Samuel L</given-names></name>
        <name><surname>Tseng</surname><given-names>Hua-an</given-names></name>
        <name><surname>Gritton</surname><given-names>Howard</given-names></name>
        <name><surname>Shroff</surname><given-names>Sanaya</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Theta and gamma rhythmic coding through two spike output modes in the hippocampus during spatial navigation</article-title>
      <source>Cell reports</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>42</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1016/j.celrep.2023.112906</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mishra2022neural">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mishra-Sharma</surname><given-names>Siddharth</given-names></name>
        <name><surname>Cranmer</surname><given-names>Kyle</given-names></name>
      </person-group>
      <article-title>Neural simulation-based inference approach for characterizing the galactic center \gamma-ray excess</article-title>
      <source>Physical Review D</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>105</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1103/PhysRevD.105.063017</pub-id>
      <fpage>063017</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-dyer2022black">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dyer</surname><given-names>Joel</given-names></name>
        <name><surname>Cannon</surname><given-names>Patrick</given-names></name>
        <name><surname>Farmer</surname><given-names>J Doyne</given-names></name>
        <name><surname>Schmon</surname><given-names>Sebastian</given-names></name>
      </person-group>
      <article-title>Black-box Bayesian inference for economic agent-based models</article-title>
      <source>arXiv preprint arXiv:2202.00625</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2202.00625</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hahn2022accelerated">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hahn</surname><given-names>ChangHoon</given-names></name>
        <name><surname>Melchior</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>Accelerated Bayesian SED modeling using amortized neural posterior estimation</article-title>
      <source>The Astrophysical Journal</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>938</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.3847/1538-4357/ac7b84</pub-id>
      <fpage>11</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-lemos2024field">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lemos</surname><given-names>Pablo</given-names></name>
        <name><surname>Parker</surname><given-names>Liam</given-names></name>
        <name><surname>Hahn</surname><given-names>ChangHoon</given-names></name>
        <name><surname>Ho</surname><given-names>Shirley</given-names></name>
        <name><surname>Eickenberg</surname><given-names>Michael</given-names></name>
        <name><surname>Hou</surname><given-names>Jiamin</given-names></name>
        <name><surname>Massara</surname><given-names>Elena</given-names></name>
        <name><surname>Modi</surname><given-names>Chirag</given-names></name>
        <name><surname>Dizgah</surname><given-names>Azadeh Moradinezhad</given-names></name>
        <name><surname>Blancard</surname><given-names>Bruno Régaldo-Saint</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Field-level simulation-based inference of galaxy clustering with convolutional neural networks</article-title>
      <source>Physical Review D</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>109</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1103/physrevd.109.083536</pub-id>
      <fpage>083536</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-muratore2022neural">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Muratore</surname><given-names>Fabio</given-names></name>
        <name><surname>Gruner</surname><given-names>Theo</given-names></name>
        <name><surname>Wiese</surname><given-names>Florian</given-names></name>
        <name><surname>Belousov</surname><given-names>Boris</given-names></name>
        <name><surname>Gienger</surname><given-names>Michael</given-names></name>
        <name><surname>Peters</surname><given-names>Jan</given-names></name>
      </person-group>
      <article-title>Neural posterior domain randomization</article-title>
      <source>Conference on robot learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <fpage>1532</fpage>
      <lpage>1542</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rossler2023skewed">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rößler</surname><given-names>Nina</given-names></name>
        <name><surname>Jungenitz</surname><given-names>Tassilo</given-names></name>
        <name><surname>Sigler</surname><given-names>Albrecht</given-names></name>
        <name><surname>Bird</surname><given-names>Alexander</given-names></name>
        <name><surname>Mittag</surname><given-names>Martin</given-names></name>
        <name><surname>Rhee</surname><given-names>Jeong Seop</given-names></name>
        <name><surname>Deller</surname><given-names>Thomas</given-names></name>
        <name><surname>Cuntz</surname><given-names>Hermann</given-names></name>
        <name><surname>Brose</surname><given-names>Nils</given-names></name>
        <name><surname>Schwarzacher</surname><given-names>Stephan W</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Skewed distribution of spines is independent of presynaptic transmitter release and synaptic plasticity, and emerges early during adult neurogenesis</article-title>
      <source>Open Biology</source>
      <publisher-name>The Royal Society</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>13</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1098/rsob.230063</pub-id>
      <fpage>230063</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gloeckler2023adversarial">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gloeckler</surname><given-names>Manuel</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Adversarial robustness of amortized Bayesian inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2305.14984</pub-id>
      <fpage>11493</fpage>
      <lpage>11524</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dyer2022calibrating">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dyer</surname><given-names>Joel</given-names></name>
        <name><surname>Cannon</surname><given-names>Patrick</given-names></name>
        <name><surname>Farmer</surname><given-names>J. Doyne</given-names></name>
        <name><surname>Schmon</surname><given-names>Sebastian M</given-names></name>
      </person-group>
      <article-title>Calibrating agent-based models to microdata with graph neural networks</article-title>
      <source>ICML 2022 workshop AI for agent-based modelling</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2206.07570</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wiqvist2021sequential">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wiqvist</surname><given-names>Samuel</given-names></name>
        <name><surname>Frellsen</surname><given-names>Jes</given-names></name>
        <name><surname>Picchini</surname><given-names>Umberto</given-names></name>
      </person-group>
      <article-title>Sequential neural posterior and likelihood approximation</article-title>
      <source>arXiv preprint arXiv:2102.06522</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2102.06522</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jin2023bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jin</surname><given-names>Huaqing</given-names></name>
        <name><surname>Verma</surname><given-names>Parul</given-names></name>
        <name><surname>Jiang</surname><given-names>Fei</given-names></name>
        <name><surname>Nagarajan</surname><given-names>Srikantan S</given-names></name>
        <name><surname>Raj</surname><given-names>Ashish</given-names></name>
      </person-group>
      <article-title>Bayesian inference of a spectral graph model for brain oscillations</article-title>
      <source>NeuroImage</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>279</volume>
      <pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120278</pub-id>
      <fpage>120278</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-spurio2023bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spurio Mancini</surname><given-names>A</given-names></name>
        <name><surname>Docherty</surname><given-names>MM</given-names></name>
        <name><surname>Price</surname><given-names>MA</given-names></name>
        <name><surname>McEwen</surname><given-names>JD</given-names></name>
      </person-group>
      <article-title>Bayesian model comparison for simulation-based inference</article-title>
      <source>RAS Techniques and Instruments</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>2</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1093/rasti/rzad051</pub-id>
      <fpage>710</fpage>
      <lpage>722</lpage>
    </element-citation>
  </ref>
  <ref id="ref-boelts2023simulation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Boelts</surname><given-names>Jan</given-names></name>
        <name><surname>Harth</surname><given-names>Philipp</given-names></name>
        <name><surname>Gao</surname><given-names>Richard</given-names></name>
        <name><surname>Udvary</surname><given-names>Daniel</given-names></name>
        <name><surname>Yáñez</surname><given-names>Felipe</given-names></name>
        <name><surname>Baum</surname><given-names>Daniel</given-names></name>
        <name><surname>Hege</surname><given-names>Hans-Christian</given-names></name>
        <name><surname>Oberlaender</surname><given-names>Marcel</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Simulation-based inference for efficient identification of generative models in computational connectomics</article-title>
      <source>PLOS Computational Biology</source>
      <publisher-name>Public Library of Science San Francisco, CA USA</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>19</volume>
      <issue>9</issue>
      <pub-id pub-id-type="doi">10.1101/2023.01.31.526269</pub-id>
      <fpage>e1011406</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-dirmeier2023simulation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dirmeier</surname><given-names>Simon</given-names></name>
        <name><surname>Albert</surname><given-names>Carlo</given-names></name>
        <name><surname>Perez-Cruz</surname><given-names>Fernando</given-names></name>
      </person-group>
      <article-title>Simulation-based inference using surjective sequential neural likelihood estimation</article-title>
      <source>arXiv preprint</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2308.01054</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-linhart2024c2st">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Linhart</surname><given-names>Julia</given-names></name>
        <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
        <name><surname>Rodrigues</surname><given-names>Pedro</given-names></name>
      </person-group>
      <article-title>L-c2st: Local diagnostics for posterior approximations in simulation-based inference</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2024">2024</year>
      <volume>36</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.2306.03580</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lemos2023sampling">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lemos</surname><given-names>Pablo</given-names></name>
        <name><surname>Coogan</surname><given-names>Adam</given-names></name>
        <name><surname>Hezaveh</surname><given-names>Yashar</given-names></name>
        <name><surname>Perreault-Levasseur</surname><given-names>Laurence</given-names></name>
      </person-group>
      <article-title>Sampling-based accuracy testing of posterior estimators for general inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2302.03026</pub-id>
      <fpage>19256</fpage>
      <lpage>19273</lpage>
    </element-citation>
  </ref>
  <ref id="ref-song2021scorebased">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Song</surname><given-names>Yang</given-names></name>
        <name><surname>Sohl-Dickstein</surname><given-names>Jascha</given-names></name>
        <name><surname>Kingma</surname><given-names>Diederik P</given-names></name>
        <name><surname>Kumar</surname><given-names>Abhishek</given-names></name>
        <name><surname>Ermon</surname><given-names>Stefano</given-names></name>
        <name><surname>Poole</surname><given-names>Ben</given-names></name>
      </person-group>
      <article-title>Score-based generative modeling through stochastic differential equations</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2011.13456</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gloeckler2024allinone">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gloeckler</surname><given-names>Manuel</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Weilbach</surname><given-names>Christian Dietrich</given-names></name>
        <name><surname>Wood</surname><given-names>Frank</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>All-in-one simulation-based inference</article-title>
      <source>Forty-first international conference on machine learning</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2404.09636</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lipman2023flow">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lipman</surname><given-names>Yaron</given-names></name>
        <name><surname>Chen</surname><given-names>Ricky T. Q.</given-names></name>
        <name><surname>Ben-Hamu</surname><given-names>Heli</given-names></name>
        <name><surname>Nickel</surname><given-names>Maximilian</given-names></name>
        <name><surname>Le</surname><given-names>Matthew</given-names></name>
      </person-group>
      <article-title>Flow matching for generative modeling</article-title>
      <source>The eleventh international conference on learning representations</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2210.02747</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-arviz_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kumar</surname><given-names>Ravin</given-names></name>
        <name><surname>Carroll</surname><given-names>Colin</given-names></name>
        <name><surname>Hartikainen</surname><given-names>Ari</given-names></name>
        <name><surname>Martin</surname><given-names>Osvaldo</given-names></name>
      </person-group>
      <article-title>ArviZ a unified library for exploratory analysis of Bayesian models in Python</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>4</volume>
      <issue>33</issue>
      <pub-id pub-id-type="doi">10.21105/joss.01143</pub-id>
      <fpage>1143</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-rozet_2021_lampe">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rozet</surname><given-names>François</given-names></name>
        <name><surname>Delaunoy</surname><given-names>Arnaud</given-names></name>
        <name><surname>Miller</surname><given-names>Benjamin</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>LAMPE: Likelihood-free amortized posterior estimation</article-title>
      <source>Statistical Software</source>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-bayesflow_2023_software">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Radev</surname><given-names>Stefan T.</given-names></name>
        <name><surname>Schmitt</surname><given-names>Marvin</given-names></name>
        <name><surname>Schumacher</surname><given-names>Lukas</given-names></name>
        <name><surname>Elsemüller</surname><given-names>Lasse</given-names></name>
        <name><surname>Pratz</surname><given-names>Valentin</given-names></name>
        <name><surname>Schälte</surname><given-names>Yannik</given-names></name>
        <name><surname>Köthe</surname><given-names>Ullrich</given-names></name>
        <name><surname>Bürkner</surname><given-names>Paul-Christian</given-names></name>
      </person-group>
      <article-title>BayesFlow: Amortized Bayesian workflows with neural networks</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2023">2023</year>
      <volume>8</volume>
      <issue>89</issue>
      <pub-id pub-id-type="doi">10.21105/joss.05702</pub-id>
      <fpage>5702</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-swyft">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>undark-lab</surname></name>
      </person-group>
      <article-title>Swyft: A system for scientific simulation-based inference at scale</article-title>
      <publisher-name>https://github.com/undark-lab/swyft</publisher-name>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-dirmeier2024simulationbasedinferencepythonpackage">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Dirmeier</surname><given-names>Simon</given-names></name>
        <name><surname>Ulzega</surname><given-names>Simone</given-names></name>
        <name><surname>Mira</surname><given-names>Antonietta</given-names></name>
        <name><surname>Albert</surname><given-names>Carlo</given-names></name>
      </person-group>
      <article-title>Simulation-based inference with the Python package sbijax</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://arxiv.org/abs/2409.19435</uri>
    </element-citation>
  </ref>
  <ref id="ref-gao2024deep">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gao</surname><given-names>Richard</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Schulz</surname><given-names>Auguste</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Deep inverse modeling reveals dynamic-dependent invariances in neural circuit mechanisms</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1101/2024.08.21.608969</pub-id>
      <fpage>2024</fpage>
      <lpage>08</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bernaerts2023combined">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bernaerts</surname><given-names>Yves</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Beck</surname><given-names>Jonas</given-names></name>
        <name><surname>Stimberg</surname><given-names>Marcel</given-names></name>
        <name><surname>Scala</surname><given-names>Federico</given-names></name>
        <name><surname>Tolias</surname><given-names>Andreas S</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob</given-names></name>
        <name><surname>Kobak</surname><given-names>Dmitry</given-names></name>
        <name><surname>Berens</surname><given-names>Philipp</given-names></name>
      </person-group>
      <article-title>Combined statistical-mechanistic modeling links ion channel genes to physiology of cortical neuron types</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1101/2023.03.02.530774</pub-id>
      <fpage>2023</fpage>
      <lpage>03</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2024comprehensive">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Xiaoyu</given-names></name>
        <name><surname>Kelly</surname><given-names>Ryan P.</given-names></name>
        <name><surname>Jenner</surname><given-names>Adrianne L.</given-names></name>
        <name><surname>Warne</surname><given-names>David J.</given-names></name>
        <name><surname>Drovandi</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>A comprehensive guide to simulation-based inference in computational biology</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://arxiv.org/abs/2409.19675</uri>
      <pub-id pub-id-type="doi">10.2139/ssrn.4982890</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dingeldein2023simulation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dingeldein</surname><given-names>Lars</given-names></name>
        <name><surname>Cossio</surname><given-names>Pilar</given-names></name>
        <name><surname>Covino</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Simulation-based inference of single-molecule force spectroscopy</article-title>
      <source>Machine Learning: Science and Technology</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>4</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1016/j.bpj.2022.11.920</pub-id>
      <fpage>025009</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-hashemi2023amortized">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hashemi</surname><given-names>Meysam</given-names></name>
        <name><surname>Vattikonda</surname><given-names>Anirudh N</given-names></name>
        <name><surname>Jha</surname><given-names>Jayant</given-names></name>
        <name><surname>Sip</surname><given-names>Viktor</given-names></name>
        <name><surname>Woodman</surname><given-names>Marmaduke M</given-names></name>
        <name><surname>Bartolomei</surname><given-names>Fabrice</given-names></name>
        <name><surname>Jirsa</surname><given-names>Viktor K</given-names></name>
      </person-group>
      <article-title>Amortized Bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators</article-title>
      <source>Neural Networks</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>163</volume>
      <pub-id pub-id-type="doi">10.1016/j.neunet.2023.03.040</pub-id>
      <fpage>178</fpage>
      <lpage>194</lpage>
    </element-citation>
  </ref>
  <ref id="ref-phan2019composable">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Phan</surname><given-names>Du</given-names></name>
        <name><surname>Pradhan</surname><given-names>Neeraj</given-names></name>
        <name><surname>Jankowiak</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Composable effects for flexible and accelerated probabilistic programming in NumPyro</article-title>
      <source>arXiv preprint arXiv:1912.11554</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.11554</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gelman2015stan">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Lee</surname><given-names>Daniel</given-names></name>
        <name><surname>Guo</surname><given-names>Jiqiang</given-names></name>
      </person-group>
      <article-title>Stan: A probabilistic programming language for Bayesian inference and optimization</article-title>
      <source>Journal of Educational and Behavioral Statistics</source>
      <publisher-name>Sage Publications Sage CA: Los Angeles, CA</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>40</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.3102/1076998615606113</pub-id>
      <fpage>530</fpage>
      <lpage>543</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ge2018t">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ge</surname><given-names>Hong</given-names></name>
        <name><surname>Xu</surname><given-names>Kai</given-names></name>
        <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
      </person-group>
      <article-title>Turing: A language for flexible probabilistic inference</article-title>
      <source>International conference on artificial intelligence and statistics, AISTATS 2018, 9-11 april 2018, playa blanca, lanzarote, canary islands, spain</source>
      <year iso-8601-date="2018">2018</year>
      <uri>http://proceedings.mlr.press/v84/ge18b.html</uri>
      <fpage>1682</fpage>
      <lpage>1690</lpage>
    </element-citation>
  </ref>
  <ref id="ref-quera-bofarull2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Quera-Bofarull</surname><given-names>Arnau</given-names></name>
        <name><surname>Dyer</surname><given-names>Joel</given-names></name>
        <name><surname>Calinescu</surname><given-names>Anisoara</given-names></name>
        <name><surname>Farmer</surname><given-names>J. Doyne</given-names></name>
        <name><surname>Wooldridge</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>BlackBIRDS: Black-box inference foR differentiable simulators</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>8</volume>
      <issue>89</issue>
      <uri>https://doi.org/10.21105/joss.05776</uri>
      <pub-id pub-id-type="doi">10.21105/joss.05776</pub-id>
      <fpage>5776</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
