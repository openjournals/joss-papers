<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4943</article-id>
<article-id pub-id-type="doi">10.21105/joss.04943</article-id>
<title-group>
<article-title>FuseMedML: a framework for accelerated discovery in
machine learning based biomedicine</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<name>
<surname>Golts</surname>
<given-names>Alex</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Raboh</surname>
<given-names>Moshe</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Shoshan</surname>
<given-names>Yoel</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Polaczek</surname>
<given-names>Sagi</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rabinovici-Cohen</surname>
<given-names>Simona</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hexter</surname>
<given-names>Efrat</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>IBM Research - Haifa, Israel</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-10-26">
<day>26</day>
<month>10</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>81</issue>
<fpage>4943</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Deep Learning</kwd>
<kwd>Machine Learning</kwd>
<kwd>Artificial Intelligence</kwd>
<kwd>Medical imaging</kwd>
<kwd>Clinical data</kwd>
<kwd>Computational biomedicine</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Machine Learning is at the forefront of scientific progress in
  Healthcare and Medicine. To accelerate scientific discovery, it is
  important to have tools that allow progress iterations to be
  collaborative, reproducible, reusable and easily built upon without
  “reinventing the wheel” for each task.
  FuseMedML, or <italic>fuse</italic>, is a Python framework designed
  for accelerated Machine Learning (ML) based discovery in the medical
  domain. It is highly flexible and designed for easy collaboration,
  encouraging code reuse. Flexibility is enabled by a generic data
  object design where data is kept in a nested (hierarchical) Python
  dictionary (NDict), allowing to efficiently process and fuse
  information from multiple modalities. Functional components allow to
  specify input and output keys, to be read from and written to the
  nested dictionary.
  Easy code reuse is enabled through key components implemented as
  standalone packages under the main <italic>fuse</italic> repo using
  the same design principles. These include <italic>fuse.data</italic> -
  a flexible data processing pipeline, <italic>fuse.dl</italic> -
  reusable Deep Learning (DL) model architecture components and loss
  functions, and <italic>fuse.eval</italic> - a library for evaluating
  ML models.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Medical research often involves multiple modalities (e.g., imaging,
  clinical data, biochemical representations) and tasks (e.g.,
  classification, segmentation, clinical condition prediction). In our
  experience working on numerous such projects, we have identified three
  key challenges: 1. Setting up or implementing a new baseline model can
  be time-consuming, even when similar projects have already been
  completed by the same lab. 2. Transferring individual components
  across projects can be difficult, leading to researchers frequently
  “reinventing the wheel.” 3. Collaborating between projects across
  modalities and domains, such as imaging and molecules, is often
  challenging.</p>
  <p>To address these challenges, FuseMedML was developed with the goal
  of simplifying and streamlining medical research projects.</p>
  <p>Before open sourcing it, we used <italic>fuse</italic> internally
  in multiple research projects
  (<xref alt="Raboh, Levanony, et al., 2022" rid="ref-raboh2022context" ref-type="bibr">Raboh,
  Levanony, et al., 2022</xref>),
  (<xref alt="Rabinovici-Cohen, Tlusty, et al., 2022" rid="ref-rabinovici2022early" ref-type="bibr">Rabinovici-Cohen,
  Tlusty, et al., 2022</xref>),
  (<xref alt="Rabinovici-Cohen, Fernández, et al., 2022" rid="ref-rabinovici2022multimodal" ref-type="bibr">Rabinovici-Cohen,
  Fernández, et al., 2022</xref>),
  (<xref alt="Jubran et al., 2021" rid="ref-jubran2021glimpse" ref-type="bibr">Jubran
  et al., 2021</xref>),
  (<xref alt="Tlusty et al., 2021" rid="ref-tlusty2021pre" ref-type="bibr">Tlusty
  et al., 2021</xref>),
  (<xref alt="Golts et al., 2022" rid="ref-golts2022ensemble" ref-type="bibr">Golts
  et al., 2022</xref>),
  (<xref alt="Barros et al." rid="ref-radiology" ref-type="bibr">Barros
  et al.</xref>) and experienced significant improvement in development
  time, reusability and collaboration. We were also able to meaningfully
  measure our progress and statistical significance of our results with
  off-the-shelf <italic>fuse.eval</italic> components that facilitate
  metrics’ confidence interval calculation and model comparison. These
  tools have enabled us to organize two challenges as part of the 2022
  International Symposium on Biomedical Imaging (ISBI)
  (<xref alt="Raboh, Golts, et al., 2022" rid="ref-knight" ref-type="bibr">Raboh,
  Golts, et al., 2022</xref>),
  (<xref alt="Pati et al., 2022" rid="ref-bright" ref-type="bibr">Pati
  et al., 2022</xref>).</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the field</title>
  <p>FuseMedML is a comprehensive machine learning library that focuses
  on the biomedical domain. It offers a range of tools covering the
  entire development process, including data preparation, model
  training, and evaluation. Built on top of popular machine learning
  frameworks such as PyTorch
  (<xref alt="Paszke et al., 2019" rid="ref-NEURIPS2019_bdbca288" ref-type="bibr">Paszke
  et al., 2019</xref>) and PyTorch Lightning
  (<xref alt="Falcon &amp; The PyTorch Lightning team, 2019" rid="ref-Falcon_PyTorch_Lightning_2019" ref-type="bibr">Falcon
  &amp; The PyTorch Lightning team, 2019</xref>), FuseMedML also
  includes flexible domain-specific capabilities to complement these
  frameworks. Overall, FuseMedML aims to facilitate machine learning
  discoveries within the healthcare and life science sectors. One way in
  which <italic>fuse</italic> can complement PyTorch is through its
  generic design concept (See
  <xref alt="Figure 1" rid="figU003Afuse_design">Figure 1</xref>) of
  storing arbitrary types of data in a specialized nested dictionary.
  This is a key driver of flexibility, allowing minimal code
  modifications when moving building blocks between different projects.
  Concretely, <italic>fuse</italic> has a dataset class that extends the
  PyTorch dataset, and a model wrapper class that enables PyTorch models
  to operate on <monospace>batch_dict</monospace>s rather than tensors.
  In the case of PyTorch Lightning, <italic>fuse</italic> integrates
  with it directly as it builds upon its comprehensive trainer class,
  also allowing users to define their models and data modules in PyTorch
  Lightning style, with flexible levels of customizability.</p>
  <fig>
    <caption><p>This figure illustrates FuseMedML’s design concept. A
    <italic>fuse</italic> component is instantiated with input and
    output keys. These keys refer to the
    <monospace>sample_dict</monospace>, the basic data sample structure
    of <italic>fuse</italic> represented by a special nested Python
    dictionary called
    “NDict”.<styled-content id="figU003Afuse_design"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/fuse_design.png" xlink:title="" />
  </fig>
  <p>There are existing PyTorch-based ML libraries that similarly to
  <italic>fuse</italic> cater to researchers in the biomedical domain.
  Two examples of such prominent libraries are MONAI
  (<xref alt="Cardoso et al., 2022" rid="ref-Cardoso_MONAI_An_open-source_2022" ref-type="bibr">Cardoso
  et al., 2022</xref>) and PyHealth
  (<xref alt="Zhao et al., 2021" rid="ref-DBLPU003AjournalsU002FcorrU002Fabs-2101-04209" ref-type="bibr">Zhao
  et al., 2021</xref>). MONAI is primarily focused on medical imaging
  applications. PyHealth on the other hand mainly focuses on health
  records data. <italic>fuse</italic> is designed to support different
  types of medical data and multimodal use cases involving imaging,
  clinical and biochemical data.
  As with generic ML frameworks like PyTorch and PyTorch Lightning,
  <italic>fuse</italic> can also coexist with the more specific
  libraries like MONAI, PyHealth or others. A user may opt to borrow
  parts from different libraries and complement them with components
  from <italic>fuse</italic>. As another example, a user may want to use
  the data <italic>ops</italic> of <italic>fuse</italic> which are
  generic and flexible, or its data caching mechanism, which allows to
  separate processing into a static and dynamic pipelines, controlling
  the desired stages to be cached.</p>
</sec>
<sec id="packages">
  <title>Packages</title>
  <sec id="fuse.data">
    <title><italic>fuse.data</italic></title>
    <p>FuseMedML’s data package is designed for building a flexible and
    powerful data pipeline with reusable building blocks called
    <italic>ops</italic>. See
    <xref alt="Figure 2" rid="figU003Adiagram">Figure 2</xref> for a
    simple example for how such a building block can be used across
    different projects.
    Each <italic>op</italic> class’s <monospace>__call__</monospace>
    function gets as an input a <monospace>sample_dict</monospace>, a
    dictionary that stores all the necessary information about a sample
    processed so far. Typically, an <italic>op</italic>’s constructor
    gets keys that specify what it should consider in
    <monospace>sample_dict</monospace> and where to store the output.
    Similarly, a minibatch is represented by a
    <monospace>batch_dict</monospace>.
    A special kind of <italic>ops</italic> are “Meta
    <italic>ops</italic>”. They can be thought of as a form of wrapper
    <italic>op</italic> around a regular, lower level
    <italic>op</italic> or function, to help achieve a special behavior
    such as repeating that low level <italic>op</italic>, applying it
    with random values and more. “Meta <italic>ops</italic>” also help
    avoid writing boilerplate code.</p>
    <p>A data pipeline may consist of a
    <monospace>static_pipeline</monospace> and a
    <monospace>dynamic_pipeline</monospace>. The output of the
    <monospace>static_pipeline</monospace> can be cached to optimize
    running time and GPU utilization. The
    <monospace>dynamic_pipeline</monospace> is responsible for “online”
    processing that we don’t want to cache, such as random
    augmentations. An instance of a <italic>fuse</italic> dataset class,
    which inherits from the PyTorch dataset class is then created from
    defined static and dynamic pipelines.
    The data package also includes generic utilities such as a PyTorch
    based sampler enabling batch class balancing and a tool for
    splitting data into folds according to predefined criteria.</p>
    <fig>
      <caption><p>In this example a medical image loader is the
      <italic>fuse</italic> component reused in projects A and B.
      Different projects can have different formats for their data
      samples, but they can all use OpMedicalImageLoader by providing
      the appropriate key names when calling it. In Project B the same
      key name is used for the input and output, resulting in the loaded
      image data overriding the image paths in the updated
      sample.<styled-content id="figU003Adiagram"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/diagram.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="fuse.dl">
    <title><italic>fuse.dl</italic></title>
    <p>FuseMedML’s DL package works with PyTorch models, only modifying
    them to interact with a <monospace>batch_dict</monospace>. For
    training, <italic>fuse.dl</italic> utilizes PyTorch-Lightning,
    either through an already made
    <monospace>LightningModuleDefault</monospace> class that inherits
    from Pytorch-Lightning’s <monospace>LightningModule</monospace>
    class, or by allowing users who seek maximal customizability to
    implement their own custom <monospace>LightningModule</monospace>
    and operate in close resemblance to the standard PyTorch-Lightning
    workflow or use alternative training loop implementations.
    <italic>fuse.dl</italic> also offers generic core DL components such
    as model architectures and losses, implemented in
    <italic>fuse</italic> style. See an example model architecture
    definition in
    <xref alt="Figure 3" rid="figU003Amodel_multi_head">Figure 3</xref>.</p>
    <fig>
      <caption><p>In this example a model architecture is defined using
      the <monospace>ModelMultiHead</monospace> class. It contains of a
      3D ResNet backbone represented by the
      <monospace>BackboneResnet3D</monospace> class and a 3D
      classification head represented by the
      <monospace>Head3D</monospace> class. Note the user can define a
      list of heads, to support a multi task use case. The inputs to the
      backbone and classification heads are defined in the
      <italic>fuse</italic> style described earlier, using the
      <monospace>batch_dict</monospace> key names with the relevant
      data. This enables easy reuse of similar model architectures
      between
      projects.<styled-content id="figU003Amodel_multi_head"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/model_multi_head.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="fuse.eval">
    <title><italic>fuse.eval</italic></title>
    <p>FuseMedML’s evaluation package is a standalone library for
    evaluating machine learning models using various performance metrics
    and comparing the results between models. It offers advanced
    capabilities such as a generic confidence interval wrapper for any
    metric, a generic one-versus-all extension for converting any binary
    metric to a multi-class scenario, and metrics for comparing models
    while considering statistical significance. The package also
    includes model calibration tools and a pipeline for combining a
    sequence of metrics with possible dependencies. In addition, the
    evaluation package supports automatic per-fold evaluation and
    subgroup analysis, and can handle large data sets through batching
    and multiprocessing. See
    <xref alt="Figure 4" rid="figU003Ametric_pipeline">Figure 4</xref>
    for an example of an evaluation metric pipeline that can be reused
    across projects.</p>
    <fig>
      <caption><p>In this example a pipeline of evaluation metric
      components is shown. It consists of two metrics: the Area Under
      the receiver operating characteristic Curve and the Area Under the
      Precision-Recall Curve. Both metrics are wrapped with a Confidence
      Interval (CI) metric, resulting in a lower and upper bound for
      each metric. The metrics are executed by an instance of the
      EvaluatorDefault class, the basic <italic>fuse.eval</italic> class
      that combines input sources, evaluates using the specified
      metrics, generates a report and returns a dictionary with all the
      metrics
      results.<styled-content id="figU003Ametric_pipeline"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/metric_pipeline.png" xlink:title="" />
    </fig>
  </sec>
</sec>
<sec id="extensions">
  <title>Extensions</title>
  <p>The core technology of FuseMedML and its component packages is
  general, while domain-specific functionality is contained within
  extensions. One such extension, <italic>fuse-imaging</italic>, is
  currently available and extends the FuseMedML data package with
  operations useful for medical imaging, as well as implementations of
  public medical datasets.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-raboh2022context">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Raboh</surname><given-names>Moshe</given-names></name>
        <name><surname>Levanony</surname><given-names>Dana</given-names></name>
        <name><surname>Dufort</surname><given-names>Paul</given-names></name>
        <name><surname>Sitek</surname><given-names>Arkadiusz</given-names></name>
      </person-group>
      <article-title>Context in medical imaging: the case of focal liver lesion classification</article-title>
      <source>Medical imaging 2022: Image processing</source>
      <person-group person-group-type="editor">
        <name><surname>Colliot</surname><given-names>Olivier</given-names></name>
        <name><surname>Išgum</surname><given-names>Ivana</given-names></name>
      </person-group>
      <publisher-name>International Society for Optics; Photonics; SPIE</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>12032</volume>
      <uri>https://doi.org/10.1117/12.2609385</uri>
      <pub-id pub-id-type="doi">10.1117/12.2609385</pub-id>
      <fpage>120320O</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-rabinovici2022early">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Rabinovici-Cohen</surname><given-names>Simona</given-names></name>
        <name><surname>Tlusty</surname><given-names>Tal</given-names></name>
        <name><surname>Fernández</surname><given-names>Xosé M.</given-names></name>
        <name><surname>Rejo</surname><given-names>Beatriz Grandal</given-names></name>
      </person-group>
      <article-title>Early prediction of metastasis in women with locally advanced breast cancer</article-title>
      <source>Medical imaging 2022: Computer-aided diagnosis</source>
      <person-group person-group-type="editor">
        <name><surname>Drukker</surname><given-names>Karen</given-names></name>
        <name><surname>Iftekharuddin</surname><given-names>Khan M.</given-names></name>
        <name><surname>Lu</surname><given-names>Hongbing</given-names></name>
        <name><surname>Mazurowski</surname><given-names>Maciej A.</given-names></name>
        <name><surname>Muramatsu</surname><given-names>Chisako</given-names></name>
        <name><surname>Samala</surname><given-names>Ravi K.</given-names></name>
      </person-group>
      <publisher-name>International Society for Optics; Photonics; SPIE</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>12033</volume>
      <uri>https://doi.org/10.1117/12.2613169</uri>
      <pub-id pub-id-type="doi">10.1117/12.2613169</pub-id>
      <fpage>120330F</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-rabinovici2022multimodal">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rabinovici-Cohen</surname><given-names>Simona</given-names></name>
        <name><surname>Fernández</surname><given-names>Xosé M.</given-names></name>
        <name><surname>Grandal Rejo</surname><given-names>Beatriz</given-names></name>
        <name><surname>Hexter</surname><given-names>Efrat</given-names></name>
        <name><surname>Hijano Cubelos</surname><given-names>Oliver</given-names></name>
        <name><surname>Pajula</surname><given-names>Juha</given-names></name>
        <name><surname>Pölönen</surname><given-names>Harri</given-names></name>
        <name><surname>Reyal</surname><given-names>Fabien</given-names></name>
        <name><surname>Rosen-Zvi</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>Multimodal prediction of five-year breast cancer recurrence in women who receive neoadjuvant chemotherapy</article-title>
      <source>Cancers</source>
      <year iso-8601-date="2022">2022</year>
      <volume>14</volume>
      <issue>16</issue>
      <issn>2072-6694</issn>
      <uri>https://www.mdpi.com/2072-6694/14/16/3848</uri>
      <pub-id pub-id-type="doi">10.3390/cancers14163848</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jubran2021glimpse">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Jubran</surname><given-names>Ibrahim</given-names></name>
        <name><surname>Raboh</surname><given-names>Moshiko</given-names></name>
        <name><surname>Perek</surname><given-names>Shaked</given-names></name>
        <name><surname>Gruen</surname><given-names>David</given-names></name>
        <name><surname>Hexter</surname><given-names>Efrat</given-names></name>
      </person-group>
      <article-title>A glimpse into the future: Disease progression simulation for breast cancer in mammograms</article-title>
      <source>Simulation and synthesis in medical imaging</source>
      <person-group person-group-type="editor">
        <name><surname>Svoboda</surname><given-names>David</given-names></name>
        <name><surname>Burgos</surname><given-names>Ninon</given-names></name>
        <name><surname>Wolterink</surname><given-names>Jelmer M.</given-names></name>
        <name><surname>Zhao</surname><given-names>Can</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <isbn>978-3-030-87592-3</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-87592-3_4</pub-id>
      <fpage>34</fpage>
      <lpage>43</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tlusty2021pre">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Tlusty</surname><given-names>Tal</given-names></name>
        <name><surname>Ozery-Flato</surname><given-names>Michal</given-names></name>
        <name><surname>Barros</surname><given-names>Vesna</given-names></name>
        <name><surname>Barkan</surname><given-names>Ella</given-names></name>
        <name><surname>Amit</surname><given-names>Mika</given-names></name>
        <name><surname>Gruen</surname><given-names>David</given-names></name>
        <name><surname>Guindy</surname><given-names>Michal</given-names></name>
        <name><surname>Arazi</surname><given-names>Tal</given-names></name>
        <name><surname>Rozin</surname><given-names>Mona</given-names></name>
        <name><surname>Rosen-Zvi</surname><given-names>Michal</given-names></name>
        <name><surname>Hexter</surname><given-names>Efrat</given-names></name>
      </person-group>
      <article-title>Pre-biopsy multi-class classification of breast lesion pathology in mammograms</article-title>
      <source>Machine learning in medical imaging</source>
      <person-group person-group-type="editor">
        <name><surname>Lian</surname><given-names>Chunfeng</given-names></name>
        <name><surname>Cao</surname><given-names>Xiaohuan</given-names></name>
        <name><surname>Rekik</surname><given-names>Islem</given-names></name>
        <name><surname>Xu</surname><given-names>Xuanang</given-names></name>
        <name><surname>Yan</surname><given-names>Pingkun</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <isbn>978-3-030-87589-3</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-87589-3_29</pub-id>
      <fpage>277</fpage>
      <lpage>286</lpage>
    </element-citation>
  </ref>
  <ref id="ref-golts2022ensemble">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Golts</surname><given-names>Alex</given-names></name>
        <name><surname>Khapun</surname><given-names>Daniel</given-names></name>
        <name><surname>Shats</surname><given-names>Daniel</given-names></name>
        <name><surname>Shoshan</surname><given-names>Yoel</given-names></name>
        <name><surname>Gilboa-Solomon</surname><given-names>Flora</given-names></name>
      </person-group>
      <article-title>An ensemble of 3D u-net based models for segmentation of kidney and masses in CT scans</article-title>
      <source>Kidney and kidney tumor segmentation</source>
      <person-group person-group-type="editor">
        <name><surname>Heller</surname><given-names>Nicholas</given-names></name>
        <name><surname>Isensee</surname><given-names>Fabian</given-names></name>
        <name><surname>Trofimova</surname><given-names>Darya</given-names></name>
        <name><surname>Tejpaul</surname><given-names>Resha</given-names></name>
        <name><surname>Papanikolopoulos</surname><given-names>Nikolaos</given-names></name>
        <name><surname>Weight</surname><given-names>Christopher</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <isbn>978-3-030-98385-7</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-98385-7_14</pub-id>
      <fpage>103</fpage>
      <lpage>115</lpage>
    </element-citation>
  </ref>
  <ref id="ref-knight">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Raboh</surname><given-names>Moshe</given-names></name>
        <name><surname>Golts</surname><given-names>Alex</given-names></name>
        <name><surname>Heller</surname><given-names>Nicholas</given-names></name>
        <name><surname>Tejpaul</surname><given-names>Resha</given-names></name>
        <name><surname>Abdallah</surname><given-names>Nour</given-names></name>
        <name><surname>Benidir</surname><given-names>Tarik</given-names></name>
        <name><surname>Campbell</surname><given-names>Steve C.</given-names></name>
        <name><surname>Remer</surname><given-names>Erick</given-names></name>
        <name><surname>Foncubierta</surname><given-names>Antonio</given-names></name>
        <name><surname>Gabrani</surname><given-names>Maria</given-names></name>
        <name><surname>Müller</surname><given-names>Henning</given-names></name>
        <name><surname>Hexter</surname><given-names>Efrat</given-names></name>
        <name><surname>Rabinovici-Cohen</surname><given-names>Simona</given-names></name>
        <name><surname>Shoshan</surname><given-names>Yoel</given-names></name>
        <name><surname>Weight</surname><given-names>Christopher</given-names></name>
        <name><surname>Rosen-Zvi</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>KNIGHT Challenge - Kidney clinical Notes and Imaging to Guide and Help personalize Treatment and biomarkers discovery</article-title>
      <publisher-name>https://research.ibm.com/haifa/Workshops/KNIGHT/</publisher-name>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-bright">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Pati</surname><given-names>Pushpak</given-names></name>
        <name><surname>Jaume</surname><given-names>Guillaume</given-names></name>
        <name><surname>Brancati</surname><given-names>Nadia</given-names></name>
        <name><surname>Müller</surname><given-names>Henning</given-names></name>
        <name><surname>Riccio</surname><given-names>Daniel</given-names></name>
        <name><surname>De Pietro</surname><given-names>Giuseppe</given-names></name>
        <name><surname>Foncubierta</surname><given-names>Antonio</given-names></name>
        <name><surname>Raboh</surname><given-names>Moshiko</given-names></name>
        <name><surname>Anniciello</surname><given-names>Anna Maria</given-names></name>
        <name><surname>Scognamiglio</surname><given-names>Giosuè</given-names></name>
        <name><surname>Feroce</surname><given-names>Florinda</given-names></name>
        <name><surname>Frucci</surname><given-names>Maria</given-names></name>
        <name><surname>Gabrani</surname><given-names>Maria</given-names></name>
      </person-group>
      <article-title>BRIGHT Challenge - BReast tumor Image classification on Gigapixel HisTopathological images</article-title>
      <publisher-name>https://research.ibm.com/haifa/Workshops/BRIGHT/</publisher-name>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-radiology">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Barros</surname><given-names>Vesna</given-names></name>
        <name><surname>Tlusty</surname><given-names>Tal</given-names></name>
        <name><surname>Barkan</surname><given-names>Ella</given-names></name>
        <name><surname>Hexter</surname><given-names>Efrat</given-names></name>
        <name><surname>Gruen</surname><given-names>David</given-names></name>
        <name><surname>Guindy</surname><given-names>Michal</given-names></name>
        <name><surname>Rosen-Zvi</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>Virtual biopsy by using artificial intelligence–based multimodal modeling of binational mammography data</article-title>
      <source>Radiology</source>
      <year iso-8601-date="0000">0000</year>
      <volume>0</volume>
      <issue>0</issue>
      <uri> 
          
              https://doi.org/10.1148/radiol.220027
          
          

      </uri>
      <pub-id pub-id-type="doi">10.1148/radiol.220027</pub-id>
      <fpage>220027</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-NEURIPS2019_bdbca288">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Wallach</surname><given-names>H.</given-names></name>
        <name><surname>Larochelle</surname><given-names>H.</given-names></name>
        <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
        <name><surname>dAlché-Buc</surname><given-names>F.</given-names></name>
        <name><surname>Fox</surname><given-names>E.</given-names></name>
        <name><surname>Garnett</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>32</volume>
      <uri>https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf</uri>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Falcon_PyTorch_Lightning_2019">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Falcon</surname><given-names>William</given-names></name>
        <string-name>The PyTorch Lightning team</string-name>
      </person-group>
      <source>PyTorch Lightning</source>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <uri>https://github.com/Lightning-AI/lightning</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3828935</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Cardoso_MONAI_An_open-source_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cardoso</surname><given-names>M. Jorge</given-names></name>
        <name><surname>Li</surname><given-names>Wenqi</given-names></name>
        <name><surname>Brown</surname><given-names>Richard</given-names></name>
        <name><surname>Ma</surname><given-names>Nic</given-names></name>
        <name><surname>Kerfoot</surname><given-names>Eric</given-names></name>
        <name><surname>Wang</surname><given-names>Yiheng</given-names></name>
        <name><surname>Murray</surname><given-names>Benjamin</given-names></name>
        <name><surname>Myronenko</surname><given-names>Andriy</given-names></name>
        <name><surname>Zhao</surname><given-names>Can</given-names></name>
        <name><surname>Yang</surname><given-names>Dong</given-names></name>
        <name><surname>Nath</surname><given-names>Vishwesh</given-names></name>
        <name><surname>He</surname><given-names>Yufan</given-names></name>
        <name><surname>Xu</surname><given-names>Ziyue</given-names></name>
        <name><surname>Hatamizadeh</surname><given-names>Ali</given-names></name>
        <name><surname>Myronenko</surname><given-names>Andriy</given-names></name>
        <name><surname>Zhu</surname><given-names>Wentao</given-names></name>
        <name><surname>Liu</surname><given-names>Yun</given-names></name>
        <name><surname>Zheng</surname><given-names>Mingxin</given-names></name>
        <name><surname>Tang</surname><given-names>Yucheng</given-names></name>
        <name><surname>Yang</surname><given-names>Isaac</given-names></name>
        <name><surname>Zephyr</surname><given-names>Michael</given-names></name>
        <name><surname>Hashemian</surname><given-names>Behrooz</given-names></name>
        <name><surname>Alle</surname><given-names>Sachidanand</given-names></name>
        <name><surname>Zalbagi Darestani</surname><given-names>Mohammad</given-names></name>
        <name><surname>Budd</surname><given-names>Charlie</given-names></name>
        <name><surname>Modat</surname><given-names>Marc</given-names></name>
        <name><surname>Vercauteren</surname><given-names>Tom</given-names></name>
        <name><surname>Wang</surname><given-names>Guotai</given-names></name>
        <name><surname>Li</surname><given-names>Yiwen</given-names></name>
        <name><surname>Hu</surname><given-names>Yipeng</given-names></name>
        <name><surname>Fu</surname><given-names>Yunguan</given-names></name>
        <name><surname>Gorman</surname><given-names>Benjamin</given-names></name>
        <name><surname>Johnson</surname><given-names>Hans</given-names></name>
        <name><surname>Genereaux</surname><given-names>Brad</given-names></name>
        <name><surname>Erdal</surname><given-names>Barbaros S.</given-names></name>
        <name><surname>Gupta</surname><given-names>Vikash</given-names></name>
        <name><surname>Diaz-Pinto</surname><given-names>Andres</given-names></name>
        <name><surname>Dourson</surname><given-names>Andre</given-names></name>
        <name><surname>Maier-Hein</surname><given-names>Lena</given-names></name>
        <name><surname>Jaeger</surname><given-names>Paul F.</given-names></name>
        <name><surname>Baumgartner</surname><given-names>Michael</given-names></name>
        <name><surname>Kalpathy-Cramer</surname><given-names>Jayashree</given-names></name>
        <name><surname>Flores</surname><given-names>Mona</given-names></name>
        <name><surname>Kirby</surname><given-names>Justin</given-names></name>
        <name><surname>Cooper</surname><given-names>Lee A. D.</given-names></name>
        <name><surname>Roth</surname><given-names>Holger R.</given-names></name>
        <name><surname>Xu</surname><given-names>Daguang</given-names></name>
        <name><surname>Bericat</surname><given-names>David</given-names></name>
        <name><surname>Floca</surname><given-names>Ralf</given-names></name>
        <name><surname>Zhou</surname><given-names>S. Kevin</given-names></name>
        <name><surname>Shuaib</surname><given-names>Haris</given-names></name>
        <name><surname>Farahani</surname><given-names>Keyvan</given-names></name>
        <name><surname>Maier-Hein</surname><given-names>Klaus H.</given-names></name>
        <name><surname>Aylward</surname><given-names>Stephen</given-names></name>
        <name><surname>Dogra</surname><given-names>Prerna</given-names></name>
        <name><surname>Ourselin</surname><given-names>Sebastien</given-names></name>
        <name><surname>Feng</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>MONAI: An open-source framework for deep learning in healthcare</article-title>
      <year iso-8601-date="2022-11">2022</year><month>11</month>
      <pub-id pub-id-type="doi">10.48550/arXiv.2211.02701</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-DBLPU003AjournalsU002FcorrU002Fabs-2101-04209">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhao</surname><given-names>Yue</given-names></name>
        <name><surname>Qiao</surname><given-names>Zhi</given-names></name>
        <name><surname>Xiao</surname><given-names>Cao</given-names></name>
        <name><surname>Glass</surname><given-names>Lucas</given-names></name>
        <name><surname>Sun</surname><given-names>Jimeng</given-names></name>
      </person-group>
      <article-title>PyHealth: A python library for health predictive models</article-title>
      <source>CoRR</source>
      <year iso-8601-date="2021">2021</year>
      <volume>abs/2101.04209</volume>
      <uri>https://arxiv.org/abs/2101.04209</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
