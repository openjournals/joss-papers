<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20250922035036-9dd0611515ea2508679268de1c14a0327f05cfc3</doi_batch_id>
    <timestamp>20250922035036</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>09</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>113</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>fairmetrics: An R package for group fairness evaluation</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Benjamin</given_name>
            <surname>Smith</surname>
            <affiliations>
              <institution><institution_name>Department of Statistical Sciences, University of Toronto</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0007-2206-0177</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jianhui</given_name>
            <surname>Gao</surname>
            <affiliations>
              <institution><institution_name>Department of Statistical Sciences, University of Toronto</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0003-0915-1473</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Benson</given_name>
            <surname>Chou</surname>
            <affiliations>
              <institution><institution_name>Department of Statistical Sciences, University of Toronto</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0007-0265-033X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jessica</given_name>
            <surname>Gronsbell</surname>
            <affiliations>
              <institution><institution_name>Department of Statistical Sciences, University of Toronto</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-5360-5869</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>09</month>
          <day>22</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>8497</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.08497</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.17100723</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/8497</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.08497</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.08497</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.08497.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="mattuMachineBias">
            <article_title>Machine Bias</article_title>
            <author>Mattu</author>
            <journal_title>ProPublica</journal_title>
            <cYear>2016</cYear>
            <unstructured_citation>Mattu, L. K., Jeff Larson. (2016). Machine Bias. In ProPublica. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.</unstructured_citation>
          </citation>
          <citation key="mehrabi_survey_21">
            <article_title>A survey on bias and fairness in machine learning</article_title>
            <author>Mehrabi</author>
            <journal_title>ACM Comput. Surv.</journal_title>
            <issue>6</issue>
            <volume>54</volume>
            <doi>10.1145/3457607</doi>
            <issn>0360-0300</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., &amp; Galstyan, A. (2021). A survey on bias and fairness in machine learning. ACM Comput. Surv., 54(6). https://doi.org/10.1145/3457607</unstructured_citation>
          </citation>
          <citation key="Gao_Chou_McCaw_Thurston_Varghese_Hong_Gronsbell_2024">
            <article_title>What is fair? Defining fairness in machine learning for health</article_title>
            <author>Gao</author>
            <journal_title>arXiv.org</journal_title>
            <doi>10.48550/arXiv.2406.09307</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Gao, J., Chou, B., McCaw, Z. R., Thurston, H., Varghese, P., Hong, C., &amp; Gronsbell, J. (2024). What is fair? Defining fairness in machine learning for health. In arXiv.org. https://doi.org/10.48550/arXiv.2406.09307</unstructured_citation>
          </citation>
          <citation key="fairness_package">
            <volume_title>fairness: Algorithmic fairness metrics</volume_title>
            <author>Kozodoi</author>
            <doi>10.32614/cran.package.fairness</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Kozodoi, N., &amp; V. Varga, T. (2021). fairness: Algorithmic fairness metrics. https://doi.org/10.32614/cran.package.fairness</unstructured_citation>
          </citation>
          <citation key="raffa2016clinical">
            <article_title>Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters (version 1.0)</article_title>
            <author>Raffa</author>
            <doi>10.13026/C2NC7F</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Raffa, J. (2016). Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters (version 1.0). https://doi.org/10.13026/C2NC7F</unstructured_citation>
          </citation>
          <citation key="raffa2016data">
            <article_title>Data analysis</article_title>
            <author>Raffa</author>
            <journal_title>Secondary analysis of electronic health records</journal_title>
            <doi>10.1007/978-3-319-43742-2_9</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Raffa, J. D., Ghassemi, M., Naumann, T., Feng, M., &amp; Hsu, D. J. (2016). Data analysis. In Secondary analysis of electronic health records (pp. 109–122). Springer, Cham. https://doi.org/10.1007/978-3-319-43742-2_9</unstructured_citation>
          </citation>
          <citation key="goldberger2000physiobank">
            <article_title>PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals</article_title>
            <author>Goldberger</author>
            <journal_title>Circulation [Online]</journal_title>
            <issue>23</issue>
            <volume>101</volume>
            <doi>10.1161/01.CIR.101.23.e215</doi>
            <cYear>2000</cYear>
            <unstructured_citation>Goldberger, A. L., Amaral, L. A. N., Glass, L., Hausdorff, J. M., Ivanov, P. Ch., Mark, R. G., Mietus, J. E., Moody, G. B., Peng, C.-K., &amp; Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online], 101(23), e215–e220. https://doi.org/10.1161/01.CIR.101.23.e215</unstructured_citation>
          </citation>
          <citation key="wisniewski2022fairmodels">
            <article_title>fairmodels: A flexible tool for bias detection, visualization, and mitigation in binary classification models</article_title>
            <author>Wiśniewski</author>
            <journal_title>The R Journal</journal_title>
            <issue>1</issue>
            <volume>14</volume>
            <doi>10.32614/RJ-2022-019</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Wiśniewski, J., &amp; Biecek, P. (2022). fairmodels: A flexible tool for bias detection, visualization, and mitigation in binary classification models. The R Journal, 14(1), 227–243. https://doi.org/10.32614/RJ-2022-019</unstructured_citation>
          </citation>
          <citation key="fairlearn_paper">
            <article_title>FairLearn: Assessing and improving fairness of AI systems</article_title>
            <author>Weerts</author>
            <journal_title>arXiv.org</journal_title>
            <doi>10.48550/arXiv.2303.16626</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Weerts, H., Dudík, M., Edgar, R., Jalali, A., Lutz, R., &amp; Madaio, M. (2023). FairLearn: Assessing and improving fairness of AI systems. In arXiv.org. https://doi.org/10.48550/arXiv.2303.16626</unstructured_citation>
          </citation>
          <citation key="mlr3fairness_package">
            <volume_title>mlr3fairness: Fairness auditing and debiasing for ’mlr3’</volume_title>
            <author>Pfisterer</author>
            <doi>10.32614/cran.package.mlr3fairness</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Pfisterer, F., Siyi, W., &amp; Lang, M. (2024). mlr3fairness: Fairness auditing and debiasing for ’mlr3’. https://doi.org/10.32614/cran.package.mlr3fairness</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
