<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4060</article-id>
<article-id pub-id-type="doi">10.21105/joss.04060</article-id>
<title-group>
<article-title>terrainr: An R package for creating immersive virtual
environments</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2402-304X</contrib-id>
<name>
<surname>Mahoney</surname>
<given-names>Michael J.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2692-7296</contrib-id>
<name>
<surname>Beier</surname>
<given-names>Colin M.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7106-0957</contrib-id>
<name>
<surname>Ackerman</surname>
<given-names>Aidan C.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Graduate Program in Environmental Science, State University
of New York College of Environmental Science and Forestry, Syracuse, New
York, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Sustainable Resources Management, State
University of New York College of Environmental Science and Forestry,
Syracuse, New York, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Landscape Architecture, State University of
New York College of Environmental Science and Forestry, Syracuse, New
York, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-01-01">
<day>1</day>
<month>1</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>69</issue>
<fpage>4060</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>virtual reality</kwd>
<kwd>GIS</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>terrainr</monospace> is an R package designed to make it
  easier to produce immersive virtual environments in the Unity video
  game engine from real-world spatial data. By providing functions for
  data access and retrieval, wrangling and format transformation, and
  import into Unity, <monospace>terrainr</monospace> improves the speed
  and reproducibility of developing such visualizations. With the
  ability to process spatial data in both raster and vector formats,
  combine data from multiple sources, and rapidly iterate on
  visualization components, <monospace>terrainr</monospace> makes it
  easy for researchers to develop IVEs from real-world data and apply
  these visualizations to new problems and domains.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>An exciting frontier in spatial visualization is the use of
  immersive virtual environments (IVEs) as a method for representing
  real-world locations. IVEs allow users to explore spatial
  representations in virtual reality (VR), aiding scientific
  communication by giving users the sense of “being there” within a
  virtual world
  (<xref alt="Hruby et al., 2019" rid="ref-Hruby2019" ref-type="bibr">Hruby
  et al., 2019</xref>). While many examples of IVEs used in research are
  entirely manually created, with a visualization designer attempting to
  develop a representation of a plausible natural environment, recent
  work has looked at the possibility of representing real-world
  landscapes by producing IVEs from spatial data
  (<xref alt="Keil et al., 2021" rid="ref-Keil2020" ref-type="bibr">Keil
  et al., 2021</xref>).</p>
  <p>However, a major hurdle in the use of IVEs as a way to represent
  real-world spaces is the gap between the tooling used to handle
  geospatial data and that used to create IVEs. IVEs are typically
  created within video game engines, which provide advanced VR
  capabilities but do not share data models or formats with traditional
  GIS systems
  (<xref alt="Hruby et al., 2019" rid="ref-Hruby2019" ref-type="bibr">Hruby
  et al., 2019</xref>). While it is possible to manually transform data
  produced by one system to formats understood by the other
  (<xref alt="Keil et al., 2021" rid="ref-Keil2020" ref-type="bibr">Keil
  et al., 2021</xref>), this process is slow and imprecise, typically
  requiring repetitive manual data processing procedures which can be
  hard to reproduce or debug. The difficulty of transforming real-world
  spatial data for usage in IVEs, alongside the labor-intensive creation
  process, is likely a factor in the slow adoption of IVEs as spatial
  visualizations and the accompanying lack of theoretical research into
  their usage
  (<xref alt="Hruby et al., 2019" rid="ref-Hruby2019" ref-type="bibr">Hruby
  et al., 2019</xref>).</p>
  <p>This paper introduces <monospace>terrainr</monospace>, a new
  package for the open-source R programming language
  (<xref alt="R Core Team, 2020" rid="ref-R" ref-type="bibr">R Core
  Team, 2020</xref>) which aids in the retrieval, manipulation, and
  transformation of spatial data for IVEs. By integrating with the most
  popular geospatial data formats within R and providing tools to
  automate importing geospatial data such as digital elevation models
  and imagery into the Unity 3D video game engine
  (<xref alt="Unity Technologies, 2020" rid="ref-Unity" ref-type="bibr">Unity
  Technologies, 2020</xref>), terrainr aims to make it easier to produce
  IVE representations of real-world locations.</p>
</sec>
<sec id="package-overview">
  <title>Package Overview</title>
  <p>The <monospace>terrainr</monospace> package provides functions for
  the retrieval, manipulation, and transformation of spatial data
  entirely within R. Package functions are loosely grouped between those
  which provide access to public domain spatial data from the U.S.
  Geological Survey’s National Map program
  (<xref alt="U.S. Geological Survey National Geospatial Program, 2020" rid="ref-TNM" ref-type="bibr">U.S.
  Geological Survey National Geospatial Program, 2020</xref>), and those
  which process arbitrary spatial data for visualization within the
  Unity 3D video game engine.</p>
  <sec id="data-access-and-retrieval">
    <title>Data Access and Retrieval</title>
    <p>The <monospace>terrainr</monospace> package provides a consistent
    API for programmatic access to public domain data from the U.S.
    Geological Survey’s National Map program from within R, allowing
    users to download data for areas within the continental United
    States from 10 separate web APIs. To download data, users specify an
    area of interest by providing objects of any class from either the
    <monospace>sf</monospace> or <monospace>raster</monospace> packages
    alongside a number of other optional parameters, including the
    desired pixel resolution and coordinate reference system of the
    returned data. <monospace>terrainr</monospace> will then attempt to
    download data for the minimal bounding box surrounding the provided
    spatial data, resampled to the target resolution and converted to
    the desired coordinate reference system.</p>
  </sec>
  <sec id="creating-ives">
    <title>Creating IVEs</title>
    <sec id="current-ive-workflow">
      <title>Current IVE workflow</title>
      <fig id="figU003Akeilworkflow">
        <caption><p>Workflow diagrams for producing IVEs using
        real-world DEMs as described in Keil et al. (2021) (left) and
        using terrainr (right). Green boxes relate to data retrieval,
        red to data processing, and yellow to import into
        Unity.</p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/workflow.png" xlink:title="" />
      </fig>
      <p>An approach for creating immersive virtual environments inside
      the Unity game engine using real-world terrain data is provided in
      Section 3 of Keil et al.
      (<xref alt="2021" rid="ref-Keil2020" ref-type="bibr">2021</xref>)
      (Figure 1). This approach involves first manually downloading data
      for an area of interest from a data portal, with the user
      responsible for inputting their area of interest into a web-based
      graphical interface or identifying which pre-generated data tile
      best matches their desired location. This data must then be
      transformed into a TIFF image and imported into image-editing
      software, where the user must convert the image into the greyscale
      colorspace, rescale it to a size accepted by the Unity engine
      (which only imports square terrains with sides of
      <inline-formula><alternatives>
      <tex-math><![CDATA[2^{x} + 1]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mn>2</mml:mn><mml:mi>x</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      pixels, for <inline-formula><alternatives>
      <tex-math><![CDATA[5 \leq x \leq 12]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>5</mml:mn><mml:mo>≤</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>)
      with an accompanying loss of spatial fidelity, then manually
      exported into the “RAW” format with planar interlacing of color
      values. Finally, the user must import this RAW file into the
      Unity, taking care to ensure that options reflecting file bit
      depth, pixel extent in the X, Y, and Z directions, resolution,
      system endianness, and terrain orientation options are set
      correctly. This process results in, as phrased by Keil et al.
      (<xref alt="Keil et al., 2021" rid="ref-Keil2020" ref-type="bibr">Keil
      et al., 2021</xref>), “an untextured terrain excluding additional
      spatial elements.” While the surface will have mostly accurate
      terrain heights, no other information will be represented (Figure
      2, left). This process incorporates multiple softwares and must be
      repeated for each tile the user wishes to import, with each tile
      limited to a maximum of 4,097 pixels in length.</p>
      <fig id="figU003Anortho">
        <caption><p>Left: Untextured terrain, as produced via the Keil
        et al (2021) methodology. Right: The same terrain surface,
        textured with aerial orthoimagery from the National Agricultural
        Inventory Program. In both images, areas closer to the camera
        are rendered in more detail, with individual pixels visible on
        the left and landscape features such as trees visible on the
        right. Both surfaces were created using the terrainr R
        package.</p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/mahoney-fig1.png" xlink:title="" />
      </fig>
      <p>It is difficult, though not impossible to add other spatial
      data to this surface. For instance, orthoimagery may be added as
      an image overlay by importing an image file as a Texture2D object
      within Unity, attaching it to a terrain tile as a TerrainLayer
      object, and then setting the X and Z dimensions of the new
      TerrainLayer to the image’s side length in pixels, assuming that
      the orthoimage has been cropped to the same extent and resolution
      as the terrain tile. The same process may be used to import any
      imagery, meaning that it is possible to manually add overlays of
      additional raster data or rasterized vector geometries to these
      scenes. However, the need to ensure that imagery maintains the
      same coordinate reference system, extent, and resolution as the
      elevation data throughout all manipulations is a notable obstacle
      to incorporating geographic data in these visualizations.</p>
    </sec>
    <sec id="terrainr-workflow">
      <title><monospace>terrainr</monospace> workflow</title>
      <p><monospace>terrainr</monospace> attempts to simplify this
      process by combining R’s advanced geospatial processing ecosystem
      and image editing packages to handle data transformation, image
      manipulation, and data transformation, while providing an
      automated method for importing terrain into Unity which abstracts
      away the many options and decisions required to import geospatial
      data (Figure 1). Users create a single-band raster, as well as an
      optional multi-band raster of the same extent, resolution, and
      sharing the same coordinate reference system, and save these
      rasters as any format supported by their GDAL installation
      (<xref alt="GDAL/OGR contributors, 2021" rid="ref-GDAL" ref-type="bibr">GDAL/OGR
      contributors, 2021</xref>). They then provide these files to the
      <monospace>make_manifest</monospace> function, which handles
      transforming both the single-band raster for importing into Unity
      as an elevation layer as well as the multi-band image for
      importing as a corresponding terrain texture. These transformed
      layers are saved as individual tiles alongside a C# script
      providing the automated terrain import methods and a “manifest”
      file listing the dimensions and relative spatial positions of each
      transformed tile. After copying these files into a new Unity
      project, users will notice a new “terrainr” menu option in their
      Unity app menu bar. This menu option produces a terrain import
      wizard which will read the manifest file, import the terrain tiles
      into Unity in their proper scale and spatial arrangement, and then
      attach any provided image overlays as terrain textures.</p>
      <fig id="figU003Avrs">
        <caption><p>From Mahoney, Beier, and Ackerman (2021), an IVE
        produced using terrainr showing a section of the Adirondack Park
        in northeastern New York State, USA. A red dot in the center of
        the image represents Johns Brook Lodge. Areas which can see and
        be seen by the lodge are brightly lit, while areas outside the
        lodge’s viewshed are dim.</p></caption>
        <graphic mimetype="image" mime-subtype="jpeg" xlink:href="media/vrs_dot.jpg" xlink:title="" />
      </fig>
      <p>On its own, <monospace>terrainr</monospace> provides for the
      first time a method for creating reproducible IVEs in Unity from
      arbitrary spatial data; any raster data format supported by GDAL
      may be used to produce visualizations, while all decisions and
      data manipulations involved in the production of the IVE are
      preserved as simple R code. Additionally, this method allows for
      IVEs to be produced from real-world data much faster than is
      possible manually; even when accounting for data download from the
      National Map, it is possible to produce a new IVE in Unity from
      whole cloth in under ten minutes. <monospace>terrainr</monospace>
      also makes it easier to work with multiple image overlays through
      its <monospace>combine_overlays</monospace> function, allowing
      users to “stack” imagery with controllable opacities in order to
      produce single images for use as terrain textures. Additionally,
      users may take advantage of the function
      <monospace>vector_to_overlay</monospace> to rasterize vector
      geometries, obtaining images of the same extent as a reference
      raster. In this way, users are able to use
      <monospace>terrainr</monospace> to represent multiple levels of
      spatial information within a single IVE; for instance, Mahoney,
      Beier and Ackerman
      (<xref alt="2021" rid="ref-vrsPaper" ref-type="bibr">2021</xref>)
      used <monospace>terrainr</monospace> to combine point geodata, a
      boolean raster of viewshed boundaries, and orthoimagery with
      elevation data into a IVE of a region within New York State’s
      Adirondack Park (Figure 3).</p>
    </sec>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the State University of New York via the
  ESF Pathways to Net Zero Carbon initiative.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>R Core Team</string-name>
      </person-group>
      <source>R: A language and environment for statistical computing</source>
      <publisher-name>R Foundation for Statistical Computing</publisher-name>
      <publisher-loc>Vienna, Austria</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <uri>https://www.R-project.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-TNM">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>U.S. Geological Survey National Geospatial Program</string-name>
      </person-group>
      <source>The National Map</source>
      <publisher-loc>Washington D. C., United States of America</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <uri>https://viewer.nationalmap.gov/services/</uri>
    </element-citation>
  </ref>
  <ref id="ref-Unity">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>Unity Technologies</string-name>
      </person-group>
      <source>Unity</source>
      <publisher-name>Unity Software Inc.</publisher-name>
      <publisher-loc>San Francisco, United States of America</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <uri>https://unity.com/</uri>
    </element-citation>
  </ref>
  <ref id="ref-GDAL">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>GDAL/OGR contributors</string-name>
      </person-group>
      <source>GDAL/OGR geospatial data abstraction software library</source>
      <publisher-name>Open Source Geospatial Foundation</publisher-name>
      <publisher-loc>USA</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <uri>https://gdal.org</uri>
    </element-citation>
  </ref>
  <ref id="ref-Keil2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Keil</surname><given-names>Julian</given-names></name>
        <name><surname>Edler</surname><given-names>Dennis</given-names></name>
        <name><surname>Schmitt</surname><given-names>Thomas</given-names></name>
        <name><surname>Dickmann</surname><given-names>Francis</given-names></name>
      </person-group>
      <article-title>Creating immersive virtual environments based on open geospatial data and game engines</article-title>
      <source>KN Journal of Cartography and Geographic Information</source>
      <year iso-8601-date="2021">2021</year>
      <volume>71</volume>
      <pub-id pub-id-type="doi">10.1007/s42489-020-00069-6</pub-id>
      <fpage>53</fpage>
      <lpage>65</lpage>
    </element-citation>
  </ref>
  <ref id="ref-vrsPaper">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mahoney</surname><given-names>Michael J</given-names></name>
        <name><surname>Beier</surname><given-names>Colin M</given-names></name>
        <name><surname>Ackerman</surname><given-names>Aidan C</given-names></name>
      </person-group>
      <article-title>Interactive landscape simulations for visual resource assessment</article-title>
      <source>VRSC 2021 conference proceedings</source>
      <person-group person-group-type="editor">
        <name><surname>Hoffman</surname><given-names>Robin</given-names></name>
        <name><surname>Chamberlain</surname><given-names>Brent</given-names></name>
        <name><surname>Smardon</surname><given-names>Richard</given-names></name>
      </person-group>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-Hruby2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hruby</surname><given-names>Florian</given-names></name>
        <name><surname>Ressl</surname><given-names>Rainer</given-names></name>
        <name><surname>Borbolla del Valle</surname><given-names>Genghis de la</given-names></name>
      </person-group>
      <article-title>Geovisualization with immersive virtual environments in theory and practice</article-title>
      <source>International Journal of Digital Earth</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>12</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1080/17538947.2018.1501106</pub-id>
      <fpage>123</fpage>
      <lpage>136</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
