<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7018</article-id>
<article-id pub-id-type="doi">10.21105/joss.07018</article-id>
<title-group>
<article-title>DisCoTec: Distributed higher-dimensional HPC simulations
with the sparse grid combination technique</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0186-4340</contrib-id>
<name>
<surname>Pollinger</surname>
<given-names>Theresa</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hurler</surname>
<given-names>Marcel</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3336-7226</contrib-id>
<name>
<surname>Craen</surname>
<given-names>Alexander Van</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Obersteiner</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4360-0212</contrib-id>
<name>
<surname>Pflüger</surname>
<given-names>Dirk</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University of Stuttgart, Scientific Computing, Stuttgart,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Technical University of Munich, Chair of Scientific
Computing, Munich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>RIKEN Center for Computational Science (R-CCS), Kobe,
Japan</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-11-16">
<day>16</day>
<month>11</month>
<year>2023</year>
</pub-date>
<volume>10</volume>
<issue>106</issue>
<fpage>7018</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>C++</kwd>
<kwd>MPI</kwd>
<kwd>structured grid-based simulations</kwd>
<kwd>sparse grids</kwd>
<kwd>black-box solvers</kwd>
<kwd>Vlasov solvers</kwd>
<kwd>massively parallel</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>DisCoTec</monospace> is a C++ framework for the sparse
  grid combination technique
  (<xref alt="Griebel et al., 1992" rid="ref-griebelCombinationTechniqueSolution1992" ref-type="bibr">Griebel
  et al., 1992</xref>), designed for massively parallel settings. It is
  implemented with shared-memory parallelism via OpenMP and
  distributed-memory parallelism via MPI, and is intended to be used in
  conjunction with existing simulation codes. For simulation codes that
  can handle nested structured grids, little to no adaptation work is
  needed for use with the <monospace>DisCoTec</monospace> framework. The
  combination technique with <monospace>DisCoTec</monospace>
  demonstrates its superiority in precision-per-memory for
  higher-dimensional time-dependent simulations, such as high-fidelity
  plasma turbulence simulations in four to six dimensions and even for
  simulations in two dimensions, improvements can be observed
  (<xref alt="Pollinger et al., 2023" rid="ref-pollingerStableMassconservingSparse2023" ref-type="bibr">Pollinger
  et al., 2023</xref>).</p>
  <p>A central part of the combination technique at scale is the
  transformation of grid coefficients into a multi-scale basis.
  <monospace>DisCoTec</monospace> provides a selection of three
  different lifting wavelets for this purpose: hierachical hat basis,
  biorthogonal, and fullweighting basis. In addition, any code that can
  operate on nested structured grids can benefit from the model order
  reduction provided by the underlying sparse grid approach used by
  <monospace>DisCoTec</monospace>, without requiring any multi-scale
  operations. An additional feature of <monospace>DisCoTec</monospace>
  is the possibility of performing widely-distributed simulations of
  higher-dimensional problems, where multiple High-Performance Computing
  (HPC) systems collaborate to solve a joint simulation, as demonstrated
  in Pollinger et al.
  (<xref alt="2024" rid="ref-pollingerRealizingJointExtremeScale2024" ref-type="bibr">2024</xref>).
  Thus, <monospace>DisCoTec</monospace> can leverage the compute power
  and main memory of multiple HPC systems, with comparatively low and
  manageable transfer costs due to the combination technique.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Higher-dimensional problems (by which we mean more than three space
  dimensions and one time dimension) quickly require infeasible amounts
  of computational resources such as memory and core-hours as the
  problem size increases—they are haunted by the so-called ‘curse of
  dimensionality’. An example of this are high-fidelity plasma
  turbulence simulations in the field of confined fusion research.
  Currently employed approaches to this problem include
  dimensionally-reduced models, such as gyrokinetics
  (<xref alt="Brizard &amp; Hahm, 2007" rid="ref-brizardFoundationsNonlinearGyrokinetic2007" ref-type="bibr">Brizard
  &amp; Hahm, 2007</xref>) (which may not always be applicable),
  particle-in-cell methods (which suffer from inherent noise
  (<xref alt="Verboncoeur, 2005" rid="ref-verboncoeurParticleSimulationPlasmas2005" ref-type="bibr">Verboncoeur,
  2005</xref>)), and restricting computations to a very limited
  resolution. A further—still developing but very promising—approach to
  the problem is low-rank methods
  (<xref alt="Einkemmer &amp; Joseph, 2021" rid="ref-einkemmerMassMomentumEnergy2021" ref-type="bibr">Einkemmer
  &amp; Joseph, 2021</xref>). Multi-scale (hierarchical) methods, such
  as the sparse grid combination technique (CT) that
  <monospace>DisCoTec</monospace> employs, provide an alternative
  approach to addressing the curse of dimensionality by considering only
  those resolutions where the highest amount of information is expected
  (<xref alt="Bungartz &amp; Griebel, 2004" rid="ref-bungartzSparseGrids2004" ref-type="bibr">Bungartz
  &amp; Griebel, 2004</xref>). While some implementations of the CT are
  available, there is currently no other implementation for parallel
  simulations that require distributed computing.
  <monospace>DisCoTec</monospace> is a C++ framework for
  massively-parallel time-dependent problems with the CT, which fills
  this gap.</p>
</sec>
<sec id="methods-sparse-grid-combination-technique-and-implementation">
  <title>Methods: Sparse grid combination technique and
  implementation</title>
  <p>The sparse grid combination technique (with time-stepping) is a
  multi-scale approach for solving higher-dimensional problems. Instead
  of solving the problem on one grid that is very finely resolved in all
  dimensions, the problem is solved on the so-called ‘component grids’
  that are all rather coarsely resolved—each of them differently in the
  different dimensions. For instance, the following schematic shows a
  two-dimensional combination scheme, consisting of seven component
  grids.</p>
  <fig>
    <caption><p>Combination scheme in two dimensions with
    <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{\ell}^{\text{min}} = (2,1)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover><mml:mtext mathvariant="normal">min</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{\ell}^{\text{max}} = (5,4)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover><mml:mtext mathvariant="normal">max</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
    periodic boundary conditions. Figure first published in Pollinger
    (<xref alt="2024" rid="ref-pollingerStableMassconservingHighdimensional2024" ref-type="bibr">2024</xref>).
    <styled-content id="figU003Acombischeme-2d"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="combischeme-2d.pdf" />
  </fig>
  <p>By updating each other’s information throughout the simulation, the
  component grids still obtain an accurate solution of the overall
  problem
  (<xref alt="Griebel et al., 1992" rid="ref-griebelCombinationTechniqueSolution1992" ref-type="bibr">Griebel
  et al., 1992</xref>). This is enabled by an intermedate transformation
  into a multi-scale (hierarchical) basis, and application of the
  combination formula <disp-formula><alternatives>
  <tex-math><![CDATA[ f^{(\text{s})} = \sum_{\vec{\ell} \in \mathcal{I} } c_{\vec{\ell}} f_{\vec{\ell}} ]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">s</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mi>ℐ</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>c</mml:mi><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover></mml:msub></mml:mrow></mml:math></alternatives></disp-formula>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[f^{(\text{s})}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">s</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>
  is the sparse grid approximation, and <inline-formula><alternatives>
  <tex-math><![CDATA[f_{\vec{\ell}}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>f</mml:mi><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover></mml:msub></mml:math></alternatives></inline-formula>
  are the component grid functions. The set of all used levels
  <inline-formula><alternatives>
  <tex-math><![CDATA[\vec{\ell}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  is often called a combination scheme <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{I}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ℐ</mml:mi></mml:math></alternatives></inline-formula>.
  In
  <xref alt="[fig:combischeme-2d]" rid="figU003Acombischeme-2d">[fig:combischeme-2d]</xref>,
  the coefficients <inline-formula><alternatives>
  <tex-math><![CDATA[c_{\vec{\ell}}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>c</mml:mi><mml:mover><mml:mo>ℓ</mml:mo><mml:mo accent="true">→</mml:mo></mml:mover></mml:msub></mml:math></alternatives></inline-formula>
  are <inline-formula><alternatives>
  <tex-math><![CDATA[-1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  for the coarser component grids (red background) and
  <inline-formula><alternatives>
  <tex-math><![CDATA[1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>
  for the finer component grids (orange background). In summary, each of
  the grids will run (one or more) time steps of the simulation, then
  exchange information with the other grids, and repeat this process
  until the simulation is finished.</p>
  <p><monospace>DisCoTec</monospace> provides the necessary
  infrastructure for the combination technique with a black-box
  approach, enabling massive parallelism—suitable for existing
  distributed solvers that use structured grids. An important feature is
  the usage of ‘process groups’, where multiple MPI ranks will
  collaborate on a set of component grids, and the solver’s existing
  parallelism can be re-used. The process groups are displayed as
  <inline-formula><alternatives>
  <tex-math><![CDATA[pg_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>
  in
  <xref alt="[fig:discotec-ranks]" rid="figU003Adiscotec-ranks">[fig:discotec-ranks]</xref>.</p>
  <fig>
    <caption><p><monospace>DisCoTec</monospace> process groups: Each
    black square denotes one MPI rank. The ranks are grouped into the
    so-called ‘process groups’. Distributed operations in
    <monospace>DisCoTec</monospace> require either communication in the
    process group, or perpendicular to it—there is no need for global
    communication or synchronization, which avoids a major scaling
    bottleneck. The manager rank is optional. Figure first published in
    Pollinger
    (<xref alt="2024" rid="ref-pollingerStableMassconservingHighdimensional2024" ref-type="bibr">2024</xref>).
    <styled-content id="figU003Adiscotec-ranks"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="discotec-ranks.pdf" />
  </fig>
  <p>In addition, the number of process groups can be increased to
  leverage the combination technique’s embarrassing parallelism in the
  solver time steps. In
  <xref alt="[fig:discotec-ranks]" rid="figU003Adiscotec-ranks">[fig:discotec-ranks]</xref>,
  this would be equivalent to adding more and more process groups to the
  right.</p>
  <p>Using <monospace>DisCoTec</monospace>, kinetic simulations were
  demonstrated to scale up to hundreds of thousands of CPU cores
  (<xref alt="Pollinger, 2024" rid="ref-pollingerStableMassconservingHighdimensional2024" ref-type="bibr">Pollinger,
  2024</xref>). By putting a special focus on saving memory, most of the
  memory is available for use by the black-box solver, even at high core
  counts. In addition, OpenMP parallelism can be used to further
  increase parallelism while being more lightweight than MPI in terms of
  memory.</p>
  <p>Through highly parallel I/O operations,
  <monospace>DisCoTec</monospace> can be used to perform simulations on
  multiple High Performance Computing systems simultaneously, if there
  exists a tool for sufficiently fast file transfer between the systems
  (<xref alt="Pollinger, 2024" rid="ref-pollingerStableMassconservingHighdimensional2024" ref-type="bibr">Pollinger,
  2024</xref>). The <monospace>DisCoTec</monospace> repository contains
  example scripts and documentation for utilizing UFTP as an example of
  a transfer tool, but the approach is not limited to UFTP.</p>
  <p><monospace>DisCoTec</monospace> provides a conveniently automated
  way of installation using a
  <ext-link ext-link-type="uri" xlink:href="https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/discotec/package.py"><monospace>spack</monospace>
  package</ext-link>
  (<xref alt="Gamblin et al., 2015" rid="ref-gamblinSpackPackageManager2015" ref-type="bibr">Gamblin
  et al., 2015</xref>), which can be used to install
  <monospace>DisCoTec</monospace> and its whole dependency tree in an
  automated manner optimized for HPC hardware.</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the field</title>
  <p>Besides <monospace>DisCoTec</monospace> there exist other
  frameworks that allow the usage of sparse grids and the combination
  technique. We will give a brief overview and outline the differences
  and application areas of the codes.</p>
  <p>The C++ code <monospace>SG++</monospace>
  (<xref alt="SG++ development team, 2018" rid="ref-SGpp" ref-type="bibr">SG++
  development team, 2018</xref>) provides a direct interface to sparse
  grids and applying them to a variety of different tasks such as
  interpolation, quadrature, optimization, PDEs, regression, and
  classification. With the help of wrappers, the framework can be used
  from various other programming languages such as Python and Matlab.
  The code targets direct implementations within sparse grids and
  provides a basic implementation of the combination technique. Although
  offering parallelization for some of the tasks, the code mainly
  targets single-node computations.</p>
  <p>The <monospace>Sparse Grids Matlab Kit</monospace>
  (<xref alt="Tamellini et al., 2024" rid="ref-TheSparseGridsMatlabKit" ref-type="bibr">Tamellini
  et al., 2024</xref>) by Piazzola and Tamellini was originally designed
  for teaching purposes and uncertainty quantification with the
  combination technique
  (<xref alt="Piazzola &amp; Tamellini, 2024" rid="ref-piazzolaSparseGridsMatlab2024" ref-type="bibr">Piazzola
  &amp; Tamellini, 2024</xref>). It offers a user friendly MATLAB
  interface for the combination technique. In addition, dimensional
  adaptivity is available for nested and non-nested sequences of
  component grid collocation points. The code is designed for usage on a
  single node which limits the parallelism to shared memory.</p>
  <p>The <monospace>sparseSpACE</monospace>
  (<xref alt="Obersteiner, 2019" rid="ref-sparseSpACE" ref-type="bibr">Obersteiner,
  2019</xref>) project offers different variants of the combination
  technique including a spatially adaptive combination technique. It
  provides implementations for various applications such as numerical
  integration, interpolation, uncertainty quantification, sparse grid
  density estimation (for classification and clustering), regression,
  and PDE calculations. The code is completely written in Python and is
  mostly sequential. The main novelty of this project is the possibility
  to add spatial adaptivity to the combination technique.</p>
  <p>This demonstrates that there exist multiple codes for sparse grids
  and the combination technique. However,
  <monospace>DisCoTec</monospace> is the only code that offers
  distributed parallelization with the combination technique and has
  demonstrated that it can scale up to full supercomputers and beyond.
  In addition, <monospace>DisCoTec</monospace> uses the most
  sophisticated approach to utilize the combination technique with
  time-dependent PDEs by employing recombinations, which increases the
  overall numerical accuracy
  (<xref alt="Pollinger et al., 2023" rid="ref-pollingerStableMassconservingSparse2023" ref-type="bibr">Pollinger
  et al., 2023</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the German Research Foundation (DFG)
  through the Priority Programme 1648 Software for Exascale Computing
  (SPPEXA).</p>
  <p>We acknowledge the support by the Stuttgart Center for Simulation
  Science (SimTech).</p>
  <p>The authors gratefully acknowledge the scientific support and HPC
  resources provided by the Erlangen National High Performance Computing
  Center (NHR@FAU) of the Friedrich-Alexander-Universität
  Erlangen-Nürnberg (FAU) under the NHR project a105cb. NHR funding is
  provided by federal and Bavarian state authorities. NHR@FAU hardware
  is partially funded by the German Research Foundation (DFG) —
  440719683.</p>
  <p>The authors gratefully acknowledge the Gauss Centre for
  Supercomputing e.V.
  (<ext-link ext-link-type="uri" xlink:href="www.gauss-centre.eu">www.gauss-centre.eu</ext-link>)
  for funding this project by providing computing time on the GCS
  Supercomputers Hermit, Hornet, Hazel Hen, and Hawk at
  Höchstleistungsrechenzentrum Stuttgart
  (<ext-link ext-link-type="uri" xlink:href="www.hlrs.de">www.hlrs.de</ext-link>).
  Simulations were performed on the national supercomputer HPE Apollo
  Hawk at the High Performance Computing Center Stuttgart (HLRS) under
  the grant number 42247.</p>
  <p>The authors gratefully acknowledge the Gauss Centre for
  Supercomputing e.V.
  (<ext-link ext-link-type="uri" xlink:href="www.gauss-centre.eu">www.gauss-centre.eu</ext-link>)
  for funding this project by providing computing time on the GCS
  Supercomputer JUWELS at Jülich Supercomputing Centre (JSC).</p>
  <p>The authors gratefully acknowledge the Gauss Centre for
  Supercomputing e.V.
  (<ext-link ext-link-type="uri" xlink:href="www.gauss-centre.eu">www.gauss-centre.eu</ext-link>)
  for funding this project by providing computing time on the GCS
  Supercomputers SuperMUC and SuperMUC-NG at Leibniz Supercomputing
  Centre
  (<ext-link ext-link-type="uri" xlink:href="www.lrz.de">www.lrz.de</ext-link>).</p>
  <p>We acknowledge contributions from Mario Heene, Christoph Kowitz,
  Alfredo Parra Hinojosa, Johannes Rentrop, Keerthi Gaddameedi, Marvin
  Dostal, Marcel Breyer, Christoph Niethammer, Philipp Offenhäuser, and
  support from HLRS, LRZ, JSC, and NHR@FAU, where we would like to
  highlight the long-standing support by Martin Bernreuther and Martin
  Ohlerich in particular.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-griebelCombinationTechniqueSolution1992">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Griebel</surname><given-names>Michael</given-names></name>
        <name><surname>Schneider</surname><given-names>Michael</given-names></name>
        <name><surname>Zenger</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>A combination technique for the solution of sparse grid problems</article-title>
      <source>Iterative Methods in Linear Algebra</source>
      <person-group person-group-type="editor">
        <name><surname>Groen</surname><given-names>P. de</given-names></name>
        <name><surname>Beauwens</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>IMACS, Elsevier, North Holland</publisher-name>
      <year iso-8601-date="1992">1992</year>
      <uri>https://ins.uni-bonn.de/media/public/publication-media/griesiam.ps.gz</uri>
      <fpage>263</fpage>
      <lpage>281</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bungartzSparseGrids2004">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bungartz</surname><given-names>Hans-Joachim</given-names></name>
        <name><surname>Griebel</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>Sparse grids</article-title>
      <source>Acta Numerica</source>
      <year iso-8601-date="2004">2004</year>
      <volume>13</volume>
      <fpage>147</fpage>
      <lpage>269</lpage>
    </element-citation>
  </ref>
  <ref id="ref-obersteiner_spatially_2021">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Obersteiner</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>A spatially adaptive and massively parallel implementation of the fault-tolerant combination technique</article-title>
      <publisher-name>Technische Universität München</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://mediatum.ub.tum.de/doc/1613369/1613369.pdf</uri>
    </element-citation>
  </ref>
  <ref id="ref-pollingerRealizingJointExtremeScale2024">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pollinger</surname><given-names>Theresa</given-names></name>
        <name><surname>Craen</surname><given-names>Alexander Van</given-names></name>
        <name><surname>Offenhäuser</surname><given-names>Philipp</given-names></name>
        <name><surname>Pflüger</surname><given-names>Dirk</given-names></name>
      </person-group>
      <article-title>Realizing joint extreme-scale simulations on multiple supercomputers—two superfacility case studies</article-title>
      <publisher-name>IEEE Computer Society</publisher-name>
      <year iso-8601-date="2024-11-09">2024</year><month>11</month><day>09</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-17">2024</year><month>11</month><day>17</day></date-in-citation>
      <isbn>9798350352917</isbn>
      <uri>https://www.computer.org/csdl/proceedings-article/sc/2024/529100b568/21HUWDIjYlO</uri>
      <pub-id pub-id-type="doi">10.1109/SC41406.2024.00104</pub-id>
      <fpage>1568</fpage>
      <lpage>1584</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pollingerStableMassconservingSparse2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pollinger</surname><given-names>Theresa</given-names></name>
        <name><surname>Rentrop</surname><given-names>Johannes</given-names></name>
        <name><surname>Pflüger</surname><given-names>Dirk</given-names></name>
        <name><surname>Kormann</surname><given-names>Katharina</given-names></name>
      </person-group>
      <article-title>A stable and mass-conserving sparse grid combination technique with biorthogonal hierarchical basis functions for kinetic simulations</article-title>
      <source>Journal of Computational Physics</source>
      <year iso-8601-date="2023-07-07">2023</year><month>07</month><day>07</day>
      <issn>0021-9991</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0021999123004333</uri>
      <pub-id pub-id-type="doi">10.1016/j.jcp.2023.112338</pub-id>
      <fpage>112338</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-pollingerStableMassconservingHighdimensional2024">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Pollinger</surname><given-names>Theresa</given-names></name>
      </person-group>
      <article-title>Stable and mass-conserving high-dimensional simulations with the sparse grid combination technique for full HPC systems and beyond</article-title>
      <year iso-8601-date="2024">2024</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-14">2024</year><month>04</month><day>14</day></date-in-citation>
      <isbn>9781885727787</isbn>
      <uri>http://elib.uni-stuttgart.de/handle/11682/14229</uri>
      <pub-id pub-id-type="doi">10.18419/opus-14210</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gamblinSpackPackageManager2015">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gamblin</surname><given-names>Todd</given-names></name>
        <name><surname>LeGendre</surname><given-names>Matthew</given-names></name>
        <name><surname>Collette</surname><given-names>Michael R.</given-names></name>
        <name><surname>Lee</surname><given-names>Gregory L.</given-names></name>
        <name><surname>Moody</surname><given-names>Adam</given-names></name>
        <name><surname>Supinski</surname><given-names>Bronis R. de</given-names></name>
        <name><surname>Futral</surname><given-names>Scott</given-names></name>
      </person-group>
      <article-title>The Spack package manager: Bringing order to HPC software chaos</article-title>
      <publisher-name>IEEE Computer Society</publisher-name>
      <year iso-8601-date="2015-11-01">2015</year><month>11</month><day>01</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-05-23">2024</year><month>05</month><day>23</day></date-in-citation>
      <isbn>978-1-4503-3723-6</isbn>
      <issn>2167-4337</issn>
      <uri>https://www.computer.org/csdl/proceedings-article/sc/2015/2807623/12OmNBf94Xq</uri>
      <pub-id pub-id-type="doi">10.1145/2807591.2807623</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-piazzolaSparseGridsMatlab2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Piazzola</surname><given-names>Chiara</given-names></name>
        <name><surname>Tamellini</surname><given-names>Lorenzo</given-names></name>
      </person-group>
      <article-title>Algorithm 1040: The sparse grids Matlab kit - a Matlab implementation of sparse grids for high-dimensional function approximation and uncertainty quantification</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <year iso-8601-date="2024">2024</year>
      <volume>50</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1145/3630023</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-brizardFoundationsNonlinearGyrokinetic2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Brizard</surname><given-names>Alain J.</given-names></name>
        <name><surname>Hahm</surname><given-names>Taik Soo</given-names></name>
      </person-group>
      <article-title>Foundations of nonlinear gyrokinetic theory</article-title>
      <source>Reviews of modern physics</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2007">2007</year>
      <volume>79</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1103/revmodphys.79.421</pub-id>
      <fpage>421</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-einkemmerMassMomentumEnergy2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Einkemmer</surname><given-names>Lukas</given-names></name>
        <name><surname>Joseph</surname><given-names>Ilon</given-names></name>
      </person-group>
      <article-title>A mass, momentum, and energy conservative dynamical low-rank scheme for the Vlasov equation</article-title>
      <source>Journal of Computational Physics</source>
      <year iso-8601-date="2021-10-15">2021</year><month>10</month><day>15</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-25">2023</year><month>09</month><day>25</day></date-in-citation>
      <volume>443</volume>
      <issn>0021-9991</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0021999121003909</uri>
      <pub-id pub-id-type="doi">10.1016/j.jcp.2021.110495</pub-id>
      <fpage>110495</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-TheSparseGridsMatlabKit">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Tamellini</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Piazzola</surname><given-names>Chiara</given-names></name>
        <name><surname>Nobile</surname><given-names>Fabio</given-names></name>
        <name><surname>Sprungk</surname><given-names>Björn</given-names></name>
        <name><surname>Porta</surname><given-names>Giovanni</given-names></name>
        <name><surname>Guignard</surname><given-names>Diane</given-names></name>
        <name><surname>Tesei</surname><given-names>Francesco</given-names></name>
      </person-group>
      <article-title>The sparse grids Matlab kit</article-title>
      <year iso-8601-date="2024-12-19">2024</year><month>12</month><day>19</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-12-19">2024</year><month>12</month><day>19</day></date-in-citation>
      <uri>https://sites.google.com/view/sparse-grids-kit/home</uri>
    </element-citation>
  </ref>
  <ref id="ref-verboncoeurParticleSimulationPlasmas2005">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Verboncoeur</surname><given-names>John P.</given-names></name>
      </person-group>
      <article-title>Particle simulation of plasmas: Review and advances</article-title>
      <source>Plasma Physics and Controlled Fusion</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-12-04">2024</year><month>12</month><day>04</day></date-in-citation>
      <volume>47</volume>
      <uri>https://iopscience.iop.org/article/10.1088/0741-3335/47/5A/017/meta?casa_token=aElJiSgwIgcAAAAA:xrmEQjmliSWfz_8HcmH7scqGnsFqepsQEqxMBxI-q8uEAvsFo6MSKB46NsoEgCI-oC1k3A3K9z8tyHKEtLsYUptMhe8gWQ</uri>
      <pub-id pub-id-type="doi">10.1088/0741-3335/47/5a/017</pub-id>
      <fpage>A231</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-SGpp">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>SG++ development team</string-name>
      </person-group>
      <article-title>SGpp</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-12-10">2024</year><month>12</month><day>10</day></date-in-citation>
      <uri>https://github.com/SGpp/SGpp</uri>
    </element-citation>
  </ref>
  <ref id="ref-sparseSpACE">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Obersteiner</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>sparseSpACE - the sparse grid spatially adaptive combination environment</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-08-07">2023</year><month>08</month><day>07</day></date-in-citation>
      <uri>https://github.com/obersteiner/sparseSpACE</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
