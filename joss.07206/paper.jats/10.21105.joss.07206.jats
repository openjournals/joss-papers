<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7206</article-id>
<article-id pub-id-type="doi">10.21105/joss.07206</article-id>
<title-group>
<article-title>StreamGen: a Python framework for generating streams of
labeled data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1477-1327</contrib-id>
<name>
<surname>Farthofer</surname>
<given-names>Laurenz A.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>KAI - Kompetenzzentrum Automobil- und Industrieelektronik
GmbH, Austria</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Institute of Computer Graphics and Vision, Graz University
of Technology, Austria</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-08-19">
<day>19</day>
<month>8</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>104</issue>
<fpage>7206</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Data Generation</kwd>
<kwd>Synthetic Data</kwd>
<kwd>Data Streams</kwd>
<kwd>Continual Learning</kwd>
<kwd>Function Composition</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<fig>
  <caption><p>A tree of sampling functions and transformations as a new
  data structure and framework for synthetic data generation. Samples
  are generated by traversing the tree from the root to the leaves. Each
  path through the tree represents its own class-conditional
  distribution. The branching points represent categorical distributions
  which determine the path to take for a sample during the tree
  traversal. By changing the parameters of the transformations over
  time, such trees can represent evolving distributions suitable to
  generate data streams (see
  <xref alt="[fig:parameter_schedule]" rid="figU003Aparameter_schedule">[fig:parameter_schedule]</xref>).<styled-content id="figU003Asampling_tree"></styled-content></p></caption>
  <graphic mimetype="image" mime-subtype="png" xlink:href="sampling_tree.png" />
</fig>
<sec id="summary">
  <title>Summary</title>
  <p>StreamGen is a framework for generating streams of labeled,
  synthetic data from trees composed of sampling functions and
  transformation monoids (see
  <xref alt="[fig:sampling_tree]" rid="figU003Asampling_tree">[fig:sampling_tree]</xref>).</p>
  <p>Due to the expensive nature of the labelling process, researchers
  and machine learning practitioners often rely on existing datasets and
  stochastic data augmentation pipelines like
  <monospace>torchvision.transforms.Compose</monospace> objects
  (<xref alt="TorchVision maintainers and contributors, 2016" rid="ref-torchvision2016" ref-type="bibr">TorchVision
  maintainers and contributors, 2016</xref>). While such methods and
  datasets are appropriate to study learning from static domains,
  emerging research fields like continual learning study learning on
  long streams of data, representing evolving experiences. StreamGen
  addresses this need by giving researchers a tool to model
  time-dependent, diverse class-conditional distributions.</p>
  <p>Such distributions can be represented through the use of a
  <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree</ext-link>
  data structure (or other more general linked structures like directed
  acyclic graphs) to store sampling functions and transformations.
  Samples are generated by traversing the tree from the root to the
  leaves. Each branching point represents a categorical distribution
  which determines the path to take for a sample during the tree
  traversal. This information can be utilized for automating the
  annotation process.</p>
  <p>Such a tree comprised of fixed transformations represents a static,
  class-conditional distribution. In order to extend the framework to
  evolving distributions (streams), either the <bold>parameters</bold>
  of the stochastic transformations or the <bold>topology</bold> of the
  tree needs to be changed over time (see
  <xref alt="[fig:parameter_schedule]" rid="figU003Aparameter_schedule">[fig:parameter_schedule]</xref>).
  Due to the complexity of designing and reasoning about evolving
  topologies, the first release of StreamGen (version 1.0) focuses on
  static tree topologies and only schedules the parameters of the
  transformations and the probabilities of the branching points.</p>
  <p>StreamGen implements the following <bold>abstractions</bold> and
  utility functions to design data streams:</p>
  <list list-type="bullet">
    <list-item>
      <p>Classes and functions to construct, schedule and visualize
      time-dependent parameters</p>
    </list-item>
    <list-item>
      <p>A selection of custom nodes based on the
      <monospace>NodeMixin</monospace> from
      <ext-link ext-link-type="uri" xlink:href="https://github.com/c0fec0de/anytree">anytree</ext-link>
      (<xref alt="c0fec0de, 2016" rid="ref-c0fec0de_anytree_2016" ref-type="bibr">c0fec0de,
      2016</xref>)</p>
    </list-item>
    <list-item>
      <p>A <monospace>SamplingTree</monospace> class with:</p>
      <list list-type="bullet">
        <list-item>
          <p>A pythonic short-hand construction via nested lists and
          dictionaries</p>
        </list-item>
        <list-item>
          <p>Parameter scheduling and configuration of all nodes via one
          <monospace>update()</monospace> call</p>
        </list-item>
        <list-item>
          <p>Multiple sampling strategies (stochastic traversal,
          stratified, pruned)</p>
        </list-item>
        <list-item>
          <p>Visualizations using
          <ext-link ext-link-type="uri" xlink:href="https://www.graphviz.org/">graphviz</ext-link>
          (<xref alt="Gansner &amp; North, 1997" rid="ref-gansner_open_1997" ref-type="bibr">Gansner
          &amp; North, 1997</xref>)</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p>Stream abstraction to use datasets created with StreamGen in CL
      frameworks like
      <ext-link ext-link-type="uri" xlink:href="https://github.com/ContinualAI/avalanche">avalanche</ext-link>
      (<xref alt="Lomonaco et al., 2021" rid="ref-lomonaco_avalanche_2021" ref-type="bibr">Lomonaco
      et al., 2021</xref>) or
      <ext-link ext-link-type="uri" xlink:href="https://github.com/Continvvm/continuum">continuum</ext-link>
      (<xref alt="Douillard &amp; Lesort, 2021" rid="ref-douillard_continuum_2021" ref-type="bibr">Douillard
      &amp; Lesort, 2021</xref>)</p>
    </list-item>
  </list>
  <p>The documentation also contains different stream generation
  examples:</p>
  <list list-type="order">
    <list-item>
      <p>Multi-class time series with different data drifts (covariate,
      prior-probability and concept shift)</p>
    </list-item>
    <list-item>
      <p>An analog version of the WM811k dataset
      (<xref alt="Wu et al., 2015" rid="ref-wu_wafer_2015" ref-type="bibr">Wu
      et al., 2015</xref>) (binary images) with covariate shift for
      Domain Adaptation research</p>
    </list-item>
    <list-item>
      <p>A defect density wafer map dataset with geometrically generated
      patterns</p>
    </list-item>
  </list>
  <fig>
    <caption><p>Changes in the topology of the tree of transformations
    are one possibility to represent evolving (time-dependent)
    distributions with different data drift scenarios.
    <styled-content id="figU003Aparameter_schedule"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="data_drifts_by_topology_changes.png" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Most machine learning systems rely on <italic>stationary, labeled,
  balanced and large-scale</italic> datasets. <bold>Incremental
  learning</bold> (IL), also referred to as <bold>lifelong
  learning</bold> (LL) or <bold>continual learning</bold> (CL), extends
  the traditional paradigm to dynamic and evolving environments, where
  learners need to acquire knowledge continually from a stream of
  experiences (as opposed to learning those concepts jointly from a
  single dataset) without forgetting concepts from past experiences â€” a
  phenomenon referred to as catastrophic forgetting
  (<xref alt="Masana et al., 2023" rid="ref-masana_class-incremental_2022" ref-type="bibr">Masana
  et al., 2023</xref>).</p>
  <p>Existing CL frameworks like
  <ext-link ext-link-type="uri" xlink:href="https://github.com/ContinualAI/avalanche">avalanche</ext-link>
  (<xref alt="Lomonaco et al., 2021" rid="ref-lomonaco_avalanche_2021" ref-type="bibr">Lomonaco
  et al., 2021</xref>) or
  <ext-link ext-link-type="uri" xlink:href="https://github.com/Continvvm/continuum">continuum</ext-link>
  (<xref alt="Douillard &amp; Lesort, 2021" rid="ref-douillard_continuum_2021" ref-type="bibr">Douillard
  &amp; Lesort, 2021</xref>) construct data streams by
  <italic>splitting</italic> large classification datasets into multiple
  <italic>experiences</italic> containing different classes
  (class-incremental learning), which has a few shortcomings:</p>
  <list list-type="bullet">
    <list-item>
      <p>Data streams from real environments are rarely comprised of
      disjoint experiences</p>
    </list-item>
    <list-item>
      <p>Such constructed scenarios offer limited insight into factors
      of the stream other than the class distribution, which are
      required to study learning scenarios with fewer constraints on the
      stream properties like domain adaptation or class-incremental
      scenarios with repetition. Some researchers even argue that the
      dominance of class-incremental scenarios has lead to the proposal
      of several rather complex methods, that completely fail in more
      realistic, unconstrained scenarios with repetition
      (<xref alt="Cossu et al., 2022" rid="ref-cossu_is_2021" ref-type="bibr">Cossu
      et al., 2022</xref>)</p>
    </list-item>
    <list-item>
      <p>The evaluation of continual learners on such scenarios is not
      trivial as evident by the wealth of proposals
      (<xref alt="Ven et al., 2024" rid="ref-van_de_ven_continual_2024" ref-type="bibr">Ven
      et al., 2024</xref>)</p>
    </list-item>
  </list>
  <p>To answer different research questions in the field of CL,
  researchers need knowledge and control over a variety of factors of
  the underlying data distribution including:</p>
  <list list-type="bullet">
    <list-item>
      <p>Class distributions</p>
    </list-item>
    <list-item>
      <p>Novelties and outliers</p>
    </list-item>
    <list-item>
      <p>Complexity and evolution of the background domain</p>
    </list-item>
    <list-item>
      <p>Semantics of the unlabeled parts of a domain</p>
    </list-item>
    <list-item>
      <p>Class dependencies and composition (for multi-label
      learning)</p>
    </list-item>
  </list>
  <p>A more economical alternative to collecting and labelling streams
  with desired properties is the <bold>generation</bold> of synthetic
  streams
  (<xref alt="Lu et al., 2018" rid="ref-lu_learning_2018" ref-type="bibr">Lu
  et al., 2018</xref>). Some mentionable efforts in that direction
  include augmentation based dataset generation like
  <ext-link ext-link-type="uri" xlink:href="https://github.com/hendrycks/robustness">ImageNet-C</ext-link>
  (<xref alt="Hendrycks &amp; Dietterich, 2018" rid="ref-hendrycks_benchmarking_2019" ref-type="bibr">Hendrycks
  &amp; Dietterich, 2018</xref>) or simulation-based approaches like the
  <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2106.02585">EndlessCLSim</ext-link>
  (<xref alt="Hess et al., 2021" rid="ref-hess_procedural_2021" ref-type="bibr">Hess
  et al., 2021</xref>), where semantically labeled street-view images
  are generated by a game engine, that procedurally generates the city
  environment and simulates drift by modifying parameters (like the
  weather and illumination conditions) over time.</p>
  <p>StreamGen builds on these ideas and provides researchers with a
  general and intuitive framework to generate data streams without
  constraints on the stream characteristics and the full knowledge of
  underlying distributions and parameters. It will lay the foundation
  for more directed and efficient research on Continual Learning.</p>
</sec>
<sec id="future-work">
  <title>Future work</title>
  <p>The generation of multi-label samples requires loops and cycles for
  a compact and convenient representation. Such scenarios are still
  representable with tree data structures by unrolling these cycles
  through many redundant paths and transformations. A representation
  using less restricted types of graphs presents an interesting future
  extension to the framework. StreamGen already defines protocols and
  base classes to include different sampler concepts in the future. More
  declarative ways to build schedules and distributions represent other
  promising extensions.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was funded by the Austrian Research Promotion Agency
  (FFG, Project No.Â 905107).</p>
  <p>Special thanks to Benjamin Steinwender, Marius Birkenbach, Nikolaus
  Neugebauer, Matthew Feickert, Hoang Anh Ngo and Iztok Fister Jr.Â for
  their valuable feedback. I also want to thank Infineon and KAI for
  letting me publish this project under a permissive and open license.
  Finally, I want to thank my university supervisors Thomas Pock and
  Marc Masana for their guidance and trust in me and my visions.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-masana_class-incremental_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Masana</surname><given-names>Marc</given-names></name>
        <name><surname>Liu</surname><given-names>Xialei</given-names></name>
        <name><surname>Twardowski</surname><given-names>BartÅ‚omiej</given-names></name>
        <name><surname>Menta</surname><given-names>Mikel</given-names></name>
        <name><surname>Bagdanov</surname><given-names>Andrew D.</given-names></name>
        <name><surname>van de Weijer</surname><given-names>Joost</given-names></name>
      </person-group>
      <article-title>Class-Incremental Learning: Survey and Performance Evaluation on Image Classification</article-title>
      <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
      <year iso-8601-date="2023-05">2023</year><month>05</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-10-08">2024</year><month>10</month><day>08</day></date-in-citation>
      <volume>45</volume>
      <issue>5</issue>
      <issn>1939-3539</issn>
      <uri>https://ieeexplore.ieee.org/document/9915459</uri>
      <pub-id pub-id-type="doi">10.1109/TPAMI.2022.3213473</pub-id>
      <fpage>5513</fpage>
      <lpage>5533</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lu_learning_2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lu</surname><given-names>Jie</given-names></name>
        <name><surname>Liu</surname><given-names>Anjin</given-names></name>
        <name><surname>Dong</surname><given-names>Fan</given-names></name>
        <name><surname>Gu</surname><given-names>Feng</given-names></name>
        <name><surname>Gama</surname><given-names>Joao</given-names></name>
        <name><surname>Zhang</surname><given-names>Guangquan</given-names></name>
      </person-group>
      <article-title>Learning under Concept Drift: A Review</article-title>
      <source>IEEE Transactions on Knowledge and Data Engineering</source>
      <year iso-8601-date="2018">2018</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-08-07">2023</year><month>08</month><day>07</day></date-in-citation>
      <issn>1041-4347</issn>
      <uri>http://arxiv.org/abs/2004.05785</uri>
      <pub-id pub-id-type="doi">10.1109/TKDE.2018.2876857</pub-id>
      <fpage>1</fpage>
      <lpage>1</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hess_procedural_2021">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hess</surname><given-names>Timm</given-names></name>
        <name><surname>Mundt</surname><given-names>Martin</given-names></name>
        <name><surname>Pliushch</surname><given-names>Iuliia</given-names></name>
        <name><surname>Ramesh</surname><given-names>Visvanathan</given-names></name>
      </person-group>
      <article-title>A Procedural World Generation Framework for Systematic Evaluation of Continual Learning</article-title>
      <year iso-8601-date="2021-06-08">2021</year><month>06</month><day>08</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-10-08">2024</year><month>10</month><day>08</day></date-in-citation>
      <uri>https://openreview.net/forum?id=LlCQWh8-pwK</uri>
    </element-citation>
  </ref>
  <ref id="ref-cossu_is_2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cossu</surname><given-names>Andrea</given-names></name>
        <name><surname>Graffieti</surname><given-names>Gabriele</given-names></name>
        <name><surname>Pellegrini</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Maltoni</surname><given-names>Davide</given-names></name>
        <name><surname>Bacciu</surname><given-names>Davide</given-names></name>
        <name><surname>Carta</surname><given-names>Antonio</given-names></name>
        <name><surname>Lomonaco</surname><given-names>Vincenzo</given-names></name>
      </person-group>
      <article-title>Is Class-Incremental Enough for Continual Learning?</article-title>
      <source>Frontiers in Artificial Intelligence</source>
      <publisher-name>Frontiers</publisher-name>
      <year iso-8601-date="2022-03-24">2022</year><month>03</month><day>24</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-10-08">2024</year><month>10</month><day>08</day></date-in-citation>
      <volume>5</volume>
      <issn>2624-8212</issn>
      <uri>https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.829842/full</uri>
      <pub-id pub-id-type="doi">10.3389/frai.2022.829842</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wu_wafer_2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Ming-Ju</given-names></name>
        <name><surname>Jang</surname><given-names>Jyh-Shing R.</given-names></name>
        <name><surname>Chen</surname><given-names>Jui-Long</given-names></name>
      </person-group>
      <article-title>Wafer Map Failure Pattern Recognition and Similarity Ranking for Large-Scale Data Sets</article-title>
      <source>IEEE Transactions on Semiconductor Manufacturing</source>
      <year iso-8601-date="2015-02">2015</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-01-30">2024</year><month>01</month><day>30</day></date-in-citation>
      <volume>28</volume>
      <issue>1</issue>
      <issn>1558-2345</issn>
      <uri>https://ieeexplore.ieee.org/document/6932449</uri>
      <pub-id pub-id-type="doi">10.1109/TSM.2014.2364237</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-van_de_ven_continual_2024">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ven</surname><given-names>Gido M. van de</given-names></name>
        <name><surname>Soures</surname><given-names>Nicholas</given-names></name>
        <name><surname>Kudithipudi</surname><given-names>Dhireesha</given-names></name>
      </person-group>
      <article-title>Continual Learning and Catastrophic Forgetting</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2024-03">2024</year><month>03</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-03-15">2024</year><month>03</month><day>15</day></date-in-citation>
      <uri>http://arxiv.org/abs/2403.05175</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2403.05175</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lomonaco_avalanche_2021">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lomonaco</surname><given-names>Vincenzo</given-names></name>
        <name><surname>Pellegrini</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Cossu</surname><given-names>Andrea</given-names></name>
        <name><surname>Carta</surname><given-names>Antonio</given-names></name>
        <name><surname>Graffieti</surname><given-names>Gabriele</given-names></name>
        <name><surname>Hayes</surname><given-names>Tyler L.</given-names></name>
        <name><surname>De Lange</surname><given-names>Matthias</given-names></name>
        <name><surname>Masana</surname><given-names>Marc</given-names></name>
        <name><surname>Pomponi</surname><given-names>Jary</given-names></name>
        <name><surname>Van De Ven</surname><given-names>Gido M.</given-names></name>
        <name><surname>Mundt</surname><given-names>Martin</given-names></name>
        <name><surname>She</surname><given-names>Qi</given-names></name>
        <name><surname>Cooper</surname><given-names>Keiland</given-names></name>
        <name><surname>Forest</surname><given-names>Jeremy</given-names></name>
        <name><surname>Belouadah</surname><given-names>Eden</given-names></name>
        <name><surname>Calderara</surname><given-names>Simone</given-names></name>
        <name><surname>Parisi</surname><given-names>German I.</given-names></name>
        <name><surname>Cuzzolin</surname><given-names>Fabio</given-names></name>
        <name><surname>Tolias</surname><given-names>Andreas S.</given-names></name>
        <name><surname>Scardapane</surname><given-names>Simone</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Ahmad</surname><given-names>Subutai</given-names></name>
        <name><surname>Popescu</surname><given-names>Adrian</given-names></name>
        <name><surname>Kanan</surname><given-names>Christopher</given-names></name>
        <name><surname>Van De Weijer</surname><given-names>Joost</given-names></name>
        <name><surname>Tuytelaars</surname><given-names>Tinne</given-names></name>
        <name><surname>Bacciu</surname><given-names>Davide</given-names></name>
        <name><surname>Maltoni</surname><given-names>Davide</given-names></name>
      </person-group>
      <article-title>Avalanche: An End-to-End Library for Continual Learning</article-title>
      <source>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</source>
      <publisher-name>IEEE</publisher-name>
      <publisher-loc>Nashville, TN, USA</publisher-loc>
      <year iso-8601-date="2021-06">2021</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-03-18">2024</year><month>03</month><day>18</day></date-in-citation>
      <isbn>978-1-66544-899-4</isbn>
      <uri>https://ieeexplore.ieee.org/document/9523188/</uri>
      <pub-id pub-id-type="doi">10.1109/CVPRW53098.2021.00399</pub-id>
      <fpage>3595</fpage>
      <lpage>3605</lpage>
    </element-citation>
  </ref>
  <ref id="ref-douillard_continuum_2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Douillard</surname><given-names>Arthur</given-names></name>
        <name><surname>Lesort</surname><given-names>TimothÃ©e</given-names></name>
      </person-group>
      <article-title>Continuum: Simple Management of Complex Continual Learning Scenarios</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2021-02">2021</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-03-18">2024</year><month>03</month><day>18</day></date-in-citation>
      <uri>http://arxiv.org/abs/2102.06253</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2102.06253</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hendrycks_benchmarking_2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hendrycks</surname><given-names>Dan</given-names></name>
        <name><surname>Dietterich</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>Benchmarking Neural Network Robustness to Common Corruptions and Perturbations</article-title>
      <year iso-8601-date="2018-09-27">2018</year><month>09</month><day>27</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-10-08">2024</year><month>10</month><day>08</day></date-in-citation>
      <uri>https://openreview.net/forum?id=HJz6tiCqYm</uri>
    </element-citation>
  </ref>
  <ref id="ref-torchvision2016">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>TorchVision maintainers and contributors</string-name>
      </person-group>
      <article-title>TorchVision: PyTorchâ€™s Computer Vision library</article-title>
      <year iso-8601-date="2016-11">2016</year><month>11</month>
      <uri>https://github.com/pytorch/vision</uri>
    </element-citation>
  </ref>
  <ref id="ref-c0fec0de_anytree_2016">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>c0fec0de</string-name>
      </person-group>
      <article-title>Anytree: Python tree data library</article-title>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <uri>https://github.com/c0fec0de/anytree</uri>
    </element-citation>
  </ref>
  <ref id="ref-gansner_open_1997">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gansner</surname><given-names>Emden</given-names></name>
        <name><surname>North</surname><given-names>Stephen</given-names></name>
      </person-group>
      <article-title>An Open Graph Visualization System and Its Applications to Software Engineering</article-title>
      <source>Software - Practice and Experience - SPE</source>
      <year iso-8601-date="1997-01">1997</year><month>01</month>
      <volume>30</volume>
      <pub-id pub-id-type="doi">10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.0.CO;2-N</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
