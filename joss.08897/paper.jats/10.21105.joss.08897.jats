<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8897</article-id>
<article-id pub-id-type="doi">10.21105/joss.08897</article-id>
<title-group>
<article-title>MDPax: GPU-accelerated MDP solvers in Python with
JAX</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4156-3419</contrib-id>
<name>
<surname>Farrington</surname>
<given-names>Joseph</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5742-0108</contrib-id>
<name>
<surname>Wong</surname>
<given-names>Wai Keong</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3073-3128</contrib-id>
<name>
<surname>Li</surname>
<given-names>Kezhi</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9928-1516</contrib-id>
<name>
<surname>Utley</surname>
<given-names>Martin</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institute of Health Informatics, University College London,
United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>NIHR University College London Hospitals Biomedical
Research Centre, United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Cambridge University Hospitals NHS Foundation Trust, United
Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Clinical Operational Research Unit, University College
London, United Kingdom</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-10-30">
<day>30</day>
<month>10</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>8897</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>optimization</kwd>
<kwd>dynamic programming</kwd>
<kwd>reinforcement learning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>MDPax is a Python library for solving large-scale Markov decision
  processes (MDPs), leveraging JAX’s
  (<xref alt="Bradbury et al., 2022" rid="ref-bradbury_jax_2022" ref-type="bibr">Bradbury
  et al., 2022</xref>) support for vectorization, parallelization, and
  just-in-time (JIT) compilation on graphics processing units (GPUs). It
  includes GPU-accelerated implementations of standard algorithms
  including value iteration and policy iteration
  (<xref alt="Sutton &amp; Barto, 2018" rid="ref-sutton_reinforcement_2018" ref-type="bibr">Sutton
  &amp; Barto, 2018</xref>).</p>
  <p>MDPs describe sequential decision-making problems in which, at each
  timestep, an agent observes the current state of its environment,
  selects an action, transitions to a new state by taking the selected
  action, and receives a reward. The goal is to find a policy (a mapping
  from observed states to actions) that maximizes the expected long-term
  reward, accounting for both the immediate and future consequences of
  actions. MDPs have been used to model a wide range of problems,
  including medical treatment planning
  (<xref alt="Schaefer et al., 2004" rid="ref-schaefer_modeling_2004" ref-type="bibr">Schaefer
  et al., 2004</xref>), traffic light control
  (<xref alt="Haijema et al., 2017" rid="ref-haijema_dynamic_2017" ref-type="bibr">Haijema
  et al., 2017</xref>), financial portfolio management
  (<xref alt="Bäuerle &amp; Rieder, 2011" rid="ref-bauerle_markov_2011" ref-type="bibr">Bäuerle
  &amp; Rieder, 2011</xref>), and conservation policy
  (<xref alt="Nicol et al., 2010" rid="ref-nicol_conservation_2010" ref-type="bibr">Nicol
  et al., 2010</xref>).</p>
  <p>Exact solution methods based on dynamic programming scale poorly
  due to the curse of dimensionality
  (<xref alt="Bellman, 1957" rid="ref-bellman_dynamic_1957" ref-type="bibr">Bellman,
  1957</xref>): the number of states can grow exponentially with problem
  parameters, quickly making computation very challenging. Deep
  reinforcement learning has proven to be very effective at finding
  approximate solutions for large problems
  (<xref alt="Arulkumaran et al., 2017" rid="ref-arulkumaran_deep_2017" ref-type="bibr">Arulkumaran
  et al., 2017</xref>), but exact solutions remain valuable both in
  their own right and for benchmarking approximate methods.</p>
  <p>The exact algorithms are well suited to parallel execution, and
  modern GPUs have thousands of processing cores over which updates can
  be effectively distributed. By building on JAX, MDPax makes it easy to
  take advantage of this hardware through a high-level Python API,
  enabling researchers and practitioners to solve problems with millions
  of states without needing expertise in GPU programming.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>MDPax was originally developed to support our work on perishable
  inventory management. Solving these problems exactly requires
  accounting not just for total inventory levels, but also for the age
  profile of the stock. As a result, the state space grows exponentially
  with the product’s maximum useful life, making realistic problem
  instances extremely large. Although many MDP solvers exist, exact
  methods are widely considered impractical or infeasible for
  realistically sized perishable inventory problems
  (<xref alt="Abouee-Mehrizi et al., 2025" rid="ref-abouee-mehrizi_platelet_2025" ref-type="bibr">Abouee-Mehrizi
  et al., 2025</xref>;
  <xref alt="De Moor et al., 2022" rid="ref-de_moor_reward_2022" ref-type="bibr">De
  Moor et al., 2022</xref>;
  <xref alt="Hendrix et al., 2019" rid="ref-hendrix_computing_2019" ref-type="bibr">Hendrix
  et al., 2019</xref>;
  <xref alt="Nahmias, 1982" rid="ref-nahmias_perishable_1982" ref-type="bibr">Nahmias,
  1982</xref>).</p>
  <p>Implementations of exact solution methods face two main challenges
  when applied to large MDPs:</p>
  <list list-type="bullet">
    <list-item>
      <p>Memory requirements: The full transition matrix describing the
      dynamics of the problem grows quadratically with the number of
      states and linearly with the number of actions, making it
      infeasible to store and process for large problems.</p>
    </list-item>
    <list-item>
      <p>Computational complexity: The core operations involve nested
      loops over states, actions, and successor states, which become
      prohibitively expensive as the state space grows.</p>
    </list-item>
  </list>
  <p>Most existing MDP libraries run exclusively on CPUs. MDPtoolbox
  (<xref alt="Chadès et al., 2014" rid="ref-chades_mdptoolbox_2014" ref-type="bibr">Chadès
  et al., 2014</xref>) provides exact solution algorithms across Python
  (<xref alt="Cordwell, 2015" rid="ref-cordwell_pymdptoolbox_2015" ref-type="bibr">Cordwell,
  2015</xref>), MATLAB
  (<xref alt="Cros, 2015" rid="ref-cros_markov_2015" ref-type="bibr">Cros,
  2015</xref>), and R
  (<xref alt="Chadès et al., 2017" rid="ref-chades_mdptoolbox_2017" ref-type="bibr">Chadès
  et al., 2017</xref>), but offers no support for parallelism or GPU
  acceleration. Two more recent Python libraries, MDPSolver
  (<xref alt="Andersen &amp; Andersen, 2025" rid="ref-andersen_mdpsolver_2025" ref-type="bibr">Andersen
  &amp; Andersen, 2025</xref>) and madupite
  (<xref alt="Gargiani et al., 2025" rid="ref-gargiani_madupite_2025" ref-type="bibr">Gargiani
  et al., 2025</xref>), aim to improve performance on large problems by
  implementing their solvers in C++ with CPU-based parallelism. In
  addition, madupite provides a broader set of inexact policy iteration
  methods to support solving larger problems. For Julia, POMDPs.jl
  (<xref alt="Egorov et al., 2017" rid="ref-egorov_pomdpsjl_2017" ref-type="bibr">Egorov
  et al., 2017</xref>) provides a flexible interface for specifying MDPs
  and supports a wide range of CPU-based solvers.</p>
  <p>The benefits of GPU-acceleration for exact methods have been
  demonstrated in the literature
  (<xref alt="Jóhannsson, 2009" rid="ref-johannsson_gpu-based_2009" ref-type="bibr">Jóhannsson,
  2009</xref>;
  <xref alt="Ortega et al., 2019" rid="ref-ortega_cuda_2019" ref-type="bibr">Ortega
  et al., 2019</xref>;
  <xref alt="Sargent &amp; Stachurski, 2025" rid="ref-sargent_quantitative_2025" ref-type="bibr">Sargent
  &amp; Stachurski, 2025</xref>), but remain uncommon in practice. We
  suggest this is due to the perceived complexity of GPU programming and
  the limited availability of researcher-friendly software that provides
  GPU-accelerated solvers. The VFI Toolkit for MATLAB
  (<xref alt="Kirkby, 2017" rid="ref-kirkby_toolkit_2017" ref-type="bibr">Kirkby,
  2017</xref>) supports GPU-acceleration but requires users to provide
  the full transition matrix, which becomes infeasible for large
  problems due to memory constraints.</p>
  <p>MDPax addresses the memory challenge by requiring users to provide
  a deterministic transition function instead of the full transition
  matrix (similar to the approach used in POMDPs.jl). This function maps
  a state, action, and random event to the resulting next state and
  reward, and is used to dynamically compute the next state and reward
  on demand. MDPax uses JAX to exploit the massive parallel processing
  capabilities of modern GPUs, significantly reducing the runtime
  required for solving large MDPs by calculating value updates for
  batches of states in parallel.</p>
  <p>MDPax has been developed to solve large MDPs with millions of
  states. For small to medium-sized MDPs, MDPax may be slower than
  existing CPU-based packages due to the overheads introduced by the use
  of JAX and GPUs, including JIT compilation and data transfer between
  the host and GPU(s). For large problems, these overheads are
  outweighed by substantial performance gains.</p>
  <p>An early version of MDPax was used in our work to solve large
  instances of three perishable inventory problems that had previously
  been described as infeasible or impractical to solve exactly
  (<xref alt="Farrington et al., 2025" rid="ref-farrington_going_2025" ref-type="bibr">Farrington
  et al., 2025</xref>). In one case, the original study reported that
  value iteration using a CPU-based MATLAB implementation failed to
  converge within a week on an MDP with over 16 million states
  (<xref alt="Hendrix et al., 2019" rid="ref-hendrix_computing_2019" ref-type="bibr">Hendrix
  et al., 2019</xref>). Using MDPax, the same algorithm consistently
  converged in under 3.5 hours on a consumer-grade GPU (based on 10 runs
  using an Nvidia GeForce RTX 3060 GPU, Python 3.12.4 and JAX 0.5.0).
  The runtime can be further reduced without any code changes using
  multiple data-centre-grade GPUs
  (<xref alt="Farrington et al., 2025" rid="ref-farrington_going_2025" ref-type="bibr">Farrington
  et al., 2025</xref>).</p>
</sec>
<sec id="features-and-design">
  <title>Features and design</title>
  <p>MDPax is structured around two core classes: the Problem and the
  Solver.</p>
  <p>The Problem class represents an MDP and is intended to be
  subclassed by users. To define a custom problem, users implement
  methods that specify the sets of states and actions, random events and
  their probabilities, and a deterministic transition function that maps
  a (state, action, random event) triple to the next state and
  corresponding reward. MDPax includes four example Problems: a forest
  management problem adapted from pymdptoolbox
  (<xref alt="Cordwell, 2015" rid="ref-cordwell_pymdptoolbox_2015" ref-type="bibr">Cordwell,
  2015</xref>) and three perishable inventory problems from the
  literature
  (<xref alt="Abouee-Mehrizi et al., 2025" rid="ref-abouee-mehrizi_platelet_2025" ref-type="bibr">Abouee-Mehrizi
  et al., 2025</xref>;
  <xref alt="De Moor et al., 2022" rid="ref-de_moor_reward_2022" ref-type="bibr">De
  Moor et al., 2022</xref>;
  <xref alt="Hendrix et al., 2019" rid="ref-hendrix_computing_2019" ref-type="bibr">Hendrix
  et al., 2019</xref>).</p>
  <p>The Solver class defines a common framework for implementing
  dynamic programming methods to solve MDPs. MDPax currently includes
  implementations of three standard algorithms: value iteration,
  relative value iteration (to optimize the average reward), and policy
  iteration. It also provides a variant of value iteration for MDPs with
  periodic dynamics (e.g., when demand depends on the day of the week),
  and a semi-asynchronous version in which updated values for each batch
  of states are made available for subsequent batch updates within the
  same iteration on the same device.</p>
  <p>For large problems, solving an MDP can still be time-consuming.
  MDPax therefore includes checkpointing functionality using Orbax
  (<xref alt="Gaffney et al., 2025" rid="ref-gaffney_orbax_2025" ref-type="bibr">Gaffney
  et al., 2025</xref>), enabling users to save and restore the state of
  the Solver and resume optimization after an interruption.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>JF was funded by UKRI training grant EP/S021612/1, the CDT in
  AI-enabled Healthcare Systems, and the Clinical and Research
  Informatics Unit at the NIHR University College London Hospitals
  Biomedical Research Centre.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-sutton_reinforcement_2018">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Sutton</surname><given-names>Richard S.</given-names></name>
        <name><surname>Barto</surname><given-names>Andrew G.</given-names></name>
      </person-group>
      <source>Reinforcement learning: An introduction</source>
      <publisher-name>The MIT Press</publisher-name>
      <publisher-loc>Cambridge, MA, USA</publisher-loc>
      <year iso-8601-date="2018">2018</year>
      <edition>2nd ed.</edition>
      <isbn>978-0-262-03924-6</isbn>
    </element-citation>
  </ref>
  <ref id="ref-ortega_cuda_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ortega</surname><given-names>G.</given-names></name>
        <name><surname>Hendrix</surname><given-names>Eligius MT</given-names></name>
        <name><surname>García</surname><given-names>I.</given-names></name>
      </person-group>
      <article-title>A CUDA approach to compute perishable inventory control policies using value iteration</article-title>
      <source>The Journal of Supercomputing</source>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-08-03">2022</year><month>08</month><day>03</day></date-in-citation>
      <volume>75</volume>
      <issue>3</issue>
      <issn>1573-0484</issn>
      <uri>https://doi.org/10.1007/s11227-018-2692-z</uri>
      <pub-id pub-id-type="doi">10.1007/s11227-018-2692-z</pub-id>
      <fpage>1580</fpage>
      <lpage>1593</lpage>
    </element-citation>
  </ref>
  <ref id="ref-johannsson_gpu-based_2009">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Jóhannsson</surname><given-names>Arsæll Pór</given-names></name>
      </person-group>
      <article-title>GPU-based Markov decision process solver</article-title>
      <publisher-name>Reykjavík University</publisher-name>
      <publisher-loc>Reykjavík, Iceland</publisher-loc>
      <year iso-8601-date="2009">2009</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-02-15">2023</year><month>02</month><day>15</day></date-in-citation>
      <uri>https://en.ru.is/media/skjol-td/MSThesis_ArsaellThorJohannsson.pdf</uri>
    </element-citation>
  </ref>
  <ref id="ref-farrington_going_2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Farrington</surname><given-names>Joseph</given-names></name>
        <name><surname>Wong</surname><given-names>Wai Keong</given-names></name>
        <name><surname>Li</surname><given-names>Kezhi</given-names></name>
        <name><surname>Utley</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Going faster to see further: Graphics processing unit-accelerated value iteration and simulation for perishable inventory control using JAX</article-title>
      <source>Annals of Operations Research</source>
      <year iso-8601-date="2025-03">2025</year><month>03</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-11">2025</year><month>05</month><day>11</day></date-in-citation>
      <issn>1572-9338</issn>
      <uri>https://doi.org/10.1007/s10479-025-06551-6</uri>
      <pub-id pub-id-type="doi">10.1007/s10479-025-06551-6</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-andersen_mdpsolver_2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Andersen</surname><given-names>Anders Reenberg</given-names></name>
        <name><surname>Andersen</surname><given-names>Jesper Fink</given-names></name>
      </person-group>
      <article-title>MDPSolver: An efficient solver for Markov decision processes</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2025-05">2025</year><month>05</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-23">2025</year><month>07</month><day>23</day></date-in-citation>
      <volume>10</volume>
      <issue>109</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.07544</uri>
      <pub-id pub-id-type="doi">10.21105/joss.07544</pub-id>
      <fpage>7544</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gargiani_madupite_2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gargiani</surname><given-names>Matilde</given-names></name>
        <name><surname>Pawlowsky</surname><given-names>Philip</given-names></name>
        <name><surname>Sieber</surname><given-names>Robin</given-names></name>
        <name><surname>Hapla</surname><given-names>Václav</given-names></name>
        <name><surname>Lygeros</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Madupite: A high-performance distributed solver for large-scale Markov decision processes</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2025-04">2025</year><month>04</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-23">2025</year><month>07</month><day>23</day></date-in-citation>
      <volume>10</volume>
      <issue>108</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.07411</uri>
      <pub-id pub-id-type="doi">10.21105/joss.07411</pub-id>
      <fpage>7411</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-nahmias_perishable_1982">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nahmias</surname><given-names>Steven</given-names></name>
      </person-group>
      <article-title>Perishable inventory theory: A review</article-title>
      <source>Operations Research</source>
      <year iso-8601-date="1982-08">1982</year><month>08</month>
      <volume>30</volume>
      <issue>4</issue>
      <issn>0030-364X</issn>
      <uri>http://pubsonline.informs.org/doi/abs/10.1287/opre.30.4.680</uri>
      <pub-id pub-id-type="doi">10.1287/opre.30.4.680</pub-id>
      <fpage>680</fpage>
      <lpage>708</lpage>
    </element-citation>
  </ref>
  <ref id="ref-arulkumaran_deep_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Arulkumaran</surname><given-names>Kai</given-names></name>
        <name><surname>Deisenroth</surname><given-names>Marc Peter</given-names></name>
        <name><surname>Brundage</surname><given-names>Miles</given-names></name>
        <name><surname>Bharath</surname><given-names>Anil Anthony</given-names></name>
      </person-group>
      <article-title>Deep reinforcement learning: A brief survey</article-title>
      <source>IEEE Signal Processing Magazine</source>
      <year iso-8601-date="2017-11">2017</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-06-15">2022</year><month>06</month><day>15</day></date-in-citation>
      <volume>34</volume>
      <issue>6</issue>
      <issn>1053-5888</issn>
      <uri>http://ieeexplore.ieee.org/document/8103164/</uri>
      <pub-id pub-id-type="doi">10.1109/MSP.2017.2743240</pub-id>
      <fpage>26</fpage>
      <lpage>38</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bellman_dynamic_1957">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bellman</surname><given-names>R.</given-names></name>
      </person-group>
      <source>Dynamic programming</source>
      <publisher-name>Princeton University Press</publisher-name>
      <publisher-loc>Princeton, NJ, USA</publisher-loc>
      <year iso-8601-date="1957">1957</year>
    </element-citation>
  </ref>
  <ref id="ref-de_moor_reward_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>De Moor</surname><given-names>Bram J.</given-names></name>
        <name><surname>Gijsbrechts</surname><given-names>Joren</given-names></name>
        <name><surname>Boute</surname><given-names>Robert N.</given-names></name>
      </person-group>
      <article-title>Reward shaping to improve the performance of deep reinforcement learning in perishable inventory management</article-title>
      <source>European Journal of Operational Research</source>
      <year iso-8601-date="2022-09">2022</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-07-25">2022</year><month>07</month><day>25</day></date-in-citation>
      <volume>301</volume>
      <issue>2</issue>
      <issn>0377-2217</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0377221721008948</uri>
      <pub-id pub-id-type="doi">10.1016/j.ejor.2021.10.045</pub-id>
      <fpage>535</fpage>
      <lpage>545</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kirkby_toolkit_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kirkby</surname><given-names>Robert</given-names></name>
      </person-group>
      <article-title>A toolkit for value function iteration</article-title>
      <source>Computational Economics</source>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-12-06">2022</year><month>12</month><day>06</day></date-in-citation>
      <volume>49</volume>
      <issue>1</issue>
      <issn>1572-9974</issn>
      <uri>https://doi.org/10.1007/s10614-015-9544-1</uri>
      <pub-id pub-id-type="doi">10.1007/s10614-015-9544-1</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bradbury_jax_2022">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Hawkins</surname><given-names>Peter</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew James</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Necula</surname><given-names>George</given-names></name>
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Wanderman-Milne</surname><given-names>Skye</given-names></name>
        <name><surname>Zhang</surname><given-names>Qiao</given-names></name>
      </person-group>
      <article-title>JAX: Composable transformations of Python+NumPy programs</article-title>
      <source>GitHub repository</source>
      <year iso-8601-date="2022">2022</year>
      <uri>http://github.com/google/jax</uri>
    </element-citation>
  </ref>
  <ref id="ref-hendrix_computing_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hendrix</surname><given-names>Eligius MT</given-names></name>
        <name><surname>Ortega</surname><given-names>G</given-names></name>
        <name><surname>Haijema</surname><given-names>René</given-names></name>
        <name><surname>Buisman</surname><given-names>Marjolein E</given-names></name>
        <name><surname>García</surname><given-names>Inmaculada</given-names></name>
      </person-group>
      <article-title>On computing optimal policies in perishable inventory control using value iteration</article-title>
      <source>Computational and Mathematical Methods</source>
      <year iso-8601-date="2019">2019</year>
      <volume>1</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1002/cmm4.1027</pub-id>
      <fpage>e1027</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-abouee-mehrizi_platelet_2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abouee-Mehrizi</surname><given-names>Hossein</given-names></name>
        <name><surname>Mirjalili</surname><given-names>Mahdi</given-names></name>
        <name><surname>Sarhangian</surname><given-names>Vahid</given-names></name>
      </person-group>
      <article-title>Platelet inventory management with approximate dynamic programming</article-title>
      <source>INFORMS Journal on Computing</source>
      <year iso-8601-date="2025-03">2025</year><month>03</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-23">2025</year><month>07</month><day>23</day></date-in-citation>
      <issn>1091-9856</issn>
      <uri>https://pubsonline.informs.org/doi/abs/10.1287/ijoc.2023.0245</uri>
      <pub-id pub-id-type="doi">10.1287/ijoc.2023.0245</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chades_mdptoolbox_2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chadès</surname><given-names>Iadine</given-names></name>
        <name><surname>Chapron</surname><given-names>Guillaume</given-names></name>
        <name><surname>Cros</surname><given-names>Marie‐Josée</given-names></name>
        <name><surname>Garcia</surname><given-names>Frédérick</given-names></name>
        <name><surname>Sabbadin</surname><given-names>Régis</given-names></name>
      </person-group>
      <article-title>MDPtoolbox: A multi‐platform toolbox to solve stochastic dynamic programming problems</article-title>
      <source>Ecography</source>
      <year iso-8601-date="2014-09">2014</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-23">2025</year><month>07</month><day>23</day></date-in-citation>
      <volume>37</volume>
      <issue>9</issue>
      <issn>0906-7590</issn>
      <uri>https://onlinelibrary.wiley.com/doi/10.1111/ecog.00888</uri>
      <pub-id pub-id-type="doi">10.1111/ecog.00888</pub-id>
      <fpage>916</fpage>
      <lpage>920</lpage>
    </element-citation>
  </ref>
  <ref id="ref-egorov_pomdpsjl_2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Egorov</surname><given-names>Maxim</given-names></name>
        <name><surname>Sunberg</surname><given-names>Zachary N.</given-names></name>
        <name><surname>Balaban</surname><given-names>Edward</given-names></name>
        <name><surname>Wheeler</surname><given-names>Tim A.</given-names></name>
        <name><surname>Gupta</surname><given-names>Jayesh K.</given-names></name>
        <name><surname>Kochenderfer</surname><given-names>Mykel J.</given-names></name>
      </person-group>
      <article-title>POMDPs.jl: A framework for sequential decision making under uncertainty</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2017">2017</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-23">2025</year><month>07</month><day>23</day></date-in-citation>
      <volume>18</volume>
      <issue>26</issue>
      <issn>1533-7928</issn>
      <uri>http://jmlr.org/papers/v18/16-300.html</uri>
      <fpage>1</fpage>
      <lpage>5</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cordwell_pymdptoolbox_2015">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Cordwell</surname><given-names>Steven</given-names></name>
      </person-group>
      <article-title>Pymdptoolbox</article-title>
      <source>GitHub repository</source>
      <year iso-8601-date="2015">2015</year>
      <uri>https://github.com/sawcordwell/pymdptoolbox</uri>
    </element-citation>
  </ref>
  <ref id="ref-chades_mdptoolbox_2017">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Chadès</surname><given-names>Iadine</given-names></name>
        <name><surname>Chapron</surname><given-names>Guillaume</given-names></name>
        <name><surname>Cros</surname><given-names>Marie‐Josée</given-names></name>
        <name><surname>Garcia</surname><given-names>Frédérick</given-names></name>
        <name><surname>Sabbadin</surname><given-names>Régis</given-names></name>
      </person-group>
      <article-title>MDPtoolbox: Markov decision processes toolbox</article-title>
      <source>The Comprehensive R Archive Network (CRAN)</source>
      <year iso-8601-date="2017">2017</year>
      <uri>https://cran.r-project.org/web/packages/MDPtoolbox</uri>
      <pub-id pub-id-type="doi">10.32614/cran.package.mdptoolbox</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-cros_markov_2015">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Cros</surname><given-names>Marie-Josee</given-names></name>
      </person-group>
      <article-title>Markov decision processes (MDP) toolbox</article-title>
      <source>MATLAB Central File Exchange</source>
      <year iso-8601-date="2015">2015</year>
      <uri>https://uk.mathworks.com/matlabcentral/fileexchange/25786-markov-decision-processes-mdp-toolbox</uri>
    </element-citation>
  </ref>
  <ref id="ref-sargent_quantitative_2025">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Sargent</surname><given-names>Thomas J</given-names></name>
        <name><surname>Stachurski</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Quantitative economics with JAX</article-title>
      <source>QuantEcon</source>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-25">2025</year><month>07</month><day>25</day></date-in-citation>
      <uri>https://jax.quantecon.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-gaffney_orbax_2025">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Gaffney</surname><given-names>Colin</given-names></name>
        <name><surname>Li</surname><given-names>Dinghua</given-names></name>
        <name><surname>Zhang</surname><given-names>John</given-names></name>
        <name><surname>Sang</surname><given-names>Ruoxin</given-names></name>
        <name><surname>Jain</surname><given-names>Ayush</given-names></name>
        <name><surname>Hu</surname><given-names>Haitang</given-names></name>
      </person-group>
      <article-title>Orbax</article-title>
      <source>GitHub repository</source>
      <year iso-8601-date="2025">2025</year>
      <uri>https://github.com/google/orbax</uri>
    </element-citation>
  </ref>
  <ref id="ref-nicol_conservation_2010">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nicol</surname><given-names>Samuel C.</given-names></name>
        <name><surname>Chadès</surname><given-names>Iadine</given-names></name>
        <name><surname>Linke</surname><given-names>Simon</given-names></name>
        <name><surname>Possingham</surname><given-names>Hugh P.</given-names></name>
      </person-group>
      <article-title>Conservation decision-making in large state spaces</article-title>
      <source>Ecological Modelling</source>
      <year iso-8601-date="2010-10">2010</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-28">2025</year><month>07</month><day>28</day></date-in-citation>
      <volume>221</volume>
      <issue>21</issue>
      <issn>0304-3800</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0304380010000803</uri>
      <pub-id pub-id-type="doi">10.1016/j.ecolmodel.2010.02.009</pub-id>
      <fpage>2531</fpage>
      <lpage>2536</lpage>
    </element-citation>
  </ref>
  <ref id="ref-schaefer_modeling_2004">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Schaefer</surname><given-names>Andrew J.</given-names></name>
        <name><surname>Bailey</surname><given-names>Matthew D.</given-names></name>
        <name><surname>Shechter</surname><given-names>Steven M.</given-names></name>
        <name><surname>Roberts</surname><given-names>Mark S.</given-names></name>
      </person-group>
      <article-title>Modeling medical treatment using Markov decision processes</article-title>
      <source>Operations Research and Health Care: A Handbook of Methods and Applications</source>
      <person-group person-group-type="editor">
        <name><surname>Brandeau</surname><given-names>Margaret L.</given-names></name>
        <name><surname>Sainfort</surname><given-names>François</given-names></name>
        <name><surname>Pierskalla</surname><given-names>William P.</given-names></name>
      </person-group>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>Boston, MA</publisher-loc>
      <year iso-8601-date="2004">2004</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-28">2025</year><month>07</month><day>28</day></date-in-citation>
      <isbn>978-1-4020-8066-1</isbn>
      <uri>https://doi.org/10.1007/1-4020-8066-2_23</uri>
      <pub-id pub-id-type="doi">10.1007/1-4020-8066-2_23</pub-id>
      <fpage>593</fpage>
      <lpage>612</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bauerle_markov_2011">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bäuerle</surname><given-names>Nicole</given-names></name>
        <name><surname>Rieder</surname><given-names>Ulrich</given-names></name>
      </person-group>
      <source>Markov decision processes with applications to finance</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2011-06">2011</year><month>06</month>
      <isbn>978-3-642-18324-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-haijema_dynamic_2017">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Haijema</surname><given-names>Rene</given-names></name>
        <name><surname>Hendrix</surname><given-names>Eligius M. T.</given-names></name>
        <name><surname>Wal</surname><given-names>Jan van der</given-names></name>
      </person-group>
      <article-title>Dynamic control of traffic lights</article-title>
      <source>Markov Decision Processes in Practice</source>
      <person-group person-group-type="editor">
        <name><surname>Boucherie</surname><given-names>Richard J.</given-names></name>
        <name><surname>Dijk</surname><given-names>Nico M. van</given-names></name>
      </person-group>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2017">2017</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-07-28">2025</year><month>07</month><day>28</day></date-in-citation>
      <isbn>978-3-319-47766-4</isbn>
      <uri>https://doi.org/10.1007/978-3-319-47766-4_13</uri>
      <pub-id pub-id-type="doi">10.1007/978-3-319-47766-4_13</pub-id>
      <fpage>371</fpage>
      <lpage>386</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
