<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4278</article-id>
<article-id pub-id-type="doi">10.21105/joss.04278</article-id>
<title-group>
<article-title>DIRECT: Deep Image REConstruction Toolkit</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Yiasemis</surname>
<given-names>George</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moriakov</surname>
<given-names>Nikita</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Karkalousos</surname>
<given-names>Dimitrios</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Caan</surname>
<given-names>Matthan</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Teuwen</surname>
<given-names>Jonas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Netherlands Cancer Institute</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>University of Amsterdam</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Amsterdam UMC, Biomedical Engineering and
Physics</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Radboud University Medical Center</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-10-30">
<day>30</day>
<month>10</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>73</issue>
<fpage>4278</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Pytorch</kwd>
<kwd>Deep Learning</kwd>
<kwd>Inverse Problem Solver</kwd>
<kwd>Image Processing</kwd>
<kwd>Deep MRI reconstruction</kwd>
<kwd>Accelerated MRI</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>DIRECT is a Python, end-to-end pipeline for solving inverse
  problems emerging in image processing. It is built with PyTorch
  (<xref alt="Paszke et al., 2019" rid="ref-NEURIPS2019_9015" ref-type="bibr">Paszke
  et al., 2019</xref>) and stores state-of-the-art deep learning imaging
  inverse problem solvers for solving inverse problems such as
  denoising, dealiasing, and reconstruction. By defining a base forward
  linear or non-linear operator, DIRECT can be used for training models
  for recovering images such as MRIs from partially observed or noisy
  input data. Additionally, it provides the user with the functionality
  to load saved weights of pre-trained models to be used for inference.
  Furthermore, it offers functions for preparing and pre-processing data
  such as <monospace>.h5</monospace> files into PyTorch datasets
  compatible with the software‚Äôs training pipeline, but also allows for
  flexibility to work with any kind of PyTorch dataset. Additionally, in
  order for the user to view the process of their experiments, it allows
  for continuous visualisation of training and validation metrics as
  well as image predictions utilising Tensorboard (examples are
  illustrated in Figures 1 and 2).</p>
  <table-wrap>
    <table>
      <colgroup>
        <col width="100%" />
      </colgroup>
      <thead>
        <tr>
          <th align="center"><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/3a9db00eb3eb7a35fc2f328d294ca8a296b190ba.png" /></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center"> Figure 1: Visualised reconstructions in
          Tensorboard </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap>
    <table>
      <colgroup>
        <col width="100%" />
      </colgroup>
      <thead>
        <tr>
          <th align="center"><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/fef5d24e2ec2efe00a9c99972eb2da55f1fa30e7.png" /></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center"> Figure 2: Visualised metrics in
          Tensorboard </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>A plethora of image processing problems arising in biology,
  chemistry, and medicine can be defined as inverse problems. Inverse
  problems aim in recovering a signal <inline-formula><alternatives>
  <tex-math><![CDATA[\vec{x} \, \in \, \mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àà</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùí≥</mml:mi></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>
  (e.g.¬†an image) that cannot be directly observed from a set of
  measurements <inline-formula><alternatives>
  <tex-math><![CDATA[\vec{y} \, \in \, \mathcal{Y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àà</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùí¥</mml:mi></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>
  and is subject to a given corruption process known as the forward
  model:</p>
  <p><named-content id="eqU003Aeq1" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[\vec{y} \, = \, \mathcal{A}(\vec{x}) \,+\,\vec{n},
      \label{eq:eq1}]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùíú</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mspace width="0.167em"></mml:mspace><mml:mo>+</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mover><mml:mi>n</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></named-content></p>
  <p>where <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{A}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>ùíú</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  denotes the forward operator and <inline-formula><alternatives>
  <tex-math><![CDATA[\vec{n}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>n</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  is some measurement noise, often assumed to be additive and normally
  distributed. Equation <xref alt="1" rid="eqU003Aeq1">1</xref> is
  usually ill-posed and therefore an explicit solution is hard to find.
  Instead, inverse problems in imaging are typically solved by
  minimizing an objective function <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{J}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>ùí•</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  which is consisted of a data-fidelity term and a regularization term
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{R}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>‚Ñõ</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  (also known as Variational Problems):</p>
  <p><named-content id="eqU003Aeq2" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[\vec{\hat{x}} \, = \, \min_{\vec{z} \, \in \, \mathcal{X}} \mathcal{J}(\vec{z}) \, = \, \min_{\vec{z} \, \in \,  \mathcal{X}} \frac{1}{2}\big|\big| \, \vec{y}\,- \, \mathcal{A}(\vec{z})\big|\big|_2^2 \,+\, \lambda \mathcal{R}(\vec{z}),\quad \lambda \, \ge \, 0.
      \label{eq:eq2}]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">ÃÇ</mml:mo></mml:mover><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:munder><mml:mo>min</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àà</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùí≥</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mstyle mathvariant="script"><mml:mi>ùí•</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:munder><mml:mo>min</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àà</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùí≥</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àí</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùíú</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:msubsup><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="0.167em"></mml:mspace><mml:mo>+</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mi>Œª</mml:mi><mml:mstyle mathvariant="script"><mml:mi>‚Ñõ</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1.0em"></mml:mspace><mml:mi>Œª</mml:mi><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚â•</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mn>0</mml:mn><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></named-content></p>
  <sec id="accelerated-parallel-mri-reconstruction">
    <title>Accelerated Parallel MRI Reconstruction</title>
    <p>Accelerated Parallel Magnetic Resonance Image (MRI)
    Reconstruction, that is, reconstructing an MR image from a set of
    partially observed (or sub-sampled) <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-space
    measurements from multiple receiver coils (parallel imaging
    (<xref alt="Larkman &amp; Nunes, 2007" rid="ref-Larkman_2007" ref-type="bibr">Larkman
    &amp; Nunes, 2007</xref>)), is par excellence an example of inverse
    problems. The base forward operator of accelerated MRI
    reconstruction is usually the two or three-dimensional Fast Fourier
    Transform (FFT) denoted as <inline-formula><alternatives>
    <tex-math><![CDATA[\mathcal{F}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>‚Ñ±</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>.</p>
    <p>More specifically, let</p>
    <p><disp-formula><alternatives>
    <tex-math><![CDATA[\vec{y} \, = \, \big\{ \vec{y}_1, \, ...,\, \vec{y}_{n_c} \big\}, \quad \vec{y}_i  \, = \, U \circ \mathcal{F} \big( S_{i} \vec{x} \big), \quad i=1,...,n_{c},]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">{</mml:mo><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:msub><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">}</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1.0em"></mml:mspace><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mi>U</mml:mi><mml:mo>‚àò</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ±</mml:mi></mml:mstyle><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1.0em"></mml:mspace><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
    <p>be the sub-sampled <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-space
    measurements acquired from <inline-formula><alternatives>
    <tex-math><![CDATA[n_c]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    receiver coils, where where <inline-formula><alternatives>
    <tex-math><![CDATA[S_{i}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    denotes a (usually unknown or estimated) coil sensitivity map,
    property of each individual coil, and <inline-formula><alternatives>
    <tex-math><![CDATA[U]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>U</mml:mi></mml:math></alternatives></inline-formula>
    a retrospective binary sub-sampling mask operator which simulates
    the sub-sampling process in clinical settings. Then, the
    corresponding inverse problem for Accelerated Parallel MRI
    Reconstruction replaces with the following optimization problem</p>
    <p><named-content id="eqU003Aeq4" content-type="equation"><disp-formula><alternatives>
    <tex-math><![CDATA[\vec{\hat{x}} \, = \, \min_{\vec{z} \, \in \,  \mathcal{X}} \sum_{i=1}^{n_{c}} \frac{1}{2}\big|\big| \, \vec{y_{i}}\,- \, U \circ \mathcal{F} ( S_{i} \vec{z} ) \big|\big|_2^2 \, + \, \lambda \mathcal{R}(\vec{z}).
        \label{eq:eq4}]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">ÃÇ</mml:mo></mml:mover><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>=</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:munder><mml:mo>min</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àà</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mstyle mathvariant="script"><mml:mi>ùí≥</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:munderover><mml:mo>‚àë</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mover><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mspace width="0.167em"></mml:mspace><mml:mo>‚àí</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mi>U</mml:mi><mml:mo>‚àò</mml:mo><mml:mstyle mathvariant="script"><mml:mi>‚Ñ±</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:msubsup><mml:mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">|</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="0.167em"></mml:mspace><mml:mo>+</mml:mo><mml:mspace width="0.167em"></mml:mspace><mml:mi>Œª</mml:mi><mml:mstyle mathvariant="script"><mml:mi>‚Ñõ</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>z</mml:mi><mml:mo accent="true">‚Éó</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></named-content></p>
    <p>Conventional approaches employed for solving include Compressed
    Sensing algorithms (CS)
    (<xref alt="Candes et al., 2006" rid="ref-1580791" ref-type="bibr">Candes
    et al., 2006</xref>;
    <xref alt="Donoho, 2006" rid="ref-1614066" ref-type="bibr">Donoho,
    2006</xref>;
    <xref alt="Lustig et al., 2007" rid="ref-Lustig2007" ref-type="bibr">Lustig
    et al., 2007</xref>), SENSE
    (<xref alt="Pruessmann et al., 1999" rid="ref-Pruessmann1999" ref-type="bibr">Pruessmann
    et al., 1999</xref>), and GRAPPA
    (<xref alt="Griswold et al., 2002" rid="ref-Griswold2002" ref-type="bibr">Griswold
    et al., 2002</xref>). Deep learning-based imaging inverse problem
    solvers have shown to outperform these conventional techniques by
    outputting reconstructed images with higher fidelity from highly
    sub-sampled <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-space
    measurements
    (<xref alt="Knoll et al., 2020" rid="ref-Knoll2020" ref-type="bibr">Knoll
    et al., 2020</xref>;
    <xref alt="L√∏nning et al., 2019" rid="ref-LONNING201964" ref-type="bibr">L√∏nning
    et al., 2019</xref>;
    <xref alt="Pal &amp; Rathi, 2021" rid="ref-arxiv.2109.08618" ref-type="bibr">Pal
    &amp; Rathi, 2021</xref>).</p>
  </sec>
</sec>
<sec id="functionality">
  <title>Functionality</title>
  <p>DIRECT stores PyTorch MRI datasets and data-loaders, multiple
  retrospective sub-sampling schemes, MRI-related transforms and
  evaluation metrics, and several state-of-the-art DL
  <xref alt="baselines" rid="baselines-stored">baselines</xref> that can
  be applied to the task of solving the inverse problem of Accelerated
  Parallel MRI Reconstruction, which make it a perfect tool for research
  in this domain. In addition to the currently implemented methods and
  already-stored baselines, the user can easily incorporate into DIRECT
  their own code following the current implementations.</p>
  <p>DIRECT also allows for easy and flexible experimentation. For an
  experiment, the user simply needs to define a configuration file that
  comprises the experiment parameters. See
  <xref alt="Configuration File" rid="configuration-file">Configuration
  File</xref> below for a configuration file template. DIRECT can be
  employed for training and/or validating models on multiple machines
  and GPUs as it is integrated with PyTorch‚Äôs
  <monospace>torch.distributed</monospace> module and NVIDIA‚Äôs cuDNN
  (<xref alt="Chetlur et al., 2014" rid="ref-chetlur2014cudnn" ref-type="bibr">Chetlur
  et al., 2014</xref>).</p>
  <sec id="configuration-file">
    <title>Configuration File</title>
    <p>All experiment parameters can be specified in a configuration
    file. These include model, dataset, sub-sampling scheme, physics,
    training, and validation. Each configuration file should be saved
    with the <monospace>.yaml</monospace> extension. The following is a
    template example of a configuration file:</p>
    <code language="yaml">model:
  model_name: &lt;nn_model_path&gt;
  model_parameter_1: &lt;nn_model_paramter_1&gt;
  model_parameter_2: &lt;nn_model_paramter_2&gt;
  ...
additional_models:
  sensitivity_model:
    model_name: &lt;nn_sensitivity_model_path&gt;
    ...
physics:
  forward_operator: fft2(centered=&lt;true_or_false&gt;)
  backward_operator: ifft2(centered=&lt;true_or_false&gt;)
  ...
training:
  datasets:
  - name: Dataset1
    lists:
    - &lt;path_to_list_1_for_Dataset1&gt;
    - &lt;path_to_list_2_for_Dataset1&gt;
    transforms:
      estimate_sensitivity_maps: &lt;true_or_false&gt;
      scaling_key: &lt;scaling_key&gt;
      image_center_crop: &lt;true_or_false&gt;
      masking:
        name: MaskingFunctionName
        accelerations: [acceleration_1, accelaration_2, ...]
        ...
    ...
  - name: Dataset2
    ...
  optimizer: &lt;optimizer&gt;
  lr: &lt;learning_rate&gt;
  batch_size: &lt;batch_size&gt;
  lr_step_size: &lt;lr_step_size&gt;
  lr_gamma: &lt;lr_gamma&gt;
  lr_warmup_iter: &lt;num_warmup_iterations&gt;
  num_iterations: &lt;num_iterations&gt;
  validation_steps: &lt;num_val_steps&gt;
  loss:
    losses:
    - function: &lt;fun1_as_in_model_engine&gt;
      multiplier: &lt;multiplier_1&gt;
    - function: &lt;fun2_as_in_model_engine&gt;
      multiplier: &lt;multiplier_2&gt;
  checkpointer:
    checkpoint_steps: &lt;num_checkpointer_steps&gt;
  metrics: [&lt;metric_1&gt;, &lt;metric_2&gt;, ...]
  ...
validation:
  datasets:
  - name: ValDataset1
    transforms:
      ...
      masking:
        ...
    text_description: &lt;val_description_1&gt;
    ...
  - name: ValDataset2
    ...
  batch_size: &lt;val_batch_size&gt;
  metrics:
  - val_metric_1
  - val_metric_2
  - ...
  ...
inference:
  dataset:
    name: InferenceDataset
    lists: ...
    transforms:
      masking:
        ...
      ...
    text_description: &lt;inference_description&gt;
    ...
  batch_size: &lt;batch_size&gt;
  ...
logging:
  tensorboard:
  num_images: &lt;num_images&gt;</code>
  </sec>
</sec>
<sec id="baselines-stored">
  <title>Baselines Stored</title>
  <table-wrap>
    <table>
      <colgroup>
        <col width="14%" />
        <col width="86%" />
      </colgroup>
      <thead>
        <tr>
          <th align="center">Model Name</th>
          <th align="center">Algorithm - Architecture</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center">RecurrentVarNet</td>
          <td align="center">Recurrent Variational Network
          (<xref alt="Yiasemis et al., 2021" rid="ref-yiasemis2021recurrent" ref-type="bibr">Yiasemis
          et al., 2021</xref>)</td>
        </tr>
        <tr>
          <td align="center">RIM</td>
          <td align="center">Recurrent Inference Machine
          (<xref alt="Beauferris et al., 2021" rid="ref-beauferris2020multichannel" ref-type="bibr">Beauferris
          et al., 2021</xref>;
          <xref alt="L√∏nning et al., 2019" rid="ref-LONNING201964" ref-type="bibr">L√∏nning
          et al., 2019</xref>)</td>
        </tr>
        <tr>
          <td align="center">LPDNet</td>
          <td align="center">Learned Primal Dual Network
          (<xref alt="Adler &amp; Oktem, 2018" rid="ref-lpd2018" ref-type="bibr">Adler
          &amp; Oktem, 2018</xref>)</td>
        </tr>
        <tr>
          <td align="center">EndToEndVarnet</td>
          <td align="center">End-to-end Variational Network
          (<xref alt="Sriram et al., 2020" rid="ref-varnetfastmri" ref-type="bibr">Sriram
          et al., 2020</xref>)</td>
        </tr>
        <tr>
          <td align="center">XPDNet</td>
          <td align="center">X - Primal Dual Network
          (<xref alt="Ramzi et al., 2021" rid="ref-ramzi2021xpdnet" ref-type="bibr">Ramzi
          et al., 2021</xref>)</td>
        </tr>
        <tr>
          <td align="center">KIKINet</td>
          <td align="center">Kspace-Image-Kspace-Image Network
          (<xref alt="Eo et al., 2018" rid="ref-kiki2018" ref-type="bibr">Eo
          et al., 2018</xref>)</td>
        </tr>
        <tr>
          <td align="center">JointICNet</td>
          <td align="center">Joint Deep Model-based MR Image and Coil
          Sensitivity Reconstruction Network
          (<xref alt="Jun et al., 2021" rid="ref-Jun_2021_CVPR" ref-type="bibr">Jun
          et al., 2021</xref>)</td>
        </tr>
        <tr>
          <td align="center">MultiDomainNet</td>
          <td align="center">Feature-level multi-domain learning with
          standardization for multi-channel data
          (<xref alt="Muckley et al., 2021" rid="ref-fastmri2021" ref-type="bibr">Muckley
          et al., 2021</xref>)</td>
        </tr>
        <tr>
          <td align="center">UNet2d</td>
          <td align="center">U-Net for MRI Reconstruction
          (<xref alt="Zbontar et al., 2019" rid="ref-zbontar2019fastmri" ref-type="bibr">Zbontar
          et al., 2019</xref>)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</sec>
<sec id="research-projects-using-direct">
  <title>Research projects using DIRECT</title>
  <p>DIRECT is the main software used for research by the MRI
  Reconstruction team of the Innovation Centre for Artificial
  Intelligence (ICAI) - AI for Oncology group of the Netherlands Cancer
  Institute (NKI).</p>
  <sec id="challenges">
    <title>Challenges</title>
    <p>DIRECT has been used for MRI Reconstruction result submissions in
    the fastMRI challenge
    (<xref alt="Muckley et al., 2021" rid="ref-fastmri2021" ref-type="bibr">Muckley
    et al., 2021</xref>) and the Multi-Coil MRI Reconstruction challenge
    (<xref alt="Beauferris et al., 2021" rid="ref-beauferris2020multichannel" ref-type="bibr">Beauferris
    et al., 2021</xref>).</p>
  </sec>
  <sec id="publications">
    <title>Publications</title>
    <p>Papers using DIRECT include Yiasemis et al.
    (<xref alt="2022" rid="ref-yiasemis2021deep" ref-type="bibr">2022</xref>)
    (presented in SPIE Medical Imaging Conference 2022) and Yiasemis et
    al.
    (<xref alt="2021" rid="ref-yiasemis2021recurrent" ref-type="bibr">2021</xref>)
    (to be presented in CVPR Conference 2022).</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-yiasemis2021deep">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Yiasemis</surname><given-names>George</given-names></name>
        <name><surname>Zhang</surname><given-names>Chaoping</given-names></name>
        <name><surname>S√°nchez</surname><given-names>Clara I.</given-names></name>
        <name><surname>Sonke</surname><given-names>Jan-Jakob</given-names></name>
        <name><surname>Teuwen</surname><given-names>Jonas</given-names></name>
      </person-group>
      <article-title>Deep MRI reconstruction with radial subsampling</article-title>
      <source>Medical imaging 2022: Physics of medical imaging</source>
      <person-group person-group-type="editor">
        <name><surname>Zhao</surname><given-names>Wei</given-names></name>
        <name><surname>Yu</surname><given-names>Lifeng</given-names></name>
      </person-group>
      <publisher-name>International Society for Optics; Photonics; SPIE</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>12031</volume>
      <uri>https://doi.org/10.1117/12.2609876</uri>
      <pub-id pub-id-type="doi">10.1117/12.2609876</pub-id>
      <fpage>801 </fpage>
      <lpage> 810</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fastmri2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Muckley</surname><given-names>Matthew J.</given-names></name>
        <name><surname>Riemenschneider</surname><given-names>Bruno</given-names></name>
        <name><surname>Radmanesh</surname><given-names>Alireza</given-names></name>
        <name><surname>Kim</surname><given-names>Sunwoo</given-names></name>
        <name><surname>Jeong</surname><given-names>Geunu</given-names></name>
        <name><surname>Ko</surname><given-names>Jingyu</given-names></name>
        <name><surname>Jun</surname><given-names>Yohan</given-names></name>
        <name><surname>Shin</surname><given-names>Hyungseob</given-names></name>
        <name><surname>Hwang</surname><given-names>Dosik</given-names></name>
        <name><surname>Mostapha</surname><given-names>Mahmoud</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Results of the 2020 fastMRI challenge for machine learning MR image reconstruction</article-title>
      <source>IEEE Transactions on Medical Imaging</source>
      <publisher-name>Institute of Electrical; Electronics Engineers (IEEE)</publisher-name>
      <year iso-8601-date="2021-09">2021</year><month>09</month>
      <volume>40</volume>
      <issue>9</issue>
      <issn>1558-254X</issn>
      <uri>http://dx.doi.org/10.1109/TMI.2021.3075856</uri>
      <pub-id pub-id-type="doi">10.1109/tmi.2021.3075856</pub-id>
      <fpage>2306</fpage>
      <lpage>2317</lpage>
    </element-citation>
  </ref>
  <ref id="ref-beauferris2020multichannel">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Beauferris</surname><given-names>Youssef</given-names></name>
        <name><surname>Teuwen</surname><given-names>Jonas</given-names></name>
        <name><surname>Karkalousos</surname><given-names>Dimitrios</given-names></name>
        <name><surname>Moriakov</surname><given-names>Nikita</given-names></name>
        <name><surname>Caan</surname><given-names>Mattha</given-names></name>
        <name><surname>Yiasemis</surname><given-names>George</given-names></name>
        <name><surname>Rodrigues</surname><given-names>L√≠via</given-names></name>
        <name><surname>Lopes</surname><given-names>Alexandre</given-names></name>
        <name><surname>Pedrini</surname><given-names>H√©lio</given-names></name>
        <name><surname>Rittner</surname><given-names>Let√≠cia</given-names></name>
        <name><surname>Dannecker</surname><given-names>Maik</given-names></name>
        <name><surname>Studenyak</surname><given-names>Viktor</given-names></name>
        <name><surname>Gr√∂ger</surname><given-names>Fabian</given-names></name>
        <name><surname>Vyas</surname><given-names>Devendra</given-names></name>
        <name><surname>Faghih-Roohi</surname><given-names>Shahrooz</given-names></name>
        <name><surname>Jethi</surname><given-names>Amrit Kumar</given-names></name>
        <name><surname>Raju</surname><given-names>Jaya Chandra</given-names></name>
        <name><surname>Sivaprakasam</surname><given-names>Mohanasankar</given-names></name>
        <name><surname>Lasby</surname><given-names>Mike</given-names></name>
        <name><surname>Nogovitsyn</surname><given-names>Nikita</given-names></name>
        <name><surname>Loos</surname><given-names>Wallace</given-names></name>
        <name><surname>Frayne</surname><given-names>Richard</given-names></name>
        <name><surname>Souza</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Multi-coil MRI reconstruction challenge ‚Äì assessing brain MRI reconstruction models and their generalizability to varying coil configurations</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/2011.07952</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.2011.07952</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-varnetfastmri">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Sriram</surname><given-names>Anuroop</given-names></name>
        <name><surname>Zbontar</surname><given-names>Jure</given-names></name>
        <name><surname>Murrell</surname><given-names>Tullie</given-names></name>
        <name><surname>Defazio</surname><given-names>Aaron</given-names></name>
        <name><surname>Zitnick</surname><given-names>C.</given-names></name>
        <name><surname>Yakubova</surname><given-names>Nafissa</given-names></name>
        <name><surname>Knoll</surname><given-names>Florian</given-names></name>
        <name><surname>Johnson</surname><given-names>Patricia</given-names></name>
      </person-group>
      <article-title>End-to-end variational networks for accelerated MRI reconstruction</article-title>
      <year iso-8601-date="2020-09">2020</year><month>09</month>
      <isbn>978-3-030-59712-2</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-59713-9_7</pub-id>
      <fpage>64</fpage>
      <lpage>73</lpage>
    </element-citation>
  </ref>
  <ref id="ref-LONNING201964">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>L√∏nning</surname><given-names>Kai</given-names></name>
        <name><surname>Putzky</surname><given-names>Patrick</given-names></name>
        <name><surname>Sonke</surname><given-names>Jan-Jakob</given-names></name>
        <name><surname>Reneman</surname><given-names>Liesbeth</given-names></name>
        <name><surname>Caan</surname><given-names>Matthan W. A.</given-names></name>
        <name><surname>Welling</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Recurrent inference machines for reconstructing heterogeneous MRI data</article-title>
      <source>Medical Image Analysis</source>
      <year iso-8601-date="2019">2019</year>
      <volume>53</volume>
      <issn>1361-8415</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S1361841518306078</uri>
      <pub-id pub-id-type="doi">10.1016/j.media.2019.01.005</pub-id>
      <fpage>64</fpage>
      <lpage>78</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lpd2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Adler</surname><given-names>Jonas</given-names></name>
        <name><surname>Oktem</surname><given-names>Ozan</given-names></name>
      </person-group>
      <article-title>Learned primal-dual reconstruction</article-title>
      <source>IEEE Transactions on Medical Imaging</source>
      <publisher-name>Institute of Electrical; Electronics Engineers (IEEE)</publisher-name>
      <year iso-8601-date="2018-06">2018</year><month>06</month>
      <volume>37</volume>
      <issue>6</issue>
      <issn>1558-254X</issn>
      <uri>http://dx.doi.org/10.1109/TMI.2018.2799231</uri>
      <pub-id pub-id-type="doi">10.1109/tmi.2018.2799231</pub-id>
      <fpage>1322</fpage>
      <lpage>1332</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ramzi2021xpdnet">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ramzi</surname><given-names>Zaccharie</given-names></name>
        <name><surname>Ciuciu</surname><given-names>Philippe</given-names></name>
        <name><surname>Starck</surname><given-names>Jean-Luc</given-names></name>
      </person-group>
      <article-title>XPDNet for MRI reconstruction: An application to the 2020 fastMRI challenge</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/2010.07290</uri>
    </element-citation>
  </ref>
  <ref id="ref-kiki2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Eo</surname><given-names>Taejoon</given-names></name>
        <name><surname>Jun</surname><given-names>Yohan</given-names></name>
        <name><surname>Kim</surname><given-names>Taeseong</given-names></name>
        <name><surname>Jang</surname><given-names>Jinseong</given-names></name>
        <name><surname>Lee</surname><given-names>Ho-Joon</given-names></name>
        <name><surname>Hwang</surname><given-names>Dosik</given-names></name>
      </person-group>
      <article-title>KIKI-net: Cross-domain convolutional neural networks for reconstructing undersampled magnetic resonance images</article-title>
      <source>Magnetic Resonance in Medicine</source>
      <year iso-8601-date="2018">2018</year>
      <volume>80</volume>
      <issue>5</issue>
      <uri>https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.27201</uri>
      <pub-id pub-id-type="doi">10.1002/mrm.27201</pub-id>
      <fpage>2188</fpage>
      <lpage>2201</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Jun_2021_CVPR">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Jun</surname><given-names>Yohan</given-names></name>
        <name><surname>Shin</surname><given-names>Hyungseob</given-names></name>
        <name><surname>Eo</surname><given-names>Taejoon</given-names></name>
        <name><surname>Hwang</surname><given-names>Dosik</given-names></name>
      </person-group>
      <article-title>Joint deep model-based MR image and coil sensitivity reconstruction network (joint-ICNet) for fast MRI</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.1109/cvpr46437.2021.00523</pub-id>
      <fpage>5270</fpage>
      <lpage>5279</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zbontar2019fastmri">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Zbontar</surname><given-names>Jure</given-names></name>
        <name><surname>Knoll</surname><given-names>Florian</given-names></name>
        <name><surname>Sriram</surname><given-names>Anuroop</given-names></name>
        <name><surname>Murrell</surname><given-names>Tullie</given-names></name>
        <name><surname>Huang</surname><given-names>Zhengnan</given-names></name>
        <name><surname>Muckley</surname><given-names>Matthew J.</given-names></name>
        <name><surname>Defazio</surname><given-names>Aaron</given-names></name>
        <name><surname>Stern</surname><given-names>Ruben</given-names></name>
        <name><surname>Johnson</surname><given-names>Patricia</given-names></name>
        <name><surname>Bruno</surname><given-names>Mary</given-names></name>
        <name><surname>Parente</surname><given-names>Marc</given-names></name>
        <name><surname>Geras</surname><given-names>Krzysztof J.</given-names></name>
        <name><surname>Katsnelson</surname><given-names>Joe</given-names></name>
        <name><surname>Chandarana</surname><given-names>Hersh</given-names></name>
        <name><surname>Zhang</surname><given-names>Zizhao</given-names></name>
        <name><surname>Drozdzal</surname><given-names>Michal</given-names></name>
        <name><surname>Romero</surname><given-names>Adriana</given-names></name>
        <name><surname>Rabbat</surname><given-names>Michael</given-names></name>
        <name><surname>Vincent</surname><given-names>Pascal</given-names></name>
        <name><surname>Yakubova</surname><given-names>Nafissa</given-names></name>
        <name><surname>Pinkerton</surname><given-names>James</given-names></name>
        <name><surname>Wang</surname><given-names>Duo</given-names></name>
        <name><surname>Owens</surname><given-names>Erich</given-names></name>
        <name><surname>Zitnick</surname><given-names>C. Lawrence</given-names></name>
        <name><surname>Recht</surname><given-names>Michael P.</given-names></name>
        <name><surname>Sodickson</surname><given-names>Daniel K.</given-names></name>
        <name><surname>Lui</surname><given-names>Yvonne W.</given-names></name>
      </person-group>
      <article-title>fastMRI: An open dataset and benchmarks for accelerated MRI</article-title>
      <year iso-8601-date="2019">2019</year>
      <uri>https://arxiv.org/abs/1811.08839</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.1811.08839</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-yiasemis2021recurrent">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Yiasemis</surname><given-names>George</given-names></name>
        <name><surname>Sonke</surname><given-names>Jan-Jakob</given-names></name>
        <name><surname>S√°nchez</surname><given-names>Clarisa</given-names></name>
        <name><surname>Teuwen</surname><given-names>Jonas</given-names></name>
      </person-group>
      <article-title>Recurrent variational network: A deep learning inverse problem solver applied to the task of accelerated MRI reconstruction</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/2111.09639</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.2111.09639</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chetlur2014cudnn">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Chetlur</surname><given-names>Sharan</given-names></name>
        <name><surname>Woolley</surname><given-names>Cliff</given-names></name>
        <name><surname>Vandermersch</surname><given-names>Philippe</given-names></name>
        <name><surname>Cohen</surname><given-names>Jonathan</given-names></name>
        <name><surname>Tran</surname><given-names>John</given-names></name>
        <name><surname>Catanzaro</surname><given-names>Bryan</given-names></name>
        <name><surname>Shelhamer</surname><given-names>Evan</given-names></name>
      </person-group>
      <article-title>cuDNN: Efficient primitives for deep learning</article-title>
      <year iso-8601-date="2014">2014</year>
      <uri>https://arxiv.org/abs/1410.0759</uri>
    </element-citation>
  </ref>
  <ref id="ref-Larkman_2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Larkman</surname><given-names>David J</given-names></name>
        <name><surname>Nunes</surname><given-names>Rita G</given-names></name>
      </person-group>
      <article-title>Parallel magnetic resonance imaging</article-title>
      <source>Physics in Medicine and Biology</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2007-03">2007</year><month>03</month>
      <volume>52</volume>
      <issue>7</issue>
      <uri>https://doi.org/10.1088/0031-9155/52/7/r01</uri>
      <pub-id pub-id-type="doi">10.1088/0031-9155/52/7/r01</pub-id>
      <fpage>R15</fpage>
      <lpage>R55</lpage>
    </element-citation>
  </ref>
  <ref id="ref-1614066">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Donoho</surname><given-names>D. L.</given-names></name>
      </person-group>
      <article-title>Compressed sensing</article-title>
      <source>IEEE Transactions on Information Theory</source>
      <year iso-8601-date="2006">2006</year>
      <volume>52</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1109/TIT.2006.871582</pub-id>
      <fpage>1289</fpage>
      <lpage>1306</lpage>
    </element-citation>
  </ref>
  <ref id="ref-NEURIPS2019_9015">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems 32</source>
      <person-group person-group-type="editor">
        <name><surname>Wallach</surname><given-names>H.</given-names></name>
        <name><surname>Larochelle</surname><given-names>H.</given-names></name>
        <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
        <name><surname>dAlch√©-Buc</surname><given-names>F.</given-names></name>
        <name><surname>Fox</surname><given-names>E.</given-names></name>
        <name><surname>Garnett</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <uri>http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      <fpage>8024</fpage>
      <lpage>8035</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Lustig2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lustig</surname><given-names>Michael</given-names></name>
        <name><surname>Donoho</surname><given-names>David</given-names></name>
        <name><surname>Pauly</surname><given-names>John M.</given-names></name>
      </person-group>
      <article-title>Sparse MRI: The application of compressed sensing for rapid MR imaging</article-title>
      <source>Magnetic Resonance in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2007">2007</year>
      <volume>58</volume>
      <issue>6</issue>
      <uri>https://doi.org/10.1002/mrm.21391</uri>
      <pub-id pub-id-type="doi">10.1002/mrm.21391</pub-id>
      <fpage>1182</fpage>
      <lpage>1195</lpage>
    </element-citation>
  </ref>
  <ref id="ref-1580791">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Candes</surname><given-names>E. J.</given-names></name>
        <name><surname>Romberg</surname><given-names>J.</given-names></name>
        <name><surname>Tao</surname><given-names>T.</given-names></name>
      </person-group>
      <article-title>Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information</article-title>
      <source>IEEE Transactions on Information Theory</source>
      <year iso-8601-date="2006">2006</year>
      <volume>52</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1109/TIT.2005.862083</pub-id>
      <fpage>489</fpage>
      <lpage>509</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Griswold2002">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Griswold</surname><given-names>Mark A.</given-names></name>
        <name><surname>Jakob</surname><given-names>Peter M.</given-names></name>
        <name><surname>Heidemann</surname><given-names>Robin M.</given-names></name>
        <name><surname>Nittka</surname><given-names>Mathias</given-names></name>
        <name><surname>Jellus</surname><given-names>Vladimir</given-names></name>
        <name><surname>Wang</surname><given-names>Jianmin</given-names></name>
        <name><surname>Kiefer</surname><given-names>Berthold</given-names></name>
        <name><surname>Haase</surname><given-names>Axel</given-names></name>
      </person-group>
      <article-title>Generalized autocalibrating partially parallel acquisitions (GRAPPA)</article-title>
      <source>Magnetic Resonance in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2002-06">2002</year><month>06</month>
      <volume>47</volume>
      <issue>6</issue>
      <uri>https://doi.org/10.1002/mrm.10171</uri>
      <pub-id pub-id-type="doi">10.1002/mrm.10171</pub-id>
      <fpage>1202</fpage>
      <lpage>1210</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Pruessmann1999">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pruessmann</surname><given-names>Klaas P.</given-names></name>
        <name><surname>Weiger</surname><given-names>Markus</given-names></name>
        <name><surname>Scheidegger</surname><given-names>Markus B.</given-names></name>
        <name><surname>Boesiger</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>SENSE: Sensitivity encoding for fast MRI</article-title>
      <source>Magnetic Resonance in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="1999-11">1999</year><month>11</month>
      <volume>42</volume>
      <issue>5</issue>
      <uri>https://doi.org/10.1002/(sici)1522-2594(199911)42:5&lt;952::aid-mrm16&gt;3.0.co;2-s</uri>
      <pub-id pub-id-type="doi">10.1002/(sici)1522-2594(199911)42:5&lt;952::aid-mrm16&gt;3.0.co;2-s</pub-id>
      <fpage>952</fpage>
      <lpage>962</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Knoll2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Knoll</surname><given-names>Florian</given-names></name>
        <name><surname>Hammernik</surname><given-names>Kerstin</given-names></name>
        <name><surname>Zhang</surname><given-names>Chi</given-names></name>
        <name><surname>Moeller</surname><given-names>Steen</given-names></name>
        <name><surname>Pock</surname><given-names>Thomas</given-names></name>
        <name><surname>Sodickson</surname><given-names>Daniel K.</given-names></name>
        <name><surname>Akcakaya</surname><given-names>Mehmet</given-names></name>
      </person-group>
      <article-title>Deep-learning methods for parallel magnetic resonance imaging reconstruction: A survey of the current approaches, trends, and issues</article-title>
      <source>IEEE Signal Processing Magazine</source>
      <publisher-name>Institute of Electrical; Electronics Engineers (IEEE)</publisher-name>
      <year iso-8601-date="2020-01">2020</year><month>01</month>
      <volume>37</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1109/msp.2019.2950640</uri>
      <pub-id pub-id-type="doi">10.1109/msp.2019.2950640</pub-id>
      <fpage>128</fpage>
      <lpage>140</lpage>
    </element-citation>
  </ref>
  <ref id="ref-arxiv.2109.08618">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pal</surname><given-names>Arghya</given-names></name>
        <name><surname>Rathi</surname><given-names>Yogesh</given-names></name>
      </person-group>
      <article-title>A review and experimental evaluation of deep learning methods for MRI reconstruction</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/2109.08618</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.2109.08618</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
