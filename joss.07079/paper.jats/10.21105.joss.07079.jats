<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7079</article-id>
<article-id pub-id-type="doi">10.21105/joss.07079</article-id>
<title-group>
<article-title>PyStack3D: A python package for fast image stack
correction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-6936-1249</contrib-id>
<name>
<surname>Quéméré</surname>
<given-names>Patrick</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6796-220X</contrib-id>
<name>
<surname>David</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Univ. Grenoble Alpes, CEA, Leti, Grenoble,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Univ. Grenoble Alpes, CEA, LITEN, Grenoble,
France</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-03-19">
<day>19</day>
<month>3</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>101</issue>
<fpage>7079</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>stack</kwd>
<kwd>image processing</kwd>
<kwd>correction</kwd>
<kwd>cropping</kwd>
<kwd>background removal</kwd>
<kwd>registration</kwd>
<kwd>intensity rescaling</kwd>
<kwd>destriping</kwd>
<kwd>curtaining</kwd>
<kwd>resampling</kwd>
<kwd>multithreading</kwd>
<kwd>multiprocessing</kwd>
<kwd>FIB-SEM</kwd>
<kwd>TOF-SIMS</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Three-dimensional reconstruction from 2D image stacks is a crucial
  technique in various scientific domains. For instance, acquisition
  techniques like Focused Ion Beam Scanning Electron Microscopy
  (FIB-SEM) leverage this approach to visualize complex structures at
  the nanoscale. However, creating a “clean” 3D stack often requires
  image corrections to remove artifacts and inconsistencies,
  particularly for volume segmentation, a crucial process for 3D
  quantitative data analysis.</p>
  <p>Here we present <monospace>PyStack3D</monospace>, a Python
  open-source library, that aims at performing several image ‘cleaning’
  tasks
  (<xref alt="[fig:PyStack3D]" rid="figU003APyStack3D">[fig:PyStack3D]</xref>)
  in the most integrated and efficient manner possible.</p>
  <fig>
    <caption><p>a) Synthetic stack with different types of defects and
    related processing. b) Corrected stack with
    <monospace>PyStack3D</monospace>. c) Ground
    truth.<styled-content id="figU003APyStack3D"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="../doc/_static/pystack3d.png" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Accurate 3D reconstruction is crucial for extracting detailed
  features across various imaging techniques. In <bold>life
  sciences</bold>, for instance, this includes identifying cellular
  organelles, understanding tissue architecture or studying protein
  localization. In <bold>energy materials</bold>, precise imaging is
  necessary for analyzing porous structures, mapping catalyst particles
  or assessing battery electrode interfaces. Various imaging methods,
  such as confocal microscopy, light sheet microscopy, and electron
  tomography, often introduce distortions or misalignments due to
  factors like optical aberrations, sample movement or inconsistent
  illumination. These issues become even more pronounced with FIB-SEM
  (<xref alt="Höflich et al., 2023" rid="ref-Hoflich" ref-type="bibr">Höflich
  et al., 2023</xref>), where artifacts from the milling process and
  variations in sample preparation can further complicate the 3D
  stack.</p>
  <p>Effective correction of these distortions is essential for reliable
  segmentation and accurate feature extraction
  (<xref alt="Osenberg et al., 2023" rid="ref-Osenberg" ref-type="bibr">Osenberg
  et al., 2023</xref>;
  <xref alt="Spehner et al., 2020" rid="ref-SPEHNER" ref-type="bibr">Spehner
  et al., 2020</xref>).</p>
</sec>
<sec id="statement-of-field">
  <title>Statement of field</title>
  <p>Certainly, one of the most widely used open-source software for
  performing image stack corrections is the Fiji software
  (<xref alt="Schindelin et al., 2012" rid="ref-Fiji" ref-type="bibr">Schindelin
  et al., 2012</xref>), a distribution of ImageJ
  (<xref alt="Schneider et al., 2012" rid="ref-ImageJ" ref-type="bibr">Schneider
  et al., 2012</xref>). Written in <bold>Java</bold>, this software
  offers numerous macros for the analysis and processing of 2D and 3D
  images. Unfortunately, not all the macros needed to perform the stack
  corrections exist, and the existing macros do not all support
  multiprocessing, which can lead to processing times of several hours
  for stacks composed of thousands of images (see
  <xref alt="Appendix" rid="appendix">Appendix</xref>).</p>
  <p>As an alternative, codes written in <bold>Python</bold> like
  <monospace>Hifiem</monospace>
  (<xref alt="Kreinin et al., 2023" rid="ref-Kreinin" ref-type="bibr">Kreinin
  et al., 2023</xref>), <monospace>PolishEM</monospace>
  (<xref alt="Fernandez et al., 2020" rid="ref-polishEM" ref-type="bibr">Fernandez
  et al., 2020</xref>) or <monospace>Napari</monospace>
  (<xref alt="Sofroniew et al., 2024" rid="ref-Napari" ref-type="bibr">Sofroniew
  et al., 2024</xref>) have been developed in recent years to achieve
  processing times of just a few minutes thanks to multiprocessing
  capabilities. <monospace>PyStack3D</monospace>, whose project started
  in 2020, is part of this trend. Designed to be executed as a workflow,
  <monospace>PyStack3D</monospace> aims to enable users to easily manage
  the automation of such workflows. With the quickly obtained results,
  users can easily readjust the parameters, and restart the processing
  if needed.</p>
</sec>
<sec id="implementation">
  <title>Implementation</title>
  <p>In <monospace>PyStack3D</monospace>, to reduce the memory
  footprint, images (called “slices”) are loaded and processed one by
  one either on a single processor or across multiple processors,
  depending on the user’s machine capabilities.</p>
  <p>The <monospace>PyStack3D</monospace> workflow is made up of
  multiple processing steps, specified in a <monospace>.toml</monospace>
  parameter file, and executed in the order desired by the user.</p>
  <p>The processing steps currently offered by
  <monospace>PyStack3D</monospace> are:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>cropping</bold> to reduce the image field of view to the
      user’s ROI (Region Of Interest)</p>
    </list-item>
    <list-item>
      <p><bold>background removal</bold> to reduce, from 2D or 3D
      polynomial approximations, large-scaled brightness and contrast
      variations issued for instance from shadowing or charging effects
      in FIB-SEM images acquisition</p>
    </list-item>
    <list-item>
      <p><bold>intensity rescaling</bold> to homogenize the ‘gray’
      intensity distribution between successive slices and smooth out
      abrupt intensity jumps that can occur due to, for instance,
      variations in the beam source.</p>
    </list-item>
    <list-item>
      <p><bold>registration</bold> to correct the image misalignment due
      to shifting, drift, rotation, … during the image acquisition
      (based on the <monospace>PyStackReg</monospace> package,
      <xref alt="Thevenaz et al., 1998" rid="ref-PyStackReg" ref-type="bibr">Thevenaz
      et al., 1998</xref>)</p>
    </list-item>
    <list-item>
      <p><bold>destriping</bold> to minimize artefacts like stripes or
      curtain effects typically found in FIB-SEM images, based on the
      <monospace>PyVSNR</monospace> package
      (<xref alt="Fehrenbach et al., 2012" rid="ref-VSNR" ref-type="bibr">Fehrenbach
      et al., 2012</xref>;
      <xref alt="Pavy &amp; Quéméré, 2024" rid="ref-pyVSNR" ref-type="bibr">Pavy
      &amp; Quéméré, 2024</xref>), or wavelet decomposition
      (<xref alt="Münch et al., 2009" rid="ref-Munch" ref-type="bibr">Münch
      et al., 2009</xref>)</p>
    </list-item>
    <list-item>
      <p><bold>resampling</bold> to correct non-uniform spatial
      inter-slice distances and enable correct 3D volume
      reconstructions</p>
    </list-item>
    <list-item>
      <p><bold>final cropping</bold> to eliminate artefacts potentially
      produced near the edges during the image processing or to select
      another ROI at the end.</p>
    </list-item>
  </list>
  <p>At the end of each process step, <monospace>PyStack3D</monospace>
  provides statistical profiles like evolution of minimum, maximum, and
  mean values for each slice, and relevant visualizations specific to
  the processing performed. In addition, 3D and 2D plots (cut-planes)
  akin to those shown in
  <xref alt="[fig:PyStack3D]" rid="figU003APyStack3D">[fig:PyStack3D]</xref>
  and
  <xref alt="[fig:workflow]" rid="figU003Aworkflow">[fig:workflow]</xref>,
  respectively, can be produced.</p>
  <p>Note that the processing can be carried out on multiple channels
  corresponding to images issued from multiple detectors, typically
  useful in the context of FIB-SEM input data. Moreover, when working
  with a Zeiss microscope, some metadata issued from the equipment can
  be automatically incorporated in the input
  <monospace>.toml</monospace> parameter file.</p>
  <p>In conclusion, <monospace>Pystack3D</monospace> has been designed
  to evolve over time and accommodate new process steps. Its code
  structure has been crafted to seamlessly integrate new
  functionalities, leveraging multiprocessing capabilities.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work, carried out on the CEA-Platform for Nanocharacterisation
  (PFNC), was supported by the ``Recherche Technologique de Base’’
  program of the French National Research Agency (ANR).</p>
  <graphic mimetype="image" mime-subtype="png" xlink:href="../doc/_static/workflow_1.png" />
  <fig>
    <caption><p>Cut-planes related to the different process steps
    applied to the stack presented in the
    <xref alt="[fig:PyStack3D]" rid="figU003APyStack3D">[fig:PyStack3D]</xref>.<styled-content id="figU003Aworkflow"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="../doc/_static/workflow_2.png" />
  </fig>
</sec>
<sec id="appendix">
  <title>Appendix</title>
  <p><bold>Processing time for a stack composed of 2000 slices</bold>
  (from
  <ext-link ext-link-type="uri" xlink:href="https://github.com/CEA-MetroCarac/pystack3d/blob/main/examples/ex_real_stack_perf.py">ex_real_stack_perf.py</ext-link>)</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th align="left">Process step</th>
          <th align="center">Fiji (s)</th>
          <th align="center">PyStack3D (s)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">cropping</td>
          <td align="center">750</td>
          <td align="center">30</td>
        </tr>
        <tr>
          <td align="left">bkg_removal (2D / 3D)</td>
          <td align="center">250 / -</td>
          <td align="center">70 / 40*</td>
        </tr>
        <tr>
          <td align="left">destriping</td>
          <td align="center">22400</td>
          <td align="center">700**</td>
        </tr>
        <tr>
          <td align="left">registration</td>
          <td align="center">5400</td>
          <td align="center">25</td>
        </tr>
        <tr>
          <td align="left">intensity_rescaling</td>
          <td align="center">-</td>
          <td align="center">25</td>
        </tr>
        <tr>
          <td align="left">resampling</td>
          <td align="center">-</td>
          <td align="center">10</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p><bold>image size</bold>: 4224 x 4224 before cropping / 2000 x 2000
  after cropping.</p>
  <p><bold>Machine</bold>: Linux - <bold>32 CPUs</bold> Intel(R) Xeon(R)
  Platinum 8362 CPU @ 2.80GHz.</p>
  <p>(*) in 3D the polynomial coefficients are calculated only once,
  unlike in 2D, where the coefficients are recalculated for each
  slice.</p>
  <p>(**) 120s with a GPU Nvidia A-100.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Fiji">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schindelin</surname><given-names>J.</given-names></name>
        <name><surname>Arganda-Carreras</surname><given-names>I.</given-names></name>
        <name><surname>Frise</surname><given-names>E</given-names></name>
      </person-group>
      <article-title>Fiji: An open-source platform for biological-image analysis</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2012">2012</year>
      <volume>9</volume>
      <uri>https://doi.org/10.1038/nmeth.2019</uri>
      <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
      <fpage>676</fpage>
      <lpage>682</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ImageJ">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schneider</surname><given-names>Caroline A</given-names></name>
        <name><surname>Rasband</surname><given-names>Wayne S</given-names></name>
        <name><surname>Eliceiri</surname><given-names>Kevin W</given-names></name>
      </person-group>
      <article-title>NIH image to ImageJ: 25 years of image analysis</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2012-07">2012</year><month>07</month>
      <volume>9</volume>
      <issue>7</issue>
      <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id>
      <fpage>671</fpage>
      <lpage>675</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PyStackReg">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Thevenaz</surname><given-names>P.</given-names></name>
        <name><surname>Ruttiman</surname><given-names>U. E.</given-names></name>
        <name><surname>Unser</surname><given-names>M.</given-names></name>
      </person-group>
      <article-title>A pyramid approach to subpixel registration based on intensity</article-title>
      <source>IEEE Transactions on Image Processing</source>
      <year iso-8601-date="1998">1998</year>
      <volume>7</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1109/83.650848</pub-id>
      <fpage>27</fpage>
      <lpage>41</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pyVSNR">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Pavy</surname><given-names>K.</given-names></name>
        <name><surname>Quéméré</surname><given-names>P.</given-names></name>
      </person-group>
      <article-title>PyVSNR 2.0.0</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <uri>https://doi.org/10.5281/zenodo.10623640</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.10623640</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-VSNR">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fehrenbach</surname><given-names>J.</given-names></name>
        <name><surname>Weiss</surname><given-names>W.</given-names></name>
        <name><surname>Lorenzo</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Variational algorithms to remove stationary noise. Application to microscopy imaging.</article-title>
      <source>IEEE Image Processing</source>
      <year iso-8601-date="2012">2012</year>
      <volume>21</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1109/TIP.2012.2206037</pub-id>
      <fpage>4420</fpage>
      <lpage>4430</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hoflich">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Höflich</surname><given-names>Katja</given-names></name>
        <name><surname>Hobler</surname><given-names>Gerhard</given-names></name>
        <name><surname>Allen</surname><given-names>Frances I</given-names></name>
        <name><surname>Wirtz</surname><given-names>Tom</given-names></name>
        <name><surname>Rius</surname><given-names>Gemma</given-names></name>
        <name><surname>McElwee-White</surname><given-names>Lisa</given-names></name>
        <name><surname>Krasheninnikov</surname><given-names>Arkady V</given-names></name>
        <name><surname>Schmidt</surname><given-names>Matthias</given-names></name>
        <name><surname>Utke</surname><given-names>Ivo</given-names></name>
        <name><surname>Klingner</surname><given-names>Nico</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Roadmap for focused ion beam technologies</article-title>
      <source>Applied Physics Reviews</source>
      <publisher-name>AIP Publishing</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>10</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1063/5.0162597</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Osenberg">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Osenberg</surname><given-names>Markus</given-names></name>
        <name><surname>Hilger</surname><given-names>André</given-names></name>
        <name><surname>Neumann</surname><given-names>Matthias</given-names></name>
        <name><surname>Wagner</surname><given-names>Amalia</given-names></name>
        <name><surname>Bohn</surname><given-names>Nicole</given-names></name>
        <name><surname>Binder</surname><given-names>Joachim R.</given-names></name>
        <name><surname>Schmidt</surname><given-names>Volker</given-names></name>
        <name><surname>Banhart</surname><given-names>John</given-names></name>
        <name><surname>Manke</surname><given-names>Ingo</given-names></name>
      </person-group>
      <article-title>Classification of FIB/SEM-tomography images for highly porous multiphase materials using random forest classifiers</article-title>
      <source>Journal of Power Sources</source>
      <year iso-8601-date="2023">2023</year>
      <volume>570</volume>
      <issn>0378-7753</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0378775323004056</uri>
      <pub-id pub-id-type="doi">10.1016/j.jpowsour.2023.233030</pub-id>
      <fpage>233030</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Kreinin">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kreinin</surname><given-names>Yuri</given-names></name>
        <name><surname>Gunn</surname><given-names>Pat</given-names></name>
        <name><surname>Chklovskii</surname><given-names>Dmitri</given-names></name>
        <name><surname>Wu</surname><given-names>Jingpeng</given-names></name>
      </person-group>
      <article-title>High-fidelity image restoration of large 3D electron microscopy volume</article-title>
      <source>bioRxiv</source>
      <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.biorxiv.org/content/early/2023/09/17/2023.09.14.557785</uri>
      <pub-id pub-id-type="doi">10.1101/2023.09.14.557785</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Napari">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Sofroniew</surname><given-names>Nicholas</given-names></name>
        <name><surname>Lambert</surname><given-names>Talley</given-names></name>
        <name><surname>Bokota</surname><given-names>Grzegorz</given-names></name>
        <name><surname>Nunez-Iglesias</surname><given-names>Juan</given-names></name>
        <name><surname>Sobolewski</surname><given-names>Peter</given-names></name>
        <name><surname>Sweet</surname><given-names>Andrew</given-names></name>
        <name><surname>Gaifas</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Evans</surname><given-names>Kira</given-names></name>
        <name><surname>Burt</surname><given-names>Alister</given-names></name>
        <name><surname>Doncila Pop</surname><given-names>Draga</given-names></name>
      </person-group>
      <article-title>napari: a multi-dimensional image viewer for Python</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024-08">2024</year><month>08</month>
      <uri>https://doi.org/10.5281/zenodo.13309520</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.13309520</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Munch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Münch</surname><given-names>Beat</given-names></name>
        <name><surname>Trtik</surname><given-names>Pavel</given-names></name>
        <name><surname>Marone</surname><given-names>Federica</given-names></name>
        <name><surname>Stampanoni</surname><given-names>Marco</given-names></name>
      </person-group>
      <article-title>Stripe and ring artifact removal with combined wavelet — fourier filtering</article-title>
      <source>Optics Express</source>
      <publisher-name>Optica Publishing Group</publisher-name>
      <year iso-8601-date="2009-05">2009</year><month>05</month>
      <volume>17</volume>
      <issue>10</issue>
      <uri>https://opg.optica.org/oe/abstract.cfm?URI=oe-17-10-8567</uri>
      <pub-id pub-id-type="doi">10.1364/OE.17.008567</pub-id>
      <fpage>8567</fpage>
      <lpage>8591</lpage>
    </element-citation>
  </ref>
  <ref id="ref-SPEHNER">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spehner</surname><given-names>Daniele</given-names></name>
        <name><surname>Steyer</surname><given-names>Anna M.</given-names></name>
        <name><surname>Bertinetti</surname><given-names>Luca</given-names></name>
        <name><surname>Orlov</surname><given-names>Igor</given-names></name>
        <name><surname>Benoit</surname><given-names>Lucas</given-names></name>
        <name><surname>Pernet-Gallay</surname><given-names>Karin</given-names></name>
        <name><surname>Schertel</surname><given-names>Andreas</given-names></name>
        <name><surname>Schultz</surname><given-names>Patrick</given-names></name>
      </person-group>
      <article-title>Cryo-FIB-SEM as a promising tool for localizing proteins in 3D</article-title>
      <source>Journal of Structural Biology</source>
      <year iso-8601-date="2020">2020</year>
      <volume>211</volume>
      <issue>1</issue>
      <issn>1047-8477</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S1047847720301015</uri>
      <pub-id pub-id-type="doi">10.1016/j.jsb.2020.107528</pub-id>
      <fpage>107528</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-polishEM">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fernandez</surname><given-names>Jose-Jesus</given-names></name>
        <name><surname>Torres</surname><given-names>Teobaldo E</given-names></name>
        <name><surname>Martin-Solana</surname><given-names>Eva</given-names></name>
        <name><surname>Goya</surname><given-names>Gerardo F</given-names></name>
        <name><surname>Fernandez-Fernandez</surname><given-names>Maria-Rosario</given-names></name>
      </person-group>
      <article-title>PolishEM: image enhancement in FIB–SEM</article-title>
      <source>Bioinformatics</source>
      <year iso-8601-date="2020-03">2020</year><month>03</month>
      <volume>36</volume>
      <issue>12</issue>
      <issn>1367-4803</issn>
      <uri>https://doi.org/10.1093/bioinformatics/btaa218</uri>
      <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa218</pub-id>
      <fpage>3947</fpage>
      <lpage>3948</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
