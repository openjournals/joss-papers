<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7050</article-id>
<article-id pub-id-type="doi">10.21105/joss.07050</article-id>
<title-group>
<article-title>MicroFloatingPoints.jl: providing very small
IEEE 754-compliant floating-point types</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1798-1568</contrib-id>
<name>
<surname>Goualard</surname>
<given-names>Frédéric</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR
6004, Nantes, France</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-09-17">
<day>17</day>
<month>9</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>101</issue>
<fpage>7050</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>floating-point arithmetic</kwd>
<kwd>visualization</kwd>
<kwd>minifloats</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The IEEE 754 standard defines the representation and the properties
  of the floating-point numbers used as surrogates for reals in computer
  programs. Most programming languages only support the 32-bit
  (<monospace>Float32</monospace>) and 64-bit
  (<monospace>Float64</monospace>) formats implemented in hardware.
  Machine learning, computer graphics, and numerical algorithms analysis
  all have a need for smaller formats, which are often neither supported
  in hardware, nor are they available as established types in
  programming languages. The
  <ext-link ext-link-type="uri" xlink:href="https://github.com/goualard-f/MicroFloatingPoints.jl"><monospace>MicroFloatingPoints.jl</monospace></ext-link>
  <ext-link ext-link-type="uri" xlink:href="https://julialang.org/">Julia</ext-link>
  library offers a parametric type that can be instantiated to compute
  with IEEE 754-compliant floating-point numbers with varying ranges and
  precisions (up to and including <monospace>Float32</monospace>). It
  also provides the programmer with various means to visualize what is
  computed.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Proving the properties of numerical algorithms involving
  floating-point numbers can be a very challenging task. Insight can
  often be gained by systematically executing the algorithm under study
  for all possible inputs. There are, however, too many values to
  consider with the classically available types
  <monospace>Float32</monospace> and <monospace>Float64</monospace>.
  Hence there is a need for libraries that offer many smaller IEEE
  754-compliant types to play with. SIPE
  (<xref alt="Lefèvre, 2013" rid="ref-lefevreSIPESmallInteger2013" ref-type="bibr">Lefèvre,
  2013</xref>), FloatX
  (<xref alt="Flegar et al., 2019" rid="ref-flegarFloatXLibraryCustomized2019" ref-type="bibr">Flegar
  et al., 2019</xref>), and CPFloat
  (<xref alt="Fasi &amp; Mikaitis, 2023" rid="ref-fasiCPFloatLibrarySimulating2023" ref-type="bibr">Fasi
  &amp; Mikaitis, 2023</xref>), to name a few, are such libraries.
  However, being written in languages such as C or C++, they lack the
  interactivity and tight integration with graphical facilities that can
  be obtained from using script languages such as
  <ext-link ext-link-type="uri" xlink:href="https://julialang.org/">Julia</ext-link>.
  <monospace>MicroFloatingPoints.jl</monospace> is a Julia library that
  fills this need by offering a parametric type,
  <monospace>Floatmu</monospace>, that can be instantiated to simulate
  in software small floating-point types:
  <monospace>Floatmu{8,23}</monospace> is a type using 8 bits to
  represent the exponent and 23 bits for the fractional part, which is
  equivalent to <monospace>Float32</monospace>;
  <monospace>Floatmu{8,7}</monospace> is equivalent to the Google Brain
  <monospace>bfloat16</monospace> format, …</p>
  <sec id="a-quick-tour">
    <title>A quick tour</title>
    <p>To obtain a (pseudo-)random float in the domain
    <inline-formula><alternatives>
    <tex-math><![CDATA[[0,1)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    for a floating-point format with a <inline-formula><alternatives>
    <tex-math><![CDATA[p]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>p</mml:mi></mml:math></alternatives></inline-formula>-bit
    significand, many libraries simply divide a pseudo-random integer
    taken from <inline-formula><alternatives>
    <tex-math><![CDATA[[0, 2^p-1]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    by <inline-formula><alternatives>
    <tex-math><![CDATA[2^p]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula>
    (<xref alt="Goualard, 2020" rid="ref-goualardGeneratingRandomFloatingPoint2020" ref-type="bibr">Goualard,
    2020</xref>). Does this ensure an even distribution of the bits in
    the fractional parts of the random floats, as required by
    applications such as <italic>differential privacy</italic>
    (<xref alt="Dwork, 2006" rid="ref-dworkDifferentialPrivacy2006" ref-type="bibr">Dwork,
    2006</xref>;
    <xref alt="Mironov, 2012" rid="ref-mironovSignificanceLeastSignificant2012" ref-type="bibr">Mironov,
    2012</xref>)? This can be systematically and quickly checked for a
    small floating-point format. We start by loading
    <monospace>MicroFloatingPoints</monospace> and
    <monospace>PyPlot</monospace> (alternatively,
    <monospace>PythonPlot</monospace> could also be used) for the
    graphics:</p>
    <code language="julia">using MicroFloatingPoints, PyPlot</code>
    <p>and we define a new IEEE 754-compliant floating-point type, say,
    with 7 bits for the exponent and 9 bits for the significand (i.e., 8
    bits for the fractional part):</p>
    <code language="julia">const E = 7 # Size of the exponent part
const f = 8 # Size of the fractional part
const p = f+1 # Size of the significand
const MuFP = Floatmu{E,f} # New IEEE 754 type</code>
    <p>We now divide all integers in <inline-formula><alternatives>
    <tex-math><![CDATA[[0,2^p-1]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    by <inline-formula><alternatives>
    <tex-math><![CDATA[2^p]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula>
    to obtain a <monospace>MuFP</monospace> float, for which we record
    the value of each bit of its fractional part. An array
    <monospace>T</monospace> with <monospace>f</monospace> cells will
    accumulate the number of occurrences of a ‘<monospace>1</monospace>’
    over all floats produced (specifically, <monospace>T[i]</monospace>
    will contain the number of times the <monospace>(f-i)</monospace>-th
    bit of the fractional part was a ‘<monospace>1</monospace>’ so
    far—with the zeroth bit being the rightmost one, as usual).</p>
    <code language="julia">T = zeros(UInt32, f)
for v in 0:(2^p-1)
    d = MuFP(v)/2^p
    fpart = bitstring(d)[2+E:end] # Isolating the fractional part
    for j in 1:f
        global T[j] += Int(fpart[j] == '1')
    end
end</code>
    <p>We now normalize to <inline-formula><alternatives>
    <tex-math><![CDATA[[0,1]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    the number of occurrences, and display the results with a bar plot
    (Figure
    <xref alt="[fig:random8]" rid="figU003Arandom8">[fig:random8]</xref>).</p>
    <code language="julia">nT = map(x -&gt; x/2^p,T)
plt.bar(1:f,nT)
plt.xticks(1:f,reverse(map((x)-&gt;string(x-1),1:f)))
plt.yticks(0:0.1:1)</code>
    <fig>
      <caption><p>Probability of being ‘1’ for each bit of the
      fractional part of a <monospace>Floatmu{7,8}</monospace> when
      dividing each integer in <inline-formula><alternatives>
      <tex-math><![CDATA[[0,2^{9}-1]]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mn>9</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
      by <inline-formula><alternatives>
      <tex-math><![CDATA[2^{9}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>2</mml:mn><mml:mn>9</mml:mn></mml:msup></mml:math></alternatives></inline-formula>.<styled-content id="figU003Arandom8"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="svg+xml" xlink:href="random.7.8.svg" />
    </fig>
    <p>We were expecting a probability of <inline-formula><alternatives>
    <tex-math><![CDATA[0.5]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.5</mml:mn></mml:math></alternatives></inline-formula>
    for each bit of the fractional part to be <monospace>1</monospace>.
    The actual plot shows that this is not the case and that the
    probability decreases for the lowest bits. It is very easy to check
    that behavior for a larger type by, e.g., changing the value of
    <monospace>f</monospace> to ‘<monospace>16</monospace>’ in our
    previous code and reexecuting the script. The result in Figure
    <xref alt="[fig:random16]" rid="figU003Arandom16">[fig:random16]</xref>
    exhibits the same behavior for the larger type
    <monospace>Floatmu{7,16}</monospace>.</p>
    <fig>
      <caption><p>Probability of being ‘1’ for each bit of the
      fractional part of a <monospace>Floatmu{7,16}</monospace> when
      dividing each integer in <inline-formula><alternatives>
      <tex-math><![CDATA[[0,2^{17}-1]]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mn>17</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
      by <inline-formula><alternatives>
      <tex-math><![CDATA[2^{17}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>2</mml:mn><mml:mn>17</mml:mn></mml:msup></mml:math></alternatives></inline-formula>.<styled-content id="figU003Arandom16"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="svg+xml" xlink:href="random.7.16.svg" />
    </fig>
  </sec>
  <sec id="limitations">
    <title>Limitations</title>
    <p>At present, all computations are performed in double precision
    (the <monospace>Float64</monospace> type), then correctly rounded to
    the <monospace>Floatmu{}</monospace> format chosen. As long as the
    precision of the <monospace>Floatmu{}</monospace> type is at most
    half the one of <monospace>Float64</monospace>, there is no
    <italic>double rounding</italic> issue
    (<xref alt="Martin-Dorel et al., 2013" rid="ref-martin-dorelIssuesRelatedDouble2013" ref-type="bibr">Martin-Dorel
    et al., 2013</xref>), and any final result obtained in that way is
    exactly the same as the one we would obtain by computing directly
    with the <monospace>Floatmu{}</monospace> precision
    (<xref alt="Rump, 2016" rid="ref-rumpIEEE754PrecisionBase2016" ref-type="bibr">Rump,
    2016</xref>).</p>
    <p>Small floating-point formats are increasingly used in machine
    learning algorithms, where the precision and range are less
    important than the capability to store and manipulate as many values
    as possible. There are already some established formats implemented
    in hardware (e.g., IEEE 754 <monospace>Float16</monospace>,
    available natively in Julia, and Google Brain
    <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format"><monospace>bfloat16</monospace></ext-link>,
    provided by the Julia Package
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaMath/BFloat16s.jl"><monospace>BFloat16s.jl</monospace></ext-link>).
    There is, however, still a need for more flexibility to test the
    behavior of algorithms with varying precisions and ranges. The
    parametric type of <monospace>MicroFloatingPoints.jl</monospace> can
    be put to good use there too, and has already been for the study of
    training neural networks
    (<xref alt="Arthur et al., 2023" rid="ref-arthurScalableImplementationRecursive2023a" ref-type="bibr">Arthur
    et al., 2023</xref>). However, since it represents all
    floating-point formats by a pair of 32 bit integers, it cannot
    compete with more specialized packages for applications that require
    storing and manipulating massive amounts of numbers. For such use
    cases, it should therefore be confined to preliminary investigations
    with more limited amounts of data.</p>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>The reviewers and the editor for JOSS suggested many improvements
  to both the manuscript and the library itself during the reviewing
  process, which significantly increased their quality.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-lefevreSIPESmallInteger2013">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lefèvre</surname><given-names>Vincent</given-names></name>
      </person-group>
      <article-title>SIPE: Small integer plus exponent</article-title>
      <source>Proceedings of the 2013 IEEE 21st symposium on computer arithmetic</source>
      <publisher-name>IEEE Computer Society</publisher-name>
      <publisher-loc>USA</publisher-loc>
      <year iso-8601-date="2013-04">2013</year><month>04</month>
      <isbn>978-0-7695-4957-6</isbn>
      <pub-id pub-id-type="doi">10.1109/ARITH.2013.22</pub-id>
      <fpage>99</fpage>
      <lpage>106</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rumpIEEE754PrecisionBase2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rump</surname><given-names>Siegfried M.</given-names></name>
      </person-group>
      <article-title>IEEE754 precision-k base-\beta arithmetic inherited by precision-m base-\beta arithmetic for k&lt;m</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <year iso-8601-date="2016-12">2016</year><month>12</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2020-09-16">2020</year><month>09</month><day>16</day></date-in-citation>
      <volume>43</volume>
      <issue>3</issue>
      <issn>0098-3500</issn>
      <uri>http://doi.org/10.1145/2785965</uri>
      <pub-id pub-id-type="doi">10.1145/2785965</pub-id>
      <fpage>20:1</fpage>
      <lpage>20:15</lpage>
    </element-citation>
  </ref>
  <ref id="ref-flegarFloatXLibraryCustomized2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Flegar</surname><given-names>Goran</given-names></name>
        <name><surname>Scheidegger</surname><given-names>Florian</given-names></name>
        <name><surname>Novaković</surname><given-names>Vedran</given-names></name>
        <name><surname>Mariani</surname><given-names>Giovani</given-names></name>
        <name><surname>Tomás</surname><given-names>Andrés E.</given-names></name>
        <name><surname>Malossi</surname><given-names>A. Cristiano I.</given-names></name>
        <name><surname>Quintana-Ortí</surname><given-names>Enrique S.</given-names></name>
      </person-group>
      <article-title>FloatX: A C++ library for customized floating-point arithmetic</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <year iso-8601-date="2019-12">2019</year><month>12</month>
      <volume>45</volume>
      <issue>4</issue>
      <issn>0098-3500</issn>
      <pub-id pub-id-type="doi">10.1145/3368086</pub-id>
      <fpage>1</fpage>
      <lpage>23</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dworkDifferentialPrivacy2006">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dwork</surname><given-names>Cynthia</given-names></name>
      </person-group>
      <article-title>Differential privacy</article-title>
      <source>Automata, languages and programming</source>
      <person-group person-group-type="editor">
        <name><surname>Bugliesi</surname><given-names>Michele</given-names></name>
        <name><surname>Preneel</surname><given-names>Bart</given-names></name>
        <name><surname>Sassone</surname><given-names>Vladimiro</given-names></name>
        <name><surname>Wegener</surname><given-names>Ingo</given-names></name>
      </person-group>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>Berlin, Heidelberg</publisher-loc>
      <year iso-8601-date="2006">2006</year>
      <isbn>978-3-540-35908-1</isbn>
      <pub-id pub-id-type="doi">10.1007/11787006_1</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-goualardGeneratingRandomFloatingPoint2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Goualard</surname><given-names>Frédéric</given-names></name>
      </person-group>
      <article-title>Generating random floating-point numbers by dividing integers: A case study</article-title>
      <source>Proceedings of the international conference on computational science</source>
      <person-group person-group-type="editor">
        <name><surname>Krzhizhanovskaya</surname><given-names>V.</given-names></name>
      </person-group>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>Amsterdam, The Netherlands</publisher-loc>
      <year iso-8601-date="2020-06">2020</year><month>06</month>
      <volume>12138</volume>
      <isbn>978-3-030-50416-8</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-030-50417-5_2</pub-id>
      <fpage>15</fpage>
      <lpage>28</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fasiCPFloatLibrarySimulating2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fasi</surname><given-names>Massimiliano</given-names></name>
        <name><surname>Mikaitis</surname><given-names>Mantas</given-names></name>
      </person-group>
      <article-title>CPFloat: A C library for simulating low-precision arithmetic</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <year iso-8601-date="2023-06">2023</year><month>06</month>
      <volume>49</volume>
      <issue>2</issue>
      <issn>0098-3500</issn>
      <pub-id pub-id-type="doi">10.1145/3585515</pub-id>
      <fpage>18:1</fpage>
      <lpage>18:32</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mironovSignificanceLeastSignificant2012">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mironov</surname><given-names>Ilya</given-names></name>
      </person-group>
      <article-title>On significance of the least significant bits for differential privacy</article-title>
      <source>Proceedings of the 2012 ACM conference on computer and communications security - CCS ’12</source>
      <publisher-name>ACM Press</publisher-name>
      <publisher-loc>Raleigh, North Carolina, USA</publisher-loc>
      <year iso-8601-date="2012">2012</year>
      <isbn>978-1-4503-1651-4</isbn>
      <pub-id pub-id-type="doi">10.1145/2382196.2382264</pub-id>
      <fpage>650</fpage>
      <lpage>661</lpage>
    </element-citation>
  </ref>
  <ref id="ref-arthurScalableImplementationRecursive2023a">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Arthur</surname><given-names>Benjamin J.</given-names></name>
        <name><surname>Kim</surname><given-names>Christopher M.</given-names></name>
        <name><surname>Chen</surname><given-names>Susu</given-names></name>
        <name><surname>Preibisch</surname><given-names>Stephan</given-names></name>
        <name><surname>Darshan</surname><given-names>Ran</given-names></name>
      </person-group>
      <article-title>A scalable implementation of the recursive least-squares algorithm for training spiking neural networks</article-title>
      <source>Frontiers in Neuroinformatics</source>
      <year iso-8601-date="2023-06">2023</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-07-23">2024</year><month>07</month><day>23</day></date-in-citation>
      <volume>17</volume>
      <issn>1662-5196</issn>
      <pub-id pub-id-type="doi">10.3389/fninf.2023.1099510</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-martin-dorelIssuesRelatedDouble2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Martin-Dorel</surname><given-names>Érik</given-names></name>
        <name><surname>Melquiond</surname><given-names>Guillaume</given-names></name>
        <name><surname>Muller</surname><given-names>Jean-Michel</given-names></name>
      </person-group>
      <article-title>Some issues related to double rounding</article-title>
      <source>BIT Numerical Mathematics</source>
      <year iso-8601-date="2013-12">2013</year><month>12</month>
      <volume>53</volume>
      <issue>4</issue>
      <issn>0006-3835</issn>
      <uri>http://link.springer.com/10.1007/s10543-013-0436-2</uri>
      <pub-id pub-id-type="doi">10.1007/s10543-013-0436-2</pub-id>
      <fpage>897</fpage>
      <lpage>924</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
