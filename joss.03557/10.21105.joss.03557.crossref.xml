<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>7772182aba093eb839f7e5c31af638fd</doi_batch_id>
    <timestamp>20211016075841</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2021</year>
        </publication_date>
        <journal_volume>
          <volume>6</volume>
        </journal_volume>
        <issue>66</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>Inscriptis - A Python-based HTML to text conversion library optimized for knowledge extraction from the Web</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Albert</given_name>
            <surname>Weichselbraun</surname>
            <ORCID>http://orcid.org/0000-0001-6399-045X</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>16</day>
          <year>2021</year>
        </publication_date>
        <pages>
          <first_page>3557</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.03557</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">“https://doi.org/10.5281/zenodo.5562417”</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/3557</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.03557</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.03557</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.03557.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="ref1">
            <doi>10.1007/s11042-019-08328-z</doi>
          </citation>
          <citation key="ref2">
            <unstructured_citation>Distributed Representations of Words and Phrases and their Compositionality, http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality, Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States, Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Gregory S. and Dean, Jeffrey, 2013, word2vec, 3111–3119, arXiv:1310.4546 PDF:/home/albert/Zotero/storage/695ESUSG/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf</unstructured_citation>
          </citation>
          <citation key="ref3">
            <doi>10.3115/v1/D14-1162</doi>
          </citation>
          <citation key="ref4">
            <doi>10.1109/JSYST.2015.2466439</doi>
          </citation>
          <citation key="ref5">
            <doi>10.1016/j.ins.2014.03.096</doi>
          </citation>
          <citation key="ref6">
            <doi>10.3390/fi13030059</doi>
          </citation>
          <citation key="ref7">
            <doi>10.1145/3430937</doi>
          </citation>
          <citation key="ref8">
            <unstructured_citation>JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase, 35, Copyright (c) 2021 Association for the Advancement of Artificial Intelligence, 2374-3468, JEL, https://ojs.aaai.org/index.php/AAAI/article/view/17796, en, 17, 2021-06-03, Proceedings of the AAAI Conference on Artificial Intelligence, Ding, Wanying and Chaudhri, Vinay K. and Chittar, Naren and Konakanchi, Krihshna, may, 2021, Number: 17, business intelligence, Deep &amp; Wide Learning, Named entity linking, 15301–15308, Summary Named entity linking in the business domain is a challenging task, since most state of the art methods rely upon comprehensive context information (e.g., from Wikipedia) that is not available for many business entities. This paper, therefore, addresses an end-to-end neural entity linking model (JEL) that uses minimal context information and margin loss to generate entity embeddings and a Wide &amp; Deep Learning model that draws upon these embeddings for entity linking. Method The authors use (i) spaCy for entity recognition and (ii) their method for linking to identified entities. Entit Embedding triple loss model that selects 10 terms that are positive context examples for an entity, and 10 randomly selected negative examples (how representative are these examples; effectiveness?) to compute contextualized entity embeddings Enitity Linking Character matching: Wide Character Learning with subword information for matching entities (more effective than verbatim matching since it also considers typos) Semantic matching: Use deep semantic embeddings to embed mentions based on the context into a vector. Compute the similarity between mention-vectors and entity-vectors based on Euclidean distance. Application similar to WISDOM - identify businesses in financial news and propagate the impact of the coverage (e.g., financial difficulties) along the supply chain., Snapshot:/home/albert/Zotero/storage/53XPV5G9/17796.html:text/html;Ding et al. - 2021 - JEL Applying End-to-End Neural Entity Linking in .pdf:/home/albert/Zotero/storage/4KWA6M6F/Ding et al. - 2021 - JEL Applying End-to-End Neural Entity Linking in .pdf:application/pdf, 5</unstructured_citation>
          </citation>
          <citation key="ref9">
            <doi>10.18653/v1/2021.acl-long.558</doi>
          </citation>
          <citation key="ref10">
            <doi>10.1080/14740338.2018.1531847</doi>
          </citation>
          <citation key="ref11">
            <unstructured_citation>Kreymer, Ilya and Nagel, Sebastian and Jackson, Andy and Levitt, Noah, IIPC Web Archive Commons - Utility code for OpenWayBack and other projects., 2021, GitHub, GitHub repository, https://github.com/commoncrawl/ia-web-commons, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref12">
            <unstructured_citation>Swartz, Aaron, html2text - a Python script that converts a page of HTML into clean, easy-to-read plain ASCII text, 2021, GitHub, GitHub repository, https://github.com/Alir3z4/html2text, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref13">
            <unstructured_citation>Belica, Michal, jusText - Heuristic based boilerplate removal tool, 2021, GitHub, GitHub repository, https://github.com/miso-belica/jusText, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref14">
            <unstructured_citation>Huggins, Jason and Gross, Paul and Wang, Jie Tina, jusText - Heuristic based boilerplate removal tool, 2021, The Selenium Project, https://www.selenium.dev, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref15">
            <unstructured_citation>Dickey, Thomas E., Lynx - The Text Web-Browser, 2021, Lynx Home Page, https://lynx.invisible-island.net, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref16">
            <unstructured_citation>Nakayama, Hiroki and Kubo, Takahiro and Kamura, Junya and Taniguchi, Yasufumi and Liang, Xu, doccano: Text Annotation Tool for Human, 2018, GitHub, GitHub repository, https://github.com/doccano/doccano, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref17">
            <unstructured_citation>Richardson, Leonard, Beautiful Soup - a library that makes it easy to scrape information from web pages, 2021, Python Package Index, PyPI repository, https://pypi.org/project/beautifulsoup4/, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref18">
            <unstructured_citation>Behnel, Stefan and Faassen, Martijn and Bicking, Ian and Joukl, Holger and Sapin, Simon and Parent, Marc-Antoine and Grisel, Olivier and Buchcik, Kasimier and Wagner, Florian and Kroymann, Emil and Everitt, Paul and Ng, Victor and Kern, Robert and Pakulat, Andreas and Sankel, David and Kasperski, Marcin and da Silva, Sidnei and Oberndörfer, Pascal, lxml - Processing XML and HTML with Python, 2021, lxml Project, https://lxml.de/, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref19">
            <unstructured_citation>Mueller, Matthew and Böhm, Felix and Mike, Jugglin and Chambers, David, Cheerio - Fast, flexible, and lean implementation of core jQuery designed specifically for the server., 2021, GitHub, GitHub repository, https://github.com/cheeriojs/cheerio, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref20">
            <unstructured_citation>Riebold, John, BoilerPy3 - Python port of Boilerpipe library, 2021, GitHub, GitHub repository, https://github.com/jmriebold/BoilerPy3, Accessed: 2021-09-02</unstructured_citation>
          </citation>
          <citation key="ref21">
            <doi>10.1109/WIIAT50758.2020.00065</doi>
          </citation>
          <citation key="ref22">
            <doi>10.1145/2487788.2487828</doi>
          </citation>
          <citation key="ref23">
            <unstructured_citation>Vienna, Austria, TextSweeper - A System for Content Extraction and Overview Page Detection, All rights reserved, Web pages not only contain main content, but also other elements such as navigation panels, advertisements and links to related documents. Furthermore, overview pages (summarization pages and entry points) duplicate and aggregate parts of articles and thereby create redundancies. The noise elements in Web pages as well as overview pages affect the performance of downstream processes such as Web-based Information Retrieval. Context Extraction’s task is identifying and extracting the main content from a Web page. In this research-in-progress paper we present an approach which not only identifies and extracts the main content, but also detects overview pages and thereby allows skipping them. The content extraction part of the system is an extension of existing Text-to-Tag ratio methods, overview page detection is accomplished with the net text length heuristic. Preliminary results and ad-hoc evaluation indicate a promising system performance. A formal evaluation and comparison to other state-of-the-art approaches is part of future work., International Conference on Information Resources Management (Conf-IRM), AIS, Lang, Heinz-Peter and Wohlgenannt, Gerhard and Weichselbraun, Albert, 2012, natural language processing, content extraction, contextualized information spaces, overview pages, text filtering, Web-based information retrieval, lang2012-textSweeper.pdf:/home/albert/Zotero/storage/BKDTK3SJ/lang2012-textSweeper.pdf:application/pdf, https://aisel.aisnet.org/confirm2012/17/</unstructured_citation>
          </citation>
          <citation key="ref24">
            <unstructured_citation>Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets, Quality at a Glance, http://arxiv.org/abs/2103.12028, With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, web-mined text datasets covering hundreds of languages. However, to date there has been no systematic analysis of the quality of these publicly available datasets, or whether the datasets actually contain content in the languages they claim to represent. In this work, we manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4), and audit the correctness of language codes in a sixth (JW300). We find that lower-resource corpora have systematic issues: at least 15 corpora are completely erroneous, and a significant fraction contains less than 50% sentences of acceptable quality. Similarly, we find 82 corpora that are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-speakers of the languages in question, and supplement the human judgements with automatic analyses. Inspired by our analysis, we recommend techniques to evaluate and improve multilingual corpora and discuss the risks that come with low-quality data releases., 2021-09-03, Caswell, Isaac and Kreutzer, Julia and Wang, Lisa and Wahab, Ahsan and van Esch, Daan and Ulzii-Orshikh, Nasanbayar and Tapo, Allahsera and Subramani, Nishant and Sokolov, Artem and Sikasote, Claytone and Setyawan, Monang and Sarin, Supheakmungkol and Samb, Sokhar and Sagot, Benoît and Rivera, Clara and Rios, Annette and Papadimitriou, Isabel and Osei, Salomey and Suárez, Pedro Javier Ortiz and Orife, Iroro and Ogueji, Kelechi and Niyongabo, Rubungo Andre and Nguyen, Toan Q. and Müller, Mathias and Müller, André and Muhammad, Shamsuddeen Hassan and Muhammad, Nanda and Mnyakeni, Ayanda and Mirzakhalov, Jamshidbek and Matangira, Tapiwanashe and Leong, Colin and Lawson, Nze and Kudugunta, Sneha and Jernite, Yacine and Jenny, Mathias and Firat, Orhan and Dossou, Bonaventure F. P. and Dlamini, Sakhile and de Silva, Nisansa and Ballı, Sakine Çabuk and Biderman, Stella and Battisti, Alessia and Baruwa, Ahmed and Bapna, Ankur and Baljekar, Pallavi and Azime, Israel Abebe and Awokoya, Ayodele and Ataman, Duygu and Ahia, Orevaoghene and Ahia, Oghenefego and Agrawal, Sweta and Adeyemi, Mofetoluwa, apr, 2021, arXiv: 2103.12028, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Caswell et al_2021_Quality at a Glance.pdf:/home/albert/Zotero/storage/K3HBQMTH/Caswell et al_2021_Quality at a Glance.pdf:application/pdf;arXiv.org Snapshot:/home/albert/Zotero/storage/XT4AS68K/2103.html:text/html, 4</unstructured_citation>
          </citation>
          <citation key="ref25">
            <doi>10.18653/v1/2020.emnlp-main.480</doi>
          </citation>
          <citation key="ref26">
            <doi>10.18653/v1/2021.naacl-main.41</doi>
          </citation>
          <citation key="ref27">
            <doi>10.14618/IDS-PUB-9021</doi>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
