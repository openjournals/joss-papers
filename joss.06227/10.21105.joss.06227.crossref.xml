<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20240406T054527-44d174b3798f45f4b3cfa1118955f8f8b54f6612</doi_batch_id>
    <timestamp>20240406054527</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>04</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>96</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>Learning from Crowds with Crowd-Kit</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Dmitry</given_name>
            <surname>Ustalov</surname>
            <ORCID>https://orcid.org/0000-0002-9979-2188</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Nikita</given_name>
            <surname>Pavlichenko</surname>
            <ORCID>https://orcid.org/0000-0002-7330-393X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Boris</given_name>
            <surname>Tseitlin</surname>
            <ORCID>https://orcid.org/0000-0001-8553-4260</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>04</month>
          <day>06</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>6227</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06227</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.10934189</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6227</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06227</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06227</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06227.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="Bernstein:10">
            <article_title>Soylent: A Word Processor with a Crowd
Inside</article_title>
            <author>Bernstein</author>
            <journal_title>Proceedings of the 23Nd annual ACM symposium
on user interface software and technology</journal_title>
            <doi>10.1145/1866029.1866078</doi>
            <isbn>978-1-4503-0271-5</isbn>
            <cYear>2010</cYear>
            <unstructured_citation>Bernstein, M. S., Little, G., Miller,
R. C., Hartmann, B., Ackerman, M. S., Karger, D. R., Crowell, D., &amp;
Panovich, K. (2010). Soylent: A Word Processor with a Crowd Inside.
Proceedings of the 23Nd Annual ACM Symposium on User Interface Software
and Technology, 313–322.
https://doi.org/10.1145/1866029.1866078</unstructured_citation>
          </citation>
          <citation key="Bradley:52">
            <article_title>Rank Analysis of Incomplete Block Designs: I.
The Method of Paired Comparisons</article_title>
            <author>Bradley</author>
            <journal_title>Biometrika</journal_title>
            <issue>3/4</issue>
            <volume>39</volume>
            <doi>10.2307/2334029</doi>
            <issn>0006-3444</issn>
            <cYear>1952</cYear>
            <unstructured_citation>Bradley, R. A., &amp; Terry, M. E.
(1952). Rank Analysis of Incomplete Block Designs: I. The Method of
Paired Comparisons. Biometrika, 39(3/4), 324–345.
https://doi.org/10.2307/2334029</unstructured_citation>
          </citation>
          <citation key="Buckley:10">
            <article_title>Overview of the TREC 2010 Relevance Feedback
Track (Notebook)</article_title>
            <author>Buckley</author>
            <journal_title>The nineteenth TREC notebook</journal_title>
            <cYear>2010</cYear>
            <unstructured_citation>Buckley, C., Lease, M., &amp;
Smucker, M. D. (2010). Overview of the TREC 2010 Relevance Feedback
Track (Notebook). The Nineteenth TREC Notebook.
https://www.ischool.utexas.edu/~ml/papers/trec-notebook-2010.pdf</unstructured_citation>
          </citation>
          <citation key="Bugakova:19">
            <article_title>Aggregation of pairwise comparisons with
reduction of biases</article_title>
            <author>Bugakova</author>
            <journal_title>2019 ICML workshop on human in the loop
learning</journal_title>
            <cYear>2019</cYear>
            <unstructured_citation>Bugakova, N., Fedorova, V., Gusev,
G., &amp; Drutsa, A. (2019). Aggregation of pairwise comparisons with
reduction of biases. 2019 ICML Workshop on Human in the Loop Learning.
https://arxiv.org/abs/1906.03711</unstructured_citation>
          </citation>
          <citation key="Chen:13">
            <article_title>Pairwise Ranking Aggregation in a
Crowdsourced Setting</article_title>
            <author>Chen</author>
            <journal_title>Proceedings of the sixth ACM international
conference on web search and data mining</journal_title>
            <doi>10.1145/2433396.2433420</doi>
            <isbn>9781450318693</isbn>
            <cYear>2013</cYear>
            <unstructured_citation>Chen, X., Bennett, P. N.,
Collins-Thompson, K., &amp; Horvitz, E. (2013). Pairwise Ranking
Aggregation in a Crowdsourced Setting. Proceedings of the Sixth ACM
International Conference on Web Search and Data Mining, 193–202.
https://doi.org/10.1145/2433396.2433420</unstructured_citation>
          </citation>
          <citation key="Chu:21">
            <article_title>Learning from Crowds by Modeling Common
Confusions</article_title>
            <author>Chu</author>
            <journal_title>Proceedings of the AAAI Conference on
Artificial Intelligence</journal_title>
            <issue>7</issue>
            <volume>35</volume>
            <doi>10.1609/aaai.v35i7.16730</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Chu, Z., Ma, J., &amp; Wang, H.
(2021). Learning from Crowds by Modeling Common Confusions. Proceedings
of the AAAI Conference on Artificial Intelligence, 35(7), 5832–5840.
https://doi.org/10.1609/aaai.v35i7.16730</unstructured_citation>
          </citation>
          <citation key="Dawid:79">
            <article_title>Maximum Likelihood Estimation of Observer
Error-Rates Using the EM Algorithm</article_title>
            <author>Dawid</author>
            <journal_title>Journal of the Royal Statistical Society,
Series C (Applied Statistics)</journal_title>
            <issue>1</issue>
            <volume>28</volume>
            <doi>10.2307/2346806</doi>
            <issn>0035-9254</issn>
            <cYear>1979</cYear>
            <unstructured_citation>Dawid, A. P., &amp; Skene, A. M.
(1979). Maximum Likelihood Estimation of Observer Error-Rates Using the
EM Algorithm. Journal of the Royal Statistical Society, Series C
(Applied Statistics), 28(1), 20–28.
https://doi.org/10.2307/2346806</unstructured_citation>
          </citation>
          <citation key="Fiscus:97">
            <article_title>A post-processing system to yield reduced
word error rates: Recognizer Output Voting Error Reduction
(ROVER)</article_title>
            <author>Fiscus</author>
            <journal_title>1997 IEEE workshop on automatic speech
recognition and understanding proceedings</journal_title>
            <doi>10.1109/ASRU.1997.659110</doi>
            <cYear>1997</cYear>
            <unstructured_citation>Fiscus, J. G. (1997). A
post-processing system to yield reduced word error rates: Recognizer
Output Voting Error Reduction (ROVER). 1997 IEEE Workshop on Automatic
Speech Recognition and Understanding Proceedings, 347–354.
https://doi.org/10.1109/ASRU.1997.659110</unstructured_citation>
          </citation>
          <citation key="Hochreiter:97">
            <article_title>Long Short-Term Memory</article_title>
            <author>Hochreiter</author>
            <journal_title>Neural Computation</journal_title>
            <issue>8</issue>
            <volume>9</volume>
            <doi>10.1162/neco.1997.9.8.1735</doi>
            <cYear>1997</cYear>
            <unstructured_citation>Hochreiter, S., &amp; Schmidhuber, J.
(1997). Long Short-Term Memory. Neural Computation, 9(8), 1735–1780.
https://doi.org/10.1162/neco.1997.9.8.1735</unstructured_citation>
          </citation>
          <citation key="Hovy:13">
            <article_title>Learning Whom to Trust with
MACE</article_title>
            <author>Hovy</author>
            <journal_title>Proceedings of the 2013 conference of the
north american chapter of the association for computational linguistics:
Human language technologies</journal_title>
            <cYear>2013</cYear>
            <unstructured_citation>Hovy, D., Berg-Kirkpatrick, T.,
Vaswani, A., &amp; Hovy, E. (2013). Learning Whom to Trust with MACE.
Proceedings of the 2013 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies,
1120–1130. https://aclanthology.org/N13-1132</unstructured_citation>
          </citation>
          <citation key="JungLinLee:18">
            <article_title>Quality Evaluation Methods for Crowdsourced
Image Segmentation</article_title>
            <author>Jung-Lin Lee</author>
            <cYear>2018</cYear>
            <unstructured_citation>Jung-Lin Lee, D., Das Sarma, A.,
&amp; Parameswaran, A. (2018). Quality Evaluation Methods for
Crowdsourced Image Segmentation [Technical Report]. Stanford University;
Stanford InfoLab.
http://ilpubs.stanford.edu:8090/1161/</unstructured_citation>
          </citation>
          <citation key="Karger:14">
            <article_title>Budget-Optimal Task Allocation for Reliable
Crowdsourcing Systems</article_title>
            <author>Karger</author>
            <journal_title>Operations Research</journal_title>
            <issue>1</issue>
            <volume>62</volume>
            <doi>10.1287/opre.2013.1235</doi>
            <issn>0030-364X</issn>
            <cYear>2014</cYear>
            <unstructured_citation>Karger, D. R., Oh, S., &amp; Shah, D.
(2014). Budget-Optimal Task Allocation for Reliable Crowdsourcing
Systems. Operations Research, 62(1), 1–24.
https://doi.org/10.1287/opre.2013.1235</unstructured_citation>
          </citation>
          <citation key="Krippendorff:18">
            <volume_title>Content Analysis: An Introduction to Its
Methodology</volume_title>
            <author>Krippendorff</author>
            <isbn>978-1-5063-9566-1</isbn>
            <cYear>2018</cYear>
            <unstructured_citation>Krippendorff, K. (2018). Content
Analysis: An Introduction to Its Methodology (Fourth Edition). SAGE
Publications, Inc. ISBN: 978-1-5063-9566-1</unstructured_citation>
          </citation>
          <citation key="Krizhevsky:09">
            <article_title>Learning Multiple Layers of Features from
Tiny Images</article_title>
            <author>Krizhevsky</author>
            <cYear>2009</cYear>
            <unstructured_citation>Krizhevsky, A. (2009). Learning
Multiple Layers of Features from Tiny Images. University of Toronto.
https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf</unstructured_citation>
          </citation>
          <citation key="Li:19">
            <article_title>A Dataset of Crowdsourced Word Sequences:
Collections and Answer Aggregation for Ground Truth
Creation</article_title>
            <author>Li</author>
            <journal_title>Proceedings of the first workshop on
aggregating and analysing crowdsourced annotations for
NLP</journal_title>
            <doi>10.18653/v1/D19-5904</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Li, J., &amp; Fukumoto, F. (2019). A
Dataset of Crowdsourced Word Sequences: Collections and Answer
Aggregation for Ground Truth Creation. Proceedings of the First Workshop
on Aggregating and Analysing Crowdsourced Annotations for NLP, 24–28.
https://doi.org/10.18653/v1/D19-5904</unstructured_citation>
          </citation>
          <citation key="Li:20">
            <article_title>Crowdsourced Text Sequence Aggregation Based
on Hybrid Reliability and Representation</article_title>
            <author>Li</author>
            <journal_title>Proceedings of the 43rd international ACM
SIGIR conference on research and development in information
retrieval</journal_title>
            <doi>10.1145/3397271.3401239</doi>
            <isbn>9781450380164</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Li, J. (2020). Crowdsourced Text
Sequence Aggregation Based on Hybrid Reliability and Representation.
Proceedings of the 43rd International ACM SIGIR Conference on Research
and Development in Information Retrieval, 1761–1764.
https://doi.org/10.1145/3397271.3401239</unstructured_citation>
          </citation>
          <citation key="Lin:14">
            <article_title>Microsoft COCO: Common Objects in
Context</article_title>
            <author>Lin</author>
            <journal_title>Computer vision – ECCV 2014</journal_title>
            <doi>10.1007/978-3-319-10602-1_48</doi>
            <isbn>978-3-319-10602-1</isbn>
            <cYear>2014</cYear>
            <unstructured_citation>Lin, T.-Y., Maire, M., Belongie, S.,
Hays, J., Perona, P., Ramanan, D., Dollár, P., &amp; Zitnick, C. L.
(2014). Microsoft COCO: Common Objects in Context. Computer Vision –
ECCV 2014, 740–755.
https://doi.org/10.1007/978-3-319-10602-1_48</unstructured_citation>
          </citation>
          <citation key="Liu:19">
            <article_title>RoBERTa: A Robustly Optimized BERT
Pretraining Approach</article_title>
            <author>Liu</author>
            <cYear>2019</cYear>
            <unstructured_citation>Liu, Y., Ott, M., Goyal, N., Du, J.,
Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., &amp;
Stoyanov, V. (2019). RoBERTa: A Robustly Optimized BERT Pretraining
Approach. https://arxiv.org/abs/1907.11692</unstructured_citation>
          </citation>
          <citation key="Ma:20">
            <article_title>Adversarial Crowdsourcing Through Robust
Rank-One Matrix Completion</article_title>
            <author>Ma</author>
            <journal_title>Advances in neural information processing
systems 33</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Ma, Q., &amp; Olshevsky, A. (2020).
Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion.
Advances in Neural Information Processing Systems 33, 21841–21852.
https://proceedings.neurips.cc/paper/2020/file/f86890095c957e9b949d11d15f0d0cd5-Paper.pdf</unstructured_citation>
          </citation>
          <citation key="Maas:11">
            <article_title>Learning Word Vectors for Sentiment
Analysis</article_title>
            <author>Maas</author>
            <journal_title>Proceedings of the 49th annual meeting of the
association for computational linguistics: Human language
technologies</journal_title>
            <cYear>2011</cYear>
            <unstructured_citation>Maas, A. L., Daly, R. E., Pham, P.
T., Huang, D., Ng, A. Y., &amp; Potts, C. (2011). Learning Word Vectors
for Sentiment Analysis. Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human Language Technologies,
142–150. https://aclanthology.org/P11-1015</unstructured_citation>
          </citation>
          <citation key="Malinin:19">
            <article_title>Uncertainty Estimation in Deep Learning with
application to Spoken Language Assessment</article_title>
            <author>Malinin</author>
            <doi>10.17863/CAM.45912</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Malinin, A. (2019). Uncertainty
Estimation in Deep Learning with application to Spoken Language
Assessment [PhD thesis, University of Cambridge].
https://doi.org/10.17863/CAM.45912</unstructured_citation>
          </citation>
          <citation key="McKinney:10">
            <article_title>Data Structures for Statistical Computing in
Python</article_title>
            <author>McKinney</author>
            <journal_title>Proceedings of the 9th python in science
conference</journal_title>
            <doi>10.25080/Majora-92bf1922-00a</doi>
            <cYear>2010</cYear>
            <unstructured_citation>McKinney, W. (2010). Data Structures
for Statistical Computing in Python. Proceedings of the 9th Python in
Science Conference, 56–61.
https://doi.org/10.25080/Majora-92bf1922-00a</unstructured_citation>
          </citation>
          <citation key="Pavlichenko:21:crowdspeech">
            <article_title>CrowdSpeech and Vox DIY: Benchmark Dataset
for Crowdsourced Audio Transcription</article_title>
            <author>Pavlichenko</author>
            <journal_title>Proceedings of the neural information
processing systems track on datasets and benchmarks</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Pavlichenko, N., Stelmakh, I., &amp;
Ustalov, D. (2021). CrowdSpeech and Vox DIY: Benchmark Dataset for
Crowdsourced Audio Transcription. Proceedings of the Neural Information
Processing Systems Track on Datasets and Benchmarks.
https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/65ded5353c5ee48d0b7d48c591b8f430-Abstract-round1.html</unstructured_citation>
          </citation>
          <citation key="Pavlichenko:21:sbs">
            <article_title>IMDB-WIKI-SbS: An Evaluation Dataset for
Crowdsourced Pairwise Comparisons</article_title>
            <author>Pavlichenko</author>
            <journal_title>NeurIPS data-centric AI
workshop</journal_title>
            <cYear>2021</cYear>
            <unstructured_citation>Pavlichenko, N., &amp; Ustalov, D.
(2021). IMDB-WIKI-SbS: An Evaluation Dataset for Crowdsourced Pairwise
Comparisons. NeurIPS Data-Centric AI Workshop.
https://datacentricai.org/neurips21/papers/115_CameraReady_NeurIPS_2021_Data_Centric_AI_IMDB_WIKI_SbS-2.pdf</unstructured_citation>
          </citation>
          <citation key="Paszke:19">
            <article_title>PyTorch: An Imperative Style,
High-Performance Deep Learning Library</article_title>
            <author>Paszke</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>32</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Paszke, A., Gross, S., Massa, F.,
Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein,
N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison,
M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., … Chintala, S.
(2019). PyTorch: An Imperative Style, High-Performance Deep Learning
Library. Advances in Neural Information Processing Systems, 32.
https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf</unstructured_citation>
          </citation>
          <citation key="Pedregosa:11">
            <article_title>Scikit-learn: Machine Learning in
Python</article_title>
            <author>Pedregosa</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <issue>85</issue>
            <volume>12</volume>
            <issn>1532-4435</issn>
            <cYear>2011</cYear>
            <unstructured_citation>Pedregosa, F., Varoquaux, G.,
Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M.,
Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A.,
Cournapeau, D., Brucher, M., Perrot, M., &amp; Duchesnay, É. (2011).
Scikit-learn: Machine Learning in Python. Journal of Machine Learning
Research, 12(85), 2825–2830.
https://jmlr.org/papers/v12/pedregosa11a.html</unstructured_citation>
          </citation>
          <citation key="Rodrigo:19">
            <article_title>spark-crowd: A Spark Package for Learning
from Crowdsourced Big Data</article_title>
            <author>Rodrigo</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <volume>20</volume>
            <issn>1532-4435</issn>
            <cYear>2019</cYear>
            <unstructured_citation>Rodrigo, E. G., Aledo, J. A., &amp;
Gámez, J. A. (2019). spark-crowd: A Spark Package for Learning from
Crowdsourced Big Data. Journal of Machine Learning Research, 20, 1–5.
https://jmlr.org/papers/v20/17-743.html</unstructured_citation>
          </citation>
          <citation key="Rodrigues:18">
            <article_title>Deep Learning from Crowds</article_title>
            <author>Rodrigues</author>
            <journal_title>Proceedings of the AAAI Conference on
Artificial Intelligence</journal_title>
            <issue>1</issue>
            <volume>32</volume>
            <doi>10.1609/aaai.v32i1.11506</doi>
            <isbn>978-1-57735-800-8</isbn>
            <cYear>2018</cYear>
            <unstructured_citation>Rodrigues, F., &amp; Pereira, F. C.
(2018). Deep Learning from Crowds. Proceedings of the AAAI Conference on
Artificial Intelligence, 32(1), 1611–1618.
https://doi.org/10.1609/aaai.v32i1.11506</unstructured_citation>
          </citation>
          <citation key="Sheshadri:13">
            <article_title>SQUARE: A Benchmark for Research on Computing
Crowd Consensus</article_title>
            <author>Sheshadri</author>
            <journal_title>Proceedings of the AAAI Conference on Human
Computation and Crowdsourcing</journal_title>
            <issue>1</issue>
            <volume>1</volume>
            <doi>10.1609/hcomp.v1i1.13088</doi>
            <cYear>2013</cYear>
            <unstructured_citation>Sheshadri, A., &amp; Lease, M.
(2013). SQUARE: A Benchmark for Research on Computing Crowd Consensus.
Proceedings of the AAAI Conference on Human Computation and
Crowdsourcing, 1(1), 156–164.
https://doi.org/10.1609/hcomp.v1i1.13088</unstructured_citation>
          </citation>
          <citation key="Simonyan:15">
            <article_title>Very Deep Convolutional Networks for
Large-Scale Image Recognition</article_title>
            <author>Simonyan</author>
            <cYear>2015</cYear>
            <unstructured_citation>Simonyan, K., &amp; Zisserman, A.
(2015). Very Deep Convolutional Networks for Large-Scale Image
Recognition. https://arxiv.org/abs/1409.1556</unstructured_citation>
          </citation>
          <citation key="Wawa">
            <article_title>Calculating Worker Agreement with Aggregate
(Wawa)</article_title>
            <author>Appen Limited</author>
            <cYear>2021</cYear>
            <unstructured_citation>Appen Limited. (2021). Calculating
Worker Agreement with Aggregate (Wawa).
https://success.appen.com/hc/en-us/articles/202703205-Calculating-Worker-Agreement-with-Aggregate-Wawa-</unstructured_citation>
          </citation>
          <citation key="Whitehill:09">
            <article_title>Whose Vote Should Count More: Optimal
Integration of Labels from Labelers of Unknown Expertise</article_title>
            <author>Whitehill</author>
            <journal_title>Advances in neural information processing
systems 22</journal_title>
            <isbn>978-1-61567-911-9</isbn>
            <cYear>2009</cYear>
            <unstructured_citation>Whitehill, J., Wu, T., Bergsma, J.,
Movellan, J. R., &amp; Ruvolo, P. L. (2009). Whose Vote Should Count
More: Optimal Integration of Labels from Labelers of Unknown Expertise.
In Advances in neural information processing systems 22 (pp. 2035–2043).
Curran Associates, Inc. ISBN: 978-1-61567-911-9</unstructured_citation>
          </citation>
          <citation key="Zhang:15">
            <article_title>CEKA: A Tool for Mining the Wisdom of
Crowds</article_title>
            <author>Zhang</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <issue>88</issue>
            <volume>16</volume>
            <issn>1532-4435</issn>
            <cYear>2015</cYear>
            <unstructured_citation>Zhang, J., Sheng, V. S., Nicholson,
B. A., &amp; Wu, X. (2015). CEKA: A Tool for Mining the Wisdom of
Crowds. Journal of Machine Learning Research, 16(88), 2853–2858.
https://jmlr.org/papers/v16/zhang15a.html</unstructured_citation>
          </citation>
          <citation key="Zhdanovskaya:23">
            <article_title>Data Labeling for Machine Learning Engineers:
Project-Based Curriculum and Data-Centric Competitions</article_title>
            <author>Zhdanovskaya</author>
            <journal_title>Proceedings of the AAAI Conference on
Artificial Intelligence</journal_title>
            <issue>13</issue>
            <volume>37</volume>
            <doi>10.1609/aaai.v37i13.26886</doi>
            <issn>2374-3468</issn>
            <cYear>2023</cYear>
            <unstructured_citation>Zhdanovskaya, A., Baidakova, D.,
&amp; Ustalov, D. (2023). Data Labeling for Machine Learning Engineers:
Project-Based Curriculum and Data-Centric Competitions. Proceedings of
the AAAI Conference on Artificial Intelligence, 37(13), 15886–15893.
https://doi.org/10.1609/aaai.v37i13.26886</unstructured_citation>
          </citation>
          <citation key="Zheng:17">
            <article_title>Truth Inference in Crowdsourcing: Is the
Problem Solved?</article_title>
            <author>Zheng</author>
            <journal_title>Proceedings of the VLDB
Endowment</journal_title>
            <issue>5</issue>
            <volume>10</volume>
            <doi>10.14778/3055540.3055547</doi>
            <issn>2150-8097</issn>
            <cYear>2017</cYear>
            <unstructured_citation>Zheng, Y., Li, G., Li, Y., Shan, C.,
&amp; Cheng, R. (2017). Truth Inference in Crowdsourcing: Is the Problem
Solved? Proceedings of the VLDB Endowment, 10(5), 541–552.
https://doi.org/10.14778/3055540.3055547</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
