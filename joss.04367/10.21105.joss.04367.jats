<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4367</article-id>
<article-id pub-id-type="doi">10.21105/joss.04367</article-id>
<title-group>
<article-title>Spiner: Performance Portable Routines for Generic,
Tabulated, Multi-Dimensional Data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6432-7860</contrib-id>
<name>
<surname>Miller</surname>
<given-names>Jonah M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Holladay</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Meyer</surname>
<given-names>Chad D.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dolence</surname>
<given-names>Joshua C.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Swaminarayan</surname>
<given-names>Sriram</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mauney</surname>
<given-names>Christopher M.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tsai</surname>
<given-names>Karen</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>CCS-2, Computational Physics and Methods, Los Alamos
National Laboratory, Los Alamos, NM</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Center for Theoretical Astrophysics, Los Alamos National
Laboratory, Los Alamos, NM</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>CCS-7, Applied Computer Science, Los Alamos National
Laboratory, Los ALamos, NM</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>XCP-4, Continuum Models and Numerical Methods, Los Alamos
National Laboratory, Los ALamos, NM</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>HPC-ENV, HPC Environments, Los Alamo National Laboratory,
Los Alamos, NM</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-03-16">
<day>16</day>
<month>3</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>75</issue>
<fpage>4367</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>C++</kwd>
<kwd>Performance portability</kwd>
<kwd>GPUs</kwd>
<kwd>Numerical methods</kwd>
<kwd>Interpolation</kwd>
<kwd>Tabulated data</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We present <monospace>Spiner</monospace>, a new,
  performance-portable library for working with tabulated data. Spiner
  provides efficient routines for multi-dimensional interpolation and
  indexing on both CPUs and GPUs—as well as more exotic
  hardware—including interwoven interpolation and indexing access
  patterns, as needed for radiation transport. Importantly,
  <monospace>Spiner</monospace> defines a data format, based on
  <monospace>HDF5</monospace>, that couples the tabulated data to the
  information required to interpolate it, which
  <monospace>Spiner</monospace> can read and move to GPU.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>As Moore’s law comes to an end, more and more performance comes
  from specialized hardware, such as GPUs. A key tool in the toolbox for
  many scientific codes is tabulated data. Fluid and continuum dynamics
  codes often encapsulate the equation of state as data tabulated in
  density and temperature, for example as published in the
  <monospace>Sesame</monospace> database
  (<xref alt="Lyon &amp; Johnson, 1992" rid="ref-sesame" ref-type="bibr">Lyon
  &amp; Johnson, 1992</xref>) or the stellar collapse database
  (<xref alt="O’Connor &amp; Ott, 2010b" rid="ref-stellarcollapseweb" ref-type="bibr">O’Connor
  &amp; Ott, 2010b</xref>), first presented in
  (<xref alt="O’Connor &amp; Ott, 2010a" rid="ref-stellarcollapsetables" ref-type="bibr">O’Connor
  &amp; Ott, 2010a</xref>). Radiation transport, such as that performed
  by
  (<xref alt="Skinner et al., 2019" rid="ref-fornax" ref-type="bibr">Skinner
  et al., 2019</xref>) and
  (<xref alt="Miller et al., 2019" rid="ref-nubhlight" ref-type="bibr">Miller
  et al., 2019</xref>) uses emissivity and absorption opacity on tables
  such as those computed in Sullivan et al.
  (<xref alt="2016" rid="ref-SullivanWeak" ref-type="bibr">2016</xref>).
  As continuum dynamics is required for a variety of applications, such
  as astrophysics, geophysics, climate science, vehicle engineering, and
  national security, utilizing a very large number of supercomputer
  cycles, providing tabulated data for these applications has the
  potential for significant impact.</p>
  <p>These capabilities must be supported on <italic>all</italic>
  hardware a code may be run on, whether this is an NVIDIA GPU, an Intel
  CPU, or a next generation accelerator manufactured by one of any
  number of hardware vendors. To our knowledge there is no performance
  portable interpolation library on which these codes can rely, and
  there is a clear need, which we have developed
  <monospace>Spiner</monospace> to meet. <monospace>Spiner</monospace>
  is now used in the open-source and on-going
  <monospace>Singularity-EOS</monospace>
  (<xref alt="The Singularity Team, 2022a" rid="ref-singularityeos" ref-type="bibr">The
  Singularity Team, 2022a</xref>),
  <monospace>Singularity-Opac</monospace>
  (<xref alt="The Singularity Team, 2022b" rid="ref-singularityopac" ref-type="bibr">The
  Singularity Team, 2022b</xref>), and Phoebus
  (<xref alt="The Phoebus Team, 2022" rid="ref-phoebus" ref-type="bibr">The
  Phoebus Team, 2022</xref>) <monospace>projects</monospace>, which have
  separate code papers in preparation.</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the Field</title>
  <p>Interpolation is a common problem, implemented countless times
  across software projects, and a core part of any introductory text on
  scientific computing
  (<xref alt="Press et al., 2007" rid="ref-press2007numerical" ref-type="bibr">Press
  et al., 2007</xref>). In graphics applications, interpolation is so
  ubiquitous that hardware primitives are provided by GPUs. These
  hardware intrinsics are, however, severely limited for scientific
  application. For example, on NVIDIA GPUs, the values to be
  interpolated must be single precision floating point, and the
  interpolation coefficients themselves are only half-precision, which
  is often insufficient to capture the high precision required for
  scientific applications. As GPUs are inherently vector devices,
  hardware interpolation is also vectorized in nature. However,
  downstream applications may be easier to reason about if scalar
  operations are available. For example, equation of state lookups often
  require root finds on interpolated data, and this can be easier to
  implement as a scalar operation, even if the final operation is
  vectorized over warps. Texture interpolation also does not support
  multi-dimensional mixed indexing/interpolation operations where, say,
  three indices of a four-dimensional array are interpolated and one is
  merely indexed into. Interpolation in the inner loop of a root-finding
  operation can be quite computationally expensive. For example, in the
  open-source general relativistic neutrino radiation hydrodynamics code
  nubhlight
  (<xref alt="Miller et al., 2019" rid="ref-nubhlight" ref-type="bibr">Miller
  et al., 2019</xref>), these operations cover approximately ten percent
  of the runtime. For simulations involving only fluid dynamics and no
  expensive six-dimensional Boltzmann solve as required for radiation,
  the fraction of a timestep can be significantly larger.</p>
  <p>Moreover, relying on hardware intrinsics is not a
  <italic>portable</italic> solution. A software interpolation library
  can, if written with care, work on not only the current generation of
  accelerators, but also on general purpose CPUs and the next generation
  of hardware as well.</p>
  <p>Unfortunately, a performance-portable implementation not tuned to a
  specific use-case or embedded in a larger project is (to our
  knowledge) not available in the literature. A common problem in
  performance-portable computing is the management of
  performance-portable data structures. Libraries, such as
  <monospace>Kokkos</monospace>
  (<xref alt="Trott et al., 2022" rid="ref-Kokkos" ref-type="bibr">Trott
  et al., 2022</xref>), often provide this functionality.</p>
  <p>Here we present <monospace>Spiner</monospace>, a
  performance-portable library for working with tabulated data, thus
  meeting the needs of simulation codes on emerging hardware.
  <monospace>Spiner</monospace> provides data structures for working
  with tabulated data on both CPU and GPU, routines for interpolating on
  and indexing into tabulated data, and a file format that couples data
  to the information required to interpolate it.
  <monospace>Spiner</monospace> therefore fills a gap in available open
  software, providing a needed service for performance-portable
  simulation codes.</p>
  <p>Interpolation is far more ubiquitous than its application in
  continuum dynamics and radiation transport, and we expect
  <monospace>Spiner</monospace> will find applications in the broader
  space of applications, such as image resampling. However, the team
  built <monospace>Spiner</monospace> with simulations in mind.</p>
</sec>
<sec id="design-principles-and-salient-features">
  <title>Design Principles and Salient Features</title>
  <p>We built <monospace>Spiner</monospace> with several design goals in
  mind. First and foremost, interpolation must be fast, sufficiently
  fast that interpolation operations are not the rate-limiting operation
  in a larger calculation. Second, <monospace>Spiner</monospace> must be
  lightweight. It should contain exactly enough features to be useful
  for relevant science applications. Similarly,
  <monospace>Spiner</monospace> must be sufficiently low-level and
  flexible that it can support all performance portability strategies
  and access patterns required of it. That said, not all needs will be
  known at conception, and needs change over time. Thus
  <monospace>Spiner</monospace> must be extendable. Finally,
  <monospace>Spiner</monospace> should be well-documented with a modern,
  easy-to-use build system. We believe we have achieved these goals.</p>
  <p>To ensure <monospace>Spiner</monospace> is lightweight and
  performant, it is header-only. To ensure performance portability, we
  rely on the <monospace>Kokkos</monospace>
  (<xref alt="Trott et al., 2022" rid="ref-Kokkos" ref-type="bibr">Trott
  et al., 2022</xref>) library to provide performance portable data
  structures and parallel dispatch. However, we recognize that another
  performance portability paradigm may be desired. Hence, we developed a
  separate library, <monospace>Ports-of-Call</monospace>, which we
  open-sourced at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/lanl/ports-of-call">lanl/ports-of-call</ext-link>
  on GitHub
  (<xref alt="The Ports-of-Call Team, 2022" rid="ref-portsofcall" ref-type="bibr">The
  Ports-of-Call Team, 2022</xref>). <monospace>Ports-of-Call</monospace>
  is a very thin abstraction around low-level device calls. It provides
  preprocessor macros to enable or disable Kokkos, an
  arbirtrary-dimensional array data structure, and hooks to add the same
  functionality for other backends such as pure CPU, OpenMP
  (<xref alt="Chandra et al., 2001" rid="ref-chandra2001parallel" ref-type="bibr">Chandra
  et al., 2001</xref>), or Cuda
  (<xref alt="NVIDIA et al., 2020" rid="ref-cuda" ref-type="bibr">NVIDIA
  et al., 2020</xref>). <monospace>Ports-of-Call</monospace> is only a
  few hundred lines long. Both Spiner and Ports-of-Call are well
  documented, with Sphinx documentation provided automatically by github
  pages and github actions. They both also have modern build systems,
  with Cmake and Spack support. Unit tests are provided by
  <monospace>Catch2</monospace>
  (<xref alt="The Catch2 Collaboration, 2013" rid="ref-Catch2" ref-type="bibr">The
  Catch2 Collaboration, 2013</xref>).</p>
  <p>The fundamental data structures are the
  <monospace>DataBox</monospace> and
  <monospace>RegularGrid1D</monospace>. The former relies heavily on the
  <monospace>PortableMDArray</monospace> data structure in
  <monospace>Ports-of-Call</monospace> for data storage, which provides
  an arbitrary-dimensional accessor to a contiguous block of data, as
  well as support for slicing, shallow copying, and resizing data. The
  latter contains information required to interpolate. The former
  contains both the data to interpolate, as well as multiple
  <monospace>RegularGrid1D</monospace>s. Both objects know how to read
  from and write to an <monospace>HDF5</monospace>
  (<xref alt="The HDF Group, 2000" rid="ref-HDF5" ref-type="bibr">The
  HDF Group, 2000</xref>) file, and the intent is that the
  <monospace>RegularGrid1D</monospace> is a hook that could be extended
  into a more sophisticated gridding or interpolation procedure. For
  example, one could implement a multi-level grid hierarchy or
  higher-order interpolation stencils. A <monospace>DataBox</monospace>
  can manage its own memory and can automatically allocate on host or
  device at runtime. Deep copies host-to-host and host-to-device are
  supported. To encourage good performance, no deep copies are ever
  implicitly performed—they must be explicitly requested. Consequently,
  <monospace>DataBox</monospace>es have reference semantics. By
  deliberate choice, <monospace>DataBox</monospace>es are not
  reference-counted and have trivial destructors. Instead, we provide an
  overload of <monospace>free</monospace> to free the data. However,
  <monospace>DataBox</monospace>es can be managed via smart pointers—and
  we provide machinery to do so. We find this approach minimizes code
  complexity and carries most of the benefits of an automatically
  reference-counted data structure.</p>
</sec>
<sec id="performance-and-accuracy">
  <title>Performance And Accuracy</title>
  <p>Since it is usually sufficient for the intended use-cases, only
  multilinear interpolation is supported, although as discussed above,
  hooks are present in the code for more sophisticated approaches. A
  convergence test is available in the test suite and shows excellent
  second-order convergence as expected. Performance on both CPUs and
  GPUs is also excellent. For example, the figure below benchmarks
  trilinear interpolation at double precision from a
  <inline-formula><alternatives>
  <tex-math><![CDATA[64^3]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>64</mml:mn><mml:mn>3</mml:mn></mml:msup></mml:math></alternatives></inline-formula>
  grid on to a cubic grid of varying sizes. We test on a single Intel
  Xeon (Haswell) core, twenty cores accross two sockets (with a Kokkos
  OpenMP backend), and one Nvidia V100 GPU (with the Kokkos Cuda
  backend). On the V100, profiling tools report we achieve 15% of peak
  performance in terms of flops and 46% of peak in terms of memory
  bandwidth.</p>
  <fig>
    <caption><p>Performance of trilinear interpolation on one Haswell
    core, twenty Haswell cores, and a V100 GPU. Smaller is better. The
    rightmost point is over 68 billion interpolation
    operations.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="spiner_interpolation_benchmark.png" xlink:title="" />
  </fig>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the U.S. Department of Energy through
  the Los Alamos National Laboratory (LANL). LANL is operated by Triad
  National Security, LLC, for the National Nuclear Security
  Administration of U.S. Department of Energy (Contract
  No. 89233218CNA000001). This research used resources provided by the
  Darwin testbed at LANL which is funded by the Computational Systems
  and Software Environments subprogram of LANL’s Advanced Simulation and
  Computing program (NNSA/DOE). This work is approved for unlimited
  release with report number LA-UR-22-22502.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-fornax">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Skinner</surname><given-names>M. Aaron</given-names></name>
        <name><surname>Dolence</surname><given-names>Joshua C.</given-names></name>
        <name><surname>Burrows</surname><given-names>Adam</given-names></name>
        <name><surname>Radice</surname><given-names>David</given-names></name>
        <name><surname>Vartanyan</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>FORNAX: A flexible code for multiphysics astrophysical simulations</article-title>
      <source>The Astrophysical Journal Supplement Series</source>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <volume>241</volume>
      <issue>1</issue>
      <uri>https://arxiv.org/abs/1806.07390</uri>
      <pub-id pub-id-type="doi">10.3847/1538-4365/ab007f</pub-id>
      <fpage>7</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-nubhlight">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miller</surname><given-names>Jonah M.</given-names></name>
        <name><surname>Ryan</surname><given-names>Ben. R.</given-names></name>
        <name><surname>Dolence</surname><given-names>Joshua C.</given-names></name>
      </person-group>
      <article-title>\nu bhlight: Radiation GRMHD for Neutrino-driven Accretion Flows</article-title>
      <source>The Astrophysical Journal Supplement Series</source>
      <year iso-8601-date="2019-04">2019</year><month>04</month>
      <volume>241</volume>
      <issue>2</issue>
      <uri>https://arxiv.org/abs/1903.09273</uri>
      <pub-id pub-id-type="doi">10.3847/1538-4365/ab09fc</pub-id>
      <fpage>30</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-sesame">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Lyon</surname><given-names>Stanford P.</given-names></name>
        <name><surname>Johnson</surname><given-names>James D.</given-names></name>
      </person-group>
      <article-title>Sesame: The Los Alamos National Laboratory equation of state database</article-title>
      <publisher-name>Los Alamos National Laboratory</publisher-name>
      <year iso-8601-date="1992">1992</year>
    </element-citation>
  </ref>
  <ref id="ref-stellarcollapsetables">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>O’Connor</surname><given-names>Evan</given-names></name>
        <name><surname>Ott</surname><given-names>Christian D</given-names></name>
      </person-group>
      <article-title>A new open-source code for spherically symmetric stellar collapse to neutron stars and black holes</article-title>
      <source>Classical and Quantum Gravity</source>
      <year iso-8601-date="2010">2010</year>
      <volume>27</volume>
      <issue>11</issue>
      <uri>http://stacks.iop.org/0264-9381/27/i=11/a=114103</uri>
      <pub-id pub-id-type="doi">10.1088/0264-9381/27/11/114103</pub-id>
      <fpage>114103</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-stellarcollapseweb">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>O’Connor</surname><given-names>Evan</given-names></name>
        <name><surname>Ott</surname><given-names>Christian D</given-names></name>
      </person-group>
      <article-title>Stellar collapse: microphysics</article-title>
      <year iso-8601-date="2010">2010</year>
      <uri>https://stellarcollapse.org/equationofstate</uri>
    </element-citation>
  </ref>
  <ref id="ref-singularityeos">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The Singularity Team</string-name>
      </person-group>
      <article-title>Singularity-EOS: Performance portable equations of state</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/lanl/singularity-eos</uri>
    </element-citation>
  </ref>
  <ref id="ref-singularityopac">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The Singularity Team</string-name>
      </person-group>
      <article-title>Singularity-opac: Performance portable opacities</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/lanl/singularity-opac</uri>
    </element-citation>
  </ref>
  <ref id="ref-phoebus">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The Phoebus Team</string-name>
      </person-group>
      <article-title>Phoebus: Phifty one ergs blows up a star</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/lanl/phoebus</uri>
    </element-citation>
  </ref>
  <ref id="ref-portsofcall">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The Ports-of-Call Team</string-name>
      </person-group>
      <article-title>Ports-of-call</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/lanl/ports-of-call</uri>
    </element-citation>
  </ref>
  <ref id="ref-Catch2">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The Catch2 Collaboration</string-name>
      </person-group>
      <article-title>Catch2</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <uri>https://github.com/catchorg/Catch2</uri>
    </element-citation>
  </ref>
  <ref id="ref-HDF5">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>The HDF Group</string-name>
      </person-group>
      <article-title>Hierarchical data format version 5</article-title>
      <year iso-8601-date="2000">2000</year>
      <uri>http://www.hdfgroup.org/HDF5</uri>
    </element-citation>
  </ref>
  <ref id="ref-SullivanWeak">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sullivan</surname><given-names>Chris</given-names></name>
        <name><surname>O’Connor</surname><given-names>Evan</given-names></name>
        <name><surname>Zegers</surname><given-names>Remco G. T.</given-names></name>
        <name><surname>Grubb</surname><given-names>Thomas</given-names></name>
        <name><surname>Austin</surname><given-names>Sam M.</given-names></name>
      </person-group>
      <article-title>The sensitivity of core-collapse supernovae to nuclear electron capture</article-title>
      <source>The Astrophysical Journal</source>
      <year iso-8601-date="2016-01">2016</year><month>01</month>
      <volume>816</volume>
      <issue>1</issue>
      <uri>https://arxiv.org/abs/1508.07348</uri>
      <pub-id pub-id-type="doi">10.3847/0004-637X/816/1/44</pub-id>
      <fpage>44</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-press2007numerical">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Press</surname><given-names>W. H.</given-names></name>
        <name><surname>Teukolsky</surname><given-names>S. A.</given-names></name>
        <name><surname>Vetterling</surname><given-names>W. T.</given-names></name>
        <name><surname>Flannery</surname><given-names>B. P.</given-names></name>
      </person-group>
      <source>Numerical recipes with source code CD-ROM 3rd edition: The art of scientific computing</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <year iso-8601-date="2007">2007</year>
      <isbn>9780521884075</isbn>
      <uri>https://books.google.com/books?id=DyykEZo4fwUC</uri>
    </element-citation>
  </ref>
  <ref id="ref-Kokkos">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Trott</surname><given-names>Christian R.</given-names></name>
        <name><surname>Lebrun-Grandié</surname><given-names>Damien</given-names></name>
        <name><surname>Arndt</surname><given-names>Daniel</given-names></name>
        <name><surname>Ciesko</surname><given-names>Jan</given-names></name>
        <name><surname>Dang</surname><given-names>Vinh</given-names></name>
        <name><surname>Ellingwood</surname><given-names>Nathan</given-names></name>
        <name><surname>Gayatri</surname><given-names>Rahulkumar</given-names></name>
        <name><surname>Harvey</surname><given-names>Evan</given-names></name>
        <name><surname>Hollman</surname><given-names>Daisy S.</given-names></name>
        <name><surname>Ibanez</surname><given-names>Dan</given-names></name>
        <name><surname>Liber</surname><given-names>Nevin</given-names></name>
        <name><surname>Madsen</surname><given-names>Jonathan</given-names></name>
        <name><surname>Miles</surname><given-names>Jeff</given-names></name>
        <name><surname>Poliakoff</surname><given-names>David</given-names></name>
        <name><surname>Powell</surname><given-names>Amy</given-names></name>
        <name><surname>Rajamanickam</surname><given-names>Sivasankaran</given-names></name>
        <name><surname>Simberg</surname><given-names>Mikael</given-names></name>
        <name><surname>Sunderland</surname><given-names>Dan</given-names></name>
        <name><surname>Turcksin</surname><given-names>Bruno</given-names></name>
        <name><surname>Wilke</surname><given-names>Jeremiah</given-names></name>
      </person-group>
      <article-title>Kokkos 3: Programming model extensions for the exascale era</article-title>
      <source>IEEE Transactions on Parallel and Distributed Systems</source>
      <year iso-8601-date="2022">2022</year>
      <volume>33</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1109/TPDS.2021.3097283</pub-id>
      <fpage>805</fpage>
      <lpage>817</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cuda">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>NVIDIA</surname></name>
        <name><surname>Vingelmann</surname><given-names>Péter</given-names></name>
        <name><surname>Fitzek</surname><given-names>Frank H. P.</given-names></name>
      </person-group>
      <article-title>CUDA, release: 10.2.89</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://developer.nvidia.com/cuda-toolkit</uri>
    </element-citation>
  </ref>
  <ref id="ref-chandra2001parallel">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Chandra</surname><given-names>Rohit</given-names></name>
        <name><surname>Dagum</surname><given-names>Leo</given-names></name>
        <name><surname>Kohr</surname><given-names>David</given-names></name>
        <name><surname>Menon</surname><given-names>Ramesh</given-names></name>
        <name><surname>Maydan</surname><given-names>Dror</given-names></name>
        <name><surname>McDonald</surname><given-names>Jeff</given-names></name>
      </person-group>
      <source>Parallel programming in OpenMP</source>
      <publisher-name>Morgan Kaufmann</publisher-name>
      <year iso-8601-date="2001">2001</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
