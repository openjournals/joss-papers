<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20221215T203417-82db368ec5ed849db36b37dc4ed30e5218f00974</doi_batch_id>
    <timestamp>20221215203417</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>12</month>
          <year>2022</year>
        </publication_date>
        <journal_volume>
          <volume>7</volume>
        </journal_volume>
        <issue>80</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>Elephas: Distributed Deep Learning with Keras &amp;
Spark</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Max</given_name>
            <surname>Pumperla</surname>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Daniel</given_name>
            <surname>Cahall</surname>
          </person_name>
        </contributors>
        <publication_date>
          <month>12</month>
          <day>15</day>
          <year>2022</year>
        </publication_date>
        <pages>
          <first_page>4073</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.04073</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.7435012</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/4073</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.04073</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.04073</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.04073.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="NIPS2012_6aca9700">
            <article_title>Large scale distributed deep
networks</article_title>
            <author>Dean</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>25</volume>
            <cYear>2012</cYear>
            <unstructured_citation>Dean, J., Corrado, G., Monga, R.,
Chen, K., Devin, M., Mao, M., Ranzato, M., Senior, A., Tucker, P., Yang,
K., Le, Q., &amp; Ng, A. (2012). Large scale distributed deep networks.
In F. Pereira, C. J. C. Burges, L. Bottou, &amp; K. Q. Weinberger
(Eds.), Advances in neural information processing systems (Vol. 25).
Curran Associates, Inc.
https://proceedings.neurips.cc/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf</unstructured_citation>
          </citation>
          <citation key="NIPS2011_218a0aef">
            <article_title>Hogwild!: A lock-free approach to
parallelizing stochastic gradient descent</article_title>
            <author>Recht</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>24</volume>
            <cYear>2011</cYear>
            <unstructured_citation>Recht, B., Re, C., Wright, S., &amp;
Niu, F. (2011). Hogwild!: A lock-free approach to parallelizing
stochastic gradient descent. In J. Shawe-Taylor, R. Zemel, P. Bartlett,
F. Pereira, &amp; K. Q. Weinberger (Eds.), Advances in neural
information processing systems (Vol. 24). Curran Associates, Inc.
https://proceedings.neurips.cc/paper/2011/file/218a0aefd1d1a4be65601cc6ddc1520e-Paper.pdf</unstructured_citation>
          </citation>
          <citation key="Noel2014DogwildD">
            <article_title>Dogwild! – distributed hogwild for CPU &amp;
GPU</article_title>
            <author>Noel</author>
            <cYear>2014</cYear>
            <unstructured_citation>Noel, C., &amp; Osindero, S. (2014).
Dogwild! – distributed hogwild for CPU &amp;
GPU.</unstructured_citation>
          </citation>
          <citation key="sergeev2018horovod">
            <article_title>Horovod: Fast and easy distributed deep
learning in TensorFlow</article_title>
            <author>Sergeev</author>
            <journal_title>arXiv preprint
arXiv:1802.05799</journal_title>
            <cYear>2018</cYear>
            <unstructured_citation>Sergeev, A., &amp; Balso, M. D.
(2018). Horovod: Fast and easy distributed deep learning in TensorFlow.
arXiv Preprint arXiv:1802.05799.</unstructured_citation>
          </citation>
          <citation key="SOCC2019_BIGDL">
            <article_title>BigDL: A distributed deep learning framework
for big data</article_title>
            <author>Dai</author>
            <journal_title>Proceedings of the ACM symposium on cloud
computing</journal_title>
            <doi>10.1145/3357223.3362707</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Dai, J. (Jinquan)., Wang, Y., Qiu,
X., Ding, D., Zhang, Y., Wang, Y., Jia, X., Zhang, L. (Cherry)., Wan,
Y., Li, Z., Wang, J., Huang, S., Wu, Z., Wang, Y., Yang, Y., She, B.,
Shi, D., Lu, Q., Huang, K., &amp; Song, G. (2019). BigDL: A distributed
deep learning framework for big data. Proceedings of the ACM Symposium
on Cloud Computing, 50–60.
https://doi.org/10.1145/3357223.3362707</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
