<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20250412123442-126af8eb41bef0657abcac096e1b8c5f530bfd86</doi_batch_id>
    <timestamp>20250412123442</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>04</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>108</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>ReadmeReady: Free and Customizable Code Documentation with LLMs - A Fine-Tuning Approach</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Sayak</given_name>
            <surname>Chakrabarty</surname>
            <affiliations>
              <institution><institution_name>Northwestern University</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0004-6179-389X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Souradip</given_name>
            <surname>Pal</surname>
            <affiliations>
              <institution><institution_name>Purdue University</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-5781-3032</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>04</month>
          <day>12</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>7489</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.07489</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.15201191</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/7489</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.07489</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.07489</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.07489.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="chomsky1956three">
            <article_title>Three models for the description of language</article_title>
            <author>Chomsky</author>
            <journal_title>IRE Transactions on information theory</journal_title>
            <issue>3</issue>
            <volume>2</volume>
            <doi>10.1109/TIT.1956.1056813</doi>
            <cYear>1956</cYear>
            <unstructured_citation>Chomsky, N. (1956). Three models for the description of language. IRE Transactions on Information Theory, 2(3), 113–124. https://doi.org/10.1109/TIT.1956.1056813</unstructured_citation>
          </citation>
          <citation key="miller2003cognitive">
            <article_title>The cognitive revolution: a historical perspective</article_title>
            <author>Miller</author>
            <journal_title>Trends in cognitive sciences</journal_title>
            <issue>3</issue>
            <volume>7</volume>
            <doi>10.1016/S1364-6613(03)00029-9</doi>
            <cYear>2003</cYear>
            <unstructured_citation>Miller, G. A. (2003). The cognitive revolution: a historical perspective. Trends in Cognitive Sciences, 7(3), 141–144. https://doi.org/10.1016/S1364-6613(03)00029-9</unstructured_citation>
          </citation>
          <citation key="graves2014neural">
            <article_title>Neural Turing Machines</article_title>
            <author>Graves</author>
            <journal_title>arXiv preprint arXiv:1410.5401</journal_title>
            <doi>10.48550/arXiv.1410.5401</doi>
            <cYear>2014</cYear>
            <unstructured_citation>Graves, A., Wayne, G., &amp; Danihelka, I. (2014). Neural Turing Machines. arXiv Preprint arXiv:1410.5401. https://doi.org/10.48550/arXiv.1410.5401</unstructured_citation>
          </citation>
          <citation key="radford2019language">
            <article_title>Language Models are Unsupervised Multitask Learners</article_title>
            <author>Radford</author>
            <journal_title>OpenAI blog</journal_title>
            <issue>8</issue>
            <volume>1</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., &amp; others. (2019). Language Models are Unsupervised Multitask Learners. OpenAI Blog, 1(8), 9.</unstructured_citation>
          </citation>
          <citation key="brown2020language">
            <article_title>Language Models are Few-Shot Learners</article_title>
            <author>Brown</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>33</volume>
            <doi>10.48550/arXiv.2005.14165</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., &amp; others. (2020). Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33, 1877–1901. https://doi.org/10.48550/arXiv.2005.14165</unstructured_citation>
          </citation>
          <citation key="ouyang2022training">
            <article_title>Training language models to follow instructions with human feedback</article_title>
            <author>Ouyang</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>35</volume>
            <doi>10.48550/arXiv.2203.02155</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., &amp; others. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35, 27730–27744. https://doi.org/10.48550/arXiv.2203.02155</unstructured_citation>
          </citation>
          <citation key="vaswani2017attention">
            <article_title>Attention is All You Need</article_title>
            <author>Vaswani</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>30</volume>
            <doi>10.48550/arXiv.1706.03762</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., &amp; Polosukhin, I. (2017). Attention is All You Need. Advances in Neural Information Processing Systems, 30. https://doi.org/10.48550/arXiv.1706.03762</unstructured_citation>
          </citation>
          <citation key="gpt-3.5-turbo">
            <article_title>Gpt-3.5-turbo</article_title>
            <author>OpenAI</author>
            <cYear>2023</cYear>
            <unstructured_citation>OpenAI. (2023). Gpt-3.5-turbo. https://github.com/openai/gpt-3.5-turbo.</unstructured_citation>
          </citation>
          <citation key="gpt-4">
            <article_title>Gpt-4</article_title>
            <author>OpenAI</author>
            <cYear>2023</cYear>
            <unstructured_citation>OpenAI. (2023). Gpt-4. https://github.com/openai/gpt-4.</unstructured_citation>
          </citation>
          <citation key="gpt-4-32k">
            <article_title>Gpt-4-32k</article_title>
            <author>OpenAI</author>
            <cYear>2023</cYear>
            <unstructured_citation>OpenAI. (2023). Gpt-4-32k. https://github.com/openai/gpt-4-32k.</unstructured_citation>
          </citation>
          <citation key="llama-2-7b-chat-gptq">
            <article_title>Llama-2-7B-chat-GPTQ</article_title>
            <author>TheBloke</author>
            <cYear>2023</cYear>
            <unstructured_citation>TheBloke. (2023). Llama-2-7B-chat-GPTQ. https://github.com/TheBloke/Llama-2-7B-Chat-GPTQ.</unstructured_citation>
          </citation>
          <citation key="code-llama-7b-instruct-gptq">
            <article_title>CodeLlama-7B-instruct-GPTQ</article_title>
            <author>TheBloke</author>
            <cYear>2023</cYear>
            <unstructured_citation>TheBloke. (2023). CodeLlama-7B-instruct-GPTQ. https://github.com/TheBloke/CodeLlama-7B-Instruct-GPTQ.</unstructured_citation>
          </citation>
          <citation key="llama-2-7b-chat-hf">
            <article_title>Llama-2-7b-chat-hf</article_title>
            <author>Meta</author>
            <cYear>2023</cYear>
            <unstructured_citation>Meta. (2023). Llama-2-7b-chat-hf. https://github.com/meta-llama/Llama-2-7b-chat-hf.</unstructured_citation>
          </citation>
          <citation key="code-llama-7b-instruct-hf">
            <article_title>CodeLlama-7b-instruct-hf</article_title>
            <author>Meta</author>
            <cYear>2023</cYear>
            <unstructured_citation>Meta. (2023). CodeLlama-7b-instruct-hf. https://github.com/meta-llama/CodeLlama-7b-Instruct-hf.</unstructured_citation>
          </citation>
          <citation key="gemma-2b-it">
            <article_title>Gemma-2b-it</article_title>
            <author>Google</author>
            <cYear>2023</cYear>
            <unstructured_citation>Google. (2023). Gemma-2b-it. https://github.com/google/gemma-2b-it.</unstructured_citation>
          </citation>
          <citation key="codegemma-2b-it">
            <article_title>Codegemma-2b-it</article_title>
            <author>Google</author>
            <cYear>2023</cYear>
            <unstructured_citation>Google. (2023). Codegemma-2b-it. https://github.com/google/codegemma-2b-it.</unstructured_citation>
          </citation>
          <citation key="autodoc-chatgpt">
            <article_title>AutoDoc-ChatGPT</article_title>
            <author>Awekrx</author>
            <cYear>2023</cYear>
            <unstructured_citation>Awekrx. (2023). AutoDoc-ChatGPT. https://github.com/awekrx/AutoDoc-ChatGPT.</unstructured_citation>
          </citation>
          <citation key="context-labs-autodoc">
            <article_title>AutoDoc</article_title>
            <author>Labs</author>
            <cYear>2023</cYear>
            <unstructured_citation>Labs, C. (2023). AutoDoc. https://github.com/context-labs/autodoc.</unstructured_citation>
          </citation>
          <citation key="microsoft-auto-github-docs-generator">
            <article_title>Auto-GitHub-docs-generator</article_title>
            <author>Microsoft</author>
            <cYear>2023</cYear>
            <unstructured_citation>Microsoft. (2023). Auto-GitHub-docs-generator. https://github.com/microsoft/auto-github-docs-generator.</unstructured_citation>
          </citation>
          <citation key="sentence-transformers-all-mpnet-base-v2">
            <article_title>Sentence transformers: All-mpnet-base-v2</article_title>
            <author>HuggingFace</author>
            <cYear>2023</cYear>
            <unstructured_citation>HuggingFace. (2023). Sentence transformers: All-mpnet-base-v2. https://huggingface.co/sentence-transformers/all-mpnet-base-v2.</unstructured_citation>
          </citation>
          <citation key="malkov2018efficient">
            <article_title>Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</article_title>
            <author>Malkov</author>
            <journal_title>IEEE transactions on pattern analysis and machine intelligence</journal_title>
            <issue>4</issue>
            <volume>42</volume>
            <doi>10.1109/TPAMI.2018.2889473</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Malkov, Y. A., &amp; Yashunin, D. A. (2018). Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(4), 824–836. https://doi.org/10.1109/TPAMI.2018.2889473</unstructured_citation>
          </citation>
          <citation key="dettmers2023qlora">
            <article_title>QLoRA: Efficient Finetuning of Quantized LLMs</article_title>
            <author>Dettmers</author>
            <journal_title>arXiv preprint arXiv:2305.14314</journal_title>
            <doi>10.48550/arXiv.2305.14314</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Dettmers, T., Pagnoni, A., Holtzman, A., &amp; Zettlemoyer, L. (2023). QLoRA: Efficient Finetuning of Quantized LLMs. arXiv Preprint arXiv:2305.14314. https://doi.org/10.48550/arXiv.2305.14314</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
