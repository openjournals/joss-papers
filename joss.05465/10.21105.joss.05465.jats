<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5465</article-id>
<article-id pub-id-type="doi">10.21105/joss.05465</article-id>
<title-group>
<article-title>GPCERF - An R package for implementing Gaussian processes
for estimating causal exposure response curves</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4315-1426</contrib-id>
<name>
<surname>Khoshnevis</surname>
<given-names>Naeem</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5300-1184</contrib-id>
<name>
<surname>Ren</surname>
<given-names>Boyu</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5177-8598</contrib-id>
<name>
<surname>Braun</surname>
<given-names>Danielle</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University Research Computing and Data Services, Harvard
University, Cambridge, Massachusetts, United States of
America</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>McLean Hospital, Belmont, Massachusetts, United States of
America</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Biostatistics, Harvard School of Public
Health, Cambridge, Massachusetts, United States of America</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-03-15">
<day>15</day>
<month>3</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>95</issue>
<fpage>5465</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>causal inference</kwd>
<kwd>Gaussian Processes</kwd>
<kwd>causal exposure response function</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We present the GPCERF R package, which employs a novel Bayesian
  approach based on Gaussian Process (GP) to estimate the causal
  exposure-response function (CERF) for continuous exposures, along with
  associated uncertainties. R packages that target causal effects under
  a binary exposure setting exist (e.g.,
  <xref alt="Ho et al., 2011" rid="ref-MatchIt_R" ref-type="bibr">Ho et
  al., 2011</xref>), as well as in the continuous exposure setting
  (e.g.,
  <xref alt="Khoshnevis et al., 2023" rid="ref-CausalGPS_R" ref-type="bibr">Khoshnevis
  et al., 2023</xref>). However, they often rely on a separate
  resampling stage to quantify uncertainty of the estimates. GPCERF
  provides a two-step end-to-end solution for causal inference with
  continuous exposures that is equipped with automatic and efficient
  uncertainty quantification. During the first step (the design phase),
  the algorithm searches for optimal hyperparameters (using the
  exposures and covariates) that achieve optimal covariate balance in
  the induced pseudo-population, i.e., that the correlation between the
  exposure and each covariate is close to zero. The selected
  hyperparameters are then used in the second step (the analysis phase)
  to estimate the CERF on the balanced data set and its associated
  uncertainty using two different types of GPs: a standard GP and a
  nearest-neighbor GP (nnGP). The standard GP offers high accuracy in
  estimating CERF but is also computationally intensive. The nnGP is a
  computationally efficient approximation of the standard GP and is
  well-suited for the analysis of large-scale datasets.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>In the GPCERF R package we have introduced a novel Bayesian
  approach. This method utilizes Gaussian Processes (GPs) as a prior for
  counterfactual outcome surfaces, offering a flexible way to estimate
  the CERF with automatic uncertainty quantification. Additionally, it
  can incorporate prior information about the level of smoothness of the
  underlying causal ERF through specifically designed covariance
  functions. Popular R packages for estimating causal ERF, such as
  CausalGPS
  (<xref alt="Khoshnevis et al., 2023" rid="ref-CausalGPS_R" ref-type="bibr">Khoshnevis
  et al., 2023</xref>;
  <xref alt="Wu et al., 2022" rid="ref-wu_2022" ref-type="bibr">Wu et
  al., 2022</xref>), ipw
  (<xref alt="van der Wal &amp; Geskus, 2011" rid="ref-ipw_paper" ref-type="bibr">van
  der Wal &amp; Geskus, 2011</xref>), npcausal
  (<xref alt="Kennedy, 2020" rid="ref-Kennedy2017npcausal" ref-type="bibr">Kennedy,
  2020</xref>) and CBPS
  (<xref alt="Fong et al., 2018" rid="ref-Fong_2018" ref-type="bibr">Fong
  et al., 2018</xref>,
  <xref alt="2022" rid="ref-CBPS_R" ref-type="bibr">2022</xref>;
  <xref alt="Imai &amp; Ratkovic, 2013" rid="ref-Imai_2013" ref-type="bibr">Imai
  &amp; Ratkovic, 2013</xref>), are primarily built on frequentist
  frameworks. To the best of the authors‚Äô knowledge, however, Bayesian
  nonparametric alternatives are relatively scarce. causaldrf
  (<xref alt="Galagate &amp; Schafer, 2022" rid="ref-causaldrf_R" ref-type="bibr">Galagate
  &amp; Schafer, 2022</xref>) uses Bayesian Additive Regression Trees
  (BART) for flexible causal ERF estimation. BCEE
  (<xref alt="Talbot et al., 2015" rid="ref-Talbot_2015" ref-type="bibr">Talbot
  et al., 2015</xref>,
  <xref alt="2023" rid="ref-bcee_R" ref-type="bibr">2023</xref>;
  <xref alt="Talbot &amp; Beaudoin, 2022" rid="ref-Talbot_2022" ref-type="bibr">Talbot
  &amp; Beaudoin, 2022</xref>) applies a Bayesian model averaging
  approach for causal ERF estimation. bkmr
  (<xref alt="Bobb et al., 2014" rid="ref-Bobb_2014" ref-type="bibr">Bobb
  et al., 2014</xref>;
  <xref alt="Bobb, 2022" rid="ref-bkmr_R" ref-type="bibr">Bobb,
  2022</xref>) employs a kernel-based Bayesian model, which is
  equivalent to a GP prior, to estimate the effect of multivariate
  exposure on the outcome of interest. However, since it does not
  explicitly address confounding in the observational data, the
  resulting estimate does not have causal interpretation.</p>
  <p>While various R packages, like GauPro
  (<xref alt="Erickson, 2023" rid="ref-GauPro_2023" ref-type="bibr">Erickson,
  2023</xref>), mlegp
  (<xref alt="Dancik, 2022" rid="ref-mlegp_2022" ref-type="bibr">Dancik,
  2022</xref>), and GPfit
  (<xref alt="MacDoanld et al., 2019" rid="ref-GPfit_2019" ref-type="bibr">MacDoanld
  et al., 2019</xref>;
  <xref alt="MacDonald et al., 2015" rid="ref-GPfit_paper_2015" ref-type="bibr">MacDonald
  et al., 2015</xref>), offer Gaussian process regression capabilities,
  we chose not to use them. The primary reason is that these packages
  rely on traditional techniques for hyper parameter tuning, such as
  sampling from the hyper-parameters‚Äô posterior distributions or
  maximizing the marginal likelihood function. Our approach, in
  contrast, aims to achieve optimal covariate balancing. By utilizing
  the posterior distributions of model parameters, we can automatically
  assess the uncertainty in our CERF estimates (for further details, see
  <xref alt="Ren et al., 2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">Ren
  et al., 2021</xref>). Since standard GPs are infamous for their
  scalability issues‚Äîparticularly due to operations involving the
  inversion of covariance matrices‚Äîwe adopt a nearest-neighbor GP (nnGP)
  (<xref alt="Abhirup Datta &amp; Gelfand, 2016" rid="ref-Datta_2016" ref-type="bibr">Abhirup
  Datta &amp; Gelfand, 2016</xref>) prior to ensure computationally
  efficient inference of the CERF in large-scale datasets. The section
  presents comparisons of the wall clock times between standard GP and
  nnGP.</p>
</sec>
<sec id="overview">
  <title>Overview</title>
  <p>In the context of causal inference for continuous exposures, one of
  the important targets for inference is the so-called casual exposure
  response function (CERF), which is defined as the expectation of the
  counterfactual outcomes over the observed covariates at a range of
  exposure levels in a given population. If we denote the counterfactual
  outcome at exposure level <inline-formula><alternatives>
  <tex-math><![CDATA[w]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>w</mml:mi></mml:math></alternatives></inline-formula>
  by <inline-formula><alternatives>
  <tex-math><![CDATA[Y(w)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Y</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  CERF is indeed the function <inline-formula><alternatives>
  <tex-math><![CDATA[R(w) = \mathbb E(Y(w))]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ùîº</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  defined on a set of <inline-formula><alternatives>
  <tex-math><![CDATA[w]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>w</mml:mi></mml:math></alternatives></inline-formula>
  of interest. One should be careful when estimating CERF from
  observational data, which usually contain not only the outcome
  <inline-formula><alternatives>
  <tex-math><![CDATA[Y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
  and exposure <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>,
  but also potential confounders <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>.
  The main reason is that if we do not adjust for the confounders
  <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  properly, this may lead to biased estimation of
  <inline-formula><alternatives>
  <tex-math><![CDATA[R(w)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  We choose to follow the approach in Hirano &amp; Imbens
  (<xref alt="2004" rid="ref-Hirano_2004" ref-type="bibr">2004</xref>),
  which is based on the generalized propensity score (GPS) to adjust for
  confounding. GPS, denoted by <inline-formula><alternatives>
  <tex-math><![CDATA[s(W,C)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  is defined as the conditional density of
  <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  given <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>.
  It has been shown that one can obtain an unbiased estimator of the
  causal effect of <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  provided the conditional distribution of
  <inline-formula><alternatives>
  <tex-math><![CDATA[Y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
  given <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[s(W,C)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is known
  (<xref alt="Hirano &amp; Imbens, 2004" rid="ref-Hirano_2004" ref-type="bibr">Hirano
  &amp; Imbens, 2004</xref>).</p>
  <p>In the GPCERF package, we use a Gaussian process (GP) prior for the
  conditional distribution of <inline-formula><alternatives>
  <tex-math><![CDATA[Y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
  given <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[s(W,C)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  This model implicitly performs non-parametric regression of
  <inline-formula><alternatives>
  <tex-math><![CDATA[Y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
  on <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[s(W,C)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  and thus we can recover <inline-formula><alternatives>
  <tex-math><![CDATA[p(Y|W, s(W,C))]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  with high accuracy. We then estimate <inline-formula><alternatives>
  <tex-math><![CDATA[E(Y(w))]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  using the posterior means of <inline-formula><alternatives>
  <tex-math><![CDATA[Y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
  at different <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>.
  See Ren et al.
  (<xref alt="2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">2021</xref>)
  for more details. We assume that the kernel function of the GP is</p>
  <p><disp-formula><alternatives>
  <tex-math><![CDATA[
  k((w, c),(w', c')) = \gamma^2h(\sqrt{\frac{(s(w, c)-(s(w', c'))^2}{\alpha}+\frac{(w - w')^2}{\beta}}),
  ]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mi>‚Ä≤</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>‚Ä≤</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>Œ≥</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>‚àí</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mi>‚Ä≤</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>‚Ä≤</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>Œ±</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo>‚àí</mml:mo><mml:mi>w</mml:mi><mml:mi>‚Ä≤</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>Œ≤</mml:mi></mml:mfrac></mml:mrow></mml:msqrt><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>where <inline-formula><alternatives>
  <tex-math><![CDATA[h : [0, \infty) \rightarrow [0, 1]]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>h</mml:mi><mml:mo>:</mml:mo><mml:mo stretchy="false" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>‚àû</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>‚Üí</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is a non-increasing function; and <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ±</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\beta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ≤</mml:mi></mml:math></alternatives></inline-formula>
  define the relative importance of GPS and exposure values,
  respectively. <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ≥</mml:mi></mml:math></alternatives></inline-formula>
  indicates the scale of the GP. We call the collection
  <inline-formula><alternatives>
  <tex-math><![CDATA[(h, \alpha, \beta, \gamma)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ±</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ≤</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ≥</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
  the hyper-parameters of the GP.</p>
  <p>The primary goal in GPCERF is to find appropriate values for the
  hyper-parameters. In the context of causal inference, ‚Äò‚Äôappropriate‚Äô‚Äô
  values of the hyper-parameters are those that make the estimator of
  CERF as if it is generated from a study with randomized design. To be
  more concrete, note that the GP estimates
  <inline-formula><alternatives>
  <tex-math><![CDATA[R(w)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  by creating a pseudo-population that is a weighted version of the
  original dataset (see more details in
  <xref alt="Ren et al., 2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">Ren
  et al., 2021</xref>). The weight for each sample in the original
  dataset is a function of the hyperparameters. By tuning the
  hyperparameters, we can minimize the sample correlations between
  <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and each component of <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  in this pseudo-population, rendering the pseudo-population to be more
  balanced on these covariates <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>.
  In practice, we minimize the covariate balance, which is a summary of
  the sample correlations between <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and each of <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  to tune our hyper-parameters. Covariate balance is computed by
  assessing the correlation between <inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  in the pseudo-population using the <italic>wCorr</italic> R package
  (<xref alt="Bailey &amp; Emad, 2023" rid="ref-wCorr_R" ref-type="bibr">Bailey
  &amp; Emad, 2023</xref>).</p>
  <p>Both GP and nnGP approaches involve two primary steps - tuning and
  estimation. GPCERF conducts a grid search on the range of provided
  <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ±</mml:mi></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[\beta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ≤</mml:mi></mml:math></alternatives></inline-formula>,
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma/\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.
  The kernel function is also selected if the user provides multiple
  candidates. During the tuning step, covariate balance is minimized by
  choosing the optimal hyperparameters.</p>
  <p>The scaling parameter <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ±</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\beta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ≤</mml:mi></mml:math></alternatives></inline-formula>
  determine how much information the estimation will draw from the two
  coordinates: GPS score (<inline-formula><alternatives>
  <tex-math><![CDATA[s(W, X)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>)
  and exposure level (<inline-formula><alternatives>
  <tex-math><![CDATA[W]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>W</mml:mi></mml:math></alternatives></inline-formula>).
  A large scaling parameter suggests that varying the corresponding
  coordinates is only associated with a minor change in the outcome,
  that is, this coordinate does not contribute too much to the variation
  of the outcome. The signal-to-noise ratio parameter
  <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma/\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  encodes how different observed data is from pure noise. A large
  <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma/\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  indicates strong associations between the outcome and the coordinates
  of GP while a small <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma/\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  suggests the observed outcome is likely to be drawn from a random
  process that is independent of the coordinates. In the setting of
  observational studies and under the no unobserved confounding
  assumption, which GPCERF is specifically designed for, both the
  exposure level and the GPS score encode important information for the
  estimation of CERF. As a result, the range of their scaling parameter
  should be comparable and the covariate balance will determine which
  coordinate is more important (smaller scaling factor). The range
  should also cover both ends of the importance from extremely important
  to nearly irrelevant. We choose to achieve this by considering the
  range on the <inline-formula><alternatives>
  <tex-math><![CDATA[log_{10}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>
  scale with equally spaced candidate values. The range of
  <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma/\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  also follows the same strategy when the prior belief about the
  strength of causal effect of the exposure is weak.</p>
  <p>In the estimation step, the optimal parameters are used to estimate
  the posterior mean and standard deviation of
  <inline-formula><alternatives>
  <tex-math><![CDATA[R(w)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  at a set of exposure values of interest. The outcome data is not used
  during the tuning step, separating the design and analysis phases. Ren
  et al.
  (<xref alt="2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">2021</xref>)
  discusses the implemented approaches in detail. In the following we
  provide an example for running the package for each implemented
  models.</p>
  <sec id="example-1-standard-gp-models">
    <title>Example 1: Standard GP models</title>
    <p>To compute the causal exposure response function, one can use the
    <monospace>etimate_cerf_gp()</monospace> function. In this example,
    we generated a synthetic dataset of 500 observations and six
    covariates. We considered the estimation of
    <inline-formula><alternatives>
    <tex-math><![CDATA[R(w)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    for <inline-formula><alternatives>
    <tex-math><![CDATA[w]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>w</mml:mi></mml:math></alternatives></inline-formula>
    that are between 5- and 95-percentiles of the observed exposure
    levels. We imposed this restriction to make sure that the positivity
    assumption, which is required for the identifiability of
    <inline-formula><alternatives>
    <tex-math><![CDATA[R(w)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    from the observed data, is not likely to be violated
    (<xref alt="Ren et al., 2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">Ren
    et al., 2021</xref>). We then developed a wrapper function to modify
    the number of threads in the SuperLearner package
    (<xref alt="Laan et al., 2007" rid="ref-vander_2007" ref-type="bibr">Laan
    et al., 2007</xref>;
    <xref alt="Polley et al., 2021" rid="ref-SuperLearner_R" ref-type="bibr">Polley
    et al., 2021</xref>). We estimated the GPS values using these
    wrapper functions. One can read more details by running
    <monospace>?GPCERF::estimate_gps</monospace> in R. To compute the
    posterior mean and standard deviation of
    <inline-formula><alternatives>
    <tex-math><![CDATA[R(w)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
    we need to provide the range of exposure values of interest and a
    range of hyperparameters that will be examined as additional input
    and parameters. The function outputs an <monospace>S3</monospace>
    object, which can be further investigated using generic functions,
    as shown below.</p>
    <code language="r script">library(GPCERF)

set.seed(781)
# Generate synthetic data with 500 data samples.
sim_data &lt;- generate_synthetic_data(sample_size = 500, 
                                    gps_spec = 1)

# SuperLearner internal libraries' wrapper. (Optional)

m_xgboost &lt;- function(nthread = 12, ...) {
  SuperLearner::SL.xgboost(nthread = nthread, ...)
}
m_ranger &lt;- function(num.threads = 12, ...){
  SuperLearner::SL.ranger(num.threads = num.threads, ...)
}

# Estimate GPS function
gps_m &lt;- estimate_gps(cov_mt = sim_data[, paste0(&quot;cf&quot;, seq(1,6))],
                      w_all = sim_data$treat,
                      sl_lib = c(&quot;m_xgboost&quot;, &quot;m_ranger&quot;),
                      dnorm_log = TRUE)

# exposure values of interest
# We trim the exposure level to satisfy positivity assumption to avoid including
# extreme exposure values.
q1 &lt;- stats::quantile(sim_data$treat, 0.05)
q2 &lt;- stats::quantile(sim_data$treat, 0.95)
w_all &lt;- seq(q1, q2, 1)

# Hyperparameters' range for grid search to find optimal hyperparameters
params_lst &lt;- list(alpha = 10 ^ seq(-2, 2, length.out = 10),
                   beta = 10 ^ seq(-2, 2, length.out = 10),
                   g_sigma = c(0.1, 1, 10),
                   tune_app = &quot;all&quot;)

# Estimate exposure response function
cerf_gp_obj &lt;- estimate_cerf_gp(sim_data,
                                w_all,
                                gps_m,
                                params = params_lst,
                                outcome_col = &quot;Y&quot;,
                                treatment_col = &quot;treat&quot;,
                                covariates_col = paste0(&quot;cf&quot;, seq(1,6)),
                                nthread = 12)
    </code>
    <p>The customized summary function provides the following:</p>
    <code language="r script">summary(cerf_gp_obj)  </code>
    <preformat>GPCERF standard Gaussian grocess exposure response function object

Optimal hyper parameters(#trial: 300): 
  alpha = 12.9154966501488   beta = 12.9154966501488   g_sigma = 0.1

Optimal covariate balance: 
  cf1 = 0.069 
  cf2 = 0.082 
  cf3 = 0.063 
  cf4 = 0.066 
  cf5 = 0.056 
  cf6 = 0.081

Original covariate balance: 
  cf1 = 0.222 
  cf2 = 0.112 
  cf3 = 0.175 
  cf4 = 0.318 
  cf5 = 0.198 
  cf6 = 0.257
            ----***----      </preformat>
    <p>As one can see, as part of the grid search, 300 different
    combination of hyper parameters have been tried.
    <xref alt="[fig:gp]" rid="figU003Agp">[fig:gp]</xref> shows the
    causal exposure response function and achieved covariate balance in
    this simulated example.</p>
    <code language="r script">plot(cerf_gp_obj)  </code>
    <fig>
      <caption><p>Plot of GP models S3 object. Left: Estimated CERF with
      credible band. Right: Covariate balance of confounders before and
      after weighting with GP
      approach.<styled-content id="figU003Agp"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/readme_gp.png" />
    </fig>
    <p>The discussion on acceptable covariate balance for causal
    inference analyses is not within the scope of this paper. However,
    in the literature, a mean covariate balance upper limit of 0.1 is
    generally considered acceptable
    (<xref alt="Wu et al., 2020" rid="ref-wu_2020" ref-type="bibr">Wu et
    al., 2020</xref>). It is possible to expand the hyperparameters‚Äô
    search domain to achieve a lower covariate balance.</p>
  </sec>
  <sec id="example-2-nearest-neighbor-gp-models">
    <title>Example 2: Nearest neighbor GP models</title>
    <p>As previously mentioned, GP models are limited in scalability. To
    address this limitation, the
    <monospace>estimate_cerf_nngp()</monospace> function can be used to
    implement nearest neighbor GP models. While most of the parameters
    for this model are similar to those used in the GP model, there are
    two additional hyperparameters specific to the nnGP model that we
    will discuss in the following.</p>
    <code language="r script">set.seed(781)
# Generate synthetic data with 500 data samples.
sim_data &lt;- generate_synthetic_data(sample_size = 5000, gps_spec = 1)

# SuperLearner internal libraries' wrapper.
m_xgboost &lt;- function(nthread = 12, ...) {
  SuperLearner::SL.xgboost(nthread = nthread, ...)
}

m_ranger &lt;- function(num.threads = 12, ...){
  SuperLearner::SL.ranger(num.threads = num.threads, ...)
}

# Estimate GPS function
gps_m &lt;- estimate_gps(cov_mt = sim_data[, paste0(&quot;cf&quot;, seq(1,6))],
                      w_all = sim_data$treat,
                      sl_lib = c(&quot;m_xgboost&quot;, &quot;m_ranger&quot;),
                      dnorm_log = TRUE)

# exposure values of interest
# We trim the exposure level to satisfy positivity assumption to avoid including
# extreme exposure values.
q1 &lt;- stats::quantile(sim_data$treat, 0.05)
q2 &lt;- stats::quantile(sim_data$treat, 0.95)

w_all &lt;- seq(q1, q2, 1)

# Hyperparameters' range for grid search to find optimal hyperparameters
params_lst &lt;- list(alpha = 10 ^ seq(-2, 2, length.out = 10),
                   beta = 10 ^ seq(-2, 2, length.out = 10),
                   g_sigma = c(0.1, 1, 10),
                   tune_app = &quot;all&quot;,
                   n_neighbor = 50,
                   block_size = 1e3)

# Estimate exposure response function
cerf_nngp_obj &lt;- estimate_cerf_nngp(sim_data,
                                    w_all,
                                    gps_m,
                                    params = params_lst,
                                    outcome_col = &quot;Y&quot;,
                                    treatment_col = &quot;treat&quot;,
                                    covariates_col = paste0(&quot;cf&quot;, seq(1,6)),
                                    nthread = 12)
    </code>
    <p>The nearest neighbor GP model contains two controlling
    parameters: <monospace>n_neighbor</monospace>, which indicates the
    size of the neighbor set, and <monospace>block_size</monospace>,
    which determines the size of the computational chunks. The choice of
    <monospace>block_size</monospace> is primarily used to balance the
    trade-off between speed and memory requirements, where a larger
    <monospace>block_size</monospace> leads to faster computation but
    also requires more memory. It is worth noting that changing
    <monospace>n_neighbor</monospace> may lead to different outcomes due
    to its approximate nature. However, the outcome values remain
    unaffected by changes to <monospace>block_size</monospace>, which
    serves as an internal optimization parameter.</p>
    <p>The customized summary function provides the following:</p>
    <code language="r script">summary(cerf_nngp_obj)</code>
    <preformat>GPCERF nearest neighbore Gaussian process exposure response function object summary

Optimal hyper parameters(#trial: 300): 
  alpha = 0.0278255940220712   beta = 0.215443469003188   g_sigma = 0.1

Optimal covariate balance: 
  cf1 = 0.062 
  cf2 = 0.070 
  cf3 = 0.091 
  cf4 = 0.062 
  cf5 = 0.076 
  cf6 = 0.088

Original covariate balance: 
  cf1 = 0.115 
  cf2 = 0.137 
  cf3 = 0.145 
  cf4 = 0.296 
  cf5 = 0.208 
  cf6 = 0.225
            ----***----      </preformat>
    <p><xref alt="[fig:nngp]" rid="figU003Anngp">[fig:nngp]</xref> shows
    the result of <monospace>plot(cerf_nngp_obj)</monospace>
    function.</p>
    <fig>
      <caption><p>Plot of nnGP models S3 object. Left: Estimated CERF
      with credible band. Right: Covariate balance of confounders before
      and after weighting with nnGP
      approach.<styled-content id="figU003Anngp"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/readme_nngp.png" />
    </fig>
  </sec>
</sec>
<sec id="performance-analyses-of-standard-and-nearest-neighbor-gp-models">
  <title>Performance analyses of standard and nearest neighbor GP
  models</title>
  <p><styled-content id="performance"></styled-content></p>
  <p>The time complexity of the standard Gaussian Process (GP) model is
  <inline-formula><alternatives>
  <tex-math><![CDATA[O(n^3)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  while for the nearest neighbor GP (nnGP) model, it is
  <inline-formula><alternatives>
  <tex-math><![CDATA[O(n * m ^ 3)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>n</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  where <inline-formula><alternatives>
  <tex-math><![CDATA[m]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>m</mml:mi></mml:math></alternatives></inline-formula>
  is the number of neighbors. An in-depth discussion on achieving these
  complexities is outside the scope of this paper. Readers interested in
  further details can refer to Ren et al.
  (<xref alt="2021" rid="ref-Ren_2021_bayesian" ref-type="bibr">2021</xref>).
  This section focuses on comparing the wall clock time of standard GP
  and nnGP models in calculating the Conditional Exposure Response
  Function (CERF) at a specific exposure level,
  <inline-formula><alternatives>
  <tex-math><![CDATA[w]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>w</mml:mi></mml:math></alternatives></inline-formula>.
  We set the hyper-parameters to values at
  <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha = \beta = \gamma/\sigma = 1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ±</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≤</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  <xref alt="[fig:performance]" rid="figU003Aperformance">[fig:performance]</xref>
  shows the comparison of standard GP model with nnGP utilizing 50
  nearest neighbors. Due to the differing parallelization architectures
  of the standard GP and nnGP in our package, we conducted this
  benchmark on a single core. The sample size was varied from 3,000 to
  10,000, a range where nnGP begins to demonstrate notable efficiency
  over the standard GP. We repeat the process 20 times with different
  seed values. We plotted wall clock time against sample size for both
  methods. To enhance the visualization of the increasing rate of wall
  clock time, we applied a log transformation to both axes. For this
  specific set of analyses the estimated slope of 3.09 (ideally 3) for
  standard GP aligns with its <inline-formula><alternatives>
  <tex-math><![CDATA[O(n^3)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  time complexity. According to the results, a sample size of 10,000
  data samples is not large enough to establish a meaningful
  relationship for the time complexity of the nnGP model
  effectively.</p>
  <fig>
    <caption><p>Representation of Wall Clock Time (s) vs.¬†Data Samples
    for Standard GP and nnGP Models. All computations are conducted with
    <inline-formula><alternatives>
    <tex-math><![CDATA[w=1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\alpha = \beta = \gamma/\sigma = 1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ±</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≤</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    The process is repeated 20 times using various seed values to ensure
    robustness. A jitter effect is applied to enhance the visibility of
    data points. Both axes are displayed on log10 scales. The solid
    lines represent the linear regression modeled as
    <inline-formula><tex-math><![CDATA[lm(log10(WC) \textasciitilde log10(n))]]></tex-math></inline-formula>.
    <styled-content id="figU003Aperformance"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/gp_vs_nngp.png" />
  </fig>
  <p><xref alt="[fig:performance_nn]" rid="figU003Aperformance_nn">[fig:performance_nn]</xref>
  compares the performance of the nnGP model across three nearest
  neighbor categories: 50, 100, and 200, using a data sample sequence
  ranging from 5,000 to 100,000 with intervals of 5,000. For each
  category, different sets of runs demonstrate a linear relationship,
  consistent with an <inline-formula><alternatives>
  <tex-math><![CDATA[O(n)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  time complexity, assuming that <inline-formula><alternatives>
  <tex-math><![CDATA[m^3]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:math></alternatives></inline-formula>
  remains constant for varying sample sizes within each category.</p>
  <fig>
    <caption><p>Representation of Wall Clock Time (s) vs.¬†Data Samples
    of the nnGP model across different nearest neighbor categories (50,
    100, 200) over a range of data sample sizes from 5,000 to 100,000 in
    5,000 increments. . All computations are conducted with
    <inline-formula><alternatives>
    <tex-math><![CDATA[w=1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\alpha = \beta = \gamma/\sigma = 1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œ±</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≤</mml:mi><mml:mo>=</mml:mo><mml:mi>Œ≥</mml:mi><mml:mi>/</mml:mi><mml:mi>œÉ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
    Both axes are displayed on log10 scales. The solid lines represent
    the linear regression modeled as
    <inline-formula><tex-math><![CDATA[lm(log10(WC) \textasciitilde log10(n))]]></tex-math></inline-formula>.
    <styled-content id="figU003Aperformance_nn"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/figures/nngp_nnsize.png" />
  </fig>
</sec>
<sec id="software-related-features">
  <title>Software related features</title>
  <p>We have implemented several features to enhance the package
  performance and usability. By utilizing an internal
  <monospace>parallel</monospace> package, the software is capable of
  scaling up in a shared memory system. Additionally, we have
  implemented a logging infrastructure that tracks the software‚Äôs
  internal progress and provides users and developers with detailed
  information on processed runs
  (<xref alt="Dar√≥czi, 2021" rid="ref-logger" ref-type="bibr">Dar√≥czi,
  2021</xref>). We have also activated continuous integration (CI)
  through GitHub actions, which runs unit tests and checks the code
  quality for any submitted pull request. The majority of the codebase
  is tested at least once. To ensure efficient development, we follow a
  successful git branching model
  (<xref alt="Driessen, 2010" rid="ref-driessen_2010" ref-type="bibr">Driessen,
  2010</xref>) and use the tidyverse styling guide. The software is
  available on CRAN
  (<xref alt="Khoshnevis et al., 2024" rid="ref-gpcerf_cran" ref-type="bibr">Khoshnevis
  et al., 2024</xref>) and is primarily written in R
  (<xref alt="R Core Team, 2023" rid="ref-R_2023" ref-type="bibr">R Core
  Team, 2023</xref>). However, some of the core computations are written
  in C++ using the <monospace>Rcpp</monospace> package
  (<xref alt="Eddelbuettel, 2013" rid="ref-rcpp_2" ref-type="bibr">Eddelbuettel,
  2013</xref>;
  <xref alt="Eddelbuettel &amp; Balamuta, 2018" rid="ref-rcpp_3" ref-type="bibr">Eddelbuettel
  &amp; Balamuta, 2018</xref>;
  <xref alt="Eddelbuettel &amp; Fran√ßois, 2011" rid="ref-rcpp_1" ref-type="bibr">Eddelbuettel
  &amp; Fran√ßois, 2011</xref>). All analyses were conducted using R
  Statistical Software [v4.2.3; R Core Team
  (<xref alt="2023" rid="ref-R_2023" ref-type="bibr">2023</xref>)].</p>
</sec>
<sec id="acknowledgement">
  <title>Acknowledgement</title>
  <p>This work was partially funded by the following grants: NIH: R01s
  R01ES028033, R01ES030616, R01AG066793, R01ES029950, RF1AG071024,
  RF1AG074372, R01MD016054, R01ES034373, R01ES028033-03S1,
  R01AG066793-02S1, and Sloan Foundation: G-2020-13946.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-R_2023">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>R Core Team</string-name>
      </person-group>
      <source>R: A language and environment for statistical computing</source>
      <publisher-name>R Foundation for Statistical Computing</publisher-name>
      <publisher-loc>Vienna, Austria</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.R-project.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-CausalGPS_R">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Khoshnevis</surname><given-names>Naeem</given-names></name>
        <name><surname>Wu</surname><given-names>Xiao</given-names></name>
        <name><surname>Braun</surname><given-names>Danielle</given-names></name>
      </person-group>
      <article-title>CausalGPS: An R package for causal inference with continuous exposures</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2310.00561</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.00561</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-MatchIt_R">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ho</surname><given-names>Daniel E.</given-names></name>
        <name><surname>Imai</surname><given-names>Kosuke</given-names></name>
        <name><surname>King</surname><given-names>Gary</given-names></name>
        <name><surname>Stuart</surname><given-names>Elizabeth A.</given-names></name>
      </person-group>
      <article-title>MatchIt: Nonparametric preprocessing for parametric causal inference</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2011">2011</year>
      <volume>42</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v042.i08</pub-id>
      <fpage>1</fpage>
      <lpage>28</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Ren_2021_bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ren</surname><given-names>Boyu</given-names></name>
        <name><surname>Wu</surname><given-names>Xiao</given-names></name>
        <name><surname>Braun</surname><given-names>Danielle</given-names></name>
        <name><surname>Pillai</surname><given-names>Natesh</given-names></name>
        <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
      </person-group>
      <article-title>Bayesian modeling for exposure response curve via Gaussian processes: Causal effects of exposure to air pollution on health outcomes</article-title>
      <source>arXiv preprint arXiv:2105.03454</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2105.03454</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wCorr_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bailey</surname><given-names>Paul</given-names></name>
        <name><surname>Emad</surname><given-names>Ahmad</given-names></name>
      </person-group>
      <source>wCorr: Weighted correlations</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://CRAN.R-project.org/package=wCorr</uri>
    </element-citation>
  </ref>
  <ref id="ref-Hirano_2004">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hirano</surname><given-names>Keisuke</given-names></name>
        <name><surname>Imbens</surname><given-names>Guido W.</given-names></name>
      </person-group>
      <article-title>The propensity score with continuous treatments</article-title>
      <source>Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives</source>
      <year iso-8601-date="2004">2004</year>
      <volume>226164</volume>
      <fpage>73</fpage>
      <lpage>84</lpage>
    </element-citation>
  </ref>
  <ref id="ref-SuperLearner_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Polley</surname><given-names>Eric</given-names></name>
        <name><surname>LeDell</surname><given-names>Erin</given-names></name>
        <name><surname>Kennedy</surname><given-names>Chris</given-names></name>
        <name><surname>van der Laan</surname><given-names>Mark</given-names></name>
      </person-group>
      <source>SuperLearner: Super learner prediction</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://CRAN.R-project.org/package=SuperLearner</uri>
    </element-citation>
  </ref>
  <ref id="ref-driessen_2010">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Driessen</surname><given-names>Vincent</given-names></name>
      </person-group>
      <article-title>A successful Git branching model</article-title>
      <publisher-name>https://nvie.com/posts/a-successful-git-branching-model/</publisher-name>
      <year iso-8601-date="2010">2010</year>
    </element-citation>
  </ref>
  <ref id="ref-logger">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Dar√≥czi</surname><given-names>Gergely</given-names></name>
      </person-group>
      <source>logger: A lightweight, modern and flexible logging utility</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://CRAN.R-project.org/package=logger</uri>
    </element-citation>
  </ref>
  <ref id="ref-gpcerf_cran">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Khoshnevis</surname><given-names>Naeem</given-names></name>
        <name><surname>Ren</surname><given-names>Boyu</given-names></name>
        <name><surname>Braun</surname><given-names>Danielle</given-names></name>
      </person-group>
      <source>GPCERF: Gaussian processes for estimating causal exposure response curves</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://CRAN.R-project.org/package=GPCERF</uri>
    </element-citation>
  </ref>
  <ref id="ref-rcpp_1">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
        <name><surname>Fran√ßois</surname><given-names>Romain</given-names></name>
      </person-group>
      <article-title>Rcpp: Seamless R and C++ integration</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2011">2011</year>
      <volume>40</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v040.i08</pub-id>
      <fpage>1</fpage>
      <lpage>18</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rcpp_2">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
      </person-group>
      <source>Seamless R and C++ integration with Rcpp</source>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>New York</publisher-loc>
      <year iso-8601-date="2013">2013</year>
      <pub-id pub-id-type="doi">10.1007/978-1-4614-6868-4</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-rcpp_3">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
        <name><surname>Balamuta</surname><given-names>James Joseph</given-names></name>
      </person-group>
      <article-title>Extending R with C++: A brief introduction to Rcpp</article-title>
      <source>The American Statistician</source>
      <year iso-8601-date="2018">2018</year>
      <volume>72</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1080/00031305.2017.1375990</pub-id>
      <fpage>28</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wu_2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Xiao</given-names></name>
        <name><surname>Braun</surname><given-names>Danielle</given-names></name>
        <name><surname>Schwartz</surname><given-names>Joel</given-names></name>
        <name><surname>Kioumourtzoglou</surname><given-names>Marianthi-Anna</given-names></name>
        <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
      </person-group>
      <article-title>Evaluating the impact of long-term exposure to fine particulate matter on mortality among the elderly</article-title>
      <source>Science Advances</source>
      <publisher-name>American Association for the Advancement of Science</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>6</volume>
      <issue>29</issue>
      <pub-id pub-id-type="doi">10.1126/sciadv.aba5692</pub-id>
      <fpage>eaba5692</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-GauPro_2023">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Erickson</surname><given-names>Collin</given-names></name>
      </person-group>
      <source>GauPro: Gaussian process fitting</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://CRAN.R-project.org/package=GauPro</uri>
    </element-citation>
  </ref>
  <ref id="ref-mlegp_2022">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Dancik</surname><given-names>Garrett M.</given-names></name>
      </person-group>
      <source>mlegp: Maximum likelihood estimates of Gaussian processes</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=mlegp</uri>
    </element-citation>
  </ref>
  <ref id="ref-GPfit_2019">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>MacDoanld</surname><given-names>Blake</given-names></name>
        <name><surname>Chipman</surname><given-names>Hugh</given-names></name>
        <name><surname>Ranjan</surname><given-names>Pritam</given-names></name>
      </person-group>
      <source>GPfit: Gaussian processes modeling</source>
      <year iso-8601-date="2019">2019</year>
      <uri>https://CRAN.R-project.org/package=GPfit</uri>
    </element-citation>
  </ref>
  <ref id="ref-causaldrf_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Galagate</surname><given-names>Douglas</given-names></name>
        <name><surname>Schafer</surname><given-names>Joseph</given-names></name>
      </person-group>
      <source>causaldrf: Estimating causal dose response functions</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=causaldrf</uri>
    </element-citation>
  </ref>
  <ref id="ref-bcee_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Talbot</surname><given-names>Denis</given-names></name>
        <name><surname>Lefebvre</surname><given-names>Genevieve</given-names></name>
        <name><surname>Atherton</surname><given-names>Juli</given-names></name>
        <name><surname>Chiu</surname><given-names>Yohann</given-names></name>
      </person-group>
      <source>BCEE: The Bayesian causal effect estimation algorithm</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://CRAN.R-project.org/package=BCEE</uri>
    </element-citation>
  </ref>
  <ref id="ref-bkmr_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Bobb</surname><given-names>Jennifer F.</given-names></name>
      </person-group>
      <source>bkmr: Bayesian kernel machine regression</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=bkmr</uri>
    </element-citation>
  </ref>
  <ref id="ref-ipw_paper">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>van der Wal</surname><given-names>Willem M.</given-names></name>
        <name><surname>Geskus</surname><given-names>Ronald B.</given-names></name>
      </person-group>
      <article-title>ipw: An R package for inverse probability weighting</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2011">2011</year>
      <volume>43</volume>
      <issue>13</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v043.i13</pub-id>
      <fpage>1</fpage>
      <lpage>23</lpage>
    </element-citation>
  </ref>
  <ref id="ref-CBPS_R">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Fong</surname><given-names>Christian</given-names></name>
        <name><surname>Ratkovic</surname><given-names>Marc</given-names></name>
        <name><surname>Imai</surname><given-names>Kosuke</given-names></name>
      </person-group>
      <source>CBPS: Covariate balancing propensity score</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=CBPS</uri>
    </element-citation>
  </ref>
  <ref id="ref-Kennedy2017npcausal">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Kennedy</surname><given-names>EH</given-names></name>
      </person-group>
      <article-title>npcausal [R package]</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/ehkennedy/npcausal</uri>
    </element-citation>
  </ref>
  <ref id="ref-Talbot_2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Talbot</surname><given-names>Denis</given-names></name>
        <name><surname>Lefebvre</surname><given-names>Genevi√®ve</given-names></name>
        <name><surname>Atherton</surname><given-names>Juli</given-names></name>
      </person-group>
      <article-title>The Bayesian causal effect estimation algorithm</article-title>
      <source>Journal of Causal Inference</source>
      <year iso-8601-date="2015">2015</year>
      <volume>3</volume>
      <issue>2</issue>
      <uri>https://doi.org/10.1515/jci-2014-0035</uri>
      <pub-id pub-id-type="doi">10.1515/jci-2014-0035</pub-id>
      <fpage>207</fpage>
      <lpage>236</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Talbot_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Talbot</surname><given-names>Denis</given-names></name>
        <name><surname>Beaudoin</surname><given-names>Claudia</given-names></name>
      </person-group>
      <article-title>A generalized double robust Bayesian model averaging approach to causal effect estimation with application to the study of osteoporotic fractures</article-title>
      <source>Journal of Causal Inference</source>
      <year iso-8601-date="2022">2022</year>
      <volume>10</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1515/jci-2021-0023</uri>
      <pub-id pub-id-type="doi">10.1515/jci-2021-0023</pub-id>
      <fpage>335</fpage>
      <lpage>371</lpage>
    </element-citation>
  </ref>
  <ref id="ref-vander_2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Laan</surname><given-names>Mark J. van der</given-names></name>
        <name><surname>Polley</surname><given-names>Eric C</given-names></name>
        <name><surname>Hubbard</surname><given-names>Alan E.</given-names></name>
      </person-group>
      <article-title>Super learner</article-title>
      <source>Statistical Applications in Genetics and Molecular Biology</source>
      <year iso-8601-date="2007">2007</year>
      <volume>6</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.2202/1544-6115.1309</uri>
      <pub-id pub-id-type="doi">10.2202/1544-6115.1309</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-GPfit_paper_2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>MacDonald</surname><given-names>Blake</given-names></name>
        <name><surname>Ranjan</surname><given-names>Pritam</given-names></name>
        <name><surname>Chipman</surname><given-names>Hugh</given-names></name>
      </person-group>
      <article-title>GPfit: An R package for fitting a Gaussian process model to deterministic simulator outputs</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2015">2015</year>
      <volume>64</volume>
      <issue>12</issue>
      <uri>https://www.jstatsoft.org/index.php/jss/article/view/v064i12</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v064.i12</pub-id>
      <fpage>1</fpage>
      <lpage>23</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Imai_2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Imai</surname><given-names>Kosuke</given-names></name>
        <name><surname>Ratkovic</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Covariate balancing propensity score</article-title>
      <source>Journal of the Royal Statistical Society Series B: Statistical Methodology</source>
      <year iso-8601-date="2013-07">2013</year><month>07</month>
      <volume>76</volume>
      <issue>1</issue>
      <issn>1369-7412</issn>
      <uri>https://doi.org/10.1111/rssb.12027</uri>
      <pub-id pub-id-type="doi">10.1111/rssb.12027</pub-id>
      <fpage>243</fpage>
      <lpage>263</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Fong_2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fong</surname><given-names>Christian</given-names></name>
        <name><surname>Hazlett</surname><given-names>Chad</given-names></name>
        <name><surname>Imai</surname><given-names>Kosuke</given-names></name>
      </person-group>
      <article-title>Covariate balancing propensity score for a continuous treatment: Application to the efficacy of political advertisements</article-title>
      <source>The Annals of Applied Statistics</source>
      <publisher-name>Institute of Mathematical Statistics</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>12</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1214/17-AOAS1101</uri>
      <pub-id pub-id-type="doi">10.1214/17-AOAS1101</pub-id>
      <fpage>156 </fpage>
      <lpage> 177</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Bobb_2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bobb</surname><given-names>Jennifer F.</given-names></name>
        <name><surname>Valeri</surname><given-names>Linda</given-names></name>
        <name><surname>Claus Henn</surname><given-names>Birgit</given-names></name>
        <name><surname>Christiani</surname><given-names>David C.</given-names></name>
        <name><surname>Wright</surname><given-names>Robert O.</given-names></name>
        <name><surname>Mazumdar</surname><given-names>Maitreyi</given-names></name>
        <name><surname>Godleski</surname><given-names>John J.</given-names></name>
        <name><surname>Coull</surname><given-names>Brent A.</given-names></name>
      </person-group>
      <article-title>Bayesian kernel machine regression for estimating the health effects of multi-pollutant mixtures</article-title>
      <source>Biostatistics</source>
      <year iso-8601-date="2014-12">2014</year><month>12</month>
      <volume>16</volume>
      <issue>3</issue>
      <issn>1465-4644</issn>
      <pub-id pub-id-type="doi">10.1093/biostatistics/kxu058</pub-id>
      <fpage>493</fpage>
      <lpage>508</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wu_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Xiao</given-names></name>
        <name><surname>Mealli</surname><given-names>Fabrizia</given-names></name>
        <name><surname>Kioumourtzoglou</surname><given-names>Marianthi-Anna</given-names></name>
        <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
        <name><surname>Braun</surname><given-names>Danielle</given-names></name>
      </person-group>
      <article-title>Matching on generalized propensity scores with continuous exposures</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>0</volume>
      <issue>0</issue>
      <pub-id pub-id-type="doi">10.1080/01621459.2022.2144737</pub-id>
      <fpage>1</fpage>
      <lpage>29</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Datta_2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abhirup Datta</surname><given-names>Andrew O. Finley</given-names><suffix>Sudipto Banerjee</suffix></name>
        <name><surname>Gelfand</surname><given-names>Alan E.</given-names></name>
      </person-group>
      <article-title>Hierarchical nearest-neighbor Gaussian process models for large geostatistical datasets</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>111</volume>
      <issue>514</issue>
      <pub-id pub-id-type="doi">10.1080/01621459.2015.1044091</pub-id>
      <fpage>800</fpage>
      <lpage>812</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
