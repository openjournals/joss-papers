<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>139e69b06a0cc5d2ee9b6c862a96cf46</doi_batch_id>
    <timestamp>20180723200805</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>http://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>07</month>
          <year>2018</year>
        </publication_date>
        <journal_volume>
          <volume>3</volume>
        </journal_volume>
        <issue>27</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>SpeechPy - A Library for Speech Processing and Recognition</title>
        </titles>
        <contributors><person_name sequence="first" contributor_role="author"><given_name>Amirsina</given_name><surname>Torfi</surname><ORCID>http://orcid.org/0000-0003-2282-4361</ORCID></person_name></contributors>
        <publication_date>
          <month>07</month>
          <day>23</day>
          <year>2018</year>
        </publication_date>
        <pages>
          <first_page>749</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.00749</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">https://doi.org/10.5281/zenodo.810391</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/749</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.00749</doi>
          <resource>http://joss.theoj.org/papers/10.21105/joss.00749</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">http://www.theoj.org/joss-papers/joss.00749/10.21105.joss.00749.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list><citation key="ref1"><unstructured_citation>The%20Aurora%20experimental%20framework%20for%20the%20performance%20evaluation%20of%20speech%20recognition%20systems%20under%20noisy%20conditions, Hirsch,%20Hans-G%C3%BCnter%20and%20Pearce,%20David, ASR2000-Automatic%20Speech%20Recognition:%20Challenges%20for%20the%20new%20Millenium%20ISCA%20Tutorial%20and%20Research%20Workshop%20(ITRW), 2000</unstructured_citation></citation><citation key="ref2"><unstructured_citation>Feature%20extraction:%20foundations%20and%20applications, Guyon,%20Isabelle%20and%20Gunn,%20Steve%20and%20Nikravesh,%20Masoud%20and%20Zadeh,%20Lofti%20A, 207, 2008, Springer</unstructured_citation></citation><citation key="ref3"><unstructured_citation>Speaker-independent%20isolated%20word%20recognition%20using%20dynamic%20features%20of%20speech%20spectrum, Furui,%20Sadaoki, IEEE%20Transactions%20on%20Acoustics,%20Speech,%20and%20Signal%20Processing, 34, 1, 52%E2%80%9359, 1986, IEEE</unstructured_citation></citation><citation key="ref4"><unstructured_citation>AUTOMATIC%20SPEECH%20RECOGNITION., Yu,%20Dong%20and%20Deng,%20Li, 2016, Springer</unstructured_citation></citation><citation key="ref5"><unstructured_citation>Fundamentals%20of%20speech%20recognition, Rabiner,%20Lawrence%20R%20and%20Juang,%20Biing-Hwang, 14, 1993, PTR%20Prentice%20Hall%20Englewood%20Cliffs</unstructured_citation></citation><citation key="ref6"><unstructured_citation>Speaker%20recognition:%20A%20tutorial, Campbell,%20Joseph%20P, Proceedings%20of%20the%20IEEE, 85, 9, 1437%E2%80%931462, 1997, IEEE</unstructured_citation></citation><citation key="ref7"><unstructured_citation>Recent%20advances%20in%20deep%20learning%20for%20speech%20research%20at%20Microsoft, Deng,%20Li%20and%20Li,%20Jinyu%20and%20Huang,%20Jui-Ting%20and%20Yao,%20Kaisheng%20and%20Yu,%20Dong%20and%20Seide,%20Frank%20and%20Seltzer,%20Michael%20and%20Zweig,%20Geoff%20and%20He,%20Xiaodong%20and%20Williams,%20Jason%20and%20others, Acoustics,%20Speech%20and%20Signal%20Processing%20(ICASSP),%202013%20IEEE%20International%20Conference%20on, 8604%E2%80%938608, 2013, IEEE</unstructured_citation></citation><citation key="ref8"><unstructured_citation>Unsupervised%20feature%20learning%20for%20audio%20classification%20using%20convolutional%20deep%20belief%20networks, Lee,%20Honglak%20and%20Pham,%20Peter%20and%20Largman,%20Yan%20and%20Ng,%20Andrew%20Y, Advances%20in%20neural%20information%20processing%20systems, 1096%E2%80%931104, 2009</unstructured_citation></citation><citation key="ref9"><unstructured_citation>Improved%20bottleneck%20features%20using%20pretrained%20deep%20neural%20networks, Yu,%20Dong%20and%20Seltzer,%20Michael%20L, Twelfth%20Annual%20Conference%20of%20the%20International%20Speech%20Communication%20Association, 2011</unstructured_citation></citation><citation key="ref10"><unstructured_citation>pyAudioAnalysis:%20An%20Open-Source%20Python%20Library%20for%20Audio%20Signal%20Analysis, Giannakopoulos,%20Theodoros, PloS%20one, 10, 12, 2015, Public%20Library%20of%20Science</unstructured_citation></citation><citation key="ref11"><unstructured_citation>Text-independent%20speaker%20verification%20using%203d%20convolutional%20neural%20networks, Torfi,%20Amirsina%20and%20Nasrabadi,%20Nasser%20M%20and%20Dawson,%20Jeremy, arXiv%20preprint%20arXiv:1705.09422, 2017</unstructured_citation></citation><citation key="ref12"><unstructured_citation>3D%20Convolutional%20Neural%20Networks%20for%20Cross%20Audio-Visual%20Matching%20Recognition, Torfi,%20Amirsina%20and%20Iranmanesh,%20Seyed%20Mehdi%20and%20Nasrabadi,%20Nasser%20and%20Dawson,%20Jeremy, IEEE%20Access, 5, 22081%E2%80%9322091, 2017, IEEE</unstructured_citation></citation><citation key="ref13"><unstructured_citation>An%20empirical%20comparison%20of%20c,%20c++,%20java,%20perl,%20python,%20rexx%20and%20tcl, Prechelt,%20Lutz, IEEE%20Computer, 33, 10, 23%E2%80%9329, 2000</unstructured_citation></citation><citation key="ref14"><doi>10.5281/zenodo.810391</doi></citation><citation key="ref15"><unstructured_citation>Coupled%203D%20Convolutional%20Neural%20Networks%20for%20Audio-Visual%20Recognition, Torfi,%20Amirsina%20and%20Iranmanesh,%20Seyed%20Mehdi%20and%20Nasrabadi,%20Nasser%20M%20and%20Dawson,%20Jeremy, arXiv%20preprint%20arXiv:1706.05739, 2017</unstructured_citation></citation><citation key="ref16"><unstructured_citation>On%20the%20Construction%20of%20Polar%20Codes%20for%20Achieving%20the%20Capacity%20of%20Marginal%20Channels, Torfi,%20Amisina%20and%20Soleymani,%20Sobhan%20and%20Vakili,%20Vahid%20Tabataba, arXiv%20preprint%20arXiv:1707.04512, 2017</unstructured_citation></citation><citation key="ref17"><unstructured_citation>A%20mathematical%20theory%20of%20communication, Shannon,%20Claude%20Elwood, ACM%20SIGMOBILE%20Mobile%20Computing%20and%20Communications%20Review, 5, 1, 3%E2%80%9355, 2001, ACM</unstructured_citation></citation><citation key="ref18"><unstructured_citation>Information%20theoretic%20feature%20extraction%20for%20audio-visual%20speech%20recognition, Gurban,%20Mihai%20and%20Thiran,%20Jean-Philippe, IEEE%20Transactions%20on%20signal%20processing, 57, 12, 4765%E2%80%934776, 2009, IEEE</unstructured_citation></citation><citation key="ref19"><unstructured_citation>Deep%20neural%20networks%20for%20small%20footprint%20text-dependent%20speaker%20verification, Variani,%20Ehsan%20and%20Lei,%20Xin%20and%20McDermott,%20Erik%20and%20Moreno,%20Ignacio%20Lopez%20and%20Gonzalez-Dominguez,%20Javier, Acoustics,%20Speech%20and%20Signal%20Processing%20(ICASSP),%202014%20IEEE%20International%20Conference%20on, 4052%E2%80%934056, 2014, IEEE</unstructured_citation></citation><citation key="ref20"><unstructured_citation>Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition:%20The%20shared%20views%20of%20four%20research%20groups, Hinton,%20Geoffrey%20and%20Deng,%20Li%20and%20Yu,%20Dong%20and%20Dahl,%20George%20E%20and%20Mohamed,%20Abdel-rahman%20and%20Jaitly,%20Navdeep%20and%20Senior,%20Andrew%20and%20Vanhoucke,%20Vincent%20and%20Nguyen,%20Patrick%20and%20Sainath,%20Tara%20N%20and%20others, IEEE%20Signal%20Processing%20Magazine, 29, 6, 82%E2%80%9397, 2012, IEEE</unstructured_citation></citation><citation key="ref21"><unstructured_citation>Deep%20learning, LeCun,%20Yann%20and%20Bengio,%20Yoshua%20and%20Hinton,%20Geoffrey, nature, 521, 7553, 436, 2015, Nature%20Publishing%20Group</unstructured_citation></citation><citation key="ref22"><unstructured_citation>Deep%20feature%20for%20text-dependent%20speaker%20verification, Liu,%20Yuan%20and%20Qian,%20Yanmin%20and%20Chen,%20Nanxin%20and%20Fu,%20Tianfan%20and%20Zhang,%20Ya%20and%20Yu,%20Kai, Speech%20Communication, 73, 1%E2%80%9313, 2015, Elsevier</unstructured_citation></citation><citation key="ref23"><unstructured_citation>Attention-Based%20Guided%20Structured%20Sparsity%20of%20Deep%20Neural%20Networks, Torfi,%20Amirsina%20and%20Shirvani,%20Rouzbeh%20A, arXiv%20preprint%20arXiv:1802.09902, 2018</unstructured_citation></citation></citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
