<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7969</article-id>
<article-id pub-id-type="doi">10.21105/joss.07969</article-id>
<title-group>
<article-title>modelbased: An R package to make the most out of your
statistical models through marginal means, marginal effects, and model
predictions</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5375-9967</contrib-id>
<name>
<surname>Makowski</surname>
<given-names>Dominique</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4287-4801</contrib-id>
<name>
<surname>Ben-Shachar</surname>
<given-names>Mattan S.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9560-6336</contrib-id>
<name>
<surname>Wiernik</surname>
<given-names>Brenton M.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1995-6531</contrib-id>
<name>
<surname>Patil</surname>
<given-names>Indrajeet</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4315-6788</contrib-id>
<name>
<surname>Thériault</surname>
<given-names>Rémi</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8895-3206</contrib-id>
<name>
<surname>Lüdecke</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>School of Psychology, University of Sussex, Brighton,
UK</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Sussex Centre for Consciousness Science, University of
Sussex, Brighton, UK</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Independent Researcher, Ramat Gan, Israel</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Independent Researcher, Tampa, FL, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Carl Zeiss AG, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Department of Psychology, New York University, New York,
NY, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Institute of Medical Sociology, University Medical Center
Hamburg-Eppendorf, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-05-13">
<day>13</day>
<month>5</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>109</issue>
<fpage>7969</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>easystats</kwd>
<kwd>marginal effects</kwd>
<kwd>marginal means</kwd>
<kwd>model predictions</kwd>
<kwd>emmeans</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Applied statistics have historically focused on statistical
  <italic>tests</italic> (e.g., <italic>t</italic>-tests, correlation
  tests, and analyses of variances, ANOVAs), seen as most apt to provide
  researchers with interpretable answers to the questions they seek.
  These tests, however, typically rely on statistical
  <italic>models</italic> — the true underlying cornerstone of modern
  data science. The replication crisis
  (<xref alt="Camerer et al., 2018" rid="ref-camerer2018evaluating" ref-type="bibr">Camerer
  et al., 2018</xref>;
  <xref alt="Open Science Collaboration, 2015" rid="ref-OSC2015estimating" ref-type="bibr">Open
  Science Collaboration, 2015</xref>) and methodological (r)evolutions
  (<xref alt="Makowski &amp; Waggoner, 2023" rid="ref-makowski2023we" ref-type="bibr">Makowski
  &amp; Waggoner, 2023</xref>) have underlined some of the issues with
  the traditional focus on statistical tests (e.g., the effacement of
  model assumptions, an emphasis on null-hypothesis testing,
  non-compatibility with more complex variance structures) and called
  for shifting the focus to the models themselves
  (<xref alt="Cumming, 2014" rid="ref-cumming2014new" ref-type="bibr">Cumming,
  2014</xref>).</p>
  <p>In line with these efforts, new tools have been created to
  facilitate the direct usage and reporting of statistical models. For
  instance, the <monospace>easystats</monospace> collection of R
  packages
  (<xref alt="Lüdecke et al., 2023" rid="ref-easystatspackage" ref-type="bibr">Lüdecke
  et al., 2023</xref>) has been developed to help researchers “tame,
  discipline, and harness” the power of statistical models. Within this
  framework, specific packages are dedicated to model parameters (the
  <monospace>parameters</monospace> package,
  <xref alt="Lüdecke et al., 2020" rid="ref-ludecke2020extracting" ref-type="bibr">Lüdecke
  et al., 2020</xref>), predictive performance (the
  <monospace>performance</monospace> package,
  <xref alt="Lüdecke et al., 2021" rid="ref-ludecke2021performance" ref-type="bibr">Lüdecke
  et al., 2021</xref>) or effect importance (the
  <monospace>effectsize</monospace> package,
  <xref alt="Ben-Shachar et al., 2020" rid="ref-ben2020effectsize" ref-type="bibr">Ben-Shachar
  et al., 2020</xref>).</p>
  <p><bold>But the models themselves pack even more
  usefulness!</bold></p>
  <p>The fundamental nature of these models—a statistical link between
  an outcome <inline-formula><alternatives>
  <tex-math><![CDATA[y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>
  and predictor variables <inline-formula><alternatives>
  <tex-math><![CDATA[X]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>—enables
  the generation of predictions for any observed or unobserved
  combination of predictors. These predictions refer to expected values
  of the outcome for given levels of predictors of interest, making it
  possible to test and visualize the model’s behaviour in a more
  meaningful and comprehensive way, and answering a broad range of
  research questions.</p>
  <p>The two most popular R packages for extracting these quantities of
  interest from statistical models are <monospace>emmeans</monospace>
  (<xref alt="Lenth, 2024" rid="ref-russell2024emmeans" ref-type="bibr">Lenth,
  2024</xref>) and <monospace>marginaleffects</monospace>
  (<xref alt="Arel-Bundock et al., 2024" rid="ref-arel2024interpret" ref-type="bibr">Arel-Bundock
  et al., 2024</xref>). These packages pack an enormously rich set of
  features and cover (almost) all imaginable needs for post-hoc analysis
  of statistical models. Their power and flexibility can be intimidating
  for users not familiar with the underlying statistical concepts. The
  <monospace>modelbased</monospace> package, built on top of these two
  packages, aims to unleash this untapped potential by providing a
  unified interface to extract marginal means, marginal effects,
  contrasts, comparisons, and model predictions from a wide range of
  statistical models. In line with the <monospace>easystats</monospace>’
  <italic>raison d’être</italic>, the <monospace>modelbased</monospace>
  package focuses on simplicity, flexibility, and user-friendliness to
  help researchers harness the full power of their models.</p>
</sec>
<sec id="key-concepts">
  <title>Key concepts</title>
  <p>Answering research questions based on statistical models means
  describing the relationship between predictors of interest (also
  called <italic>focal</italic> predictors) and the outcome, as well as
  differences between observed groups in the sample. There are four key
  concepts in <monospace>modelbased</monospace> to achieve this:
  Predictions, and Marginal Means, Effects, and Contrasts.</p>
  <sec id="predictions">
    <title>Predictions</title>
    <p>At a fundamental level, <monospace>modelbased</monospace> and
    similar packages leverage model <italic>predictions</italic>. These
    predictions can be of different types, depending on the model and
    the question at hand. For instance, predictions can be associated
    with <bold>confidence intervals</bold>
    (<monospace>predict = &quot;expectation&quot;</monospace>) or
    <bold>prediction intervals</bold>
    (<monospace>predict = &quot;prediction&quot;</monospace>). The
    former corresponds to the uncertainty around the “relationship”
    (i.e., the conditional estimate, typically of the expectation
    (<inline-formula><alternatives>
    <tex-math><![CDATA[E[X]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>)
    according to a model’s parameters), while the latter is typically
    larger and provides information about the range which individual
    observations might fall in. Moreover, for generalized linear models
    (GLMs), predictions can be made on the <bold>response scale</bold>
    (<monospace>predict = &quot;response&quot;</monospace>) or the
    <bold>link scale</bold>
    (<monospace>predict = &quot;link&quot;</monospace>). This
    corresponds for instance to predictions in terms of probability
    (response scale) or log odds (link scale) for logistic regression
    models.</p>
    <p>These different types of estimates can be obtained for
    observations in the original dataset - which is useful to assess the
    model’s goodness-of-fit - for new data (typically a “data grid”),
    which is useful for visualization.</p>
    <p>For convenience, the <monospace>modelbased</monospace> package
    includes four related functions, which mostly differ in their
    default arguments for <monospace>data</monospace> and
    <monospace>predict</monospace><xref ref-type="fn" rid="fn1">1</xref>:</p>
    <list list-type="bullet">
      <list-item>
        <p><monospace>estimate_prediction()</monospace>: original data,
        prediction intervals.</p>
      </list-item>
      <list-item>
        <p><monospace>estimate_expectation()</monospace>: original data,
        confidence intervals.</p>
      </list-item>
      <list-item>
        <p><monospace>estimate_relation()</monospace>: data grid,
        predictions on the response scale.</p>
      </list-item>
      <list-item>
        <p><monospace>estimate_link()</monospace>: data grid,
        predictions on the link scale.</p>
      </list-item>
    </list>
  </sec>
  <sec id="marginal-means-contrasts-and-effects">
    <title>Marginal means, contrasts and effects</title>
    <sec id="means">
      <title>Means</title>
      <p>The concept of “marginal” in this context refers to how
      non-focal predictors (i.e., those not of direct interest, for
      instance “adjustment” variables added to “control” for it) are
      treated. While predictions, as described above, fix by default
      non-focal variables at their reference level, marginal means
      compute the empirical or theoretical averages over them. These
      kind of predictions are a good representation of the sample,
      because they are not based on very specific characteristics. For
      example, predictions can be made for specific combinations of
      predictors, such as people with <italic>high</italic> income,
      while marginal means might calculate the expected outcome for an
      <italic>average</italic> observation (averaged over income).</p>
      <p>The <monospace>modelbased</monospace> package provides a simple
      and clear interface to extract marginal means via the
      <monospace>estimate_means()</monospace> function (with focal
      predictors specified using the <monospace>by</monospace>
      argument), which can be considered as the “marginal” pendant to
      <monospace>estimate_relation()</monospace>.</p>
    </sec>
    <sec id="contrasts">
      <title>Contrasts</title>
      <p>The computation of these model-based quantities allow for the
      direct statistical comparison of the predicted outcomes across
      different groups or levels of a focal predictor, in the form of
      marginal contrasts. Rather than simply observing differences in
      marginal means, contrast analysis quantifies these differences and
      assesses their statistical significance, as well as its associated
      uncertainty (e.g., confidence intervals).</p>
      <p>In <monospace>modelbased</monospace>, this can be achieved
      using the <monospace>estimate_contrasts()</monospace> function.
      Focal predictors are specified in the
      <monospace>contrast</monospace> argument. As with the other
      functions, further stratification or grouping can be made with the
      <monospace>by</monospace> argument (for instance, to analyze the
      difference between two levels of a factor alongside the values of
      another interacting predictor).</p>
    </sec>
    <sec id="effects">
      <title>Effects</title>
      <p>Finally, the same approach can be used for the effects, i.e.,
      the parameters of the model. While predictions and marginal means
      can be used to better understand the <italic>relationship</italic>
      of predictors with the outcome (e.g., to estimate “the average
      health score for a person at the age of sixty is 80 points”),
      marginal <italic>effects</italic> evaluate the (average)
      <italic>effect</italic> of a parameter (often called “slope”),
      telling you that “the average effect (i.e., relationship) of age
      on the health score is a decrease of 5 points per year”.</p>
      <p>For the simple case of linear regression without interaction
      terms, the regression coefficient (slope) equals the marginal
      effect. However, in even slightly more complex situations (e.g.,
      with interactions or non-linear effects), the slope is not
      constant across the predictor’s values, and estimating the
      <italic>average</italic> slope, or marginal effect, can become
      useful.</p>
      <p>Again, the <monospace>modelbased</monospace> package has a
      simple function to do so,
      <monospace>estimate_slopes()</monospace>. This function calculates
      the <italic>trend</italic> or average effect, usually for numeric
      predictors. The <monospace>trend</monospace> argument specifies
      the focal predictors, while <monospace>by</monospace> allows for
      further grouping.</p>
    </sec>
    <sec id="marginalization-types">
      <title>Marginalization Types</title>
      <p>Until this point we have discussed marginal means and effects
      as being “averaged” over non-focal predictors, but there are
      actually various ways of doing so. The
      <monospace>estimate_means()</monospace>,
      <monospace>estimate_contrasts()</monospace>, and
      <monospace>estimate_slopes()</monospace> have an
      <monospace>estimate</monospace> argument that determines how
      predictions are averaged (“marginalized”). The options are:</p>
      <list list-type="bullet">
        <list-item>
          <p><bold>“typical”</bold> (default): Calculates predictions
          for a balanced data grid representing all combinations of
          focal predictor levels (specified in
          <monospace>by</monospace>). For non-focal numeric predictors,
          it uses the mean; for non-focal categorical predictors, it
          averages over all the levels. This represents a “typical”
          observation based on the data grid and is useful for comparing
          groups. It answers: <italic>“What would the average outcome be
          for a ‘typical’ observation?”</italic>. This is the default
          approach when estimating marginal means using the
          <monospace>emmeans</monospace> package.</p>
        </list-item>
        <list-item>
          <p><bold>“average”</bold>: Calculates predictions for each
          observation in the sample and then averages these predictions
          within each group defined by the focal predictors. This
          reflects the sample’s actual distribution of non-focal
          predictors, not a balanced grid. It answers: <italic>“What is
          the predicted value for an average observation in my
          data?”</italic>.</p>
        </list-item>
        <list-item>
          <p><bold>“population”</bold>: “Clones” each observation,
          creating copies with all possible combinations of focal
          predictor levels. It then averages the predictions across
          these “counterfactual” observations (non-observed
          permutations) within each group. This extrapolates to a
          hypothetical broader population, considering “what if”
          scenarios. It answers: <italic>“What is the predicted response
          for the ‘average’ observation in a broader possible target
          population?”</italic>. This approach entails more assumptions
          about the likelihood of different combinations, but can be
          more apt to generalize.</p>
        </list-item>
      </list>
      <p>Setting <monospace>estimate = &quot;average&quot;</monospace>
      can be useful to calculate the average expected outcome from those
      observations <italic>from the sample</italic> at hand. For
      analyses emphasizing outcome differences between groups (e.g.,
      when computing contrasts) and particularly when causal effects are
      being considered, it may be beneficial to model a hypothetical
      population not directly represented in the sample. This approach,
      known as <italic>G-computation</italic>
      (<xref alt="Chatton &amp; Rohrer, 2024" rid="ref-chatton_rohrer_2024" ref-type="bibr">Chatton
      &amp; Rohrer, 2024</xref>), is implemented by setting
      <monospace>estimate = &quot;population&quot;</monospace>.</p>
    </sec>
  </sec>
  <sec id="group-level-estimates-for-mixed-models">
    <title>Group-level estimates for Mixed Models</title>
    <p>The <monospace>modelbased</monospace> package also provides the
    <monospace>estimate_grouplevel()</monospace> function to
    conveniently extract parameters related to random factors, which
    typically correspond to group-level parameters (e.g., the
    intercept’s or slope’s value for each participant). These are known
    as BLUPs (Best Linear Unbiased Predictions) and can be estimated in
    two manners:</p>
    <list list-type="bullet">
      <list-item>
        <p><bold>“random”</bold> (default): Corresponds typically to the
        relative deviation of each individual group from their fixed
        effect. As such, a coefficient close to 0 means that the
        participants’ effect is the same as the population-level
        effect</p>
      </list-item>
      <list-item>
        <p><bold>“total”</bold>: Returns the absolute individual-level
        effects, which typically corresponds to the sum of the relative
        random effect with its corresponding fixed effects.</p>
      </list-item>
    </list>
    <p>Estimating these indices using mixed models can have important
    benefits over an empirical approach consisting of computing raw
    group means, of fitting individual models to all individuals
    separately. In particular, it is more resilient and robust to the
    presence of few or missing data, and naturally applies
    partial-pooling - <italic>aka</italic> “shrinkage”, which combines
    information from the group and the overall population. This means
    that group estimates are “pulled” towards the population-level
    estimate if they are more uncertain (i.e., includes less
    observations), in essence giving more weight to more reliable
    estimates. Estimates shrinkage prevents overfitting and improves
    generalizability
    (<xref alt="Pan &amp; Huang, 2014" rid="ref-pan2014random" ref-type="bibr">Pan
    &amp; Huang, 2014</xref>).</p>
  </sec>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>The <monospace>iris</monospace> dataset contains measures in
  centimeters of three different species of iris flowers (setosa,
  versicolor, and virginica,
  <xref alt="Anderson, 1936" rid="ref-anderson_species_1936" ref-type="bibr">Anderson,
  1936</xref>). Imagine the following linear model in which we predict
  those flowers’ petal width (<monospace>Petal.Width</monospace>) from
  the interaction between their petal length
  (<monospace>Petal.Length</monospace>) and their
  <monospace>Species</monospace>.</p>
  <code language="r script">library(easystats)

model &lt;- lm(Petal.Width ~ Petal.Length * Species, data = iris)

parameters::parameters(model) |&gt;
  print(select = &quot;minimal&quot;)</code>
  <preformat>#&gt; Parameter                           | Coefficient |        95% CI |      p
#&gt; --------------------------------------------------------------------------
#&gt; (Intercept)                         |       -0.05 | [-0.47, 0.38] | 0.823 
#&gt; Petal Length                        |        0.20 | [-0.09, 0.49] | 0.170 
#&gt; Species [versicolor]                |       -0.04 | [-0.66, 0.59] | 0.909 
#&gt; Species [virginica]                 |        1.18 | [ 0.52, 1.84] | &lt; .001
#&gt; Petal Length × Species [versicolor] |        0.13 | [-0.18, 0.44] | 0.405 
#&gt; Petal Length × Species [virginica]  |       -0.04 | [-0.34, 0.26] | 0.789</preformat>
  <preformat>#&gt; 
#&gt; Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
#&gt;   using a Wald t-distribution approximation.</preformat>
  <p>The model’s <bold>parameters</bold> can be challenging to interpret
  and do not offer us all the insights that this model actually
  contains.</p>
  <sec id="visualize-relationship">
    <title>Visualize relationship</title>
    <p>The <italic>modelbased</italic> provides some basic plotting
    capabilities, which means that most outputs can be visualized using
    the <monospace>plot()</monospace> function. We can start by easily
    visualizing the relationship between our response variable and our
    predictors (Figure 1).</p>
    <code language="r script">estimate_relation(model, by = c(&quot;Petal.Length&quot;, &quot;Species&quot;), length = 100) |&gt;
  plot(show_data = TRUE)</code>
    <fig id="figU003Afig1">
      <caption><p>Scatter plot of petal length by pelal width, grouped
      by species</p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="fig1-1.pdf" />
    </fig>
    <p>But what is the <bold>average value</bold> of
    <monospace>Petal.Width</monospace> for each species?</p>
  </sec>
  <sec id="marginal-means">
    <title>Marginal Means</title>
    <p>The marginal means can be computed, which are the mean
    predictions for each level of a categorical predictor,
    <italic>averaged across</italic> all levels of other predictors
    (<monospace>Petal.Length</monospace> in this case).</p>
    <code language="r script">estimate_means(model, by = &quot;Species&quot;)</code>
    <preformat>#&gt; Estimated Marginal Means
#&gt; 
#&gt; Species    | Mean |   SE |       95% CI | t(144)
#&gt; ------------------------------------------------
#&gt; setosa     | 0.71 | 0.34 | [0.04, 1.37] |   2.11
#&gt; versicolor | 1.16 | 0.04 | [1.09, 1.23] |  31.44
#&gt; virginica  | 1.74 | 0.09 | [1.57, 1.91] |  20.20
#&gt; 
#&gt; Variable predicted: Petal.Width
#&gt; Predictors modulated: Species
#&gt; Predictors averaged: Petal.Length (3.8)</preformat>
    <p>However, are these different species <bold>significantly
    different</bold> from each other?</p>
  </sec>
  <sec id="marginal-contrasts">
    <title>Marginal Contrasts</title>
    <p>We can estimate all the pairwise contrasts between the levels of
    the <monospace>Species</monospace> factor.</p>
    <code language="r script">estimate_contrasts(model, contrast = &quot;Species&quot;)</code>
    <preformat>#&gt; Marginal Contrasts Analysis
#&gt; 
#&gt; Level1     | Level2     | Difference |   SE |        95% CI | t(144) |      p
#&gt; -----------------------------------------------------------------------------
#&gt; versicolor | setosa     |       0.45 | 0.34 | [-0.22, 1.12] |   1.34 |  0.183
#&gt; virginica  | setosa     |       1.03 | 0.35 | [ 0.35, 1.72] |   2.97 |  0.003
#&gt; virginica  | versicolor |       0.58 | 0.09 | [ 0.39, 0.76] |   6.18 | &lt; .001
#&gt; 
#&gt; Variable predicted: Petal.Width
#&gt; Predictors contrasted: Species
#&gt; Predictors averaged: Petal.Length (3.8)
#&gt; p-values are uncorrected.</preformat>
    <p>As we can see, the average difference between
    <italic>versicolor</italic> and <italic>setosa</italic> is not
    significant.</p>
  </sec>
  <sec id="marginal-slopes">
    <title>Marginal Slopes</title>
    <p>Similarly, we can compute the marginal effect of
    <monospace>Petal.Length</monospace> (i.e., the “slope”) for each
    species.</p>
    <code language="r script">estimate_slopes(model, trend = &quot;Petal.Length&quot;, by = &quot;Species&quot;)</code>
    <preformat>#&gt; Estimated Marginal Effects
#&gt; 
#&gt; Species    | Slope |   SE |        95% CI | t(144) |      p
#&gt; -----------------------------------------------------------
#&gt; setosa     |  0.20 | 0.15 | [-0.09, 0.49] |   1.38 |  0.170
#&gt; versicolor |  0.33 | 0.05 | [ 0.22, 0.44] |   6.14 | &lt; .001
#&gt; virginica  |  0.16 | 0.05 | [ 0.07, 0.25] |   3.49 | &lt; .001
#&gt; 
#&gt; Marginal effects estimated for Petal.Length
#&gt; Type of slope was dY/dX</preformat>
    <p>This shows that there is a significant positive relationship
    between <monospace>Petal.Length</monospace> and
    <monospace>Petal.Width</monospace> for all species but
    <italic>setosa</italic>.</p>
  </sec>
  <sec id="marginal-contrasts-of-slopes">
    <title>Marginal Contrasts of Slopes</title>
    <p>Finally, we can even compute the contrasts between the slopes of
    <monospace>Petal.Length</monospace> for each species.</p>
    <code language="r script">estimate_contrasts(model, contrast = &quot;Petal.Length&quot;, by = &quot;Species&quot;)</code>
    <preformat>#&gt; Marginal Contrasts Analysis
#&gt; 
#&gt; Level1     | Level2     | Difference |   SE |         95% CI | t(144) |     p
#&gt; -----------------------------------------------------------------------------
#&gt; versicolor | setosa     |       0.13 | 0.16 | [-0.18,  0.44] |   0.83 | 0.405
#&gt; virginica  | setosa     |      -0.04 | 0.15 | [-0.34,  0.26] |  -0.27 | 0.789
#&gt; virginica  | versicolor |      -0.17 | 0.07 | [-0.31, -0.03] |  -2.41 | 0.017
#&gt; 
#&gt; Variable predicted: Petal.Width
#&gt; Predictors contrasted: Petal.Length
#&gt; Predictors averaged: Petal.Length (3.8)
#&gt; p-values are uncorrected.</preformat>
    <p>The effect of <monospace>Petal.Length</monospace> on
    <monospace>Petal.Width</monospace> is significantly stronger in
    <italic>virginica</italic> compared to
    <italic>versicolor</italic>.</p>
  </sec>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p>The <monospace>modelbased</monospace> package provides a simple and
  intuitive interface to extract and visualize important information
  contained within statistical models.</p>
</sec>
<sec id="declarations">
  <title>Declarations</title>
  <sec id="funding-information">
    <title>Funding information</title>
    <p>This research received no external funding.</p>
  </sec>
  <sec id="competing-interests">
    <title>Competing Interests</title>
    <p>The authors declare no conflict of interest</p>
  </sec>
  <sec id="availability-of-data-and-materials-data-transparency">
    <title>Availability of data and materials (data
    transparency)</title>
    <p>All data used in this paper uses data included with base R.</p>
  </sec>
  <sec id="code-availability">
    <title>Code availability</title>
    <p>The <monospace>modelbased</monospace> package is available at the
    official website (https://easystats.github.io/modelbased), on CRAN
    (https://cran.r-project.org/package=modelbased), and on the
    R-Universe (https://easystats.r-universe.dev/modelbased). The source
    code is available on GitHub
    (https://github.com/easystats/modelbased), and the package can be
    installed from CRAN with
    <monospace>install.packages(&quot;modelbased&quot;)</monospace> or
    from R-Universe with
    <monospace>install.packages(&quot;modelbased&quot;, repos = &quot;https://easystats.r-universe.dev&quot;)</monospace>.</p>
  </sec>
  <sec id="contributions">
    <title>Contributions</title>
    <p>DM: Writing- Original draft preparation, Writing- Reviewing and
    Editing, Software. MSB-S, BMW, IP, RT, and DL: Writing- Reviewing
    and Editing, Software.</p>
  </sec>
  <sec id="acknowledgements">
    <title>Acknowledgements</title>
    <p><italic>{modelbased}</italic> is part of the collaborative
    <ext-link ext-link-type="uri" xlink:href="https://github.com/easystats/easystats"><italic>easystats</italic></ext-link>
    ecosystem
    (<xref alt="Lüdecke et al., 2023" rid="ref-easystatspackage" ref-type="bibr">Lüdecke
    et al., 2023</xref>). Thus, we thank all
    <ext-link ext-link-type="uri" xlink:href="https://github.com/orgs/easystats/people">members
    of easystats</ext-link>, contributors, and users alike.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-cumming2014new">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cumming</surname><given-names>Geoff</given-names></name>
      </person-group>
      <article-title>The new statistics: Why and how</article-title>
      <source>Psychological science</source>
      <publisher-name>Sage Publications Sage CA: Los Angeles, CA</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>25</volume>
      <issue>1</issue>
      <fpage>7</fpage>
      <lpage>29</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pan2014random">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pan</surname><given-names>Jianxin</given-names></name>
        <name><surname>Huang</surname><given-names>Chao</given-names></name>
      </person-group>
      <article-title>Random effects selection in generalized linear mixed models via shrinkage penalty function</article-title>
      <source>Statistics and Computing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>24</volume>
      <pub-id pub-id-type="doi">10.1007/s11222-013-9398-0</pub-id>
      <fpage>725</fpage>
      <lpage>738</lpage>
    </element-citation>
  </ref>
  <ref id="ref-OSC2015estimating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>Open Science Collaboration</string-name>
      </person-group>
      <article-title>Estimating the reproducibility of psychological science</article-title>
      <source>Science</source>
      <year iso-8601-date="2015">2015</year>
      <volume>349</volume>
      <uri>https://doi.org/10.1126/science.aac4716</uri>
      <pub-id pub-id-type="doi">10.1126/science.aac4716</pub-id>
      <fpage>aac4716</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-camerer2018evaluating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Camerer</surname><given-names>Colin F.</given-names></name>
        <name><surname>Dreber</surname><given-names>Anna</given-names></name>
        <name><surname>Holzmeister</surname><given-names>Felix</given-names></name>
        <name><surname>Ho</surname><given-names>Teck-Hua</given-names></name>
        <name><surname>Huber</surname><given-names>Jürgen</given-names></name>
        <name><surname>Johannesson</surname><given-names>Magnus</given-names></name>
        <name><surname>Kirchler</surname><given-names>Michael</given-names></name>
        <name><surname>Nave</surname><given-names>Gideon</given-names></name>
        <name><surname>Nosek</surname><given-names>Brian A.</given-names></name>
        <name><surname>Pfeiffer</surname><given-names>Thomas</given-names></name>
        <name><surname>Altmejd</surname><given-names>Adam</given-names></name>
        <name><surname>Buttrick</surname><given-names>Nick</given-names></name>
        <name><surname>Chan</surname><given-names>Taizan</given-names></name>
        <name><surname>Chen</surname><given-names>Yiling</given-names></name>
        <name><surname>Forsell</surname><given-names>Eskil</given-names></name>
        <name><surname>Gampa</surname><given-names>Anup</given-names></name>
        <name><surname>Heikensten</surname><given-names>Emma</given-names></name>
        <name><surname>Hummer</surname><given-names>Lily</given-names></name>
        <name><surname>Imai</surname><given-names>Taisuke</given-names></name>
        <name><surname>Isaksson</surname><given-names>Siri</given-names></name>
        <name><surname>Manfredi</surname><given-names>Dylan</given-names></name>
        <name><surname>Rose</surname><given-names>Julia</given-names></name>
        <name><surname>Wagenmakers</surname><given-names>Eric-Jan</given-names></name>
        <name><surname>Wu</surname><given-names>Hang</given-names></name>
      </person-group>
      <article-title>Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015</article-title>
      <source>Nature Human Behaviour</source>
      <year iso-8601-date="2018">2018</year>
      <volume>2</volume>
      <uri>https://doi.org/10.1038/s41562-018-0399-z</uri>
      <pub-id pub-id-type="doi">10.1038/s41562-018-0399-z</pub-id>
      <fpage>637</fpage>
      <lpage>644</lpage>
    </element-citation>
  </ref>
  <ref id="ref-makowski2023we">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Makowski</surname><given-names>Dominique</given-names></name>
        <name><surname>Waggoner</surname><given-names>Philip D</given-names></name>
      </person-group>
      <article-title>Where are we going with statistical computing? From mathematical statistics to collaborative data science</article-title>
      <source>Mathematics</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>11</volume>
      <uri>https://doi.org/10.3390/math11081821</uri>
      <pub-id pub-id-type="doi">10.3390/math11081821</pub-id>
      <fpage>1821</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-easystatspackage">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Lüdecke</surname><given-names>Daniel</given-names></name>
        <name><surname>Makowski</surname><given-names>Dominique</given-names></name>
        <name><surname>Ben-Shachar</surname><given-names>Mattan S.</given-names></name>
        <name><surname>Patil</surname><given-names>Indrajeet</given-names></name>
        <name><surname>Wiernik</surname><given-names>Brenton M.</given-names></name>
        <name><surname>Bacher</surname><given-names>Etienne</given-names></name>
        <name><surname>Thériault</surname><given-names>Rémi</given-names></name>
      </person-group>
      <article-title>easystats: Streamline model interpretation, visualization, and reporting</article-title>
      <year iso-8601-date="2023-02-04">2023</year><month>02</month><day>04</day>
      <uri>https://easystats.github.io/easystats/</uri>
    </element-citation>
  </ref>
  <ref id="ref-ludecke2020extracting">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lüdecke</surname><given-names>Daniel</given-names></name>
        <name><surname>Ben-Shachar</surname><given-names>Mattan S</given-names></name>
        <name><surname>Patil</surname><given-names>Indrajeet</given-names></name>
        <name><surname>Makowski</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>Extracting, computing and exploring the parameters of statistical models using R</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>53</issue>
      <uri>https://doi.org/10.21105/joss.02445</uri>
      <pub-id pub-id-type="doi">10.21105/joss.02445</pub-id>
      <fpage>2445</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ludecke2021performance">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lüdecke</surname><given-names>Daniel</given-names></name>
        <name><surname>Ben-Shachar</surname><given-names>Mattan S.</given-names></name>
        <name><surname>Patil</surname><given-names>Indrajeet</given-names></name>
        <name><surname>Waggoner</surname><given-names>Philip</given-names></name>
        <name><surname>Makowski</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>performance: An R package for assessment, comparison and testing of statistical models</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>60</issue>
      <uri>https://doi.org/10.21105/joss.03139</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03139</pub-id>
      <fpage>3139</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ben2020effectsize">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ben-Shachar</surname><given-names>Mattan S</given-names></name>
        <name><surname>Lüdecke</surname><given-names>Daniel</given-names></name>
        <name><surname>Makowski</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>effectsize: Estimation of effect size indices and standardized parameters</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>56</issue>
      <uri>https://doi.org/10.21105/joss.02815</uri>
      <pub-id pub-id-type="doi">10.21105/joss.02815</pub-id>
      <fpage>2815</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-russell2024emmeans">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Lenth</surname><given-names>Russell V.</given-names></name>
      </person-group>
      <source>emmeans: Estimated marginal means, aka least-squares means</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://doi.org/10.32614/CRAN.package.emmeans</uri>
      <pub-id pub-id-type="doi">10.32614/CRAN.package.emmeans</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-arel2024interpret">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Arel-Bundock</surname><given-names>Vincent</given-names></name>
        <name><surname>Greifer</surname><given-names>Noah</given-names></name>
        <name><surname>Heiss</surname><given-names>Andrew</given-names></name>
      </person-group>
      <article-title>How to interpret statistical models using marginaleffects for R and Python</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2024">2024</year>
      <volume>111</volume>
      <uri>https://doi.org/10.18637/jss.v111.i09</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v111.i09</pub-id>
      <fpage>1</fpage>
      <lpage>32</lpage>
    </element-citation>
  </ref>
  <ref id="ref-chatton_rohrer_2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chatton</surname><given-names>Arthur</given-names></name>
        <name><surname>Rohrer</surname><given-names>Julia M.</given-names></name>
      </person-group>
      <article-title>The causal cookbook: Recipes for propensity scores, g-computation, and doubly robust standardization</article-title>
      <source>Advances in Methods and Practices in Psychological Science</source>
      <year iso-8601-date="2024">2024</year>
      <volume>7</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1177/25152459241236149</uri>
      <pub-id pub-id-type="doi">10.1177/25152459241236149</pub-id>
      <fpage>25152459241236149</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-anderson_species_1936">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Anderson</surname><given-names>Edgar</given-names></name>
      </person-group>
      <article-title>The Species Problem in Iris</article-title>
      <source>Annals of the Missouri Botanical Garden</source>
      <year iso-8601-date="1936-09">1936</year><month>09</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-12">2025</year><month>05</month><day>12</day></date-in-citation>
      <volume>23</volume>
      <issue>3</issue>
      <uri>https://www.jstor.org/stable/2394164?origin=crossref</uri>
      <pub-id pub-id-type="doi">10.2307/2394164</pub-id>
      <fpage>457</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>These functions can become redundant if the
    defaults are changed. For instance,
    <monospace>estimate_relation(..., predict = &quot;link&quot;)</monospace>
    is equivalent to <monospace>estimate_link(...)</monospace>.</p>
  </fn>
</fn-group>
</back>
</article>
