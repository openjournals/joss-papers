<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5136</article-id>
<article-id pub-id-type="doi">10.21105/joss.05136</article-id>
<title-group>
<article-title>Trash AI: A Web GUI for Serverless Computer Vision
Analysis of Images of Trash</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9226-3104</contrib-id>
<name>
<surname>Cowger</surname>
<given-names>Win</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Hollingsworth</surname>
<given-names>Steven</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fey</surname>
<given-names>Day</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Norris</surname>
<given-names>Mary C</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Walter</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kerge</surname>
<given-names>Kristiina</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Haamer</surname>
<given-names>Kris</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Durante</surname>
<given-names>Gina</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hernandez</surname>
<given-names>Brianda</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Moore Institute for Plastic Pollution Research,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Code for Sacramento and Open Fresno, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>California Department of Transportation, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Let’s Do It Foundation, Estonia</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-09-01">
<day>1</day>
<month>9</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>89</issue>
<fpage>5136</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>tensorflow.js</kwd>
<kwd>IndexDB</kwd>
<kwd>Plastic Pollution</kwd>
<kwd>Trash</kwd>
<kwd>Litter</kwd>
<kwd>AI</kwd>
<kwd>Image Classification</kwd>
<kwd>Serverless</kwd>
<kwd>vue</kwd>
<kwd>vuetify</kwd>
<kwd>vite</kwd>
<kwd>pinia</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Although computer vision classification routines have been created
  for trash, they have not been accessible to most researchers due to
  the challenges in deploying the models. Trash AI is a web GUI
  (Graphical User Interface) for serverless computer vision
  classification of individual items of trash within images, hosted at
  www.trashai.org. With a single batch upload and download, a user can
  automatically describe the types and quantities of trash in all of
  their images.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Trash in the environment is a widespread problem that is difficult
  to measure. Policy makers require high quality data on trash to create
  effective policies. Classical measurement techniques require surveyors
  with pen and paper to manually quantify every piece of trash at a
  site. This method is time-consuming. Scientists are actively trying to
  address this issue by using imaging to better understand the
  prevalence and distribution of trash in an
  <monospace>efficient yet effective manner</monospace>
  (<xref alt="K. Kerge, 2020" rid="ref-WADEAIU003A2020" ref-type="bibr">K.
  Kerge, 2020</xref>;
  <xref alt="Lieshout et al., 2020" rid="ref-vanLieshoutU003A2020" ref-type="bibr">Lieshout
  et al., 2020</xref>;
  <xref alt="Lynch, 2018" rid="ref-LynchU003A2018" ref-type="bibr">Lynch,
  2018</xref>;
  <xref alt="Majchrowska et al., 2022" rid="ref-MajchrowskaU003A2022" ref-type="bibr">Majchrowska
  et al., 2022</xref>;
  <xref alt="Moore et al., 2020" rid="ref-MooreU003A2020" ref-type="bibr">Moore
  et al., 2020</xref>;
  <xref alt="Proença &amp; Simões, 2020" rid="ref-ProençaU003A2020" ref-type="bibr">Proença
  &amp; Simões, 2020</xref>;
  <xref alt="Waterboards, 2018" rid="ref-WaterboardsU003A2018" ref-type="bibr">Waterboards,
  2018</xref>;
  <xref alt="Wuu, 2018" rid="ref-WuuU003A2018" ref-type="bibr">Wuu,
  2018</xref>). Image-based reporting of trash using cell phones,
  laptops, and other devices has been a
  <monospace>valuable solution</monospace>
  (<xref alt="Lynch, 2018" rid="ref-LynchU003A2018" ref-type="bibr">Lynch,
  2018</xref>). Applications for AI in detecting trash using imagery
  currently include: cameras mounted on <monospace>bridges</monospace>
  (<xref alt="Lieshout et al., 2020" rid="ref-vanLieshoutU003A2020" ref-type="bibr">Lieshout
  et al., 2020</xref>), <monospace>drone imaging</monospace>
  (<xref alt="Moore et al., 2020" rid="ref-MooreU003A2020" ref-type="bibr">Moore
  et al., 2020</xref>), cameras on
  <monospace>street sweepers</monospace>
  (<xref alt="Waterboards, 2018" rid="ref-WaterboardsU003A2018" ref-type="bibr">Waterboards,
  2018</xref>), and cell phone app based reporting of
  <monospace>trash</monospace>
  (<xref alt="Lynch, 2018" rid="ref-LynchU003A2018" ref-type="bibr">Lynch,
  2018</xref>). Although there are many artificial intelligence
  algorithms developed for trash classification, none are readily
  accessible to the average litter researcher. The primary limitation is
  that artificial intelligence (AI) algorithms are primarily run through
  programming languages (not graphic user interfaces), difficult to
  deploy without AI expertise, and often live on a server (which costs
  money to host). New developments in browser-side AI (e.g.,
  tensorflow.js) and serverless architecture (e.g., AWS Lambda) have
  created the opportunity to have affordable browser-side artificial
  intelligence in a web GUI, alleviating both obstacles. We present
  Trash AI, an open source service for making computer vision available
  to anyone with a web browser and images of trash.</p>
</sec>
<sec id="demo">
  <title>Demo</title>
  <p>We have a full video tutorial on
  <ext-link ext-link-type="uri" xlink:href="https://youtu.be/u0DxGrbPOC0">Youtube</ext-link></p>
  <sec id="basic-workflow">
    <title>Basic workflow:</title>
    <sec id="section">
      <title>1.</title>
      <fig>
        <caption><p>Upload images by dragging onto the
        screen.<styled-content id="figU003Aexample1"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/584bc42d833ad11ddb263125e73da5a057151585.png" />
      </fig>
    </sec>
    <sec id="section-1">
      <title>2.</title>
      <fig>
        <caption><p>View results while images are
        processing.<styled-content id="figU003Aexample2"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/8d7230166c1b40a29c4e6306dd5dac8f75f71ce1.png" />
      </fig>
    </sec>
    <sec id="section-2">
      <title>3.</title>
      <fig>
        <caption><p>View summary results of detected
        trash.<styled-content id="figU003Aexample3"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/c18e1b63759f1240c8bb14fc1f4a0b0ddabf85b9.png" />
      </fig>
    </sec>
    <sec id="section-3">
      <title>4.</title>
      <fig>
        <caption><p>View results mapped if the images have location
        stamp.<styled-content id="figU003Aexample4"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/6df0bdf8d1da058103f347b72d5a1a5efc75d51a.png" />
      </fig>
    </sec>
    <sec id="section-4">
      <title>5.</title>
      <fig>
        <caption><p>Click download all to extract a zip folder with
        labeled images and
        metadata.<styled-content id="figU003Aexample5"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/ad20d27dc6dd6e979be96da8a3b2cf4dc40a8780.png" />
      </fig>
    </sec>
    <sec id="section-5">
      <title>6.</title>
      <fig>
        <caption><p>View labeled images from downloaded
        results.<styled-content id="figU003Aexample6"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/0441eda5e9cd946485eef5a1670b76f071784323.png" />
      </fig>
    </sec>
    <sec id="section-6">
      <title>7.</title>
      <fig>
        <caption><p>View metadata for each image using “image_hash.json”
        (using
        https://jsoneditoronline.org/).<styled-content id="figU003Aexample7"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/a82b2d8b2ae9e21ee0c5e90c93f380683a6b181f.png" />
      </fig>
    </sec>
    <sec id="section-7">
      <title>8.</title>
      <fig>
        <caption><p>View metadata for all images in “summary.json”
        (using
        https://jsoneditoronline.org/).<styled-content id="figU003Aexample8"></styled-content></p></caption>
        <graphic mimetype="image" mime-subtype="png" xlink:href="media/cd22e1da57f30a0cfe76e2901d516fddca7f0c8a.png" />
      </fig>
    </sec>
  </sec>
</sec>
<sec id="method">
  <title>Method</title>
  <sec id="workflow-overview">
    <title>Workflow Overview</title>
    <p>Trash AI is trained on the
    <ext-link ext-link-type="uri" xlink:href="http://tacodataset.org/">TACO
    dataset</ext-link> using
    <ext-link ext-link-type="uri" xlink:href="https://pytorch.org/">YOLO
    5</ext-link>. Trash AI stores images in
    <ext-link ext-link-type="uri" xlink:href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API">IndexDB</ext-link>
    to keep the data primarily browser side and uses
    <ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/js">tensorflow.js</ext-link>
    to keep analysis browser side too. When images are uploaded to the
    browser, Trash AI provides the prediction of the model as a
    graphical output. The raw data from the model and labeled images can
    be downloaded in batch to expedite analyses.</p>
  </sec>
  <sec id="ai-training">
    <title>AI Training</title>
    <p>The AI model was developed starting with the TACO dataset, which
    was available with a complimentary Jupyter Notebook on
    <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/datasets/kneroma/tacotrashdataset">Kaggle</ext-link>.
    An example notebook was referenced, which used the default
    <monospace>YOLO v5 model</monospace>
    (<xref alt="Jocher et al., 2020" rid="ref-JocherU003A2020" ref-type="bibr">Jocher
    et al., 2020</xref>) as the basic model to begin transfer learning.
    Next, transfer learning was completed using the entire TACO dataset
    to import the image classes and annotations in the YOLO v5
    model.</p>
  </sec>
  <sec id="limitations">
    <title>Limitations</title>
    <p>From our experience, the accuracy of the model varies depending
    on the quality of the images and their context/background. “Trash”
    is a word people use for an object that lacks purpose, and the
    purpose of an object is often not obvious in an image. Trash is a
    nuanced classification because the same object in different settings
    will not be considered trash (e.g., a drink bottle on someone’s desk
    vs in the forest lying on the ground). This is the main challenge
    with any image-based trash detection algorithm. Not everything that
    LOOKS like trash IS trash. This and other complexities to trash
    classification make a general trash AI a challenging (yet
    worthwhile) long-term endeavor. The algorithm is primarily trained
    on the TACO dataset, which is composed of images of single pieces of
    trash, with the trash lying on the ground (&lt; 1 m away). Thus,
    model class prediction of trash in these kinds of images will
    generally be better than trash appearing in aerial images or imaged
    from a vehicle, for example.</p>
  </sec>
</sec>
<sec id="availability">
  <title>Availability</title>
  <p>Trash AI is hosted on the web at www.trashai.org. The source code
  is
  <ext-link ext-link-type="uri" xlink:href="https://github.com/code4sac/trash-ai">available
  on GitHub</ext-link> with an
  <ext-link ext-link-type="uri" xlink:href="https://mit-license.org/">MIT
  license</ext-link>. The source code can be run offline on any machine
  that can install
  <ext-link ext-link-type="uri" xlink:href="www.docker.com">Docker and
  Docker-compose</ext-link>.
  <ext-link ext-link-type="uri" xlink:href="https://github.com/code4sac/trash-ai#trash-ai-web-application-for-serverless-image-classification-of-trash">Documentation</ext-link>
  is maintained by Code for Sacramento and Open Fresno on GitHub and
  will be updated with each release.
  <ext-link ext-link-type="uri" xlink:href="https://github.com/code4sac/trash-ai/blob/manuscript/docs/git-aws-account-setup.md">Nonexhaustive
  instructions for AWS deployment</ext-link> is available for anyone
  attempting production level deployment.</p>
</sec>
<sec id="future-goals">
  <title>Future Goals</title>
  <p>This workflow is likely to be highly useful for a wide variety of
  computer vision applications and we hope that people reuse the code
  for applications beyond trash detection. We aim to increase the
  labeling of images by creating a user interface that allows users to
  improve the annotations that the model is currently predicting by
  manually restructuring the bounding boxes and relabeling the classes.
  We aim to work in collaboration with the TACO development team to
  improve our workflow integration to get additional data into the
  <ext-link ext-link-type="uri" xlink:href="http://tacodataset.org/">TACO
  training dataset</ext-link> by creating an option for users to share
  their data. Future models will expand the annotations to include the
  <monospace>Trash Taxonomy</monospace>
  (<xref alt="Hapich et al., 2022" rid="ref-HapichU003A2022" ref-type="bibr">Hapich
  et al., 2022</xref>) classes and add an option to choose between other
  models besides the current model.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Code for Sacramento and Open Fresno led the development of the
  software tool. The Moore Institute for Plastic Pollution Research
  advised on priorities and led the drafting of this manuscript. Let’s
  Do It Foundation assisted with original products leading up to trash
  AI in the development of WADE AI. We acknowledge the work of the Code
  for Sacramento and Open Fresno team, brigades of Code for America,
  without whom this project would not have been possible, and
  acknowledge the input of the California Water Monitoring Council Trash
  Monitoring Workgroup. In particular, we would like to acknowledge Gary
  Conley, Tony Hale, Emin Israfil, Tom Novotny, Margaret McCauley,
  Julian Fulton, Janna Taing, Elizabeth Pierotti, Kevin Fries, J.Z.
  Zhang, Joseph Falkner, Democracy Lab, Brad Anderson, Jim Ewald, Don
  Brower, and University of Houston. We acknowledge financial support
  from McPike Zima Charitable Foundation, the National Renewable Energy
  Laboratory, and the Possibility Lab.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-JocherU003A2020">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Jocher</surname><given-names>Glenn</given-names></name>
        <name><surname>Stoken</surname><given-names>Alex</given-names></name>
        <name><surname>Borovec</surname><given-names>Jirka</given-names></name>
        <name><surname>NanoCode012</surname></name>
        <name><surname>ChristopherSTAN</surname></name>
        <name><surname>Changyu</surname><given-names>Liu</given-names></name>
        <name><surname>Laughing</surname></name>
        <name><surname>tkianai</surname></name>
        <name><surname>Hogan</surname><given-names>Adam</given-names></name>
        <name><surname>lorenzomammana</surname></name>
        <name><surname>yxNONG</surname></name>
        <name><surname>AlexWang1900</surname></name>
        <name><surname>Diaconu</surname><given-names>Laurentiu</given-names></name>
        <name><surname>Marc</surname></name>
        <name><surname>wanghaoyang0106</surname></name>
        <name><surname>ml5ah</surname></name>
        <name><surname>Doug</surname></name>
        <name><surname>Ingham</surname><given-names>Francisco</given-names></name>
        <name><surname>Frederik</surname></name>
        <name><surname>Guilhen</surname></name>
        <name><surname>Hatovix</surname></name>
        <name><surname>Poznanski</surname><given-names>Jake</given-names></name>
        <name><surname>Fang</surname><given-names>Jiacong</given-names></name>
        <name><surname>于力军</surname><given-names>Lijun Yu</given-names></name>
        <name><surname>changyu98</surname></name>
        <name><surname>Wang</surname><given-names>Mingyu</given-names></name>
        <name><surname>Gupta</surname><given-names>Naman</given-names></name>
        <name><surname>Akhtar</surname><given-names>Osama</given-names></name>
        <name><surname>PetrDvoracek</surname></name>
        <name><surname>Rai</surname><given-names>Prashant</given-names></name>
      </person-group>
      <article-title>ultralytics/yolov5: v3.1 - Bug Fixes and Performance Improvements</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2020-10">2020</year><month>10</month>
      <uri>https://doi.org/10.5281/zenodo.4154370</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.4154370</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-MooreU003A2020">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Moore</surname><given-names>Shelly</given-names></name>
        <name><surname>Hale</surname><given-names>Tony</given-names></name>
        <name><surname>Weisberg</surname><given-names>Stephen B</given-names></name>
        <name><surname>Flores</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Kauhanen</surname><given-names>Pete</given-names></name>
      </person-group>
      <article-title>California trash monitoring methods and assessments playbook</article-title>
      <publisher-name>San Francisco Estuary Institute</publisher-name>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-HapichU003A2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hapich</surname><given-names>Hannah</given-names></name>
        <name><surname>Cowger</surname><given-names>Win</given-names></name>
        <name><surname>Gray</surname><given-names>Andrew</given-names></name>
        <name><surname>Tangri</surname><given-names>Neil</given-names></name>
        <name><surname>Hale</surname><given-names>Tony</given-names></name>
        <name><surname>Magdy</surname><given-names>Amr</given-names></name>
        <name><surname>Vermilye</surname><given-names>Antoinette</given-names></name>
        <name><surname>Yu</surname><given-names>Walter</given-names></name>
        <name><surname>Ayres</surname><given-names>Dick</given-names></name>
        <name><surname>Moore</surname><given-names>Charles</given-names></name>
        <name><surname>Vermilye</surname><given-names>John</given-names></name>
        <name><surname>Singh</surname><given-names>Samiksha</given-names></name>
        <name><surname>Haiman</surname><given-names>Aaron N K</given-names></name>
        <name><surname>Youngblood</surname><given-names>Kathryn</given-names></name>
        <name><surname>Kang</surname><given-names>Yunfan</given-names></name>
        <name><surname>McCauley</surname><given-names>Margaret</given-names></name>
        <name><surname>Lok</surname><given-names>Trevor</given-names></name>
        <name><surname>Moore</surname><given-names>Shelly</given-names></name>
        <name><surname>Baggs</surname><given-names>Eric</given-names></name>
        <name><surname>Lippiatt</surname><given-names>Sherry</given-names></name>
        <name><surname>Kohler</surname><given-names>Peter</given-names></name>
        <name><surname>Conley</surname><given-names>Gary</given-names></name>
        <name><surname>Taing</surname><given-names>Janna</given-names></name>
        <name><surname>Mock</surname><given-names>Jeremiah</given-names></name>
      </person-group>
      <article-title>Trash taxonomy tool: Harmonizing classification systems used to describe trash in environments</article-title>
      <source>Microplastics and Nanoplastics</source>
      <year iso-8601-date="2022-06">2022</year><month>06</month>
      <volume>2</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1186/s43591-022-00035-1</pub-id>
      <fpage>15</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-WaterboardsU003A2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Waterboards</surname></name>
      </person-group>
      <article-title>Trash tracker</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <uri>https://github.com/CAWaterBoardDataCenter/Trash-Tracker</uri>
    </element-citation>
  </ref>
  <ref id="ref-vanLieshoutU003A2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lieshout</surname><given-names>Colin van</given-names></name>
        <name><surname>Oeveren</surname><given-names>Kees van</given-names></name>
        <name><surname>Emmerik</surname><given-names>Tim van</given-names></name>
        <name><surname>Postma</surname><given-names>Eric</given-names></name>
      </person-group>
      <article-title>Automated river plastic monitoring using deep learning and cameras</article-title>
      <source>Earth and Space Science</source>
      <year iso-8601-date="2020">2020</year>
      <volume>7</volume>
      <issue>8</issue>
      <uri>https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019EA000960</uri>
      <pub-id pub-id-type="doi">10.1029/2019EA000960</pub-id>
      <fpage>e2019EA000960</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-LynchU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lynch</surname><given-names>Seán</given-names></name>
      </person-group>
      <article-title>OpenLitterMap.com – open data on plastic pollution with blockchain rewards (littercoin)</article-title>
      <source>Open Geospatial Data, Software and Standards</source>
      <year iso-8601-date="2018-06">2018</year><month>06</month>
      <volume>3</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1186/s40965-018-0050-y</pub-id>
      <fpage>6</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-WADEAIU003A2020">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>K. Kerge</surname><given-names>K. Haamer</given-names><suffix>W. Cowger</suffix></name>
      </person-group>
      <article-title>WADE AI trash detection</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/letsdoitworld/wade-ai</uri>
    </element-citation>
  </ref>
  <ref id="ref-WuuU003A2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wuu</surname><given-names>S.</given-names></name>
      </person-group>
      <article-title>Litter detection tensorflow</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <uri>https://github.com/isaychris/litter-detection-tensorflow</uri>
    </element-citation>
  </ref>
  <ref id="ref-MajchrowskaU003A2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Majchrowska</surname><given-names>Sylwia</given-names></name>
        <name><surname>Mikołajczyk</surname><given-names>Agnieszka</given-names></name>
        <name><surname>Ferlin</surname><given-names>Maria</given-names></name>
        <name><surname>Klawikowska</surname><given-names>Zuzanna</given-names></name>
        <name><surname>Plantykow</surname><given-names>Marta A.</given-names></name>
        <name><surname>Kwasigroch</surname><given-names>Arkadiusz</given-names></name>
        <name><surname>Majek</surname><given-names>Karol</given-names></name>
      </person-group>
      <article-title>Deep learning-based waste detection in natural and urban environments</article-title>
      <source>Waste Management</source>
      <year iso-8601-date="2022">2022</year>
      <volume>138</volume>
      <issn>0956-053X</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0956053X21006474</uri>
      <pub-id pub-id-type="doi">10.1016/j.wasman.2021.12.001</pub-id>
      <fpage>274</fpage>
      <lpage>284</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ProençaU003A2020">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Proença</surname><given-names>Pedro F</given-names></name>
        <name><surname>Simões</surname><given-names>Pedro</given-names></name>
      </person-group>
      <article-title>TACO: Trash annotations in context for litter detection</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://arxiv.org/abs/2003.06975</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.2003.06975</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
