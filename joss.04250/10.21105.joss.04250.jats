<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4250</article-id>
<article-id pub-id-type="doi">10.21105/joss.04250</article-id>
<title-group>
<article-title>JOAN: a framework for human-automated vehicle interaction
experiments in a virtual reality driving simulator</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7077-9812</contrib-id>
<name>
<surname>Beckers</surname>
<given-names>Niek</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5614-1262</contrib-id>
<name>
<surname>Siebinga</surname>
<given-names>Olger</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Giltay</surname>
<given-names>Joris</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>van der Kraan</surname>
<given-names>André</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Human-Robot Interaction group, Department of Cognitive
Robotics, Faculty 3mE, Delft University of Technology, Mekelweg 2, 2628
CD Delft, The Netherlands</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-02-07">
<day>7</day>
<month>2</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>82</issue>
<fpage>4250</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Human-automated vehicle interaction</kwd>
<kwd>Automated driving</kwd>
<kwd>Human factors experiments</kwd>
<kwd>Simulation</kwd>
<kwd>Virtual Reality</kwd>
<kwd>CARLA</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>With the rapid development of automated driving systems, human
  drivers will soon have to share the road, and interact with,
  autonomous vehicles (AVs). To design AVs that can be safely introduced
  in our mixed traffic, research into human-AV interaction is needed.
  Driving simulators are invaluable tools, however, existing driving
  simulators are expensive, implementing new functionalities (e.g., AV
  control algorithms) can be difficult, and setting up new experiments
  can be tedious. To address these issues, we present JOAN, a framework
  for human-AV interaction experiments. JOAN connects to the open-source
  AV-simulation program Carla and enables quick and easy implementation
  of simple driving experiments. It supports experiments in VR, a
  variety of human input devices, and haptic feedback. JOAN is easy to
  use, flexible, and enables researchers to design, store, and perform
  human-factors experiments without writing a single line of code.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Real-world traffic is rapidly changing: automated vehicles, even
  autonomous vehicles, are rapidly being introduced on the roads
  interacting with other road users. It is likely that traffic will be
  mixed for the coming decades, with manually driven vehicles, vehicles
  of various levels of automation, and vulnerable road users (e.g.,
  pedestrians and cyclists) sharing the same road
  (<xref alt="Di &amp; Shi, 2021" rid="ref-di2020_survey" ref-type="bibr">Di
  &amp; Shi, 2021</xref>). Therefore, investigating the interaction
  between AVs and other road users is critical for the development of
  safe and acceptable AV behavior. Driving simulators are invaluable
  tools to study such human-AV interactions.</p>
  <p>State-of-the-art driving simulators use motion platforms, immersive
  graphics
  (<xref alt="WIVW, 2020" rid="ref-wivw-scilab" ref-type="bibr">WIVW,
  2020</xref>), and/or high-fidelity haptic feedback
  (<xref alt="Mulder et al., 2012" rid="ref-mulder2012_sharing" ref-type="bibr">Mulder
  et al., 2012</xref>) to create simulations with high levels of realism
  (<xref alt="Slob, 2008" rid="ref-slob2008_stateoftheart" ref-type="bibr">Slob,
  2008</xref>). However, such simulators require dedicated and often
  expensive hardware, limiting their availability for algorithm
  development and evaluation. Furthermore, they require a steep
  programming learning curve and lack the flexibility to quickly
  implement customized experiments.</p>
  <p>Alternatively, virtual-reality-based driving simulators offer
  reasonable levels of realism, require relatively low-cost hardware,
  and are generally more flexible in terms of rapid algorithm
  development or experiment evaluation. Traffic simulators based on the
  Unity game engine have been developed for studying human-human
  interaction in mixed traffic
  (<xref alt="Bazilinskyy et al., 2020" rid="ref-bazilinskyy2020_coupled" ref-type="bibr">Bazilinskyy
  et al., 2020</xref>;
  <xref alt="Kearney &amp; Noyce, 2018" rid="ref-kearney2018_multimodal" ref-type="bibr">Kearney
  &amp; Noyce, 2018</xref>). However, both lack the framework to
  implement AV driving models, which is necessary to simulate
  mixed-traffic scenarios.</p>
  <p>Several game engine-based simulators exist that only specifically
  focus on AV algorithm development (e.g., Shah et al.
  (<xref alt="2018" rid="ref-airsim2017fsr" ref-type="bibr">2018</xref>),
  LG Electronics America R&amp;D Center
  (<xref alt="2020" rid="ref-lgsvlsim" ref-type="bibr">2020</xref>),
  Dosovitskiy
  (<xref alt="2017" rid="ref-dosovitskiy2017_carla" ref-type="bibr">2017</xref>)).
  While such simulators provide possibilities for implementing,
  training, and evaluating fully automated driving algorithm, they do
  not support human-in-the-loop experiments. A popular open-source
  simulators is CARLA (based on the Unreal-Engine); it provides a
  flexible and well-documented API, pre-trained automated driving
  models, common roadmap standards (OpenDrive), and is actively
  maintained.</p>
  <p>Silvera et al. extended Carla to support human-in-the-loop
  experiments
  (<xref alt="Silvera et al., 2022" rid="ref-Silvera2022" ref-type="bibr">Silvera
  et al., 2022</xref>). They created an affordable driving simulator
  primarily implemented in C++ and python that can be used for human-AV
  interaction experiments which leverages the benefits of CARLA for AV
  development. However, because their software is not set up with a more
  general experiment framework that allows customizability, their
  software is restricted to specific hardware (both for human input and
  VR headsets) and requires extensive programming to implement
  customized experiments.</p>
  <p>To address these issues, we created JOAN, an open-source framework
  for conducting human-in-the-loop driving experiments. JOAN interfaces
  with Carla, is written in Python, is fully customizable through code
  and graphical user interfaces (GUI). JOAN can be used with a variety
  of human input devices, including game console controllers (e.g.,Xbox
  or PlayStation), generic USB controllers (e.g., Logitech G920), or a
  SensoDrive high-fidelity steering wheel
  (<xref alt="SensoDrive, 2022" rid="ref-sensodrive" ref-type="bibr">SensoDrive,
  2022</xref>) (for including haptic feedback). JOAN includes a
  framework for experiment design to create and execute experiments, and
  provides reliable data acquisition. These features can be accessed
  through a user-friendly interface, which means no extensive (knowledge
  of) programming nor a lot of time is required to set up new
  experiments.</p>
  <p>For detailed instructions on how to install and use JOAN, see our
  online documentation<xref ref-type="fn" rid="fn1">1</xref>. JOAN can
  be found in a GitHub repository<xref ref-type="fn" rid="fn2">2</xref>,
  a video with more information can be found on
  YouTube<xref ref-type="fn" rid="fn3">3</xref>.</p>
</sec>
<sec id="software-functionality">
  <title>Software functionality</title>
  <p>We set the following requirements for JOAN based on the needs of a
  typical human-in-the-loop driving experiment. JOAN should:</p>
  <list list-type="bullet">
    <list-item>
      <p>provide reliable data acquisition,</p>
    </list-item>
    <list-item>
      <p>enable researchers to connect multiple types of user input
      devices,</p>
    </list-item>
    <list-item>
      <p>facilitate the design and execution of experiment protocols;
      create repeatable traffic scenarios involving multiple agents,</p>
    </list-item>
    <list-item>
      <p>provide an easy way to design experiments by providing access
      to most functionality from a GUI,</p>
    </list-item>
    <list-item>
      <p>be flexible and extensible by design, and</p>
    </list-item>
    <list-item>
      <p>include support for haptic feedback.</p>
    </list-item>
  </list>
  <p>JOAN consists of modules, each with a functionality, to address the
  flexibility and extensibility requirements. These modules can be
  enabled or disabled based on the needs of a researcher, if needed they
  can easily be adapted, and researchers can create new modules to
  implement new functionality. The standard modules included with
  JOAN:</p>
  <list list-type="bullet">
    <list-item>
      <p>log and plot experiment data,</p>
    </list-item>
    <list-item>
      <p>handle hardware inputs,</p>
    </list-item>
    <list-item>
      <p>design and execute experiments with multiple conditions,</p>
    </list-item>
    <list-item>
      <p>implement traffic scenarios with dynamic triggers for
      events,</p>
    </list-item>
    <list-item>
      <p>provide a human with haptic feedback.</p>
    </list-item>
  </list>
  <p>Each module has its own GUI which appears if the module is enabled.
  These interfaces provide access to all standard functionality of the
  module. A researcher can design and perform a simple human-in-the-loop
  experiment without writing a single line of code. The documentation
  provides more information for researchers who want to adapt existing
  modules (e.g. to implement new hardware), or who want to write a new
  module (e.g. to implement specific controllers).</p>
</sec>
<sec id="usage-in-science-and-education">
  <title>Usage in Science and Education</title>
  <p>JOAN was used to quickly develop and perform several
  human-in-the-loop experiments (including various MSc students, for a
  published example, see
  (<xref alt="Melman et al., 2021" rid="ref-Melman2021" ref-type="bibr">Melman
  et al., 2021</xref>)), illustrating that JOAN provides a framework
  that is flexible and quick to implement (most projects are completed
  in 6 months). Furthermore, a core research focus of our department is
  the haptic interaction between human drivers and their vehicles (e.g.,
  Abbink et al.
  (<xref alt="2018" rid="ref-abbink2018_topology" ref-type="bibr">2018</xref>),
  Mulder et al.
  (<xref alt="2012" rid="ref-mulder2012_sharing" ref-type="bibr">2012</xref>)),
  for which we implemented a module to control a haptic force-feedback
  steering wheel. The <monospace>SteeringWheelController</monospace>
  module enables implementation of control algorithms for force feedback
  and comes with two example implementations: a standard PD controller
  (<xref alt="Mulder et al., 2012" rid="ref-mulder2012_sharing" ref-type="bibr">Mulder
  et al., 2012</xref>) and a Four Design Choice Architecture controller
  (FDCA)
  (<xref alt="van Paassen et al., 2017" rid="ref-vanpaassen2017_four" ref-type="bibr">van
  Paassen et al., 2017</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank Timo, Cedric, Sam, Peter, Mark, and Tarbiya for their
  support in the initial stages of software development.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-abbink2018_topology">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abbink</surname><given-names>David A.</given-names></name>
        <name><surname>Carlson</surname><given-names>Tom</given-names></name>
        <name><surname>Mulder</surname><given-names>Mark</given-names></name>
        <name><surname>de Winter</surname><given-names>Joost C. F.</given-names></name>
        <name><surname>Aminravan</surname><given-names>Farzad</given-names></name>
        <name><surname>Gibo</surname><given-names>Tricia L.</given-names></name>
        <name><surname>Boer</surname><given-names>Erwin R.</given-names></name>
      </person-group>
      <article-title>A Topology of Shared Control Systems in Diversity</article-title>
      <source>IEEE Transactions on Human-Machine Systems</source>
      <year iso-8601-date="2018-10">2018</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2020-03-20">2020</year><month>03</month><day>20</day></date-in-citation>
      <volume>48</volume>
      <issue>5</issue>
      <issn>2168-2291</issn>
      <uri>https://ieeexplore.ieee.org/document/8353134/</uri>
      <pub-id pub-id-type="doi">10.1109/THMS.2018.2791570</pub-id>
      <fpage>509</fpage>
      <lpage>525</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bazilinskyy2020_coupled">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bazilinskyy</surname><given-names>Pavlo</given-names></name>
        <name><surname>Kooijman</surname><given-names>Lars</given-names></name>
        <name><surname>Dodou</surname><given-names>Dimitra</given-names></name>
        <name><surname>de Winter</surname><given-names>J. C. F.</given-names></name>
      </person-group>
      <article-title>Coupled simulator for research on the interaction between pedestrians and (automated) vehicles</article-title>
      <source>19th Driving Simulation Conference (DSC)</source>
      <publisher-loc>Antibes, France</publisher-loc>
      <year iso-8601-date="2020">2020</year>
      <fpage>7</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-wivw-scilab">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>WIVW</surname></name>
      </person-group>
      <article-title>Driving simulation and SILAB</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://wivw.de/en/silab</uri>
    </element-citation>
  </ref>
  <ref id="ref-sensodrive">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>SensoDrive</surname></name>
      </person-group>
      <article-title>SensoDrive force feedback</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://www.sensodrive.de/products/force-feedback-products.php</uri>
    </element-citation>
  </ref>
  <ref id="ref-airsim2017fsr">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Shah</surname><given-names>Shital</given-names></name>
        <name><surname>Dey</surname><given-names>Debadeepta</given-names></name>
        <name><surname>Lovett</surname><given-names>Chris</given-names></name>
        <name><surname>Kapoor</surname><given-names>Ashish</given-names></name>
      </person-group>
      <article-title>AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles</article-title>
      <year iso-8601-date="2018">2018</year>
      <uri>http://link.springer.com/10.1007/978-3-319-67361-5_40</uri>
      <pub-id pub-id-type="doi">10.1007/978-3-319-67361-5_40</pub-id>
      <fpage>621</fpage>
      <lpage>635</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lgsvlsim">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>LG Electronics America R&amp;D Center</surname><given-names>Advanced Platform Lab at the</given-names></name>
      </person-group>
      <article-title>LGSVL simulator</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://www.lgsvlsimulator.com/</uri>
    </element-citation>
  </ref>
  <ref id="ref-kearney2018_multimodal">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Kearney</surname><given-names>Joseph K</given-names></name>
        <name><surname>Noyce</surname><given-names>David A</given-names></name>
      </person-group>
      <article-title>Multi-Modal Distributed Simulation Combining Cars, Bicyclists, and Pedestrians</article-title>
      <year iso-8601-date="2018">2018</year>
      <fpage>31</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-dosovitskiy2017_carla">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dosovitskiy</surname><given-names>Alexey</given-names></name>
      </person-group>
      <article-title>CARLA: An Open Urban Driving Simulator</article-title>
      <source>Proceedings of the 1st Annual Conference on Robot Learning</source>
      <publisher-loc>Mountain View, California</publisher-loc>
      <year iso-8601-date="2017">2017</year>
      <uri>http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf</uri>
      <fpage>1</fpage>
      <lpage>16</lpage>
    </element-citation>
  </ref>
  <ref id="ref-slob2008_stateoftheart">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Slob</surname><given-names>JJ</given-names></name>
      </person-group>
      <article-title>State-of-the-art driving simulators, a literature survey</article-title>
      <year iso-8601-date="2008">2008</year>
    </element-citation>
  </ref>
  <ref id="ref-mulder2012_sharing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mulder</surname><given-names>Mark</given-names></name>
        <name><surname>Abbink</surname><given-names>David A.</given-names></name>
        <name><surname>Boer</surname><given-names>Erwin R.</given-names></name>
      </person-group>
      <article-title>Sharing Control With Haptics: Seamless Driver Support From Manual to Automatic Control</article-title>
      <source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source>
      <year iso-8601-date="2012-10">2012</year><month>10</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2020-03-20">2020</year><month>03</month><day>20</day></date-in-citation>
      <volume>54</volume>
      <issue>5</issue>
      <issn>0018-7208</issn>
      <uri>http://journals.sagepub.com/doi/10.1177/0018720812443984</uri>
      <pub-id pub-id-type="doi">10.1177/0018720812443984</pub-id>
      <fpage>786</fpage>
      <lpage>798</lpage>
    </element-citation>
  </ref>
  <ref id="ref-vanpaassen2017_four">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>van Paassen</surname><given-names>Marinus M.</given-names></name>
        <name><surname>Boink</surname><given-names>Rolf</given-names></name>
        <name><surname>Abbink</surname><given-names>David A.</given-names></name>
        <name><surname>Mulder</surname><given-names>Mark</given-names></name>
        <name><surname>Mulder</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Four Design Choices for Haptic Shared Control</article-title>
      <source>Advances in Aviation Psychology, Volume 2: Using Scientific Methods to Address Practical Human Factors Needs</source>
      <person-group person-group-type="editor">
        <name><surname>Vidulich</surname><given-names>Michael A.</given-names></name>
        <name><surname>Tsang</surname><given-names>Pamela S.</given-names></name>
        <name><surname>Flach</surname><given-names>John</given-names></name>
      </person-group>
      <publisher-name>Routledge</publisher-name>
      <year iso-8601-date="2017-05">2017</year><month>05</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2020-05-22">2020</year><month>05</month><day>22</day></date-in-citation>
      <edition>First</edition>
      <isbn>978-1-315-56571-2</isbn>
      <uri>https://www.taylorfrancis.com/books/9781317185208</uri>
      <pub-id pub-id-type="doi">10.4324/9781315565712</pub-id>
      <fpage>237</fpage>
      <lpage>254</lpage>
    </element-citation>
  </ref>
  <ref id="ref-di2020_survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Di</surname><given-names>Xuan</given-names></name>
        <name><surname>Shi</surname><given-names>Rongye</given-names></name>
      </person-group>
      <article-title>A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning</article-title>
      <source>Transportation Research Part C: Emerging Technologies</source>
      <publisher-name>Elsevier Ltd</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>125</volume>
      <issue>July 2020</issue>
      <uri>https://doi.org/10.1016/j.trc.2021.103008</uri>
      <pub-id pub-id-type="doi">10.1016/j.trc.2021.103008</pub-id>
      <fpage>103008</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Silvera2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Silvera</surname><given-names>Gustavo</given-names></name>
        <name><surname>Biswas</surname><given-names>Abhijat</given-names></name>
        <name><surname>Admoni</surname><given-names>Henny</given-names></name>
      </person-group>
      <article-title>DReyeVR: Democratizing Virtual Reality Driving Simulation for Behavioural &amp; Interaction Research</article-title>
      <year iso-8601-date="2022-01">2022</year><month>01</month>
      <uri>http://arxiv.org/abs/2201.01931</uri>
    </element-citation>
  </ref>
  <ref id="ref-Melman2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Melman</surname><given-names>Timo</given-names></name>
        <name><surname>Visser</surname><given-names>Peter</given-names></name>
        <name><surname>Mouton</surname><given-names>Xavier</given-names></name>
        <name><surname>Winter</surname><given-names>Joost de</given-names></name>
      </person-group>
      <article-title>Creating the Illusion of Sportiness: Evaluating Modified Throttle Mapping and Artificial Engine Sound for Electric Vehicles</article-title>
      <source>Journal of Advanced Transportation</source>
      <person-group person-group-type="editor">
        <name><surname>Luca</surname><given-names>Stefano de</given-names></name>
      </person-group>
      <year iso-8601-date="2021-10">2021</year><month>10</month>
      <volume>2021</volume>
      <issn>2042-3195</issn>
      <uri>https://www.hindawi.com/journals/jat/2021/4396401/</uri>
      <pub-id pub-id-type="doi">10.1155/2021/4396401</pub-id>
      <fpage>1</fpage>
      <lpage>15</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>https://joan.readthedocs.io</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>https://www.github.com/tud-hri/joan</p>
  </fn>
  <fn id="fn3">
    <label>3</label><p>https://www.youtube.com/watch?v=TLLw48isYJU</p>
  </fn>
</fn-group>
</back>
</article>
