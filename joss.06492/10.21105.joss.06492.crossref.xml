<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20240704160846-57e489a6b25087fd25ea082ec77638396bcdf617</doi_batch_id>
    <timestamp>20240704160846</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>07</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>99</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>ATHENA: A Fortran package for neural networks</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Ned Thaddeus</given_name>
            <surname>Taylor</surname>
            <ORCID>https://orcid.org/0000-0002-9134-9712</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>07</month>
          <day>04</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>6492</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06492</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.6084/m9.figshare.26158630</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6492</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06492</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06492</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06492.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="curcic2019parallel">
            <article_title>A parallel Fortran framework for neural
networks and deep learning</article_title>
            <author>Curcic</author>
            <journal_title>SIGPLAN Fortran Forum</journal_title>
            <issue>1</issue>
            <volume>38</volume>
            <doi>10.1145/3323057.3323059</doi>
            <issn>1061-7264</issn>
            <cYear>2019</cYear>
            <unstructured_citation>Curcic, M. (2019). A parallel Fortran
framework for neural networks and deep learning. SIGPLAN Fortran Forum,
38(1), 4–21.
https://doi.org/10.1145/3323057.3323059</unstructured_citation>
          </citation>
          <citation key="ghiasi2018dropblock">
            <article_title>DropBlock: A regularization method for
convolutional networks</article_title>
            <author>Ghiasi</author>
            <journal_title>Proceedings of the 32nd international
conference on neural information processing systems</journal_title>
            <cYear>2018</cYear>
            <unstructured_citation>Ghiasi, G., Lin, T.-Y., &amp; Le, Q.
V. (2018). DropBlock: A regularization method for convolutional
networks. Proceedings of the 32nd International Conference on Neural
Information Processing Systems, 10750–10760.
https://dl.acm.org/doi/10.5555/3327546.3327732</unstructured_citation>
          </citation>
          <citation key="ioffe2015batch">
            <article_title>Batch normalization: Accelerating deep
network training by reducing internal covariate shift</article_title>
            <author>Ioffe</author>
            <journal_title>Proceedings of the 32nd international
conference on international conference on machine learning - volume
37</journal_title>
            <cYear>2015</cYear>
            <unstructured_citation>Ioffe, S., &amp; Szegedy, C. (2015).
Batch normalization: Accelerating deep network training by reducing
internal covariate shift. Proceedings of the 32nd International
Conference on International Conference on Machine Learning - Volume 37,
448–456.
https://dl.acm.org/doi/10.5555/3045118.3045167</unstructured_citation>
          </citation>
          <citation key="srivastava2014dropout">
            <article_title>Dropout: A simple way to prevent neural
networks from overfitting</article_title>
            <author>Srivastava</author>
            <journal_title>J. Mach. Learn. Res.</journal_title>
            <issue>1</issue>
            <volume>15</volume>
            <issn>1532-4435</issn>
            <cYear>2014</cYear>
            <unstructured_citation>Srivastava, N., Hinton, G.,
Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout:
A simple way to prevent neural networks from overfitting. J. Mach.
Learn. Res., 15(1), 1929–1958.
https://dl.acm.org/doi/10.5555/2627435.2670313</unstructured_citation>
          </citation>
          <citation key="reid2018new">
            <article_title>The new features of Fortran
2018</article_title>
            <author>Reid</author>
            <journal_title>SIGPLAN Fortran Forum</journal_title>
            <issue>1</issue>
            <volume>37</volume>
            <doi>10.1145/3206214.3206215</doi>
            <issn>1061-7264</issn>
            <cYear>2018</cYear>
            <unstructured_citation>Reid, J. (2018). The new features of
Fortran 2018. SIGPLAN Fortran Forum, 37(1), 5–43.
https://doi.org/10.1145/3206214.3206215</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
