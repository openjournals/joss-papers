<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8033</article-id>
<article-id pub-id-type="doi">10.21105/joss.08033</article-id>
<title-group>
<article-title>WunDeeDB.jl: An easy to use, zero config, WAL, SQLite
backend vector database</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0026-5725</contrib-id>
<name>
<surname>Mantzaris</surname>
<given-names>Alexander V.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Statistics and Data Science, University of
Central Florida (UCF), USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>10</volume>
<issue>110</issue>
<fpage>8033</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>ANN</kwd>
<kwd>Embeddings</kwd>
<kwd>Search</kwd>
<kwd>Vector DB</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>WunDeeDB.jl is a package written in Julia
  (<xref alt="Bezanson et al., 2017" rid="ref-julia" ref-type="bibr">Bezanson
  et al., 2017</xref>) that provides a disk-backed system for storing,
  searching, and managing embedding vectors at scale, influenced by
  disk-oriented graph-based ANN techniques
  (<xref alt="Jayaram Subramanya et al., 2019" rid="ref-jayaram2019diskann" ref-type="bibr">Jayaram
  Subramanya et al., 2019</xref>;
  <xref alt="Pan et al., 2023" rid="ref-pan2023lm" ref-type="bibr">Pan
  et al., 2023</xref>;
  <xref alt="Singh et al., 2021" rid="ref-singh2021freshdiskann" ref-type="bibr">Singh
  et al., 2021</xref>) and the broader insights from hierarchical
  small-world graphs
  (<xref alt="Malkov &amp; Yashunin, 2018" rid="ref-malkov2018efficient" ref-type="bibr">Malkov
  &amp; Yashunin, 2018</xref>;
  <xref alt="Wang et al., 2021" rid="ref-wang2021comprehensive" ref-type="bibr">Wang
  et al., 2021</xref>). By maintaining embeddings in an SQLite database
  and optionally using graph-based indices, WunDeeDB.jl minimizes
  in-memory overhead while supporting efficient similarity searches on
  commodity hardware. Its design also facilitates integration with
  common vector-database or ML pipelines that rely on embedding
  retrieval. The widely known DiskANN algorithm, has an open source code
  base
  (<xref alt="Simhadri et al., 2023" rid="ref-diskann-github" ref-type="bibr">Simhadri
  et al., 2023</xref>) and implements many of the core principles that
  underlines DiskANN development directions.</p>
  <p>In contrast to fully in-memory approaches, WunDeeDB.jl leverages
  disk-based storage and user-configurable adjacency (e.g., HNSW,
  LM-DiskANN, or fallback linear search), allowing large-scale data to
  be handled without saturating RAM. It supports incremental insertions
  and deletions, ensuring the index remains up-to-date as datasets
  evolve. By combining these disk-native strategies with tunable BFS
  expansions and adjacency pruning, WunDeeDB.jl enables robust nearest
  neighbor searches for high-dimensional embeddings.</p>
  <p>Features include:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>SQLite-backed embeddings</bold> with automatic
      consistency checks on dimension and data type.</p>
    </list-item>
    <list-item>
      <p><bold>Optional ANN indexing</bold> (HNSW, LM-DiskANN) or linear
      fallback, selectable at DB initialization.</p>
    </list-item>
    <list-item>
      <p><bold>Incremental insert/delete</bold> operations that update
      disk-based adjacency structures to keep pace with dataset
      changes.</p>
    </list-item>
    <list-item>
      <p><bold>Configurable BFS expansions</bold> (e.g.,
      <monospace>EF_SEARCH</monospace>,
      <monospace>EF_CONSTRUCTION</monospace>) to balance search speed
      vs. recall.</p>
    </list-item>
    <list-item>
      <p><bold>Choice of Precision</bold> the user can choose any of the
      standard base precisions to store the embeddings as.</p>
    </list-item>
  </list>
  <p>With these capabilities, <bold>WunDeeDB.jl</bold> offers a
  practical and scalable solution for disk-based embedding management,
  building on research showing the viability of disk-native approaches
  for large ANN indexes
  (<xref alt="Jayaram Subramanya et al., 2019" rid="ref-jayaram2019diskann" ref-type="bibr">Jayaram
  Subramanya et al., 2019</xref>;
  <xref alt="Pan et al., 2023" rid="ref-pan2023lm" ref-type="bibr">Pan
  et al., 2023</xref>;
  <xref alt="Singh et al., 2021" rid="ref-singh2021freshdiskann" ref-type="bibr">Singh
  et al., 2021</xref>). It is designed for minimal configuration,
  providing Write-Ahead Logging (WAL) and transactions.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Approximate Nearest Neighbor (ANN) search is a key element in
  recommendation systems, large-scale retrieval, and embedding-based
  machine learning
  (<xref alt="Wang et al., 2021" rid="ref-wang2021comprehensive" ref-type="bibr">Wang
  et al., 2021</xref>). Traditional in-memory approaches often face
  significant memory demands and slower scaling when dealing with more
  points than can fit in core memory. By persisting adjacency structures
  on disk rather than in RAM, WunDeeDB.jl tackles these
  bottlenecks—building on disk-based ANN research
  (<xref alt="Jayaram Subramanya et al., 2019" rid="ref-jayaram2019diskann" ref-type="bibr">Jayaram
  Subramanya et al., 2019</xref>;
  <xref alt="Pan et al., 2023" rid="ref-pan2023lm" ref-type="bibr">Pan
  et al., 2023</xref>;
  <xref alt="Singh et al., 2021" rid="ref-singh2021freshdiskann" ref-type="bibr">Singh
  et al., 2021</xref>) and provides:</p>
  <list list-type="order">
    <list-item>
      <p><bold>Reduced Memory Overhead</bold>: Only a fraction of data
      resides in memory, making it feasible to handle larger datasets on
      commodity hardware.
      </p>
    </list-item>
    <list-item>
      <p><bold>Dynamic Updates</bold>: Graph-based indexing supports
      insertions and deletions, allowing adaptation to evolving or
      streaming data.
      </p>
    </list-item>
    <list-item>
      <p><bold>High Recall</bold>: Adjusting BFS expansions and
      adjacency parameters yields near state-of-the-art accuracy in
      neighbor retrieval.
      </p>
    </list-item>
    <list-item>
      <p><bold>Scalable &amp; Simple Architecture</bold>: Built using
      Julia’s performance ecosystem, WunDeeDB.jl integrates disk
      operations with numeric libraries, and is straightforward to
      install.</p>
    </list-item>
  </list>
  <p>This approach benefits practitioners needing large-scale nearest
  neighbor indices without requiring specialized clusters or massive
  RAM. Within the Julia package ecosystem such an implementation is not
  currently provided. The closest package is introduced in Tellez &amp;
  Ruiz
  (<xref alt="2022" rid="ref-tellez2022similaritysearch" ref-type="bibr">2022</xref>),
  which provides essential ANN algorithms but they reside in memory and
  not disk, do not provide data protection through transactions or
  journaling such as WAL (Write Ahead Logging). For users that need
  these features along with ANN, this package provides them as well as
  being cross platform.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Thanks to the Julia community for their continued support of
  open-source scientific computing.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-pan2023lm">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pan</surname><given-names>Yu</given-names></name>
        <name><surname>Sun</surname><given-names>Jianxin</given-names></name>
        <name><surname>Yu</surname><given-names>Hongfeng</given-names></name>
      </person-group>
      <article-title>Lm-diskann: Low memory footprint in disk-native dynamic graph-based ann indexing</article-title>
      <source>2023 IEEE international conference on big data (BigData)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/BigData59044.2023.10386517</pub-id>
      <fpage>5987</fpage>
      <lpage>5996</lpage>
    </element-citation>
  </ref>
  <ref id="ref-singh2021freshdiskann">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Singh</surname><given-names>Aditi</given-names></name>
        <name><surname>Subramanya</surname><given-names>Suhas Jayaram</given-names></name>
        <name><surname>Krishnaswamy</surname><given-names>Ravishankar</given-names></name>
        <name><surname>Simhadri</surname><given-names>Harsha Vardhan</given-names></name>
      </person-group>
      <article-title>Freshdiskann: A fast and accurate graph-based ann index for streaming similarity search</article-title>
      <source>arXiv preprint arXiv:2105.09613</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2105.09613</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jayaram2019diskann">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jayaram Subramanya</surname><given-names>Suhas</given-names></name>
        <name><surname>Devvrit</surname><given-names>Fnu</given-names></name>
        <name><surname>Simhadri</surname><given-names>Harsha Vardhan</given-names></name>
        <name><surname>Krishnawamy</surname><given-names>Ravishankar</given-names></name>
        <name><surname>Kadekodi</surname><given-names>Rohan</given-names></name>
      </person-group>
      <article-title>Diskann: Fast accurate billion-point nearest neighbor search on a single node</article-title>
      <source>Advances in neural information processing Systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>32</volume>
      <pub-id pub-id-type="doi">10.1145/3543507.3583552</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-diskann-github">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Simhadri</surname><given-names>Harsha Vardhan</given-names></name>
        <name><surname>Krishnaswamy</surname><given-names>Ravishankar</given-names></name>
        <name><surname>Srinivasa</surname><given-names>Gopal</given-names></name>
        <name><surname>Subramanya</surname><given-names>Suhas Jayaram</given-names></name>
        <name><surname>Antonijevic</surname><given-names>Andrija</given-names></name>
        <name><surname>Pryce</surname><given-names>Dax</given-names></name>
        <name><surname>Kaczynski</surname><given-names>David</given-names></name>
        <name><surname>Williams</surname><given-names>Shane</given-names></name>
        <name><surname>Gollapudi</surname><given-names>Siddarth</given-names></name>
        <name><surname>Sivashankar</surname><given-names>Varun</given-names></name>
        <name><surname>Karia</surname><given-names>Neel</given-names></name>
        <name><surname>Singh</surname><given-names>Aditi</given-names></name>
        <name><surname>Jaiswal</surname><given-names>Shikhar</given-names></name>
        <name><surname>Mahapatro</surname><given-names>Neelam</given-names></name>
        <name><surname>Adams</surname><given-names>Philip</given-names></name>
        <name><surname>Tower</surname><given-names>Bryan</given-names></name>
        <name><surname>Patel</surname><given-names>Yash</given-names></name>
      </person-group>
      <article-title>DiskANN: Graph-structured indices for scalable, fast, fresh and filtered approximate nearest neighbor search</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/Microsoft/DiskANN</uri>
    </element-citation>
  </ref>
  <ref id="ref-wang2021comprehensive">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Mengzhao</given-names></name>
        <name><surname>Xu</surname><given-names>Xiaoliang</given-names></name>
        <name><surname>Yue</surname><given-names>Qiang</given-names></name>
        <name><surname>Wang</surname><given-names>Yuxiang</given-names></name>
      </person-group>
      <article-title>A comprehensive survey and experimental comparison of graph-based approximate nearest neighbor search</article-title>
      <source>arXiv preprint arXiv:2101.12631</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.14778/3476249.3476255</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-malkov2018efficient">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Malkov</surname><given-names>Yu A</given-names></name>
        <name><surname>Yashunin</surname><given-names>Dmitry A</given-names></name>
      </person-group>
      <article-title>Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</article-title>
      <source>IEEE transactions on pattern analysis and machine intelligence</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>42</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1109/TPAMI.2018.2889473</pub-id>
      <fpage>824</fpage>
      <lpage>836</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tellez2022similaritysearch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tellez</surname><given-names>Eric S</given-names></name>
        <name><surname>Ruiz</surname><given-names>Guillermo</given-names></name>
      </person-group>
      <article-title>Similaritysearch.jl: Autotuned nearest neighbor indexes for Julia</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2022">2022</year>
      <volume>7</volume>
      <issue>75</issue>
      <pub-id pub-id-type="doi">10.21105/joss.04442</pub-id>
      <fpage>4442</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-julia">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
      </person-group>
      <article-title>Julia: A fresh approach to numerical computing</article-title>
      <source>SIAM Review</source>
      <publisher-name>Society for Industrial &amp; Applied Mathematics (SIAM)</publisher-name>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <volume>59</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1137%2F141000671</uri>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
