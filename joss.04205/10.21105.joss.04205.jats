<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4205</article-id>
<article-id pub-id-type="doi">10.21105/joss.04205</article-id>
<title-group>
<article-title>swyft: Truncated Marginal Neural Ratio Estimation in
Python</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0387-8727</contrib-id>
<name>
<surname>Miller</surname>
<given-names>Benjamin Kurt</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8035-4308</contrib-id>
<name>
<surname>Cole</surname>
<given-names>Alex</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7579-8684</contrib-id>
<name>
<surname>Weniger</surname>
<given-names>Christoph</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3286-0139</contrib-id>
<name>
<surname>Nattino</surname>
<given-names>Francesco</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-5373-5209</contrib-id>
<name>
<surname>Ku</surname>
<given-names>Ou</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-5733-4795</contrib-id>
<name>
<surname>Grootes</surname>
<given-names>Meiert W.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Gravitation Astroparticle Physics Amsterdam (GRAPPA),
University of Amsterdam, Science Park 904, 1098 XH
Amsterdam</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Amsterdam Machine Learning Lab (AMLab), University of
Amsterdam, Science Park 904, 1098 XH Amsterdam</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>AI4Science Lab, University of Amsterdam, Science Park 904,
1098 XH Amsterdam</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Netherlands eScience Center, Science Park 140, 1098 XG
Amsterdam, The Netherlands</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-12-12">
<day>12</day>
<month>12</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>75</issue>
<fpage>4205</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>simulation-based inference</kwd>
<kwd>likelihood-free inference</kwd>
<kwd>machine learning</kwd>
<kwd>bayesian inference</kwd>
<kwd>system identification</kwd>
<kwd>parameter identification</kwd>
<kwd>inverse problem</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Parametric stochastic numerical simulators are ubiquitous in
  science. They model observed phenomena by mapping a parametric
  representation of simulation conditions to a hypothetical
  observation–effectively sampling from a probability distribution over
  observational data known as the likelihood. Simulators are
  advantageous because they easily encode relevant scientific knowledge.
  <italic>Simulation-based inference</italic> (SBI) is a machine
  learning technique which applies a simulator, a fitted statistical
  surrogate model, and a set of prior beliefs to estimate a
  probabilistic description of the parameters which plausibly generated
  some observational data. This description of parameters is known as
  the posterior and it is the end-product of Bayesian inference.</p>
  <p>Our package <monospace>swyft</monospace> implements a specific,
  simulation-efficient SBI method called <italic>Truncated Marginal
  Neural Ratio Estimation</italic> (TMNRE)
  (<xref alt="Miller et al., 2021" rid="ref-miller2021truncated" ref-type="bibr">Miller
  et al., 2021</xref>); it estimates the likelihood-to-evidence ratio to
  approximate the posterior, as in Hermans et al.
  (<xref alt="2020" rid="ref-Hermans2019" ref-type="bibr">2020</xref>).
  <monospace>swyft</monospace>
  (<xref alt="Miller et al., 2020" rid="ref-swyft" ref-type="bibr">Miller
  et al., 2020</xref>) provides a collection of tools to simulate and
  store data, locally or in a distributed computing setting, and perform
  (marginalized) simulation-based Bayesian inference. It produces
  ready-to-publish plots that demonstrate the calibration of the
  posterior estimate along with the posterior itself.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Estimating the posterior can be prohibitively expensive for complex
  data and slow simulators. Part of the reason is the sequential nature
  of likelihood-based Markov chain Monte-Carlo
  (<xref alt="Hastings, 1970" rid="ref-hastings" ref-type="bibr">Hastings,
  1970</xref>;
  <xref alt="Metropolis et al., 1953" rid="ref-metropolis" ref-type="bibr">Metropolis
  et al., 1953</xref>). In contrast, SBI parallelizes simulation in most
  circumstances, thereby reducing the practical waiting time for
  results. In pursuit of further simulation efficiency, Miller et al.
  (<xref alt="2021" rid="ref-miller2021truncated" ref-type="bibr">2021</xref>)
  argue that fitting the joint posterior for all parameters is
  unnecessary when a marginal estimate of the posterior will suffice.
  Some SBI methods are amortized, whereby the statistical model is fit
  to estimate posteriors for all possible observations simultaneously.
  While amortization enables necessary posterior calibration checks,
  like expected coverage probability
  (<xref alt="Hermans et al., 2021" rid="ref-hermans2021averting" ref-type="bibr">Hermans
  et al., 2021</xref>;
  <xref alt="Miller et al., 2021" rid="ref-miller2021truncated" ref-type="bibr">Miller
  et al., 2021</xref>), it is more efficient to fit the model on only a
  subset of the parameters that could have plausibly generated the
  observation.</p>
  <p><monospace>swyft</monospace> satisfies necessary requirements, like
  estimating the marginal posteriors of interest and enabling posterior
  calibration checks, while taking a lean approach to avoid all
  unnecessary simulation. In this pursuit, <monospace>swyft</monospace>
  truncates the prior to regions relevant for given observational data
  and reuses compatible existing simulations.
  <monospace>swyft</monospace> automates irksome matters like
  distributed computing and data storage with
  <monospace>dask</monospace>
  (<xref alt="Dask Development Team, 2016" rid="ref-dask" ref-type="bibr">Dask
  Development Team, 2016</xref>) and <monospace>zarr</monospace>
  (<xref alt="Miles et al., 2021" rid="ref-zarr" ref-type="bibr">Miles
  et al., 2021</xref>) respectively. <monospace>swyft</monospace> is
  designed to:</p>
  <list list-type="order">
    <list-item>
      <p>Estimate arbitrary marginal posteriors, i.e., the posterior
      over parameters of interest, marginalizing over nuisance
      parameters.</p>
    </list-item>
    <list-item>
      <p>Perform targeted inference by truncating the prior distribution
      with an indicator function estimated in a sequence of
      inferences.</p>
    </list-item>
    <list-item>
      <p>Estimate the expected coverage probability of fully amortized
      SBI posteriors and locally amortized posteriors that are limited
      to truncated regions.</p>
    </list-item>
    <list-item>
      <p>Seamlessly reuse simulations from previous analyses by drawing
      already-simulated data first via a flexible storage solution.</p>
    </list-item>
    <list-item>
      <p>Integrate advanced distribution and storage tools to simplify
      application of complex simulators.</p>
    </list-item>
  </list>
  <p>Although there is a rich ecosystem of SBI implementations, TMNRE
  did not naturally fit in an existing framework since it requires
  parallel estimation of marginal posteriors and a truncated prior.
  <monospace>swyft</monospace> does the parallel training of the ratio
  using another dimension in a PyTorch tensor and created a custom
  truncated prior data structure to overcome these challenges.
  <monospace>swyft</monospace> aims to meet the ever-increasing demand
  for efficient and testable Bayesian inference in fields like physics,
  cosmology, and astronomy by implementing TMNRE together with practical
  distributed computing and storage tools.</p>
  <sec id="existing-research-with-swyft">
    <title>Existing research with <monospace>swyft</monospace></title>
    <p>The software package has enabled inference on dark matter
    substructure in strongly lensed galaxies
    (<xref alt="Coogan et al., 2020" rid="ref-coogan2020targeted" ref-type="bibr">Coogan
    et al., 2020</xref>), estimated cosmological parameters from cosmic
    microwave background simulation data
    (<xref alt="Cole et al., 2021" rid="ref-cole2021fast" ref-type="bibr">Cole
    et al., 2021</xref>), and was cited in a white paper laying out a
    vision for astropartical physics research during the next decade
    (<xref alt="Batista et al., 2021" rid="ref-batista2021eucapt" ref-type="bibr">Batista
    et al., 2021</xref>). Ongoing work with <monospace>swyft</monospace>
    aims to reduce the response time to gravitational wave triggers from
    LIGO-Virgo by estimating the marginal posterior with unprecedented
    speed. There is an existing proof-of-concept by Delaunoy et al.
    (<xref alt="2020" rid="ref-delaunoy2020lightning" ref-type="bibr">2020</xref>)
    although the <monospace>swyft</monospace> software package was not
    applied. Generally, speeding up gravitational wave inference using
    simulation-based inference is an active area of research
    (<xref alt="Chua &amp; Vallisneri, 2020" rid="ref-chua2020learning" ref-type="bibr">Chua
    &amp; Vallisneri, 2020</xref>;
    <xref alt="Dax et al., 2021" rid="ref-dax2021real" ref-type="bibr">Dax
    et al., 2021</xref>;
    <xref alt="Gabbard et al., 2022" rid="ref-gabbard2022bayesian" ref-type="bibr">Gabbard
    et al., 2022</xref>). In another work-in-progress,
    <monospace>swyft</monospace> helps to characterize the
    magnetohydrodynamics of binary neutron star mergers using
    multi-messenger gravitational and electrodynamic data where
    marginalization would be impossible with likelihood-based
    methods.</p>
  </sec>
  <sec id="related-theoretical-work">
    <title>Related theoretical work</title>
    <p>There is a long tradition of likelihood-free inference, also
    known as <italic>Approximate Bayesian Computation</italic> (ABC),
    going back to as early as the 1980s
    (<xref alt="Beaumont et al., 2009" rid="ref-Beaumont2009-gl" ref-type="bibr">Beaumont
    et al., 2009</xref>;
    <xref alt="Diggle &amp; Gratton, 1984" rid="ref-diggle1984monte" ref-type="bibr">Diggle
    &amp; Gratton, 1984</xref>;
    <xref alt="Rubin, 1984" rid="ref-first_abc" ref-type="bibr">Rubin,
    1984</xref>;
    <xref alt="Tavaré et al., 1997" rid="ref-second_abc" ref-type="bibr">Tavaré
    et al., 1997</xref>;
    <xref alt="Toni et al., 2009" rid="ref-Toni2009-fd" ref-type="bibr">Toni
    et al., 2009</xref>). Traditional techniques use Monte-Carlo
    rejection sampling and are summarized by Sisson et al.
    (<xref alt="2018" rid="ref-sisson2018handbook" ref-type="bibr">2018</xref>)
    and Karabatsos &amp; Leisen
    (<xref alt="2018" rid="ref-karabatsos2018approximate" ref-type="bibr">2018</xref>).
    We track the development of classifiers for the estimation of
    likelihood ratios to a few references. Cranmer et al.
    (<xref alt="2015" rid="ref-Cranmer2015" ref-type="bibr">2015</xref>)
    compared the ratio between the likelihood of a freely varying
    parameter and a fixed reference value for frequentist inference.
    Pham et al.
    (<xref alt="2014" rid="ref-pham2014note" ref-type="bibr">2014</xref>)
    estimated the ratio between likelihoods for Markov chain Monte-Carlo
    sampling. Thomas et al.
    (<xref alt="2016" rid="ref-thomas2016likelihood" ref-type="bibr">2016</xref>)
    and Gutmann et al.
    (<xref alt="2018" rid="ref-gutmann2018likelihood" ref-type="bibr">2018</xref>)
    introduced the framework which allows for likelihood-to-evidence
    ratio estimation. Like <monospace>swyft</monospace>, Blum &amp;
    François
    (<xref alt="2010" rid="ref-blum2010non" ref-type="bibr">2010</xref>)
    proposed to truncate the prior for sampling but do so within an ABC
    scheme.</p>
    <p>Modern SBI is a quickly evolving field that has several
    techniques under development
    (<xref alt="Cranmer et al., 2020" rid="ref-Cranmer2020" ref-type="bibr">Cranmer
    et al., 2020</xref>). Neural network-based methods are categorized
    according to the term they approximate in Bayes’ formula.
    <monospace>swyft</monospace> is a method which approximates the
    likelihood-to-evidence ratio <inline-formula><alternatives>
    <tex-math><![CDATA[\frac{p(x \mid \theta)}{p(x)}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>∣</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>
    where <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>
    are the parameters and <inline-formula><alternatives>
    <tex-math><![CDATA[x]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
    is the observational data. Works by Hermans et al.
    (<xref alt="2020" rid="ref-Hermans2019" ref-type="bibr">2020</xref>),
    Durkan et al.
    (<xref alt="2020" rid="ref-Durkan2020" ref-type="bibr">2020</xref>),
    and Rozet &amp; Louppe
    (<xref alt="2021" rid="ref-rozet2021arbitrary" ref-type="bibr">2021</xref>)
    are closely related to <monospace>swyft</monospace> as they also
    approximate the likelihood-to-evidence ratio. Like
    <monospace>swyft</monospace>, Rozet &amp; Louppe
    (<xref alt="2021" rid="ref-rozet2021arbitrary" ref-type="bibr">2021</xref>)
    estimate marginal posteriors, but unlike swyft, they attempt to
    amortize over all possible marginals with a single neural network.
    Other methods estimate the posterior directly
    (<xref alt="Durkan et al., 2020" rid="ref-Durkan2020" ref-type="bibr">Durkan
    et al., 2020</xref>;
    <xref alt="Greenberg et al., 2019" rid="ref-greenberg2019automatic" ref-type="bibr">Greenberg
    et al., 2019</xref>;
    <xref alt="Lueckmann et al., 2017" rid="ref-lueckmann2017flexible" ref-type="bibr">Lueckmann
    et al., 2017</xref>;
    <xref alt="Papamakarios &amp; Murray, 2016" rid="ref-epsilon_free" ref-type="bibr">Papamakarios
    &amp; Murray, 2016</xref>) or the likelihood itself
    (<xref alt="Lueckmann et al., 2019" rid="ref-lueckmann2019likelihood" ref-type="bibr">Lueckmann
    et al., 2019</xref>;
    <xref alt="Papamakarios et al., 2019" rid="ref-papamakarios2019sequential" ref-type="bibr">Papamakarios
    et al., 2019</xref>).</p>
  </sec>
  <sec id="related-software">
    <title>Related software</title>
    <p><monospace>swyft</monospace> is unique because it implements
    TMNRE and a method for simulation reuse. It also offers
    sophisticated distributed simulation and storage tools coupled
    directly to the software. We briefly discuss the alternatives in the
    thriving ecosystem of SBI software packages.</p>
    <p><monospace>sbi</monospace>
    (<xref alt="Tejero-Cantero et al., 2020" rid="ref-sbi" ref-type="bibr">Tejero-Cantero
    et al., 2020</xref>) features a selection of modern neural SBI
    algorithms. It is accompanied by a benchmark
    <monospace>sbibm</monospace>
    (<xref alt="Lueckmann et al., 2021" rid="ref-sbibm" ref-type="bibr">Lueckmann
    et al., 2021</xref>) which tests those methods against a set of
    tractable toy problems. <monospace>pydelfi</monospace>
    (<xref alt="Alsing, 2019" rid="ref-pydelfi-repo" ref-type="bibr">Alsing,
    2019</xref>) estimates the likelihood of a learned summary statistic
    (<xref alt="Alsing et al., 2018" rid="ref-alsing2018massive" ref-type="bibr">Alsing
    et al., 2018</xref>,
    <xref alt="2019" rid="ref-alsing2019fast" ref-type="bibr">2019</xref>)–<monospace>swyft</monospace>
    users should pay special attention to this repository since it can
    also project out nuisance parameters
    (<xref alt="Alsing &amp; Wandelt, 2019" rid="ref-alsing2019nuisance" ref-type="bibr">Alsing
    &amp; Wandelt, 2019</xref>). <monospace>carl</monospace>
    (<xref alt="Louppe et al., 2016" rid="ref-louppe2016" ref-type="bibr">Louppe
    et al., 2016</xref>) uses a classifier to estimate the likelihood
    ratio as Cranmer et al.
    (<xref alt="2015" rid="ref-Cranmer2015" ref-type="bibr">2015</xref>)
    did and <monospace>hypothesis</monospace>
    (<xref alt="Hermans, 2019" rid="ref-hypothesis-repo" ref-type="bibr">Hermans,
    2019</xref>) includes several toy simulators.</p>
    <p>Non-neural implementations for SBI also exist.
    <monospace>elfi</monospace>
    (<xref alt="Lintusaari et al., 2018" rid="ref-elfi2018" ref-type="bibr">Lintusaari
    et al., 2018</xref>) implements BOLFI, an algorithm based on
    Gaussian processes
    (<xref alt="Gutmann et al., 2016" rid="ref-gutmann2016bayesian" ref-type="bibr">Gutmann
    et al., 2016</xref>). <monospace>pyabc</monospace>
    (<xref alt="Klinger et al., 2018" rid="ref-Klinger2018" ref-type="bibr">Klinger
    et al., 2018</xref>) and <monospace>ABCpy</monospace>
    (<xref alt="Dutta et al., 2017" rid="ref-dutta2017" ref-type="bibr">Dutta
    et al., 2017</xref>) are two suites of ABC algorithms.</p>
  </sec>
</sec>
<sec id="description-of-software">
  <title>Description of software</title>
  <p><monospace>swyft</monospace> implements <italic>Marginal Neural
  Ratio Estimation</italic> (MNRE), a method which trains an amortized
  likelihood-to-evidence ratio estimator for any marginal posterior of
  interest. <monospace>swyft</monospace> makes it easy to estimate a set
  of marginals in parallel, e.g., for a corner plot. To use
  <monospace>swyft</monospace>, the operator must provide a
  quantification of prior beliefs, a python-callable or bash-scriptable
  simulator, and an observation-of-interest.</p>
  <p>Performing TMNRE with <monospace>swyft</monospace>, by restricting
  simulation to a truncated prior region, is simple and demonstrated in
  the documentation. Constructing these truncated regions can be done
  manually or based on a previous inference. Routines are provided for
  all necessary plots and for calculating the expected coverage
  probability of a given likelihood-to-evidence ratio estimator. This
  calculation is essential as a sanity check to determine whether the
  approximate posterior is calibrated.</p>
  <p>The machine learning aspects of <monospace>swyft</monospace> are
  implemented in PyTorch
  (<xref alt="Paszke et al., 2019" rid="ref-pytorch" ref-type="bibr">Paszke
  et al., 2019</xref>) while the truncated prior is implemented within
  <monospace>numpy</monospace>
  (<xref alt="Harris et al., 2020" rid="ref-harris2020array" ref-type="bibr">Harris
  et al., 2020</xref>). Storing previously simulated data for reuse in
  later analyses is accomplished with <monospace>zarr</monospace>
  (<xref alt="Miles et al., 2021" rid="ref-zarr" ref-type="bibr">Miles
  et al., 2021</xref>) and parallelization of simulation is achieved
  with <monospace>dask</monospace>
  (<xref alt="Dask Development Team, 2016" rid="ref-dask" ref-type="bibr">Dask
  Development Team, 2016</xref>). <monospace>swyft</monospace> has other
  important dependencies, namely <monospace>scipy</monospace>
  (<xref alt="Virtanen et al., 2020" rid="ref-2020SciPy-NMeth" ref-type="bibr">Virtanen
  et al., 2020</xref>), <monospace>seaborn</monospace>
  (<xref alt="Waskom, 2021" rid="ref-Waskom2021" ref-type="bibr">Waskom,
  2021</xref>), <monospace>matplotlib</monospace>
  (<xref alt="Hunter, 2007" rid="ref-HunterU003A2007" ref-type="bibr">Hunter,
  2007</xref>), <monospace>pandas</monospace>
  (<xref alt="McKinney, 2010" rid="ref-mckinney-proc-scipy-2010" ref-type="bibr">McKinney,
  2010</xref>;
  <xref alt="Reback et al., 2021" rid="ref-reback2020pandas" ref-type="bibr">Reback
  et al., 2021</xref>), and <monospace>jupyter</monospace>
  (<xref alt="Kluyver et al., 2016" rid="ref-jupyter" ref-type="bibr">Kluyver
  et al., 2016</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The developers of <monospace>swyft</monospace> want to thank early
  adopters of the software Adam Coogan, Noemi Anau Montel, Kosio
  Karchev, Elias Dubbeldam, Uddipta Bhardwaj, and Ioannis Bousdoukos. We
  are grateful for the additional expertise offered by Patrick Forré and
  Samaya Nissanke.</p>
  <p>Benjamin Kurt Miller is funded by the University of Amsterdam
  Faculty of Science (FNWI), Informatics Institute (IvI), and the
  Institute of Physics (IoP). This project received funding from the
  European Research Council (ERC) under the European Union’s Horizon
  2020 research and innovation programme (Grant agreement No. 864035 –
  UnDark). This work was also supported by the Netherlands eScience
  Center and SURF under grant number ETEC.2019.018. This work was
  carried out on the Dutch national e-infrastructure with the support of
  SURF Cooperative. We also would like to thank SURF for providing
  computational resources via the EINF-1194 grant.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-pytorch">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems 32</source>
      <person-group person-group-type="editor">
        <name><surname>Wallach</surname><given-names>H.</given-names></name>
        <name><surname>Larochelle</surname><given-names>H.</given-names></name>
        <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
        <name><surname>Alché-Buc</surname><given-names>F. d</given-names></name>
        <name><surname>Fox</surname><given-names>E.</given-names></name>
        <name><surname>Garnett</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <uri>http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      <fpage>8024</fpage>
      <lpage>8035</lpage>
    </element-citation>
  </ref>
  <ref id="ref-harris2020array">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Walt</surname><given-names>St’efan J. van der</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Wieser</surname><given-names>Eric</given-names></name>
        <name><surname>Taylor</surname><given-names>Julian</given-names></name>
        <name><surname>Berg</surname><given-names>Sebastian</given-names></name>
        <name><surname>Smith</surname><given-names>Nathaniel J.</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Picus</surname><given-names>Matti</given-names></name>
        <name><surname>Hoyer</surname><given-names>Stephan</given-names></name>
        <name><surname>Kerkwijk</surname><given-names>Marten H. van</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Haldane</surname><given-names>Allan</given-names></name>
        <name><surname>R’ıo</surname><given-names>Jaime Fern’andez del</given-names></name>
        <name><surname>Wiebe</surname><given-names>Mark</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>G’erard-Marchant</surname><given-names>Pierre</given-names></name>
        <name><surname>Sheppard</surname><given-names>Kevin</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Abbasi</surname><given-names>Hameer</given-names></name>
        <name><surname>Gohlke</surname><given-names>Christoph</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2020-09">2020</year><month>09</month>
      <volume>585</volume>
      <issue>7825</issue>
      <uri>https://doi.org/10.1038/s41586-020-2649-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
  <ref id="ref-2020SciPy-NMeth">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
        <name><surname>Haberland</surname><given-names>Matt</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Burovski</surname><given-names>Evgeni</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Bright</surname><given-names>Jonathan</given-names></name>
        <name><surname>van der Walt</surname><given-names>Stéfan J.</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Wilson</surname><given-names>Joshua</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Mayorov</surname><given-names>Nikolay</given-names></name>
        <name><surname>Nelson</surname><given-names>Andrew R. J.</given-names></name>
        <name><surname>Jones</surname><given-names>Eric</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Larson</surname><given-names>Eric</given-names></name>
        <name><surname>Carey</surname><given-names>C J</given-names></name>
        <name><surname>Polat</surname><given-names>İlhan</given-names></name>
        <name><surname>Feng</surname><given-names>Yu</given-names></name>
        <name><surname>Moore</surname><given-names>Eric W.</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Laxalde</surname><given-names>Denis</given-names></name>
        <name><surname>Perktold</surname><given-names>Josef</given-names></name>
        <name><surname>Cimrman</surname><given-names>Robert</given-names></name>
        <name><surname>Henriksen</surname><given-names>Ian</given-names></name>
        <name><surname>Quintero</surname><given-names>E. A.</given-names></name>
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Archibald</surname><given-names>Anne M.</given-names></name>
        <name><surname>Ribeiro</surname><given-names>Antônio H.</given-names></name>
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>van Mulbregt</surname><given-names>Paul</given-names></name>
        <string-name>SciPy 1.0 Contributors</string-name>
      </person-group>
      <article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2020">2020</year>
      <volume>17</volume>
      <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>
      <fpage>261</fpage>
      <lpage>272</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Waskom2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Waskom</surname><given-names>Michael L.</given-names></name>
      </person-group>
      <article-title>Seaborn: Statistical data visualization</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>60</issue>
      <uri>https://doi.org/10.21105/joss.03021</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03021</pub-id>
      <fpage>3021</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-HunterU003A2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hunter</surname><given-names>J. D.</given-names></name>
      </person-group>
      <article-title>Matplotlib: A 2D graphics environment</article-title>
      <source>Computing in Science &amp; Engineering</source>
      <publisher-name>IEEE COMPUTER SOC</publisher-name>
      <year iso-8601-date="2007">2007</year>
      <volume>9</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
      <fpage>90</fpage>
      <lpage>95</lpage>
    </element-citation>
  </ref>
  <ref id="ref-jupyter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Kluyver</surname><given-names>Thomas</given-names></name>
        <name><surname>Ragan-Kelley</surname><given-names>Benjamin</given-names></name>
        <name><surname>Pérez</surname><given-names>Fernando</given-names></name>
        <name><surname>Granger</surname><given-names>Brian</given-names></name>
        <name><surname>Bussonnier</surname><given-names>Matthias</given-names></name>
        <name><surname>Frederic</surname><given-names>Jonathan</given-names></name>
        <name><surname>Kelley</surname><given-names>Kyle</given-names></name>
        <name><surname>Hamrick</surname><given-names>Jessica</given-names></name>
        <name><surname>Grout</surname><given-names>Jason</given-names></name>
        <name><surname>Corlay</surname><given-names>Sylvain</given-names></name>
        <name><surname>Ivanov</surname><given-names>Paul</given-names></name>
        <name><surname>Avila</surname><given-names>Damián</given-names></name>
        <name><surname>Abdalla</surname><given-names>Safia</given-names></name>
        <name><surname>Willing</surname><given-names>Carol</given-names></name>
        <name><surname>team</surname><given-names>Jupyter development</given-names></name>
      </person-group>
      <article-title>Jupyter notebooks - a publishing format for reproducible computational workflows</article-title>
      <source>Positioning and power in academic publishing: Players, agents and agendas</source>
      <person-group person-group-type="editor">
        <name><surname>Loizides</surname><given-names>Fernando</given-names></name>
        <name><surname>Scmidt</surname><given-names>Birgit</given-names></name>
      </person-group>
      <publisher-name>IOS Press</publisher-name>
      <publisher-loc>Netherlands</publisher-loc>
      <year iso-8601-date="2016">2016</year>
      <uri>https://eprints.soton.ac.uk/403913/</uri>
      <fpage>87</fpage>
      <lpage>90</lpage>
    </element-citation>
  </ref>
  <ref id="ref-reback2020pandas">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Reback</surname><given-names>Jeff</given-names></name>
        <name><surname>jbrockmendel</surname></name>
        <name><surname>McKinney</surname><given-names>Wes</given-names></name>
        <name><surname>Bossche</surname><given-names>Joris Van den</given-names></name>
        <name><surname>Augspurger</surname><given-names>Tom</given-names></name>
        <name><surname>Cloud</surname><given-names>Phillip</given-names></name>
        <name><surname>Hawkins</surname><given-names>Simon</given-names></name>
        <name><surname>Roeschke</surname><given-names>Matthew</given-names></name>
        <name><surname>gfyoung</surname></name>
        <name><surname>Sinhrks</surname></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Pandas-dev/pandas</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2021-12">2021</year><month>12</month>
      <pub-id pub-id-type="doi">10.5281/zenodo.3509134</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-mckinney-proc-scipy-2010">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>McKinney</surname></name>
      </person-group>
      <article-title>Data Structures for Statistical Computing in Python</article-title>
      <source>Proceedings of the 9th Python in Science Conference</source>
      <person-group person-group-type="editor">
        <name><surname>Walt</surname></name>
        <name><surname>Millman</surname></name>
      </person-group>
      <year iso-8601-date="2010">2010</year>
      <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id>
      <fpage>56 </fpage>
      <lpage> 61</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dask">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>Dask Development Team</string-name>
      </person-group>
      <source>Dask: Library for dynamic task scheduling</source>
      <year iso-8601-date="2016">2016</year>
      <uri>https://dask.org</uri>
    </element-citation>
  </ref>
  <ref id="ref-zarr">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miles</surname><given-names>Alistair</given-names></name>
        <name><surname>jakirkham</surname></name>
        <name><surname>Bussonnier</surname><given-names>Matthias</given-names></name>
        <name><surname>Moore</surname><given-names>Josh</given-names></name>
        <name><surname>Fulton</surname><given-names>Andrew</given-names></name>
        <name><surname>Bourbeau</surname><given-names>James</given-names></name>
        <name><surname>Onalan</surname><given-names>Tarik</given-names></name>
        <name><surname>Hamman</surname><given-names>Joe</given-names></name>
        <name><surname>Patel</surname><given-names>Zain</given-names></name>
        <name><surname>Rocklin</surname><given-names>Matthew</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Zarr-developers/zarr-python:</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <pub-id pub-id-type="doi">10.5281/zenodo.5712786</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-miller2021truncated">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miller</surname><given-names>Benjamin Kurt</given-names></name>
        <name><surname>Cole</surname><given-names>Alex</given-names></name>
        <name><surname>Forré</surname><given-names>Patrick</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
        <name><surname>Weniger</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Truncated marginal neural ratio estimation</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2021">2021</year>
      <volume>34</volume>
    </element-citation>
  </ref>
  <ref id="ref-swyft">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miller</surname><given-names>Benjamin Kurt</given-names></name>
        <name><surname>Cole</surname><given-names>Alex</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
        <name><surname>Weniger</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Simulation-efficient marginal posterior estimation with swyft: Stop wasting your precious time</article-title>
      <source>Machine Learning and the Physical Sciences: Workshop at the 34th Conference on Neural Information Processing Systems (NeurIPS)</source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-batista2021eucapt">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Batista</surname><given-names>R Alves</given-names></name>
        <name><surname>Amin</surname><given-names>MA</given-names></name>
        <name><surname>Barenboim</surname><given-names>G</given-names></name>
        <name><surname>Bartolo</surname><given-names>N</given-names></name>
        <name><surname>Baumann</surname><given-names>D</given-names></name>
        <name><surname>Bauswein</surname><given-names>A</given-names></name>
        <name><surname>Bellini</surname><given-names>E</given-names></name>
        <name><surname>Benisty</surname><given-names>D</given-names></name>
        <name><surname>Bertone</surname><given-names>G</given-names></name>
        <name><surname>Blasi</surname><given-names>P</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>EuCAPT white paper: Opportunities and challenges for theoretical astroparticle physics in the next decade</article-title>
      <source>arXiv preprint arXiv:2110.10074</source>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-coogan2020targeted">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Coogan</surname><given-names>Adam</given-names></name>
        <name><surname>Karchev</surname><given-names>Konstantin</given-names></name>
        <name><surname>Weniger</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Targeted likelihood-free inference of dark matter substructure in strongly-lensed galaxies</article-title>
      <source>Machine Learning and the Physical Sciences: Workshop at the 34th Conference on Neural Information Processing Systems (NeurIPS)</source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-cole2021fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cole</surname><given-names>Alex</given-names></name>
        <name><surname>Miller</surname><given-names>Benjamin Kurt</given-names></name>
        <name><surname>Witte</surname><given-names>Samuel J</given-names></name>
        <name><surname>Cai</surname><given-names>Maxwell X</given-names></name>
        <name><surname>Grootes</surname><given-names>Meiert W</given-names></name>
        <name><surname>Nattino</surname><given-names>Francesco</given-names></name>
        <name><surname>Weniger</surname><given-names>Christoph</given-names></name>
      </person-group>
      <article-title>Fast and credible likelihood-free cosmology with truncated marginal neural ratio estimation</article-title>
      <source>arXiv preprint arXiv:2111.08030</source>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-sbibm">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Boelts</surname><given-names>Jan</given-names></name>
        <name><surname>Greenberg</surname><given-names>David</given-names></name>
        <name><surname>Goncalves</surname><given-names>Pedro</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob</given-names></name>
      </person-group>
      <article-title>Benchmarking simulation-based inference</article-title>
      <source>Proceedings of the 24th international conference on artificial intelligence and statistics</source>
      <person-group person-group-type="editor">
        <name><surname>Banerjee</surname><given-names>Arindam</given-names></name>
        <name><surname>Fukumizu</surname><given-names>Kenji</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>130</volume>
      <uri>http://proceedings.mlr.press/v130/lueckmann21a.html</uri>
      <fpage>343</fpage>
      <lpage>351</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hermans2021averting">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hermans</surname><given-names>Joeri</given-names></name>
        <name><surname>Delaunoy</surname><given-names>Arnaud</given-names></name>
        <name><surname>Rozet</surname><given-names>François</given-names></name>
        <name><surname>Wehenkel</surname><given-names>Antoine</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Averting a crisis in simulation-based inference</article-title>
      <source>arXiv preprint arXiv:2110.06581</source>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-Cranmer2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cranmer</surname><given-names>Kyle</given-names></name>
        <name><surname>Brehmer</surname><given-names>Johann</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>The frontier of simulation-based inference</article-title>
      <source>Proc. Natl. Acad. Sci. U. S. A.</source>
      <year iso-8601-date="2020-05">2020</year><month>05</month>
    </element-citation>
  </ref>
  <ref id="ref-sbi">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tejero-Cantero</surname><given-names>Alvaro</given-names></name>
        <name><surname>Boelts</surname><given-names>Jan</given-names></name>
        <name><surname>Deistler</surname><given-names>Michael</given-names></name>
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Durkan</surname><given-names>Conor</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J.</given-names></name>
        <name><surname>Greenberg</surname><given-names>David S.</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H.</given-names></name>
      </person-group>
      <article-title>Sbi: A toolkit for simulation-based inference</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>52</issue>
      <uri>https://doi.org/10.21105/joss.02505</uri>
      <pub-id pub-id-type="doi">10.21105/joss.02505</pub-id>
      <fpage>2505</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-elfi2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lintusaari</surname><given-names>Jarno</given-names></name>
        <name><surname>Vuollekoski</surname><given-names>Henri</given-names></name>
        <name><surname>Kangasrääsiö</surname><given-names>Antti</given-names></name>
        <name><surname>Skytén</surname><given-names>Kusti</given-names></name>
        <name><surname>Järvenpää</surname><given-names>Marko</given-names></name>
        <name><surname>Marttinen</surname><given-names>Pekka</given-names></name>
        <name><surname>Gutmann</surname><given-names>Michael U</given-names></name>
        <name><surname>Vehtari</surname><given-names>Aki</given-names></name>
        <name><surname>Corander</surname><given-names>Jukka</given-names></name>
        <name><surname>Kaski</surname><given-names>Samuel</given-names></name>
      </person-group>
      <article-title>ELFI: Engine for likelihood-free inference</article-title>
      <source>The Journal of Machine Learning Research</source>
      <publisher-name>JMLR</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>19</volume>
      <issue>1</issue>
      <fpage>643</fpage>
      <lpage>649</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hypothesis-repo">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Hermans</surname><given-names>Joeri</given-names></name>
      </person-group>
      <article-title>Hypothesis</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/montefiore-ai/hypothesis; GitHub</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-pydelfi-repo">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Alsing</surname><given-names>Justin</given-names></name>
      </person-group>
      <article-title>pydelfi: Density estimation likelihood-free inference</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/justinalsing/pydelfi; GitHub</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-louppe2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
        <name><surname>Cranmer</surname><given-names>Kyle</given-names></name>
        <name><surname>Pavez</surname><given-names>Juan</given-names></name>
      </person-group>
      <article-title>carl: A likelihood-free inference toolbox</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>1</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.21105/joss.00011</pub-id>
      <fpage>11</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Klinger2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Klinger</surname><given-names>Emmanuel</given-names></name>
        <name><surname>Rickert</surname><given-names>Dennis</given-names></name>
        <name><surname>Hasenauer</surname><given-names>Jan</given-names></name>
      </person-group>
      <article-title>pyABC: Distributed, likelihood-free inference</article-title>
      <source>Bioinformatics</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>34</volume>
      <issue>20</issue>
      <pub-id pub-id-type="doi">10.1093/bioinformatics/bty361</pub-id>
      <fpage>3591</fpage>
      <lpage>3593</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dutta2017">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dutta</surname><given-names>Ritabrata</given-names></name>
        <name><surname>Schoengens</surname><given-names>Marcel</given-names></name>
        <name><surname>Onnela</surname><given-names>Jukka-Pekka</given-names></name>
        <name><surname>Mira</surname><given-names>Antonietta</given-names></name>
      </person-group>
      <article-title>ABCpy: A user-friendly, extensible, and parallel library for approximate bayesian computation</article-title>
      <source>Proceedings of the platform for advanced scientific computing conference</source>
      <year iso-8601-date="2017">2017</year>
      <uri>http://doi.acm.org/10.1145/3093172.3093233</uri>
      <pub-id pub-id-type="doi">10.1145/3093172.3093233</pub-id>
      <fpage>8:1</fpage>
      <lpage>8:9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-greenberg2019automatic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Greenberg</surname><given-names>David</given-names></name>
        <name><surname>Nonnenmacher</surname><given-names>Marcel</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob</given-names></name>
      </person-group>
      <article-title>Automatic posterior transformation for likelihood-free inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <fpage>2404</fpage>
      <lpage>2414</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rozet2021arbitrary">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rozet</surname><given-names>François</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Arbitrary marginal neural ratio estimation for simulation-based inference</article-title>
      <source>Machine Learning and the Physical Sciences: Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS)</source>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-Hermans2019">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hermans</surname><given-names>Joeri</given-names></name>
        <name><surname>Begy</surname><given-names>Volodimir</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Likelihood-free mcmc with amortized approximate ratio estimators</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <fpage>4239</fpage>
      <lpage>4248</lpage>
    </element-citation>
  </ref>
  <ref id="ref-papamakarios2019sequential">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Sterratt</surname><given-names>David</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows</article-title>
      <source>The 22nd international conference on artificial intelligence and statistics</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <fpage>837</fpage>
      <lpage>848</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Durkan2020">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Durkan</surname><given-names>Conor</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
      </person-group>
      <article-title>On contrastive learning for likelihood-free inference</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <fpage>2771</fpage>
      <lpage>2781</lpage>
    </element-citation>
  </ref>
  <ref id="ref-epsilon_free">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Papamakarios</surname><given-names>George</given-names></name>
        <name><surname>Murray</surname><given-names>Iain</given-names></name>
      </person-group>
      <article-title>Fast \epsilon-free inference of simulation models with bayesian conditional density estimation</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Lee</surname><given-names>D.</given-names></name>
        <name><surname>Sugiyama</surname><given-names>M.</given-names></name>
        <name><surname>Luxburg</surname><given-names>U.</given-names></name>
        <name><surname>Guyon</surname><given-names>I.</given-names></name>
        <name><surname>Garnett</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>29</volume>
      <uri>https://proceedings.neurips.cc/paper/2016/file/6aca97005c68f1206823815f66102863-Paper.pdf</uri>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-lueckmann2017flexible">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Gonçalves</surname><given-names>Pedro J</given-names></name>
        <name><surname>Bassetto</surname><given-names>Giacomo</given-names></name>
        <name><surname>Öcal</surname><given-names>Kaan</given-names></name>
        <name><surname>Nonnenmacher</surname><given-names>Marcel</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H</given-names></name>
      </person-group>
      <article-title>Flexible statistical inference for mechanistic models of neural dynamics</article-title>
      <source>Proceedings of the 31st international conference on neural information processing systems</source>
      <year iso-8601-date="2017">2017</year>
      <fpage>1289</fpage>
      <lpage>1299</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lueckmann2019likelihood">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lueckmann</surname><given-names>Jan-Matthis</given-names></name>
        <name><surname>Bassetto</surname><given-names>Giacomo</given-names></name>
        <name><surname>Karaletsos</surname><given-names>Theofanis</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H</given-names></name>
      </person-group>
      <article-title>Likelihood-free inference with emulator networks</article-title>
      <source>Symposium on advances in approximate bayesian inference</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <fpage>32</fpage>
      <lpage>53</lpage>
    </element-citation>
  </ref>
  <ref id="ref-alsing2019fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alsing</surname><given-names>Justin</given-names></name>
        <name><surname>Charnock</surname><given-names>Tom</given-names></name>
        <name><surname>Feeney</surname><given-names>Stephen</given-names></name>
        <name><surname>Wandelt</surname><given-names>Benjamin</given-names></name>
      </person-group>
      <article-title>Fast likelihood-free cosmology with neural density estimators and active learning</article-title>
      <source>Monthly Notices of the Royal Astronomical Society</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>488</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1093/mnras/stz1960</pub-id>
      <fpage>4440</fpage>
      <lpage>4458</lpage>
    </element-citation>
  </ref>
  <ref id="ref-alsing2018massive">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alsing</surname><given-names>Justin</given-names></name>
        <name><surname>Wandelt</surname><given-names>Benjamin</given-names></name>
        <name><surname>Feeney</surname><given-names>Stephen</given-names></name>
      </person-group>
      <article-title>Massive optimal data compression and density estimation for scalable, likelihood-free inference in cosmology</article-title>
      <source>Monthly Notices of the Royal Astronomical Society</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>477</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1093/mnras/sty819</pub-id>
      <fpage>2874</fpage>
      <lpage>2885</lpage>
    </element-citation>
  </ref>
  <ref id="ref-alsing2019nuisance">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alsing</surname><given-names>Justin</given-names></name>
        <name><surname>Wandelt</surname><given-names>Benjamin</given-names></name>
      </person-group>
      <article-title>Nuisance hardened data compression for fast likelihood-free inference</article-title>
      <source>Monthly Notices of the Royal Astronomical Society</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>488</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1093/mnras/stz1900</pub-id>
      <fpage>5093</fpage>
      <lpage>5103</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gutmann2016bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gutmann</surname><given-names>Michael U</given-names></name>
        <name><surname>Corander</surname><given-names>Jukka</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Bayesian optimization for likelihood-free inference of simulator-based statistical models</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2016">2016</year>
    </element-citation>
  </ref>
  <ref id="ref-pham2014note">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pham</surname><given-names>Kim Cuc</given-names></name>
        <name><surname>Nott</surname><given-names>David J</given-names></name>
        <name><surname>Chaudhuri</surname><given-names>Sanjay</given-names></name>
      </person-group>
      <article-title>A note on approximating ABC-MCMC using flexible classifiers</article-title>
      <source>Stat</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>3</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1002/sta4.56</pub-id>
      <fpage>218</fpage>
      <lpage>227</lpage>
    </element-citation>
  </ref>
  <ref id="ref-thomas2016likelihood">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Thomas</surname><given-names>Owen</given-names></name>
        <name><surname>Dutta</surname><given-names>Ritabrata</given-names></name>
        <name><surname>Corander</surname><given-names>Jukka</given-names></name>
        <name><surname>Kaski</surname><given-names>Samuel</given-names></name>
        <name><surname>Gutmann</surname><given-names>Michael U</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Likelihood-free inference by ratio estimation</article-title>
      <source>Bayesian Analysis</source>
      <publisher-name>International Society for Bayesian Analysis</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <pub-id pub-id-type="doi">10.1214/20-ba1238</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gutmann2018likelihood">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gutmann</surname><given-names>Michael U</given-names></name>
        <name><surname>Dutta</surname><given-names>Ritabrata</given-names></name>
        <name><surname>Kaski</surname><given-names>Samuel</given-names></name>
        <name><surname>Corander</surname><given-names>Jukka</given-names></name>
      </person-group>
      <article-title>Likelihood-free inference via classification</article-title>
      <source>Statistics and Computing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>28</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1007/s11222-017-9738-6</pub-id>
      <fpage>411</fpage>
      <lpage>425</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Cranmer2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cranmer</surname><given-names>Kyle</given-names></name>
        <name><surname>Pavez</surname><given-names>Juan</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Approximating likelihood ratios with calibrated discriminative classifiers</article-title>
      <source>arXiv preprint arXiv:1506.02169</source>
      <year iso-8601-date="2015">2015</year>
    </element-citation>
  </ref>
  <ref id="ref-sisson2018handbook">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Sisson</surname><given-names>Scott A</given-names></name>
        <name><surname>Fan</surname><given-names>Yanan</given-names></name>
        <name><surname>Beaumont</surname><given-names>Mark</given-names></name>
      </person-group>
      <source>Handbook of approximate bayesian computation</source>
      <publisher-name>CRC Press</publisher-name>
      <year iso-8601-date="2018">2018</year>
    </element-citation>
  </ref>
  <ref id="ref-karabatsos2018approximate">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Karabatsos</surname><given-names>George</given-names></name>
        <name><surname>Leisen</surname><given-names>Fabrizio</given-names></name>
      </person-group>
      <article-title>An approximate likelihood perspective on ABC methods</article-title>
      <source>Statistics Surveys</source>
      <publisher-name>Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist.,; the …</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>12</volume>
      <pub-id pub-id-type="doi">10.1214/18-ss120</pub-id>
      <fpage>66</fpage>
      <lpage>104</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Toni2009-fd">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Toni</surname><given-names>Tina</given-names></name>
        <name><surname>Welch</surname><given-names>David</given-names></name>
        <name><surname>Strelkowa</surname><given-names>Natalja</given-names></name>
        <name><surname>Ipsen</surname><given-names>Andreas</given-names></name>
        <name><surname>Stumpf</surname><given-names>Michael P H</given-names></name>
      </person-group>
      <article-title>Approximate bayesian computation scheme for parameter inference and model selection in dynamical systems</article-title>
      <source>J. R. Soc. Interface</source>
      <year iso-8601-date="2009-02">2009</year><month>02</month>
      <volume>6</volume>
      <issue>31</issue>
      <pub-id pub-id-type="doi">10.1098/rsif.2008.0172</pub-id>
      <fpage>187</fpage>
      <lpage>202</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Beaumont2009-gl">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Beaumont</surname><given-names>Mark A</given-names></name>
        <name><surname>Cornuet</surname><given-names>Jean-Marie</given-names></name>
        <name><surname>Marin</surname><given-names>Jean-Michel</given-names></name>
        <name><surname>Robert</surname><given-names>Christian P</given-names></name>
      </person-group>
      <article-title>Adaptive approximate bayesian computation</article-title>
      <source>Biometrika</source>
      <publisher-name>[Oxford University Press, Biometrika Trust]</publisher-name>
      <year iso-8601-date="2009">2009</year>
      <volume>96</volume>
      <issue>4</issue>
      <fpage>983</fpage>
      <lpage>990</lpage>
    </element-citation>
  </ref>
  <ref id="ref-diggle1984monte">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Diggle</surname><given-names>Peter J</given-names></name>
        <name><surname>Gratton</surname><given-names>Richard J</given-names></name>
      </person-group>
      <article-title>Monte carlo methods of inference for implicit statistical models</article-title>
      <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="1984">1984</year>
      <volume>46</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1111/j.2517-6161.1984.tb01290.x</pub-id>
      <fpage>193</fpage>
      <lpage>212</lpage>
    </element-citation>
  </ref>
  <ref id="ref-first_abc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rubin</surname><given-names>Donald B.</given-names></name>
      </person-group>
      <article-title>Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician</article-title>
      <source>The Annals of Statistics</source>
      <publisher-name>Institute of Mathematical Statistics</publisher-name>
      <year iso-8601-date="1984">1984</year>
      <volume>12</volume>
      <issue>4</issue>
      <uri>https://doi.org/10.1214/aos/1176346785</uri>
      <pub-id pub-id-type="doi">10.1214/aos/1176346785</pub-id>
      <fpage>1151 </fpage>
      <lpage> 1172</lpage>
    </element-citation>
  </ref>
  <ref id="ref-second_abc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tavaré</surname><given-names>Simon</given-names></name>
        <name><surname>Balding</surname><given-names>David J</given-names></name>
        <name><surname>Griffiths</surname><given-names>R C</given-names></name>
        <name><surname>Donnelly</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>Inferring Coalescence Times From DNA Sequence Data</article-title>
      <source>Genetics</source>
      <year iso-8601-date="1997-02">1997</year><month>02</month>
      <volume>145</volume>
      <issue>2</issue>
      <issn>1943-2631</issn>
      <uri>https://doi.org/10.1093/genetics/145.2.505</uri>
      <pub-id pub-id-type="doi">10.1093/genetics/145.2.505</pub-id>
      <fpage>505</fpage>
      <lpage>518</lpage>
    </element-citation>
  </ref>
  <ref id="ref-blum2010non">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blum</surname><given-names>Michael GB</given-names></name>
        <name><surname>François</surname><given-names>Olivier</given-names></name>
      </person-group>
      <article-title>Non-linear regression models for approximate bayesian computation</article-title>
      <source>Statistics and computing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>20</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1007/s11222-009-9116-0</pub-id>
      <fpage>63</fpage>
      <lpage>73</lpage>
    </element-citation>
  </ref>
  <ref id="ref-metropolis">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Metropolis</surname><given-names>Nicholas</given-names></name>
        <name><surname>Rosenbluth</surname><given-names>Arianna W</given-names></name>
        <name><surname>Rosenbluth</surname><given-names>Marshall N</given-names></name>
        <name><surname>Teller</surname><given-names>Augusta H</given-names></name>
        <name><surname>Teller</surname><given-names>Edward</given-names></name>
      </person-group>
      <article-title>Equation of state calculations by fast computing machines</article-title>
      <source>J. Chem. Phys.</source>
      <publisher-name>American Institute of Physics</publisher-name>
      <year iso-8601-date="1953-06">1953</year><month>06</month>
      <volume>21</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.2172/4390578</pub-id>
      <fpage>1087</fpage>
      <lpage>1092</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hastings">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hastings</surname><given-names>W K</given-names></name>
      </person-group>
      <article-title>Monte carlo sampling methods using markov chains and their applications</article-title>
      <source>Biometrika</source>
      <publisher-name>Oxford Academic</publisher-name>
      <year iso-8601-date="1970-04">1970</year><month>04</month>
      <volume>57</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1093/biomet/57.1.97</pub-id>
      <fpage>97</fpage>
      <lpage>109</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gabbard2022bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gabbard</surname><given-names>Hunter</given-names></name>
        <name><surname>Messenger</surname><given-names>Chris</given-names></name>
        <name><surname>Heng</surname><given-names>Ik Siong</given-names></name>
        <name><surname>Tonolini</surname><given-names>Francesco</given-names></name>
        <name><surname>Murray-Smith</surname><given-names>Roderick</given-names></name>
      </person-group>
      <article-title>Bayesian parameter estimation using conditional variational autoencoders for gravitational-wave astronomy</article-title>
      <source>Nature Physics</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>18</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1038/s41567-021-01425-7</pub-id>
      <fpage>112</fpage>
      <lpage>117</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dax2021real">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dax</surname><given-names>Maximilian</given-names></name>
        <name><surname>Green</surname><given-names>Stephen R</given-names></name>
        <name><surname>Gair</surname><given-names>Jonathan</given-names></name>
        <name><surname>Macke</surname><given-names>Jakob H</given-names></name>
        <name><surname>Buonanno</surname><given-names>Alessandra</given-names></name>
        <name><surname>Schölkopf</surname><given-names>Bernhard</given-names></name>
      </person-group>
      <article-title>Real-time gravitational wave science with neural posterior estimation</article-title>
      <source>Physical review letters</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>127</volume>
      <issue>24</issue>
      <pub-id pub-id-type="doi">10.1103/PhysRevLett.127.241103</pub-id>
      <fpage>241103</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-chua2020learning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chua</surname><given-names>Alvin JK</given-names></name>
        <name><surname>Vallisneri</surname><given-names>Michele</given-names></name>
      </person-group>
      <article-title>Learning bayesian posteriors with neural networks for gravitational-wave inference</article-title>
      <source>Physical review letters</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>124</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1103/PhysRevLett.124.041102</pub-id>
      <fpage>041102</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-delaunoy2020lightning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Delaunoy</surname><given-names>Arnaud</given-names></name>
        <name><surname>Wehenkel</surname><given-names>Antoine</given-names></name>
        <name><surname>Hinderer</surname><given-names>Tanja</given-names></name>
        <name><surname>Nissanke</surname><given-names>Samaya</given-names></name>
        <name><surname>Weniger</surname><given-names>Christoph</given-names></name>
        <name><surname>Williamson</surname><given-names>Andrew R</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
      </person-group>
      <article-title>Lightning-fast gravitational wave parameter inference through neural amortization</article-title>
      <source>Machine Learning and the Physical Sciences: Workshop at the 34th Conference on Neural Information Processing Systems (NeurIPS)</source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
