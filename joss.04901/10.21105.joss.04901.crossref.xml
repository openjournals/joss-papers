<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20230220T080628-5fc91adb1a22a53b81424c1a892e50c3cfdf93cc</doi_batch_id>
    <timestamp>20230220080628</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>02</month>
          <year>2023</year>
        </publication_date>
        <journal_volume>
          <volume>8</volume>
        </journal_volume>
        <issue>82</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>BlenderProc2: A Procedural Pipeline for Photorealistic
Rendering</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Maximilian</given_name>
            <surname>Denninger</surname>
            <ORCID>https://orcid.org/0000-0002-1557-2234</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Dominik</given_name>
            <surname>Winkelbauer</surname>
            <ORCID>https://orcid.org/0000-0001-7443-1071</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Martin</given_name>
            <surname>Sundermeyer</surname>
            <ORCID>https://orcid.org/0000-0003-0587-9643</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Wout</given_name>
            <surname>Boerdijk</surname>
            <ORCID>https://orcid.org/0000-0003-0789-5970</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Markus</given_name>
            <surname>Knauer</surname>
            <ORCID>https://orcid.org/0000-0001-8229-9410</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Klaus H.</given_name>
            <surname>Strobl</surname>
            <ORCID>https://orcid.org/0000-0001-8123-0606</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Matthias</given_name>
            <surname>Humt</surname>
            <ORCID>https://orcid.org/0000-0002-1523-9335</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Rudolph</given_name>
            <surname>Triebel</surname>
            <ORCID>https://orcid.org/0000-0002-7975-036X</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>02</month>
          <day>20</day>
          <year>2023</year>
        </publication_date>
        <pages>
          <first_page>4901</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.04901</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.7654630</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/4901</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.04901</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.04901</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.04901.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="habitat">
            <article_title>Habitat: A Platform for Embodied AI
Research</article_title>
            <author>Manolis Savva*</author>
            <journal_title>Proceedings of the IEEE/CVF international
conference on computer vision (ICCV)</journal_title>
            <doi>10.1109/ICCV.2019.00943</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Manolis Savva*, Abhishek Kadian*,
Oleksandr Maksymets*, Zhao, Y., Wijmans, E., Jain, B., Straub, J., Liu,
J., Koltun, V., Malik, J., Parikh, D., &amp; Batra, D. (2019). Habitat:
A Platform for Embodied AI Research. Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV).
https://doi.org/10.1109/ICCV.2019.00943</unstructured_citation>
          </citation>
          <citation key="NDDS">
            <article_title>NDDS: NVIDIA deep learning dataset
synthesizer</article_title>
            <author>To</author>
            <cYear>2018</cYear>
            <unstructured_citation>To, T., Tremblay, J., McKay, D.,
Yamaguchi, Y., Leung, K., Balanon, A., Cheng, J., Hodge, W., &amp;
Birchfield, S. (2018). NDDS: NVIDIA deep learning dataset
synthesizer.</unstructured_citation>
          </citation>
          <citation key="Stillleben">
            <article_title>Stillleben: Realistic scene synthesis for
deep learning in robotics</article_title>
            <author>Schwarz</author>
            <doi>10.48550/ARXIV.2005.05659</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Schwarz, M., &amp; Behnke, S. (2020).
Stillleben: Realistic scene synthesis for deep learning in robotics.
https://doi.org/10.48550/ARXIV.2005.05659</unstructured_citation>
          </citation>
          <citation key="Front3D">
            <article_title>3D-FRONT: 3D furnished rooms with layouts and
semantics</article_title>
            <author>Fu</author>
            <journal_title>Proceedings of the IEEE/CVF international
conference on computer vision</journal_title>
            <doi>10.48550/ARXIV.2011.09127</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Fu, H., Cai, B., Gao, L., Zhang,
L.-X., Wang, J., Li, C., Zeng, Q., Sun, C., Jia, R., Zhao, B., &amp;
others. (2021). 3D-FRONT: 3D furnished rooms with layouts and semantics.
Proceedings of the IEEE/CVF International Conference on Computer Vision,
10933–10942.
https://doi.org/10.48550/ARXIV.2011.09127</unstructured_citation>
          </citation>
          <citation key="shapenet">
            <article_title>ShapeNet: An information-rich 3D model
repository</article_title>
            <author>Chang</author>
            <doi>10.48550/ARXIV.1512.03012</doi>
            <cYear>2015</cYear>
            <unstructured_citation>Chang, A. X., Funkhouser, T., Guibas,
L., Hanrahan, P., Huang, Q., Li, Z., Savarese, S., Savva, M., Song, S.,
Su, H., Xiao, J., Yi, L., &amp; Yu, F. (2015). ShapeNet: An
information-rich 3D model repository (arXiv:1512.03012 [cs.GR]).
Stanford University — Princeton University — Toyota Technological
Institute at Chicago.
https://doi.org/10.48550/ARXIV.1512.03012</unstructured_citation>
          </citation>
          <citation key="nvisii">
            <article_title>NViSII: A scriptable tool for photorealistic
image generation</article_title>
            <author>Morrical</author>
            <cYear>2021</cYear>
            <unstructured_citation>Morrical, N., Tremblay, J., Lin, Y.,
Tyree, S., Birchfield, S., Pascucci, V., &amp; Wald, I. (2021). NViSII:
A scriptable tool for photorealistic image generation.
https://arxiv.org/abs/2105.13962</unstructured_citation>
          </citation>
          <citation key="denninger2019blenderproc">
            <article_title>BlenderProc</article_title>
            <author>Denninger</author>
            <journal_title>arXiv preprint
arXiv:1911.01911</journal_title>
            <doi>10.48550/ARXIV.1911.01911</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Denninger, M., Sundermeyer, M.,
Winkelbauer, D., Zidan, Y., Olefir, D., Elbadrawy, M., Lodhi, A., &amp;
Katam, H. (2019). BlenderProc. arXiv Preprint arXiv:1911.01911.
https://doi.org/10.48550/ARXIV.1911.01911</unstructured_citation>
          </citation>
          <citation key="denninger2020blenderproc">
            <article_title>Blenderproc: Reducing the reality gap with
photorealistic rendering</article_title>
            <author>Denninger</author>
            <journal_title>International conference on robotics: Sciene
and systems, RSS 2020</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Denninger, M., Sundermeyer, M.,
Winkelbauer, D., Olefir, D., Hodan, T., Zidan, Y., Elbadrawy, M.,
Knauer, M., Katam, H., &amp; Lodhi, A. (2020). Blenderproc: Reducing the
reality gap with photorealistic rendering. International Conference on
Robotics: Sciene and Systems, RSS 2020.</unstructured_citation>
          </citation>
          <citation key="kubric">
            <article_title>Kubric: A scalable dataset
generator</article_title>
            <author>Greff</author>
            <doi>10.48550/ARXIV.2203.03570</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Greff, K., Belletti, F., Beyer, L.,
Doersch, C., Du, Y., Duckworth, D., Fleet, D. J., Gnanapragasam, D.,
Golemo, F., Herrmann, C., Kipf, T., Kundu, A., Lagun, D., Laradji, I.,
Liu, H.-T. (Derek), Meyer, H., Miao, Y., Nowrouzezahrai, D., Oztireli,
C., … Tagliasacchi, A. (2022). Kubric: A scalable dataset generator.
https://doi.org/10.48550/ARXIV.2203.03570</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
