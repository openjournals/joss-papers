<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4971</article-id>
<article-id pub-id-type="doi">10.21105/joss.04971</article-id>
<title-group>
<article-title>GraphNeT: Graph neural networks for neutrino telescope
event reconstruction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0823-056X</contrib-id>
<name>
<surname>Søgaard</surname>
<given-names>Andreas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8890-4124</contrib-id>
<name>
<surname>Ørsøe</surname>
<given-names>Rasmus F.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1383-2810</contrib-id>
<name>
<surname>Holm</surname>
<given-names>Morten</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1243-9980</contrib-id>
<name>
<surname>Bozianu</surname>
<given-names>Leon</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2410-400X</contrib-id>
<name>
<surname>Rosted</surname>
<given-names>Aske</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0221-3037</contrib-id>
<name>
<surname>Petersen</surname>
<given-names>Troels C.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6533-4085</contrib-id>
<name>
<surname>Iversen</surname>
<given-names>Kaare Endrup</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-1162-9770</contrib-id>
<name>
<surname>Hermansen</surname>
<given-names>Andreas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Guggenmos</surname>
<given-names>Tim</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-5759-0490</contrib-id>
<name>
<surname>Andresen</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7776-4875</contrib-id>
<name>
<surname>Minh</surname>
<given-names>Martin Ha</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4829-3469</contrib-id>
<name>
<surname>Neste</surname>
<given-names>Ludwig</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0000-8530-7041</contrib-id>
<name>
<surname>Holmes</surname>
<given-names>Moust</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-2463-2930</contrib-id>
<name>
<surname>Pontén</surname>
<given-names>Axel</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8795-0601</contrib-id>
<name>
<surname>DeHolton</surname>
<given-names>Kayla Leonard</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6354-5209</contrib-id>
<name>
<surname>Eller</surname>
<given-names>Philipp</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Niels Bohr Institute, University of Copenhagen,
Denmark</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Technical University of Munich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Chiba University, Japan</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Technical University of Dortmund, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Uppsala University, Sweden</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Pennsylvania State University, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-05-12">
<day>12</day>
<month>5</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>85</issue>
<fpage>4971</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>machine learning</kwd>
<kwd>deep learning</kwd>
<kwd>neural networks</kwd>
<kwd>graph neural networks</kwd>
<kwd>astrophysics</kwd>
<kwd>particle physics</kwd>
<kwd>neutrinos</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Neutrino telescopes, such as ANTARES
  (<xref alt="ANTARES Collaboration, 2011b" rid="ref-ANTARESU003A2011hfw" ref-type="bibr">ANTARES
  Collaboration, 2011b</xref>), IceCube
  (<xref alt="IceCube Collaboration, 2012" rid="ref-DeepCore" ref-type="bibr">IceCube
  Collaboration, 2012</xref>,
  <xref alt="2017" rid="ref-AartsenU003A2016nxy" ref-type="bibr">2017</xref>),
  KM3NeT
  (<xref alt="KM3NeT Collaboration, 2016" rid="ref-KM3NetU003A2016zxf" ref-type="bibr">KM3NeT
  Collaboration, 2016</xref>), and Baikal-GVD
  (<xref alt="Baikal-GVD Collaboration, 2018" rid="ref-Baikal-GVDU003A2018isr" ref-type="bibr">Baikal-GVD
  Collaboration, 2018</xref>) have the science goal of detecting
  neutrinos and measuring their properties and origins. Reconstruction
  at these experiments is concerned with classifying the type of event
  or estimating properties of the interaction.</p>
  <p><monospace>GraphNeT</monospace>
  (<xref alt="Søgaard et al., 2023" rid="ref-Sogaard_GraphNeT_2023" ref-type="bibr">Søgaard
  et al., 2023</xref>) is an open-source Python framework aimed at
  providing high quality, user friendly, end-to-end functionality to
  perform reconstruction tasks at neutrino telescopes using graph neural
  networks (GNNs). <monospace>GraphNeT</monospace> makes it fast and
  easy to train complex models that can provide event reconstruction
  with state-of-the-art performance, for arbitrary detector
  configurations, with inference times that are orders of magnitude
  faster than traditional reconstruction techniques
  (<xref alt="IceCube Collaboration, 2022a" rid="ref-gnn_icecube" ref-type="bibr">IceCube
  Collaboration, 2022a</xref>).</p>
  <p>GNNs from <monospace>GraphNeT</monospace> are flexible enough to be
  applied to data from all neutrino telescopes, including future
  projects such as IceCube extensions
  (<xref alt="IceCube-Gen2 Collaboration, 2017" rid="ref-IceCubeU003A2016xxt" ref-type="bibr">IceCube-Gen2
  Collaboration, 2017</xref>,
  <xref alt="2021" rid="ref-IceCube-Gen2U003A2020qha" ref-type="bibr">2021</xref>;
  <xref alt="IceCube-PINGU Collaboration, 2014" rid="ref-IceCube-PINGUU003A2014okk" ref-type="bibr">IceCube-PINGU
  Collaboration, 2014</xref>) or P-ONE
  (<xref alt="P-ONE Collaboration, 2020" rid="ref-P-ONEU003A2020ljt" ref-type="bibr">P-ONE
  Collaboration, 2020</xref>). This means that GNN-based reconstruction
  can be used to provide state-of-the-art performance on most
  reconstruction tasks in neutrino telescopes, at real-time event rates,
  across experiments and physics analyses, with vast potential impact
  for neutrino and astro-particle physics.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Neutrino telescopes typically consist of thousands of optical
  modules (OMs) to detect the Cherenkov light produced from particle
  interactions in the detector medium. The number of photo-electrons
  recorded by the OMs in each event roughly scales with the energy of
  the incident particle, from a few photo-electrons and up to tens of
  thousands.</p>
  <p>Reconstructing the particle type and parameters from individual
  recordings (called events) in these experiments is a challenge due to
  irregular detector geometry, inhomogeneous detector medium, sparsity
  of the data, the large variations of the amount of signal between
  different events, and the sheer number of events that need to be
  reconstructed.</p>
  <p>Multiple approaches have been employed, including relatively simple
  methods
  (<xref alt="ANTARES Collaboration, 2011a" rid="ref-AguilarU003A2011zz" ref-type="bibr">ANTARES
  Collaboration, 2011a</xref>;
  <xref alt="IceCube Collaboration, 2022b" rid="ref-IceCubeU003A2022kff" ref-type="bibr">IceCube
  Collaboration, 2022b</xref>) that are robust but limited in precision
  and likelihood-based methods
  (<xref alt="Aartsen &amp; others, 2014" rid="ref-AartsenU003A2013bfa" ref-type="bibr">Aartsen
  &amp; others, 2014</xref>;
  <xref alt="Abbasi et al., 2013" rid="ref-Abbasi_2013" ref-type="bibr">Abbasi
  et al., 2013</xref>;
  <xref alt="AMANDA Collaboration, 2004" rid="ref-AhrensU003A2003fg" ref-type="bibr">AMANDA
  Collaboration, 2004</xref>;
  <xref alt="ANTARES Collaboration, 2017" rid="ref-ANTARESU003A2017ivh" ref-type="bibr">ANTARES
  Collaboration, 2017</xref>;
  <xref alt="Chirkin, 2013" rid="ref-ChirkinU003A2013avz" ref-type="bibr">Chirkin,
  2013</xref>;
  <xref alt="IceCube Collaboration, 2014" rid="ref-AartsenU003A2013vja" ref-type="bibr">IceCube
  Collaboration, 2014</xref>,
  <xref alt="2021b" rid="ref-IceCubeU003A2021oqo" ref-type="bibr">2021b</xref>,
  <xref alt="2022b" rid="ref-IceCubeU003A2022kff" ref-type="bibr">2022b</xref>)
  that can attain a high accuracy at the price of high computational
  cost and detector specific assumptions.</p>
  <p>Recently, machine learning (ML) methods have started to be used,
  such as convolutional neural networks (CNNs)
  (<xref alt="IceCube Collaboration, 2021a" rid="ref-AbbasiU003A2021ryj" ref-type="bibr">IceCube
  Collaboration, 2021a</xref>;
  <xref alt="KM3NeT Collaboration, 2020" rid="ref-AielloU003A2020orq" ref-type="bibr">KM3NeT
  Collaboration, 2020</xref>) that are comparatively fast, but require
  detector data being transformed into a regular pixel or voxel grid.
  Other approaches get around the geometric limitations, but increase
  the computational cost to a similar level as the traditional
  likelihood methods
  (<xref alt="Eller et al., 2022" rid="ref-EllerU003A2022xvi" ref-type="bibr">Eller
  et al., 2022</xref>).</p>
  <p>Instead, GNNs can be thought of as generalised CNNs that work on
  data with any geometry, making this paradigm a natural fit for
  neutrino telescope data.</p>
  <p>The <monospace>GraphNeT</monospace> framework provides the
  end-to-end tools to train and deploy GNN reconstruction models.
  <monospace>GraphNeT</monospace> leverages industry-standard tools such
  as <monospace>pytorch</monospace>
  (<xref alt="Paszke et al., 2019" rid="ref-NEURIPS2019_9015" ref-type="bibr">Paszke
  et al., 2019</xref>), <monospace>PyG</monospace>
  (<xref alt="Fey &amp; Lenssen, 2019" rid="ref-Fey_Fast_Graph_Representation_2019" ref-type="bibr">Fey
  &amp; Lenssen, 2019</xref>), <monospace>lightning</monospace>
  (<xref alt="Falcon &amp; The PyTorch Lightning team, 2019" rid="ref-Falcon_PyTorch_Lightning_2019" ref-type="bibr">Falcon
  &amp; The PyTorch Lightning team, 2019</xref>), and
  <monospace>wandb</monospace>
  (<xref alt="Biewald, 2020" rid="ref-wandb" ref-type="bibr">Biewald,
  2020</xref>) for building and training GNNs as well as particle
  physics standard tools such as <monospace>awkward</monospace>
  (<xref alt="Pivarski et al., 2020" rid="ref-jim_pivarski_2020_3952674" ref-type="bibr">Pivarski
  et al., 2020</xref>) for handling the variable-size data representing
  particle interaction events in neutrino telescopes. The inference
  speed on a single GPU allows for processing the full online datastream
  of current neutrino telescopes in real-time.</p>
</sec>
<sec id="impact-on-physics">
  <title>Impact on physics</title>
  <p><monospace>GraphNeT</monospace> provides a common framework for ML
  developers and physicists that wish to use the state-of-the-art GNN
  tools in their research. By uniting both user groups,
  <monospace>GraphNeT</monospace> aims to increase the longevity and
  usability of individual code contributions from ML developers by
  building a general, reusable software package based on software
  engineering best practices, and lowers the technical threshold for
  physicists that wish to use the most performant tools for their
  scientific problems.</p>
  <p>The <monospace>GraphNeT</monospace> models can improve event
  classification and yield very accurate reconstruction, e.g., for low
  energy neutrinos observed in IceCube. Here, a GNN implemented in
  <monospace>GraphNeT</monospace> was applied to the problem of neutrino
  oscillations in IceCube, leading to significant improvements in both
  energy and angular reconstruction in the energy range relevant to
  oscillation studies
  (<xref alt="IceCube Collaboration, 2022a" rid="ref-gnn_icecube" ref-type="bibr">IceCube
  Collaboration, 2022a</xref>). Furthermore, it was shown that the GNN
  could improve muon vs. neutrino classification and thereby the
  efficiency and purity of a neutrino sample for such an analysis.</p>
  <p>Similarly, improved angular reconstruction has a great impact on,
  e.g., neutrino point source analyses.</p>
  <p>Finally, the fast (order millisecond) reconstruction allows for a
  whole new type of cosmic alerts at lower energies, which were
  previously unfeasible. GNN-based reconstruction makes it possible to
  identify low energy (&lt; 10 TeV) neutrinos and monitor their rate,
  direction, and energy in real-time. This will enable cosmic neutrino
  alerts based on such neutrinos for the first time ever, despite a
  large background of neutrinos that are not of cosmic origin.</p>
</sec>
<sec id="usage">
  <title>Usage</title>
  <p><monospace>GraphNeT</monospace> comprises a number of modules
  providing the necessary tools to build workflows from ingesting raw
  training data in domain-specific formats to deploying trained models
  in domain-specific reconstruction chains, as illustrated in
  <xref alt="[fig:flowchart]" rid="figU003Aflowchart">[fig:flowchart]</xref>.</p>
  <fig>
    <caption><p>High-level overview of a typical workflow using
    <monospace>GraphNeT</monospace>:
    <monospace>graphnet.data</monospace> enables converting
    domain-specific data to industry-standard, intermediate file formats
    and reading this data; <monospace>graphnet.models</monospace> allows
    for configuring and building complex GNN models using simple,
    physics-oriented components;
    <monospace>graphnet.training</monospace> manages model training and
    experiment logging; and finally,
    <monospace>graphnet.deployment</monospace> allows for using trained
    models for inference in domain-specific reconstruction
    chains.<styled-content id="figU003Aflowchart"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="media/flowchart.pdf" />
  </fig>
  <p><monospace>graphnet.models</monospace> provides modular components
  subclassing <monospace>torch.nn.Module</monospace>, meaning that users
  only need to import a few existing, purpose-built components and chain
  them together to form a complete GNN. ML developers can contribute to
  <monospace>GraphNeT</monospace> by extending this suite of model
  components — through new layer types, physics tasks, graph
  connectivities, etc. — and experiment with optimising these for
  different reconstruction tasks using experiment tracking.</p>
  <p>These models are trained using
  <monospace>graphnet.training</monospace> on data prepared using
  <monospace>graphnet.data</monospace>, to satisfy the high I/O loads
  required when training ML models on large batches of events, which
  domain-specific neutrino physics data formats typically do not
  allow.</p>
  <p>Trained models are deployed to a domain-specific reconstruction
  chain, yielding predictions, using the components in
  <monospace>graphnet.deployment</monospace>. This can either be through
  model files or container images, making deployment as portable and
  dependency-free as possible.</p>
  <p>By splitting up the GNN development as in
  <xref alt="[fig:flowchart]" rid="figU003Aflowchart">[fig:flowchart]</xref>,
  <monospace>GraphNeT</monospace> allows physics users to interface only
  with high-level building blocks or pre-trained models that can be used
  directly in their reconstruction chains, while allowing ML developers
  to continuously improve and expand the framework’s capabilities.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Andreas Søgaard has received funding from the European Union’s
  Horizon 2020 research and innovation programme under the Marie
  Skłodowska-Curie grant agreement No. 890778. The work of Rasmus Ørsøe
  was partly performed in the framework of the PUNCH4NFDI consortium
  supported by DFG fund “NFDI 39/1”, Germany.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Sogaard_GraphNeT_2023">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Søgaard</surname><given-names>Andreas</given-names></name>
        <name><surname>F. Ørsøe</surname><given-names>Rasmus</given-names></name>
        <name><surname>Holm</surname><given-names>Morten</given-names></name>
        <name><surname>Bozianu</surname><given-names>Leon</given-names></name>
        <name><surname>Rosted</surname><given-names>Aske</given-names></name>
        <name><surname>C. Petersen</surname><given-names>Troels</given-names></name>
        <name><surname>Endrup Iversen</surname><given-names>Kaare</given-names></name>
        <name><surname>Hermansen</surname><given-names>Andreas</given-names></name>
        <name><surname>Guggenmos</surname><given-names>Tim</given-names></name>
        <name><surname>Andresen</surname><given-names>Peter</given-names></name>
        <name><surname>Ha Minh</surname><given-names>Martin</given-names></name>
        <name><surname>Neste</surname><given-names>Ludwig</given-names></name>
        <name><surname>Holmes</surname><given-names>Moust</given-names></name>
        <name><surname>Pontén</surname><given-names>Axel</given-names></name>
        <name><surname>Leonard DeHolton</surname><given-names>Kayla</given-names></name>
        <name><surname>Eller</surname><given-names>Philipp</given-names></name>
      </person-group>
      <article-title>GraphNeT</article-title>
      <year iso-8601-date="2023-05">2023</year><month>05</month>
      <uri>https://github.com/graphnet-team/graphnet</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.6720188</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-NEURIPS2019_9015">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems 32</source>
      <person-group person-group-type="editor">
        <name><surname>Wallach</surname><given-names>H.</given-names></name>
        <name><surname>Larochelle</surname><given-names>H.</given-names></name>
        <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
        <name><surname>dAlché-Buc</surname><given-names>F.</given-names></name>
        <name><surname>Fox</surname><given-names>E.</given-names></name>
        <name><surname>Garnett</surname><given-names>R.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <uri>http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.01703</pub-id>
      <fpage>8024</fpage>
      <lpage>8035</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Fey_Fast_Graph_Representation_2019">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Fey</surname><given-names>Matthias</given-names></name>
        <name><surname>Lenssen</surname><given-names>Jan Eric</given-names></name>
      </person-group>
      <article-title>Fast Graph Representation Learning with PyTorch Geometric</article-title>
      <year iso-8601-date="2019-05">2019</year><month>05</month>
      <uri>https://github.com/pyg-team/pytorch_geometric</uri>
    </element-citation>
  </ref>
  <ref id="ref-Falcon_PyTorch_Lightning_2019">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Falcon</surname><given-names>William</given-names></name>
        <string-name>The PyTorch Lightning team</string-name>
      </person-group>
      <article-title>PyTorch Lightning</article-title>
      <year iso-8601-date="2019-03">2019</year><month>03</month>
      <uri>https://github.com/Lightning-AI/lightning</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3828935</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wandb">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Biewald</surname><given-names>Lukas</given-names></name>
      </person-group>
      <article-title>Experiment tracking with weights and biases</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://www.wandb.com/</uri>
    </element-citation>
  </ref>
  <ref id="ref-jim_pivarski_2020_3952674">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Pivarski</surname><given-names>Jim</given-names></name>
        <name><surname>Escott</surname><given-names>Charles</given-names></name>
        <name><surname>Smith</surname><given-names>Nicholas</given-names></name>
        <name><surname>Hedges</surname><given-names>Michael</given-names></name>
        <name><surname>Proffitt</surname><given-names>Mason</given-names></name>
        <name><surname>Escott</surname><given-names>Charlie</given-names></name>
        <name><surname>Nandi</surname><given-names>Jaydeep</given-names></name>
        <name><surname>Rembser</surname><given-names>Jonas</given-names></name>
        <name><surname>bfis</surname></name>
        <name><surname>benkrikler</surname></name>
        <name><surname>Gray</surname><given-names>Lindsey</given-names></name>
        <name><surname>Davis</surname><given-names>Doug</given-names></name>
        <name><surname>Schreiner</surname><given-names>Henry</given-names></name>
        <name><surname>Nollde</surname></name>
        <name><surname>Fackeldey</surname><given-names>Peter</given-names></name>
        <name><surname>Das</surname><given-names>Pratyush</given-names></name>
      </person-group>
      <article-title>Scikit-hep/awkward-array: 0.13.0</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2020-07">2020</year><month>07</month>
      <uri>https://doi.org/10.5281/zenodo.3952674</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3952674</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-AartsenU003A2016nxy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>The IceCube Neutrino Observatory: Instrumentation and Online Systems</article-title>
      <source>JINST</source>
      <year iso-8601-date="2017">2017</year>
      <volume>12</volume>
      <issue>03</issue>
      <uri>https://arxiv.org/abs/1612.05093</uri>
      <pub-id pub-id-type="doi">10.1088/1748-0221/12/03/P03012</pub-id>
      <fpage>P03012</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-DeepCore">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>The design and performance of IceCube DeepCore</article-title>
      <source>Astropart. Phys.</source>
      <year iso-8601-date="2012">2012</year>
      <volume>35</volume>
      <issue>10</issue>
      <issn>0927-6505</issn>
      <pub-id pub-id-type="doi">10.1016/j.astropartphys.2012.01.004</pub-id>
      <fpage>615</fpage>
      <lpage>624</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ANTARESU003A2011hfw">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>ANTARES Collaboration</string-name>
      </person-group>
      <article-title>ANTARES: the first undersea neutrino telescope</article-title>
      <source>Nucl. Instrum. Meth. A</source>
      <year iso-8601-date="2011">2011</year>
      <volume>656</volume>
      <uri>https://arxiv.org/abs/1104.1607</uri>
      <pub-id pub-id-type="doi">10.1016/j.nima.2011.06.103</pub-id>
      <fpage>11</fpage>
      <lpage>38</lpage>
    </element-citation>
  </ref>
  <ref id="ref-KM3NetU003A2016zxf">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>KM3NeT Collaboration</string-name>
      </person-group>
      <article-title>Letter of intent for KM3NeT 2.0</article-title>
      <source>J. Phys. G</source>
      <year iso-8601-date="2016">2016</year>
      <volume>43</volume>
      <issue>8</issue>
      <uri>https://arxiv.org/abs/1601.07459</uri>
      <pub-id pub-id-type="doi">10.1088/0954-3899/43/8/084001</pub-id>
      <fpage>084001</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-IceCube-Gen2U003A2020qha">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube-Gen2 Collaboration</string-name>
      </person-group>
      <article-title>IceCube-Gen2: the window to the extreme Universe</article-title>
      <source>J. Phys. G</source>
      <year iso-8601-date="2021">2021</year>
      <volume>48</volume>
      <issue>6</issue>
      <uri>https://arxiv.org/abs/2008.04323</uri>
      <pub-id pub-id-type="doi">10.1088/1361-6471/abbd48</pub-id>
      <fpage>060501</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-IceCube-PINGUU003A2014okk">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube-PINGU Collaboration</string-name>
      </person-group>
      <article-title>Letter of Intent: The Precision IceCube Next Generation Upgrade (PINGU)</article-title>
      <year iso-8601-date="2014-01">2014</year><month>01</month>
      <uri>https://arxiv.org/abs/1401.2046</uri>
    </element-citation>
  </ref>
  <ref id="ref-IceCubeU003A2016xxt">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube-Gen2 Collaboration</string-name>
      </person-group>
      <article-title>PINGU: A Vision for Neutrino and Particle Physics at the South Pole</article-title>
      <source>J. Phys. G</source>
      <year iso-8601-date="2017">2017</year>
      <volume>44</volume>
      <issue>5</issue>
      <uri>https://arxiv.org/abs/1607.02671</uri>
      <pub-id pub-id-type="doi">10.1088/1361-6471/44/5/054006</pub-id>
      <fpage>054006</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Baikal-GVDU003A2018isr">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>Baikal-GVD Collaboration</string-name>
      </person-group>
      <article-title>Baikal-GVD: status and prospects</article-title>
      <source>EPJ Web Conf.</source>
      <person-group person-group-type="editor">
        <name><surname>Volkova</surname><given-names>V. E.</given-names></name>
        <name><surname>Zhezher</surname><given-names>Y. V.</given-names></name>
        <name><surname>Levkov</surname><given-names>D. G.</given-names></name>
        <name><surname>Rubakov</surname><given-names>V. A.</given-names></name>
        <name><surname>Matveev</surname><given-names>V. A.</given-names></name>
      </person-group>
      <year iso-8601-date="2018">2018</year>
      <volume>191</volume>
      <uri>https://arxiv.org/abs/1808.10353</uri>
      <pub-id pub-id-type="doi">10.1051/epjconf/201819101006</pub-id>
      <fpage>01006</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-P-ONEU003A2020ljt">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>P-ONE Collaboration</string-name>
      </person-group>
      <article-title>The Pacific Ocean Neutrino Experiment</article-title>
      <source>Nature Astron.</source>
      <year iso-8601-date="2020">2020</year>
      <volume>4</volume>
      <issue>10</issue>
      <uri>https://arxiv.org/abs/2005.09493</uri>
      <pub-id pub-id-type="doi">10.1038/s41550-020-1182-4</pub-id>
      <fpage>913</fpage>
      <lpage>915</lpage>
    </element-citation>
  </ref>
  <ref id="ref-AguilarU003A2011zz">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>ANTARES Collaboration</string-name>
      </person-group>
      <article-title>A fast algorithm for muon track reconstruction and its application to the ANTARES neutrino telescope</article-title>
      <source>Astropart. Phys.</source>
      <year iso-8601-date="2011">2011</year>
      <volume>34</volume>
      <uri>https://arxiv.org/abs/1105.4116</uri>
      <pub-id pub-id-type="doi">10.1016/j.astropartphys.2011.01.003</pub-id>
      <fpage>652</fpage>
      <lpage>662</lpage>
    </element-citation>
  </ref>
  <ref id="ref-IceCubeU003A2022kff">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>Low Energy Event Reconstruction in IceCube DeepCore</article-title>
      <year iso-8601-date="2022-03">2022</year><month>03</month>
      <uri>https://arxiv.org/abs/2203.02303</uri>
    </element-citation>
  </ref>
  <ref id="ref-ANTARESU003A2017ivh">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>ANTARES Collaboration</string-name>
      </person-group>
      <article-title>An algorithm for the reconstruction of neutrino-induced showers in the ANTARES neutrino telescope</article-title>
      <source>Astron. J.</source>
      <year iso-8601-date="2017">2017</year>
      <volume>154</volume>
      <issue>6</issue>
      <uri>https://arxiv.org/abs/1708.03649</uri>
      <pub-id pub-id-type="doi">10.3847/1538-3881/aa9709</pub-id>
      <fpage>275</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-AhrensU003A2003fg">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>AMANDA Collaboration</string-name>
      </person-group>
      <article-title>Muon track reconstruction and data selection techniques in AMANDA</article-title>
      <source>Nucl. Instrum. Meth. A</source>
      <year iso-8601-date="2004">2004</year>
      <volume>524</volume>
      <uri>https://arxiv.org/abs/astro-ph/0407044</uri>
      <pub-id pub-id-type="doi">10.1016/j.nima.2004.01.065</pub-id>
      <fpage>169</fpage>
      <lpage>194</lpage>
    </element-citation>
  </ref>
  <ref id="ref-AbbasiU003A2021ryj">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>A Convolutional Neural Network based Cascade Reconstruction for the IceCube Neutrino Observatory</article-title>
      <source>JINST</source>
      <year iso-8601-date="2021">2021</year>
      <volume>16</volume>
      <uri>https://arxiv.org/abs/2101.11589</uri>
      <pub-id pub-id-type="doi">10.1088/1748-0221/16/07/P07041</pub-id>
      <fpage>P07041</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-AielloU003A2020orq">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>KM3NeT Collaboration</string-name>
      </person-group>
      <article-title>Event reconstruction for KM3NeT/ORCA using convolutional neural networks</article-title>
      <source>JINST</source>
      <year iso-8601-date="2020">2020</year>
      <volume>15</volume>
      <issue>10</issue>
      <uri>https://arxiv.org/abs/2004.08254</uri>
      <pub-id pub-id-type="doi">10.1088/1748-0221/15/10/P10005</pub-id>
      <fpage>P10005</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-AartsenU003A2013vja">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>Energy Reconstruction Methods in the IceCube Neutrino Telescope</article-title>
      <source>JINST</source>
      <year iso-8601-date="2014">2014</year>
      <volume>9</volume>
      <uri>https://arxiv.org/abs/1311.4767</uri>
      <pub-id pub-id-type="doi">10.1088/1748-0221/9/03/P03009</pub-id>
      <fpage>P03009</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Abbasi_2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Abbasi</surname><given-names>R.</given-names></name>
        <name><surname>Abdou</surname><given-names>Y.</given-names></name>
        <name><surname>Ackermann</surname><given-names>M.</given-names></name>
        <name><surname>Adams</surname><given-names>J.</given-names></name>
        <name><surname>Aguilar</surname><given-names>J. A.</given-names></name>
        <name><surname>Ahlers</surname><given-names>M.</given-names></name>
        <name><surname>Altmann</surname><given-names>D.</given-names></name>
        <name><surname>Andeen</surname><given-names>K.</given-names></name>
        <name><surname>Auffenberg</surname><given-names>J.</given-names></name>
        <name><surname>Bai</surname><given-names>X.</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>An improved method for measuring muon energy using the truncated mean of dE/dx</article-title>
      <source>Nucl. Instum. Meth. A</source>
      <year iso-8601-date="2013-03">2013</year><month>03</month>
      <volume>703</volume>
      <issn>0168-9002</issn>
      <fpage>190</fpage>
      <lpage>198</lpage>
    </element-citation>
  </ref>
  <ref id="ref-IceCubeU003A2021oqo">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>A muon-track reconstruction exploiting stochastic losses for large-scale Cherenkov detectors</article-title>
      <source>JINST</source>
      <year iso-8601-date="2021">2021</year>
      <volume>16</volume>
      <issue>08</issue>
      <uri>https://arxiv.org/abs/2103.16931</uri>
      <pub-id pub-id-type="doi">10.1088/1748-0221/16/08/P08034</pub-id>
      <fpage>P08034</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-AartsenU003A2013bfa">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Aartsen</surname><given-names>M. G.</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Improvement in Fast Particle Track Reconstruction with Robust Statistics</article-title>
      <source>Nucl. Instrum. Meth. A</source>
      <year iso-8601-date="2014">2014</year>
      <volume>736</volume>
      <uri>https://arxiv.org/abs/1308.5501</uri>
      <pub-id pub-id-type="doi">10.1016/j.nima.2013.10.074</pub-id>
      <fpage>143</fpage>
      <lpage>149</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ChirkinU003A2013avz">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chirkin</surname><given-names>Dmitry</given-names></name>
      </person-group>
      <article-title>Event reconstruction in IceCube based on direct event re-simulation</article-title>
      <source>33rd International Cosmic Ray Conference</source>
      <year iso-8601-date="2013">2013</year>
    </element-citation>
  </ref>
  <ref id="ref-gnn_icecube">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>IceCube Collaboration</string-name>
      </person-group>
      <article-title>Graph Neural Networks for Low-Energy Event Classification &amp; Reconstruction in IceCube</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://arxiv.org/abs/2209.03042</uri>
    </element-citation>
  </ref>
  <ref id="ref-EllerU003A2022xvi">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Eller</surname><given-names>Philipp</given-names></name>
        <name><surname>Fienberg</surname><given-names>Aaron</given-names></name>
        <name><surname>Weldert</surname><given-names>Jan</given-names></name>
        <name><surname>Wendel</surname><given-names>Garrett</given-names></name>
        <name><surname>Böser</surname><given-names>Sebastian</given-names></name>
        <name><surname>Cowen</surname><given-names>D. F.</given-names></name>
      </person-group>
      <article-title>A flexible event reconstruction based on machine learning and likelihood principles</article-title>
      <year iso-8601-date="2022-08">2022</year><month>08</month>
      <uri>https://arxiv.org/abs/2208.10166</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
