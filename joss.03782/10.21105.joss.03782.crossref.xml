<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>d45cefb7ed53a5eb657cc599d4e28c91</doi_batch_id>
    <timestamp>20211015151824</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2021</year>
        </publication_date>
        <journal_volume>
          <volume>6</volume>
        </journal_volume>
        <issue>66</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>sbp-env: A Python Package for Sampling-based Motion Planner and Samplers</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Tin</given_name>
            <surname>Lai</surname>
            <ORCID>http://orcid.org/0000-0003-0641-5250</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>15</day>
          <year>2021</year>
        </publication_date>
        <pages>
          <first_page>3782</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.03782</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">“https://doi.org/10.5281/zenodo.5572325”</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/3782</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.03782</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.03782</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.03782.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="ref1">
            <doi>10.1109/access.2014.2302442</doi>
          </citation>
          <citation key="ref2">
            <doi>10.1109/access.2020.3023200</doi>
          </citation>
          <citation key="ref3">
            <doi>10.1109/robio.2015.7419012</doi>
          </citation>
          <citation key="ref4">
            <doi>10.1109/csip.2012.6308826</doi>
          </citation>
          <citation key="ref5">
            <doi>10.1109/robot.2005.1570709</doi>
          </citation>
          <citation key="ref6">
            <doi>10.1109/aim.2012.6265953</doi>
          </citation>
          <citation key="ref7">
            <doi>10.1109/robot.1996.509171</doi>
          </citation>
          <citation key="ref8">
            <unstructured_citation>Rapid Replanning in Consecutive Pick-and-Place Tasks with Lazy Experience Graph, Lai, Tin and Ramos, Fabio, 2021, 2109.10209, arXiv, cs.RO, arXiv:2109.10209 [cs.RO], en</unstructured_citation>
          </citation>
          <citation key="ref9">
            <unstructured_citation>Learning to Plan Optimally with Flow-Based Motion Planner, Lai, Tin and Ramos, Fabio, 2020, 2010.11323, arXiv, cs.RO, arXiv:2010.11323 [cs.RO], en</unstructured_citation>
          </citation>
          <citation key="ref10">
            <unstructured_citation>Parallelised Diffeomorphic Sampling-based Motion Planning, Lai, Tin and Zhi, Weiming and Hermans, Tucker and Ramos, Fabio, Conference on Robot Learning (CoRL), 2021, Proceedings of Machine Learning Research</unstructured_citation>
          </citation>
          <citation key="ref11">
            <doi>10.1109/icra.2019.8793618</doi>
          </citation>
          <citation key="ref12">
            <doi>10.1109/icra40945.2020.9197338</doi>
          </citation>
          <citation key="ref13">
            <doi>10.1007/978-3-319-03194-1_2</doi>
          </citation>
          <citation key="ref14">
            <doi>10.1109/mmar.2016.7575302</doi>
          </citation>
          <citation key="ref15">
            <doi>10.1109/lra.2020.2969145</doi>
          </citation>
          <citation key="ref16">
            <unstructured_citation>Rapidly-exploring Random Forest: Adaptively Exploits Local Structure with Generalised Multi-Trees Motion Planning, Lai, Tin, 2021, 2103.04487, arXiv, arXiv:2103.04487 [cs.RO], en, cs.RO</unstructured_citation>
          </citation>
          <citation key="ref17">
            <unstructured_citation>Pytorch: An imperative style, high-performance deep learning library, Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others, Advances in neural information processing systems, 32, 8026–8037, 2019</unstructured_citation>
          </citation>
          <citation key="ref18">
            <unstructured_citation>Tensorflow: A system for large-scale machine learning, Abadi, Martı́n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others, 12th USENIX symposium on operating systems design and implementation (OSDI 16), 265–283, 2016</unstructured_citation>
          </citation>
          <citation key="ref19">
            <unstructured_citation>PlannerFlows: Learning Motion Samplers with Normalising Flows, Lai, Tin and Ramos, Fabio, IEEE/RSJ Proceedings of The International Conference on Intelligent Robots and Systems (IROS), 2021, IEEE</unstructured_citation>
          </citation>
          <citation key="ref20">
            <doi>10.1109/isatp.2001.928961</doi>
          </citation>
          <citation key="ref21">
            <unstructured_citation>The open motion planning library, Sucan, Ioan A and Moll, Mark and Kavraki, Lydia E, IEEE Robotics &amp; Automation Magazine, 19, 4, 72–82, 2012, IEEE</unstructured_citation>
          </citation>
          <citation key="ref22">
            <unstructured_citation>PythonRobotics: a Python code collection of robotics algorithms, Sakai, Atsushi and Ingram, Daniel and Dinius, Joseph and Chawla, Karan and Raffin, Antonin and Paques, Alexis, 2018, 1808.10703, arXiv, cs.RO</unstructured_citation>
          </citation>
          <citation key="ref23">
            <doi>10.1109/mra.2011.2181749</doi>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
