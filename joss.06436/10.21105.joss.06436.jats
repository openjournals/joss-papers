<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6436</article-id>
<article-id pub-id-type="doi">10.21105/joss.06436</article-id>
<title-group>
<article-title>HiddenMarkovModels.jl: generic, fast and reliable state
space modeling</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4866-1687</contrib-id>
<name>
<surname>Dalle</surname>
<given-names>Guillaume</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Information, Learning and Physics laboratory, Ecole
Polytechnique Fédérale de Lausanne (EPFL), Station 11, CH-1015
Lausanne</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Information and Network Dynamics laboratory, Ecole
Polytechnique Fédérale de Lausanne (EPFL), Station 14, CH-1015
Lausanne</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Statistical Physics of Computation laboratory, Ecole
Polytechnique Fédérale de Lausanne (EPFL), CH-1015
Lausanne</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-02-22">
<day>22</day>
<month>2</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>96</issue>
<fpage>6436</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>statistics</kwd>
<kwd>hmm</kwd>
<kwd>inference</kwd>
<kwd>estimation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Hidden Markov Models (or HMMs) are a very popular statistical
  framework, with numerous applications ranging from speech recognition
  to bioinformatics. They characterize a sequence of
  <italic>observations</italic> <inline-formula><alternatives>
  <tex-math><![CDATA[Y_1, \dots, Y_T]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>
  by assuming the existence of a hidden sequence of
  <italic>states</italic> <inline-formula><alternatives>
  <tex-math><![CDATA[X_1, \dots, X_T]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.
  The distribution of a state <inline-formula><alternatives>
  <tex-math><![CDATA[X_t]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  can only depend on the previous state <inline-formula><alternatives>
  <tex-math><![CDATA[X_{t-1}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
  and the distribution of an observation <inline-formula><alternatives>
  <tex-math><![CDATA[Y_t]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  can only depend on the current state <inline-formula><alternatives>
  <tex-math><![CDATA[X_t]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.
  In addition, both of these dynamics may be influenced by exogenous
  control variables <inline-formula><alternatives>
  <tex-math><![CDATA[U_1, \dots, U_T]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.
  This is a very versatile and practical set of assumptions: see Rabiner
  (<xref alt="1989" rid="ref-rabinerTutorialHiddenMarkov1989" ref-type="bibr">1989</xref>)
  for an introduction, Cappé et al.
  (<xref alt="2005" rid="ref-cappeInferenceHiddenMarkov2005" ref-type="bibr">2005</xref>)
  for a book-length treatment and Bengio &amp; Frasconi
  (<xref alt="1994" rid="ref-bengioInputOutputHMM1994" ref-type="bibr">1994</xref>)
  for a seminal discussion of HMMs with controls.</p>
  <p>Given a sequence of observations and a parametric family of HMMs
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathbb{P}_\theta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>ℙ</mml:mi><mml:mi>θ</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
  there are several problems one can face. In generic graphical models,
  these problems are often intractable, but HMMs have a tree-like
  structure that yields exact solution procedures with polynomial
  complexity. The package <monospace>HiddenMarkovModels.jl</monospace>
  leverages the Julia language
  (<xref alt="Bezanson et al., 2017" rid="ref-bezansonJuliaFreshApproach2017" ref-type="bibr">Bezanson
  et al., 2017</xref>) to implement those algorithms in a
  <italic>generic</italic>, <italic>fast</italic> and
  <italic>reliable</italic> way.</p>
  <table-wrap>
    <table>
      <colgroup>
        <col width="87%" />
        <col width="13%" />
      </colgroup>
      <thead>
        <tr>
          <th>Inference problem</th>
          <th>Algorithm</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Best state sequence <inline-formula><alternatives>
          <tex-math><![CDATA[\mathrm{argmax}_{X_{1:T}}~\mathbb{P}_\theta(X_{1:T} \vert Y_{1:T}, U_{1:T})]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mspace width="0.222em"></mml:mspace><mml:msub><mml:mi>ℙ</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td>Viterbi</td>
        </tr>
        <tr>
          <td>Observation sequence likelihood
          <inline-formula><alternatives>
          <tex-math><![CDATA[\mathbb{P}_\theta(Y_{1:T} \vert U_{1:T})]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>ℙ</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td>Forward</td>
        </tr>
        <tr>
          <td>State marginals <inline-formula><alternatives>
          <tex-math><![CDATA[\mathbb{P}_\theta(X_t \vert Y_{1:T}, U_{1:T})]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>ℙ</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td>Forward-backward</td>
        </tr>
        <tr>
          <td>Maximum likelihood parameter
          <inline-formula><alternatives>
          <tex-math><![CDATA[\mathrm{argmax}_\theta~\mathbb{P}_\theta(Y_{1:T} \vert U_{1:T})]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mi>θ</mml:mi></mml:msub><mml:mspace width="0.222em"></mml:mspace><mml:msub><mml:mi>ℙ</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">|</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td>Baum-Welch</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The initial motivation for HiddenMarkovModels.jl was an application
  of HMMs to reliability analysis for the French railway company SNCF
  (<xref alt="Dalle, 2022" rid="ref-dalleMachineLearningCombinatorial2022" ref-type="bibr">Dalle,
  2022</xref>). In this industrial use case, the observations were
  marked temporal point processes (sequences of timed events with
  structured metadata) generated by condition monitoring systems,
  possibly influenced by the daily activity of the train unit.</p>
  <p>Unfortunately, nearly all implementations of HMMs we surveyed (in
  Julia and Python) expect the observations to be generated by a
  <italic>predefined set of distributions</italic>, with <italic>no
  temporal heterogeneity</italic>. In Julia, the previous reference
  package <monospace>HMMBase.jl</monospace>
  (<xref alt="Mouchet, 2023" rid="ref-mouchetHMMBaseJlHidden2023" ref-type="bibr">Mouchet,
  2023</xref>) requires compliance with the
  <monospace>Distributions.jl</monospace>
  (<xref alt="Besançon et al., 2021" rid="ref-besanconDistributionsJlDefinition2021" ref-type="bibr">Besançon
  et al., 2021</xref>) interface, which precludes anything not scalar-
  or array-valued, let alone point processes. In Python, the
  <monospace>numpy</monospace>-based <monospace>hmmlearn</monospace>
  (<xref alt="hmmlearn developers, 2023" rid="ref-hmmlearndevelopersHmmlearnHiddenMarkov2023" ref-type="bibr">hmmlearn
  developers, 2023</xref>) and the <monospace>PyTorch</monospace>-based
  <monospace>pomegranate</monospace>
  (<xref alt="Schreiber, 2018" rid="ref-schreiberPomegranateFastFlexible2018" ref-type="bibr">Schreiber,
  2018</xref>,
  <xref alt="2014/2024" rid="ref-schreiberJmschreiPomegranate2024" ref-type="bibr">2014/2024</xref>)
  each offer a catalogue of discrete and continuous distributions, but
  do not allow for easy extension by the user. The more recent
  <monospace>JAX</monospace>-based <monospace>dynamax</monospace>
  (<xref alt="Chang et al., 2022/2024" rid="ref-changDynamaxStateSpace2024" ref-type="bibr">Chang
  et al., 2022/2024</xref>;
  <xref alt="Murphy, 2023" rid="ref-murphyProbabilisticMachineLearning2023" ref-type="bibr">Murphy,
  2023</xref>;
  <xref alt="Särkkä &amp; Svensson, 2023" rid="ref-sarkkaBayesianFilteringSmoothing2023" ref-type="bibr">Särkkä
  &amp; Svensson, 2023</xref>) is the only package adopting an
  extensible interface with optional controls, similar to ours.</p>
  <p>Focusing on Julia specifically, other downsides of
  <monospace>HMMBase.jl</monospace> include the lack of support for
  <italic>multiple observation sequences</italic>, <italic>automatic
  differentiation</italic>, <italic>sparse transition matrices</italic>
  or <italic>number types beyond 64-bit floating point</italic>. Two
  other Julia packages each provide a subset of functionalities that
  <monospace>HMMBase.jl</monospace> lacks, namely
  <monospace>HMMGradients.jl</monospace>
  (<xref alt="Antonello, 2021" rid="ref-antonelloHMMGradientsJlEnables2021" ref-type="bibr">Antonello,
  2021</xref>) and <monospace>MarkovModels.jl</monospace>
  (<xref alt="Ondel et al., 2022" rid="ref-ondelGPUAcceleratedForwardBackwardAlgorithm2022" ref-type="bibr">Ondel
  et al., 2022</xref>), but they are less developed and ill-suited to
  uninformed users.</p>
</sec>
<sec id="package-design">
  <title>Package design</title>
  <p><monospace>HiddenMarkovModels.jl</monospace> was designed to
  overcome the limitations mentioned above, following a few guiding
  principles.</p>
  <p>Our package is <italic>generic</italic>. Observations can be
  arbitrary objects, and the associated distributions only need to
  implement two methods: a loglikelihood
  <monospace>logdensityof(dist, x)</monospace> and a sampler
  <monospace>rand(rng, x)</monospace>. Number types are not restricted,
  and automatic differentiation of the sequence loglikelihood
  (<xref alt="Qin et al., 2000" rid="ref-qinDirectOptimizationApproach2000" ref-type="bibr">Qin
  et al., 2000</xref>) is supported both in forward and reverse mode,
  partly thanks to <monospace>ChainRulesCore.jl</monospace>
  (<xref alt="White et al., 2022" rid="ref-whiteJuliaDiffChainRulesJl2022a" ref-type="bibr">White
  et al., 2022</xref>). The extendable
  <monospace>AbstractHMM</monospace> interface allows incorporating
  features such as priors or structured transitions, as well as temporal
  or control dependency, simply by redefining three methods:</p>
  <code language="julia">initialization(hmm)
transition_matrix(hmm, control)
obs_distributions(hmm, control)</code>
  <p>Our package is <italic>fast</italic>. Julia’s blend of multiple
  dispatch and just-in-time compilation delivers satisfactory speed even
  when working with unexpected types that Python’s tensor backends could
  not easily handle. Inference routines rely on BLAS calls for linear
  algebra, and exploit multithreading to process sequences in
  parallel.</p>
  <p>Our package is <italic>reliable</italic>. It is thoroughly tested
  and documented, with an extensive API reference and accessible
  tutorials. Special care was given to code quality, type stability, and
  compatibility checks with various downstream packages (like automatic
  differentiation packages).</p>
  <p>However, our package is also <italic>limited in scope</italic>. It
  aims at CPU efficiency for moderately-sized state spaces, and remains
  untested on GPU. Furthermore, it does not manipulate probabilities in
  the logarithmic domain, but instead uses the scaling trick
  (<xref alt="Rabiner, 1989" rid="ref-rabinerTutorialHiddenMarkov1989" ref-type="bibr">Rabiner,
  1989</xref>) with a variation borrowed from
  <monospace>HMMBase.jl</monospace>. Thus, its numerical stability might
  be worse than that of Python counterparts on challenging instances.
  Luckily, thanks to unrestricted number types, users are free to bring
  in third-party packages like
  <monospace>LogarithmicNumbers.jl</monospace>
  (<xref alt="Rowley, 2023" rid="ref-rowleyLogarithmicNumbersJlLogarithmic2023" ref-type="bibr">Rowley,
  2023</xref>) to recover additional precision.</p>
</sec>
<sec id="benchmarks">
  <title>Benchmarks</title>
  <p>We compare <monospace>HiddenMarkovModels.jl</monospace>,
  <monospace>HMMBase.jl</monospace>, <monospace>hmmlearn</monospace>,
  <monospace>pomegranate</monospace> and <monospace>dynamax</monospace>
  on a test case with univariate Gaussian observations. The reason for
  this low-dimensional choice is to spend most of the time in the
  generic HMM routines themselves, as opposed to the loglikelihood
  computations which are problem-specific. The data consists of
  <inline-formula><alternatives>
  <tex-math><![CDATA[50]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>50</mml:mn></mml:math></alternatives></inline-formula>
  independent sequences of length <inline-formula><alternatives>
  <tex-math><![CDATA[100]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>100</mml:mn></mml:math></alternatives></inline-formula>
  each, with a number of states varying from
  <inline-formula><alternatives>
  <tex-math><![CDATA[2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2</mml:mn></mml:math></alternatives></inline-formula>
  to <inline-formula><alternatives>
  <tex-math><![CDATA[10]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>10</mml:mn></mml:math></alternatives></inline-formula>,
  to which we apply all inference algorithms (with Baum-Welch performing
  <inline-formula><alternatives>
  <tex-math><![CDATA[5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>5</mml:mn></mml:math></alternatives></inline-formula>
  iterations).</p>
  <p>All benchmarks were run in Julia version 1.10.2 with
  <monospace>BenchmarkTools.jl</monospace>
  (<xref alt="Chen &amp; Revels, 2016" rid="ref-chenRobustBenchmarkingNoisy2016" ref-type="bibr">Chen
  &amp; Revels, 2016</xref>), calling Python with
  <monospace>PythonCall.jl</monospace>
  (<xref alt="Rowley, 2022" rid="ref-rowleyPythonCallJlPython2022" ref-type="bibr">Rowley,
  2022</xref>), and plotting results with
  <monospace>CairoMakie.jl</monospace>
  (<xref alt="Danisch &amp; Krumbiegel, 2021" rid="ref-danischMakieJlFlexible2021" ref-type="bibr">Danisch
  &amp; Krumbiegel, 2021</xref>). The comparison code imports
  <monospace>HiddenMarkovModels.jl</monospace> version 0.5.0 (commit
  <ext-link ext-link-type="uri" xlink:href="https://github.com/gdalle/HiddenMarkovModels.jl/commit/f7cf63b48fb4853376071772ce35c55a73f57e5c">f7cf63b</ext-link>),
  and it is accessible in the
  <ext-link ext-link-type="uri" xlink:href="https://github.com/gdalle/HiddenMarkovModels.jl/tree/f7cf63b48fb4853376071772ce35c55a73f57e5c/libs/HMMComparison"><monospace>libs/HMMComparison/</monospace></ext-link>
  subfolder of our GitHub repository. We tried to minimize parallelism
  effects by running everything on a single thread, and made the
  assumption that the Julia-to-Python overhead is negligible compared to
  the algorithm runtime.</p>
  <fig>
    <caption><p>Benchmark of HMM packages</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/c757159dd30450ddff87a7fdf8facbb159f96fb1.png" />
  </fig>
  <p>As we can see, <monospace>HiddenMarkovModels.jl</monospace> is the
  fastest option in Julia, and the second-fastest overall behind
  <monospace>dynamax</monospace> (we think the large runtimes of
  <monospace>dynamax</monospace> in Baum-Welch might stem from
  <ext-link ext-link-type="uri" xlink:href="https://github.com/probml/dynamax/issues/359">incorrect
  benchmarks</ext-link>). The key observation is that we achieved this
  speedup over <monospace>HMMBase.jl</monospace> while
  <italic>simultaneously increasing generality</italic> in half a dozen
  different ways.</p>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p><monospace>HiddenMarkovModels.jl</monospace> fills a longstanding
  gap in the Julia package ecosystem, by providing an efficient and
  flexible framework for state space modeling.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Work on this package started during my PhD at École des Ponts, in
  partnership with SNCF Réseau and SNCF Voyageurs, whose support I
  acknowledge. It continued during my postdoctoral position at EPFL.</p>
  <p>My gratitude goes to Maxime Mouchet and Jacob Schreiber, the
  developers of <monospace>HMMBase.jl</monospace> and
  <monospace>pomegranate</monospace> respectively, for their help and
  advice. In particular, Maxime agreed to designate
  <monospace>HiddenMarkovModels.jl</monospace> as the official successor
  to <monospace>HMMBase.jl</monospace>, for which I thank him.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-antonelloHMMGradientsJlEnables2021">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Antonello</surname><given-names>Niccolò</given-names></name>
      </person-group>
      <article-title>HMMGradients.jl: Enables computing the gradient of the parameters of Hidden Markov Models (HMMs)</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2021-06-07">2021</year><month>06</month><day>07</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-12">2023</year><month>09</month><day>12</day></date-in-citation>
      <uri>https://doi.org/10.5281/zenodo.4454565</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.4454565</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bengioInputOutputHMM1994">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>
        <name><surname>Frasconi</surname><given-names>Paolo</given-names></name>
      </person-group>
      <article-title>An Input Output HMM Architecture</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <publisher-name>MIT Press</publisher-name>
      <year iso-8601-date="1994">1994</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-03-12">2023</year><month>03</month><day>12</day></date-in-citation>
      <volume>7</volume>
      <uri>https://proceedings.neurips.cc/paper/1994/hash/8065d07da4a77621450aa84fee5656d9-Abstract.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-besanconDistributionsJlDefinition2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Besançon</surname><given-names>Mathieu</given-names></name>
        <name><surname>Papamarkou</surname><given-names>Theodore</given-names></name>
        <name><surname>Anthoff</surname><given-names>David</given-names></name>
        <name><surname>Arslan</surname><given-names>Alex</given-names></name>
        <name><surname>Byrne</surname><given-names>Simon</given-names></name>
        <name><surname>Lin</surname><given-names>Dahua</given-names></name>
        <name><surname>Pearson</surname><given-names>John</given-names></name>
      </person-group>
      <article-title>Distributions.jl: Definition and Modeling of Probability Distributions in the JuliaStats Ecosystem</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2021-07-25">2021</year><month>07</month><day>25</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-09-19">2022</year><month>09</month><day>19</day></date-in-citation>
      <volume>98</volume>
      <issn>1548-7660</issn>
      <uri>https://doi.org/10.18637/jss.v098.i16</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v098.i16</pub-id>
      <fpage>1</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bezansonJuliaFreshApproach2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
      </person-group>
      <article-title>Julia: A Fresh Approach to Numerical Computing</article-title>
      <source>SIAM Review</source>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-12-03">2022</year><month>12</month><day>03</day></date-in-citation>
      <volume>59</volume>
      <issue>1</issue>
      <issn>0036-1445</issn>
      <uri>https://epubs.siam.org/doi/10.1137/141000671</uri>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cappeInferenceHiddenMarkov2005">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Cappé</surname><given-names>Olivier</given-names></name>
        <name><surname>Moulines</surname><given-names>Eric</given-names></name>
        <name><surname>Rydén</surname><given-names>Tobias</given-names></name>
      </person-group>
      <source>Inference in Hidden Markov Models</source>
      <publisher-name>Springer New York</publisher-name>
      <publisher-loc>New York, NY</publisher-loc>
      <year iso-8601-date="2005">2005</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-12-03">2022</year><month>12</month><day>03</day></date-in-citation>
      <isbn>978-0-387-28982-3</isbn>
      <uri>http://link.springer.com/10.1007/0-387-28982-8</uri>
      <pub-id pub-id-type="doi">10.1007/0-387-28982-8</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-changDynamaxStateSpace2024">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Chang</surname><given-names>Peter</given-names></name>
        <name><surname>Harper-Donnelly</surname><given-names>Giles</given-names></name>
        <name><surname>Kara</surname><given-names>Aleyna</given-names></name>
        <name><surname>Li</surname><given-names>Xinglong</given-names></name>
        <name><surname>Linderman</surname><given-names>Scott</given-names></name>
        <name><surname>Murphy</surname><given-names>Kevin</given-names></name>
      </person-group>
      <article-title>Dynamax: State Space Models library in JAX</article-title>
      <publisher-name>Probabilistic machine learning</publisher-name>
      <year iso-8601-date="2024-02-22">2024</year><month>02</month><day>22</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-02-22">2024</year><month>02</month><day>22</day></date-in-citation>
      <uri>https://github.com/probml/dynamax</uri>
    </element-citation>
  </ref>
  <ref id="ref-chenRobustBenchmarkingNoisy2016">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>Jiahao</given-names></name>
        <name><surname>Revels</surname><given-names>Jarrett</given-names></name>
      </person-group>
      <article-title>Robust benchmarking in noisy environments</article-title>
      <year iso-8601-date="2016-08-15">2016</year><month>08</month><day>15</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-02-29">2024</year><month>02</month><day>29</day></date-in-citation>
      <uri>http://arxiv.org/abs/1608.04295</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1608.04295</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dalleMachineLearningCombinatorial2022">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Dalle</surname><given-names>Guillaume</given-names></name>
      </person-group>
      <article-title>Machine learning and combinatorial optimization algorithms, with applications to railway planning</article-title>
      <publisher-name>École des Ponts ParisTech</publisher-name>
      <year iso-8601-date="2022-12-16">2022</year><month>12</month><day>16</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-05">2024</year><month>04</month><day>05</day></date-in-citation>
      <uri>https://pastel.hal.science/tel-04053322</uri>
    </element-citation>
  </ref>
  <ref id="ref-danischMakieJlFlexible2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Danisch</surname><given-names>Simon</given-names></name>
        <name><surname>Krumbiegel</surname><given-names>Julius</given-names></name>
      </person-group>
      <article-title>Makie.jl: Flexible high-performance data visualization for Julia</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021-09-01">2021</year><month>09</month><day>01</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-02-29">2024</year><month>02</month><day>29</day></date-in-citation>
      <volume>6</volume>
      <issue>65</issue>
      <issn>2475-9066</issn>
      <uri>https://joss.theoj.org/papers/10.21105/joss.03349</uri>
      <pub-id pub-id-type="doi">10.21105/joss.03349</pub-id>
      <fpage>3349</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-hmmlearndevelopersHmmlearnHiddenMarkov2023">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>hmmlearn developers</string-name>
      </person-group>
      <article-title>Hmmlearn: Hidden Markov Models in Python, with scikit-learn like API</article-title>
      <publisher-name>hmmlearn</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-12">2023</year><month>09</month><day>12</day></date-in-citation>
      <uri>https://github.com/hmmlearn/hmmlearn</uri>
    </element-citation>
  </ref>
  <ref id="ref-mouchetHMMBaseJlHidden2023">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Mouchet</surname><given-names>Maxime</given-names></name>
      </person-group>
      <article-title>HMMBase.jl: Hidden Markov Models for Julia</article-title>
      <year iso-8601-date="2023">2023</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-12">2023</year><month>09</month><day>12</day></date-in-citation>
      <uri>https://github.com/maxmouchet/HMMBase.jl</uri>
    </element-citation>
  </ref>
  <ref id="ref-murphyProbabilisticMachineLearning2023">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Murphy</surname><given-names>Kevin P.</given-names></name>
      </person-group>
      <source>Probabilistic Machine Learning: Advanced Topics</source>
      <publisher-name>The MIT Press</publisher-name>
      <publisher-loc>Cambridge, Massachusetts London, England</publisher-loc>
      <year iso-8601-date="2023-08-15">2023</year><month>08</month><day>15</day>
      <isbn>978-0-262-04843-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-ondelGPUAcceleratedForwardBackwardAlgorithm2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ondel</surname><given-names>Lucas</given-names></name>
        <name><surname>Lam-Yee-Mui</surname><given-names>Léa-Marie</given-names></name>
        <name><surname>Kocour</surname><given-names>Martin</given-names></name>
        <name><surname>Corro</surname><given-names>Caio Filippo</given-names></name>
        <name><surname>Burget</surname><given-names>Lukás</given-names></name>
      </person-group>
      <article-title>GPU-Accelerated Forward-Backward Algorithm with Application to Lattice-Free MMI</article-title>
      <source>ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source>
      <year iso-8601-date="2022-05">2022</year><month>05</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-03-01">2024</year><month>03</month><day>01</day></date-in-citation>
      <issn>2379-190X</issn>
      <uri>https://ieeexplore.ieee.org/document/9746824</uri>
      <pub-id pub-id-type="doi">10.1109/ICASSP43922.2022.9746824</pub-id>
      <fpage>8417</fpage>
      <lpage>8421</lpage>
    </element-citation>
  </ref>
  <ref id="ref-qinDirectOptimizationApproach2000">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Qin</surname><given-names>Feng</given-names></name>
        <name><surname>Auerbach</surname><given-names>Anthony</given-names></name>
        <name><surname>Sachs</surname><given-names>Frederick</given-names></name>
      </person-group>
      <article-title>A Direct Optimization Approach to Hidden Markov Modeling for Single Channel Kinetics</article-title>
      <source>Biophysical Journal</source>
      <year iso-8601-date="2000-10-01">2000</year><month>10</month><day>01</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-08-06">2022</year><month>08</month><day>06</day></date-in-citation>
      <volume>79</volume>
      <issue>4</issue>
      <issn>0006-3495</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0006349500764411</uri>
      <pub-id pub-id-type="doi">10.1016/S0006-3495(00)76441-1</pub-id>
      <fpage>1915</fpage>
      <lpage>1927</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rabinerTutorialHiddenMarkov1989">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rabiner</surname><given-names>L. R.</given-names></name>
      </person-group>
      <article-title>A tutorial on hidden Markov models and selected applications in speech recognition</article-title>
      <source>Proceedings of the IEEE</source>
      <year iso-8601-date="1989-02">1989</year><month>02</month>
      <volume>77</volume>
      <issue>2</issue>
      <issn>1558-2256</issn>
      <pub-id pub-id-type="doi">10.1109/5.18626</pub-id>
      <fpage>257</fpage>
      <lpage>286</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rowleyLogarithmicNumbersJlLogarithmic2023">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Rowley</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>LogarithmicNumbers.jl: A logarithmic number system for Julia.</article-title>
      <year iso-8601-date="2023-05-24">2023</year><month>05</month><day>24</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-09-12">2023</year><month>09</month><day>12</day></date-in-citation>
      <uri>https://github.com/cjdoris/LogarithmicNumbers.jl</uri>
    </element-citation>
  </ref>
  <ref id="ref-rowleyPythonCallJlPython2022">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Rowley</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>PythonCall.jl: Python and Julia in harmony</article-title>
      <publisher-name>JuliaPy</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-02-29">2024</year><month>02</month><day>29</day></date-in-citation>
      <uri>https://github.com/JuliaPy/PythonCall.jl</uri>
    </element-citation>
  </ref>
  <ref id="ref-sarkkaBayesianFilteringSmoothing2023">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Särkkä</surname><given-names>Simo</given-names></name>
        <name><surname>Svensson</surname><given-names>Lennart</given-names></name>
      </person-group>
      <source>Bayesian Filtering and Smoothing</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <publisher-loc>Cambridge</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-05">2024</year><month>04</month><day>05</day></date-in-citation>
      <edition>2</edition>
      <isbn>978-1-108-92664-5</isbn>
      <uri>https://www.cambridge.org/core/books/bayesian-filtering-and-smoothing/F88740E8D25010CF3119A5CA379FA37A</uri>
      <pub-id pub-id-type="doi">10.1017/9781108917407</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-schreiberJmschreiPomegranate2024">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Schreiber</surname><given-names>Jacob</given-names></name>
      </person-group>
      <article-title>Jmschrei/pomegranate</article-title>
      <year iso-8601-date="2024-04-03">2024</year><month>04</month><day>03</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-05">2024</year><month>04</month><day>05</day></date-in-citation>
      <uri>https://github.com/jmschrei/pomegranate</uri>
    </element-citation>
  </ref>
  <ref id="ref-schreiberPomegranateFastFlexible2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schreiber</surname><given-names>Jacob</given-names></name>
      </person-group>
      <article-title>Pomegranate: Fast and Flexible Probabilistic Modeling in Python</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2018">2018</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2019-05-16">2019</year><month>05</month><day>16</day></date-in-citation>
      <volume>18</volume>
      <issue>164</issue>
      <issn>1533-7928</issn>
      <uri>http://jmlr.org/papers/v18/17-636.html</uri>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-whiteJuliaDiffChainRulesJl2022a">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>White</surname><given-names>Lyndon</given-names></name>
        <name><surname>Abbott</surname><given-names>Michael</given-names></name>
        <name><surname>Zgubic</surname><given-names>Miha</given-names></name>
        <name><surname>Revels</surname><given-names>Jarrett</given-names></name>
        <name><surname>Arslan</surname><given-names>Alex</given-names></name>
        <name><surname>Axen</surname><given-names>Seth</given-names></name>
        <name><surname>Schaub</surname><given-names>Simeon</given-names></name>
        <name><surname>Robinson</surname><given-names>Nick</given-names></name>
        <name><surname>Ma</surname><given-names>Yingbo</given-names></name>
        <name><surname>Dhingra</surname><given-names>Gaurav</given-names></name>
        <string-name>willtebbutt</string-name>
        <name><surname>Heim</surname><given-names>Niklas</given-names></name>
        <name><surname>Widmann</surname><given-names>David</given-names></name>
        <name><surname>Rosemberg</surname><given-names>Andrew David Werner</given-names></name>
        <name><surname>Schmitz</surname><given-names>Niklas</given-names></name>
        <name><surname>Rackauckas</surname><given-names>Christopher</given-names></name>
        <name><surname>Heintzmann</surname><given-names>Rainer</given-names></name>
        <string-name>frankschae</string-name>
        <name><surname>Fischer</surname><given-names>Keno</given-names></name>
        <name><surname>Robson</surname><given-names>Alex</given-names></name>
        <string-name>mattBrzezinski</string-name>
        <name><surname>Zhabinski</surname><given-names>Andrei</given-names></name>
        <name><surname>Besançon</surname><given-names>Mathieu</given-names></name>
        <name><surname>Vertechi</surname><given-names>Pietro</given-names></name>
        <name><surname>Gowda</surname><given-names>Shashi</given-names></name>
        <name><surname>Fitzgibbon</surname><given-names>Andrew</given-names></name>
        <name><surname>Lucibello</surname><given-names>Carlo</given-names></name>
        <name><surname>Vogt</surname><given-names>Curtis</given-names></name>
        <name><surname>Gandhi</surname><given-names>Dhairya</given-names></name>
        <name><surname>Chorney</surname><given-names>Fernando</given-names></name>
      </person-group>
      <article-title>JuliaDiff/ChainRules.jl: V1.23.0</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2022-01-20">2022</year><month>01</month><day>20</day>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-04-05">2024</year><month>04</month><day>05</day></date-in-citation>
      <uri>https://zenodo.org/records/5881966</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.5881966</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
