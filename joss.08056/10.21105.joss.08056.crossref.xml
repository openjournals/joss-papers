<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20251020184700-cee87713f4141be96b58e2f4958407bf83ac3524</doi_batch_id>
    <timestamp>20251020184700</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>114</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>DeepTrees: Tree Crown Segmentation and Analysis in Remote Sensing Imagery with PyTorch</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Taimur</given_name>
            <surname>Khan</surname>
            <affiliations>
              <institution><institution_name>Helmholtz Center for Environmental Research – UFZ</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0001-7833-5474</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Caroline</given_name>
            <surname>Arnold</surname>
            <affiliations>
              <institution><institution_name>Helmholtz-Zentrum hereon</institution_name></institution>
              <institution><institution_name>Helmholtz AI</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-9458-1517</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Harsh</given_name>
            <surname>Grover</surname>
            <affiliations>
              <institution><institution_name>Helmholtz-Zentrum hereon</institution_name></institution>
              <institution><institution_name>Helmholtz AI</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0009-0000-2055-7525</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>20</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>8056</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.08056</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.17371394</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/8056</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.08056</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.08056</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.08056.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="freudenberg2022">
            <article_title>Individual tree crown delineation in high-resolution remote sensing images based on u-net</article_title>
            <author>Freudenberg</author>
            <journal_title>Neural Computing and Applications</journal_title>
            <issue>24</issue>
            <volume>34</volume>
            <doi>10.1007/s00521-022-07640-4</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Freudenberg, M., Magdon, P., &amp; Nölke, N. (2022). Individual tree crown delineation in high-resolution remote sensing images based on u-net. Neural Computing and Applications, 34(24), 22197–22207. https://doi.org/10.1007/s00521-022-07640-4</unstructured_citation>
          </citation>
          <citation key="zhao2023">
            <article_title>A systematic review of individual tree crown detection and delineation with convolutional neural networks (CNN)</article_title>
            <author>Zhao</author>
            <journal_title>Current Forestry Reports</journal_title>
            <issue>3</issue>
            <volume>9</volume>
            <doi>10.1007/s40725-023-00184-3</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Zhao, H., Morgenroth, J., Pearse, G., &amp; Schindler, J. (2023). A systematic review of individual tree crown detection and delineation with convolutional neural networks (CNN). Current Forestry Reports, 9(3), 149–170. https://doi.org/10.1007/s40725-023-00184-3</unstructured_citation>
          </citation>
          <citation key="weinstein2019">
            <article_title>Individual tree-crown detection in RGB imagery using semi-supervised deep learning neural networks</article_title>
            <author>Weinstein</author>
            <journal_title>Remote Sensing</journal_title>
            <issue>11</issue>
            <volume>11</volume>
            <doi>10.3390/rs11111309</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Weinstein, B. G., Marconi, S., Bohlman, S., Zare, A., &amp; White, E. (2019). Individual tree-crown detection in RGB imagery using semi-supervised deep learning neural networks. Remote Sensing, 11(11), 1309. https://doi.org/10.3390/rs11111309</unstructured_citation>
          </citation>
          <citation key="weinstein2020">
            <article_title>Cross-site learning in deep learning RGB tree crown detection</article_title>
            <author>Weinstein</author>
            <journal_title>Ecological Informatics</journal_title>
            <volume>56</volume>
            <doi>10.1016/j.ecoinf.2020.101061</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Weinstein, B. G., Marconi, S., Bohlman, S. A., Zare, A., &amp; White, E. P. (2020). Cross-site learning in deep learning RGB tree crown detection. Ecological Informatics, 56, 101061. https://doi.org/10.1016/j.ecoinf.2020.101061</unstructured_citation>
          </citation>
          <citation key="cong2022">
            <article_title>Citrus tree crown segmentation of orchard spraying robot based on RGB-d image and improved mask r-CNN</article_title>
            <author>Cong</author>
            <journal_title>Applied Sciences</journal_title>
            <issue>1</issue>
            <volume>13</volume>
            <doi>10.3390/app13010164</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Cong, P., Zhou, J., Li, S., Lv, K., &amp; Feng, H. (2022). Citrus tree crown segmentation of orchard spraying robot based on RGB-d image and improved mask r-CNN. Applied Sciences, 13(1), 164. https://doi.org/10.3390/app13010164</unstructured_citation>
          </citation>
          <citation key="sun2022">
            <article_title>Individual tree crown segmentation and crown width extraction from a heightmap derived from aerial laser scanning data using a deep learning framework</article_title>
            <author>Sun</author>
            <journal_title>Frontiers in Plant Science</journal_title>
            <volume>13</volume>
            <doi>10.3389/fpls.2022.914974</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Sun, C., Huang, C., Zhang, H., Chen, B., An, F., Wang, L., &amp; Yun, T. (2022). Individual tree crown segmentation and crown width extraction from a heightmap derived from aerial laser scanning data using a deep learning framework. Frontiers in Plant Science, 13, 914974. https://doi.org/10.3389/fpls.2022.914974</unstructured_citation>
          </citation>
          <citation key="moussaid2021">
            <article_title>Tree crowns segmentation and classification in overlapping orchards based on satellite images and unsupervised learning algorithms</article_title>
            <author>Moussaid</author>
            <journal_title>Journal of Imaging</journal_title>
            <issue>11</issue>
            <volume>7</volume>
            <doi>10.3390/jimaging7110241</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Moussaid, A., Fkihi, S. E., &amp; Zennayi, Y. (2021). Tree crowns segmentation and classification in overlapping orchards based on satellite images and unsupervised learning algorithms. Journal of Imaging, 7(11), 241. https://doi.org/10.3390/jimaging7110241</unstructured_citation>
          </citation>
          <citation key="zheng2024">
            <article_title>A review of individual tree crown detection and delineation from optical remote sensing images: Current progress and future</article_title>
            <author>Zheng</author>
            <journal_title>IEEE Geoscience and Remote Sensing Magazine</journal_title>
            <doi>10.1109/MGRS.2024.3479871</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Zheng, J., Yuan, S., Li, W., Fu, H., Yu, L., &amp; Huang, J. (2024). A review of individual tree crown detection and delineation from optical remote sensing images: Current progress and future. IEEE Geoscience and Remote Sensing Magazine. https://doi.org/10.1109/MGRS.2024.3479871</unstructured_citation>
          </citation>
          <citation key="tolan2024">
            <article_title>Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar</article_title>
            <author>Tolan</author>
            <journal_title>Remote Sensing of Environment</journal_title>
            <volume>300</volume>
            <doi>10.1016/j.rse.2023.113888</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Tolan, J., Yang, H.-I., Nosarzewski, B., Couairon, G., Vo, H. V., Brandt, J., Spore, J., Majumdar, S., Haziza, D., Vamaraju, J., &amp; others. (2024). Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar. Remote Sensing of Environment, 300, 113888. https://doi.org/10.1016/j.rse.2023.113888</unstructured_citation>
          </citation>
          <citation key="fayad2024">
            <article_title>Hy-TeC: A hybrid vision transformer model for high-resolution and large-scale mapping of canopy height</article_title>
            <author>Fayad</author>
            <journal_title>Remote Sensing of Environment</journal_title>
            <volume>302</volume>
            <doi>10.1016/j.rse.2023.113945</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Fayad, I., Ciais, P., Schwartz, M., Wigneron, J.-P., Baghdadi, N., Truchis, A. de, d’Aspremont, A., Frappart, F., Saatchi, S., Sean, E., &amp; others. (2024). Hy-TeC: A hybrid vision transformer model for high-resolution and large-scale mapping of canopy height. Remote Sensing of Environment, 302, 113945. https://doi.org/10.1016/j.rse.2023.113945</unstructured_citation>
          </citation>
          <citation key="pan2024">
            <article_title>The enduring world forest carbon sink</article_title>
            <author>Pan</author>
            <journal_title>Nature</journal_title>
            <issue>8021</issue>
            <volume>631</volume>
            <doi>10.1038/s41586-024-07602-x</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Pan, Y., Birdsey, R. A., Phillips, O. L., Houghton, R. A., Fang, J., Kauppi, P. E., Keith, H., Kurz, W. A., Ito, A., Lewis, S. L., &amp; others. (2024). The enduring world forest carbon sink. Nature, 631(8021), 563–569. https://doi.org/10.1038/s41586-024-07602-x</unstructured_citation>
          </citation>
          <citation key="sharma2024">
            <article_title>Urban trees’ potential for regulatory services in the urban environment: An exploration of carbon sequestration</article_title>
            <author>Sharma</author>
            <journal_title>Environmental Monitoring and Assessment</journal_title>
            <issue>6</issue>
            <volume>196</volume>
            <doi>10.1007/s10661-024-12634-x</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Sharma, S., Hussain, S., Kumar, P., &amp; Singh, A. N. (2024). Urban trees’ potential for regulatory services in the urban environment: An exploration of carbon sequestration. Environmental Monitoring and Assessment, 196(6), 504. https://doi.org/10.1007/s10661-024-12634-x</unstructured_citation>
          </citation>
          <citation key="taimur_khan_2025">
            <article_title>DeepTrees_halle (revision 0c528b9)</article_title>
            <author>Taimur Khan</author>
            <doi>10.57967/hf/4213</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Taimur Khan. (2025). DeepTrees_halle (revision 0c528b9). Hugging Face. https://doi.org/10.57967/hf/4213</unstructured_citation>
          </citation>
          <citation key="wu2022">
            <article_title>Entropy-based active learning for object detection with progressive diversity constraint</article_title>
            <author>Wu</author>
            <doi>10.48550/arXiv.2204.07965</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Wu, J., Chen, J., &amp; Huang, D. (2022). Entropy-based active learning for object detection with progressive diversity constraint (pp. 9397–9406). https://doi.org/10.48550/arXiv.2204.07965</unstructured_citation>
          </citation>
          <citation key="PyTorchLightning24">
            <article_title>PyTorch Lightning</article_title>
            <author>Falcon</author>
            <doi>10.5281/zenodo.3828935</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Falcon, W., &amp; The PyTorch Lightning team. (2024). PyTorch Lightning (Version 2.4). https://doi.org/10.5281/zenodo.3828935</unstructured_citation>
          </citation>
          <citation key="fao2022">
            <article_title>Global forest resources assessment 2022</article_title>
            <author>Food</author>
            <doi>10.4060/cb9360en</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Food, &amp; United Nations, A. O. of the. (2022). Global forest resources assessment 2022. https://doi.org/10.4060/cb9360en</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
