<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8056</article-id>
<article-id pub-id-type="doi">10.21105/joss.08056</article-id>
<title-group>
<article-title>DeepTrees: Tree Crown Segmentation and Analysis in Remote
Sensing Imagery with PyTorch</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7833-5474</contrib-id>
<name>
<surname>Khan</surname>
<given-names>Taimur</given-names>
</name>
<email>taimur.khan@ufz.de</email>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9458-1517</contrib-id>
<name>
<surname>Arnold</surname>
<given-names>Caroline</given-names>
</name>
<email>caroline.arnold@hereon.de</email>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0000-2055-7525</contrib-id>
<name>
<surname>Grover</surname>
<given-names>Harsh</given-names>
</name>
<email>harsh.grover@hereon.de</email>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Helmholtz Center for Environmental Research –
UFZ</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Helmholtz-Zentrum hereon</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Helmholtz AI</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-01-01">
<day>1</day>
<month>1</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>8056</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Deep Learning</kwd>
<kwd>Remote Sensing</kwd>
<kwd>Geospatial</kwd>
<kwd>Vegetation Ecology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>DeepTrees is a Python package for tree crown segmentation and
  analysis in remote sensing imagery. It uses PyTorch for training and
  predicting on large-scale datasets. Designed for direct integration
  with geospatial workflows, DeepTrees provides data loaders,
  transforms, and utility functions, enabling efficient experimentation
  in tree crown segmentation and tree traits analysis.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Accurate tree crown segmentation is essential for ecological
  modeling, biomass estimation, and forest management
  (<xref alt="Food &amp; United Nations, 2022" rid="ref-fao2022" ref-type="bibr">Food
  &amp; United Nations, 2022</xref>). Traditional methods often depend
  on labor-intensive manual delineation or specialized scripts. With the
  rise of high-resolution imagery from satellites, aircraft, and UAVs, a
  scalable, open-source tool is needed to:</p>
  <list list-type="bullet">
    <list-item>
      <p>Automate the segmentation of tree crowns across diverse
      landscapes and across sensor types.</p>
    </list-item>
    <list-item>
      <p>Seamlessly integrate with geospatial workflows for data
      loading, tiling, and inference.</p>
    </list-item>
    <list-item>
      <p>Provide methods for crown morphological and traits
      analysis.</p>
    </list-item>
    <list-item>
      <p>Support reproducible research with transparent and customizable
      training pipelines.</p>
    </list-item>
    <list-item>
      <p>Go beyond tree crown segmentation and into analysis.</p>
    </list-item>
  </list>
  <p>Deep learning has been widely applied to crown detection,
  especially with CNNs and U-Net-based models on RGB, multispectral, and
  lidar data
  (<xref alt="Freudenberg et al., 2022" rid="ref-freudenberg2022" ref-type="bibr">Freudenberg
  et al., 2022</xref>;
  <xref alt="Zhao et al., 2023" rid="ref-zhao2023" ref-type="bibr">Zhao
  et al., 2023</xref>). Semi-supervised and cross-site learning
  approaches improve generalization across environments
  (<xref alt="Weinstein et al., 2019" rid="ref-weinstein2019" ref-type="bibr">Weinstein
  et al., 2019</xref>,
  <xref alt="2020" rid="ref-weinstein2020" ref-type="bibr">2020</xref>).
  Despite the advancements in detection, segmentation tools remain
  limited. Some methods target specific domains, such as orchard
  segmentation with RGB-D imagery
  (<xref alt="Cong et al., 2022" rid="ref-cong2022" ref-type="bibr">Cong
  et al., 2022</xref>) or canopy height maps from laser scanning
  (<xref alt="Sun et al., 2022" rid="ref-sun2022" ref-type="bibr">Sun et
  al., 2022</xref>). Yet, in heterogeneous landscapes, challenges
  persist—overlapping crowns, diverse canopy structures, and seasonal
  variation hinder generalization
  (<xref alt="Moussaid et al., 2021" rid="ref-moussaid2021" ref-type="bibr">Moussaid
  et al., 2021</xref>;
  <xref alt="Zheng et al., 2024" rid="ref-zheng2024" ref-type="bibr">Zheng
  et al., 2024</xref>).</p>
  <p>Few tools go beyond detection to include structural or ecological
  analysis. Most focus on crown detection/segmentation alone, without
  integrating downstream applications like canopy height modeling,
  carbon estimation, or forest structure analysis
  (<xref alt="Fayad et al., 2024" rid="ref-fayad2024" ref-type="bibr">Fayad
  et al., 2024</xref>;
  <xref alt="Pan et al., 2024" rid="ref-pan2024" ref-type="bibr">Pan et
  al., 2024</xref>;
  <xref alt="Tolan et al., 2024" rid="ref-tolan2024" ref-type="bibr">Tolan
  et al., 2024</xref>). This leaves a gap for tools that combine
  segmentation with ecological insights, especially for urban forests
  (<xref alt="Sharma et al., 2024" rid="ref-sharma2024" ref-type="bibr">Sharma
  et al., 2024</xref>) and large ecosystems.</p>
</sec>
<sec id="library-overview">
  <title>Library overview</title>
  <p>The DeepTrees package offers a comprehensive framework for tree
  crown segmentation and analysis, supporting both single-image and
  batch inference. It generates multiple outputs—tree crown masks,
  outlines, distance transforms, uncertainty (entropy) maps, individual
  tree rasters, and crown polygons. These facilitate detailed
  morphological analysis and integrate seamlessly with geospatial
  workflows, aiding ecological monitoring and forest management (Figure
  1).</p>
  <p>A key feature is model fine-tuning and training. Users can train
  models from scratch or fine-tune pre-trained ones on new datasets. We
  include the original U-Nets from the TreeCrownDelineation project
  (<xref alt="Freudenberg et al., 2022" rid="ref-freudenberg2022" ref-type="bibr">Freudenberg
  et al., 2022</xref>). Transfer learning helps adapt models to varied
  environments and imaging conditions, improving segmentation
  performance across ecological and geographic contexts. Custom
  backbones are supported, allowing integration of new architectures
  like Geospatial Foundation Models (GFMs).</p>
  <p>Beyond segmentation, DeepTrees computes key tree traits critical
  for ecological studies and forest management. Users can derive indices
  like the Green Chlorophyll Index (GCI), Hue Index, and Normalized
  Difference Vegetation Index (NDVI), which assess vegetation health and
  chlorophyll content from spectral bands. The module also calculates
  structural traits such as the longest spread and cross-spread of tree
  crowns, providing insights into crown morphology. These outputs
  support downstream tasks like biomass estimation and vegetation health
  monitoring.</p>
  <p>A significant challenge in training deep learning models for remote
  sensing applications is the limited availability of annotated data, as
  tree crown delineation requires domain expertise. To address this
  issue, DeepTrees addresses this via an active learning loop that
  reduces labeling effort. By quantifying uncertainty at pixel and tile
  levels during inference, it identifies the most informative samples
  for manual annotation—accelerating model performance gains
  (<xref alt="Wu et al., 2022" rid="ref-wu2022" ref-type="bibr">Wu et
  al., 2022</xref>).</p>
  <p>Built with PyTorch Lightning
  (<xref alt="Falcon &amp; The PyTorch Lightning team, 2024" rid="ref-PyTorchLightning24" ref-type="bibr">Falcon
  &amp; The PyTorch Lightning team, 2024</xref>), DeepTrees ensures
  scalability and reproducibility. Its modular architecture supports
  extensibility and ease of use, comprising:</p>
  <list list-type="bullet">
    <list-item>
      <p><monospace>TreeCrownDelineationDataModule</monospace>:
      Standardizes data handling for training and inference.</p>
    </list-item>
    <list-item>
      <p><monospace>TreeCrownDelineationBaseDataset</monospace>: Handles
      loading and preprocessing, extended by:</p>
      <list list-type="bullet">
        <list-item>
          <p><monospace>TreeCrownDelineationDataset</monospace>:
          Generates random raster crops for training.</p>
        </list-item>
        <list-item>
          <p><monospace>TreeCrownDelineationInferenceDataset</monospace>:
          Provides full raster tiles for inference.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p><monospace>DeepTreesModel</monospace>: A LightningModule
      supporting multiple backbones with training, validation, and
      evaluation metrics.</p>
    </list-item>
    <list-item>
      <p><monospace>Trainer</monospace>: Manages training and inference
      on CPU or GPU (GPU recommended for efficiency).</p>
    </list-item>
  </list>
  <p>DeepTrees uses Hydra for configuration, accepting YAML config files
  and arguments that define module parameters for training and inference
  scripts.</p>
  <p>By unifying segmentation, active learning, and tree crown analysis,
  DeepTrees offers a robust, scalable solution for crown delineation and
  analysis. Its modular, open-source design makes it ideal for
  researchers and practitioners using aerial, UAV, or satellite imagery
  at scale.</p>
  <fig>
    <caption><p>Overview of the DeepTrees workflow for tree crown
    segmentation and analysis. The system processes high-resolution RGBi
    raster tiles (GeoTIFF format) using a data loader, which prepares
    input data for training, fine-tuning, or prediction. The model can
    be trained using polygon annotations (SHP format) and fine-tuned
    based on pixel-wise entropy maps (GeoTIFF format) to improve
    segmentation quality through active learning. During inference,
    DeepTrees generates multiple outputs, including tree masks, crown
    outlines, distance transform maps, tree crown polygons (exportable
    as SHP, GeoJSON, or SQLite), and allometric metrics. The system
    supports both pre-trained and updated model weights, enabling
    flexible and adaptive tree crown delineation.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="https://codebase.helmholtz.cloud/taimur.khan/DeepTrees/-/raw/joss/static/deeptrees.png" />
  </fig>
</sec>
<sec id="pre-trained-models-and-datasets">
  <title>Pre-trained Models and Datasets</title>
  <p>DeepTrees includes pre-trained models from Freudenberg et al.
  (<xref alt="2022" rid="ref-freudenberg2022" ref-type="bibr">2022</xref>)
  and our own training data.</p>
  <p>Additionally, the package provides a labelled dataset of tree
  crowns in the Halle region as ESRI shapefiles, which can be used for
  training and evaluation
  (<xref alt="Taimur Khan, 2025" rid="ref-taimur_khan_2025" ref-type="bibr">Taimur
  Khan, 2025</xref>). The tree crowns are labelled with the following
  classes:</p>
  <list list-type="bullet">
    <list-item>
      <p>0 = tree
      </p>
    </list-item>
    <list-item>
      <p>1 = cluster of trees
      </p>
    </list-item>
    <list-item>
      <p>2 = unsure
      </p>
    </list-item>
    <list-item>
      <p>3 = dead trees</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>DeepTrees is part of the
  “<ext-link ext-link-type="uri" xlink:href="https://deeptrees.de">DeepTrees:
  Deep-Learning based spatiotemporal tree inventorying and monitoring
  from public orthoimages</ext-link>” project, funded by the Integration
  Platform “Sustainable Future Land Use” at Helmholtz-Centre for
  Environmental Research – UFZ within the Programme oriented Funding
  (PoF) period IV of the Helmholtz Program “Changing Earth – Sustaining
  our Future”, Topic 5 “Landscapes of the Future. This repository is
  based on the work described in Freudenberg et al.
  (<xref alt="2022" rid="ref-freudenberg2022" ref-type="bibr">2022</xref>).
  This work was supported by Helmholtz Association’s Initiative and
  Networking Fund through Helmholtz AI [grant number: ZT-I-PF-5-01].
  This work used resources of the Deutsches Klimarechenzentrum (DKRZ)
  granted by its Scientific Steering Committee (WLA) under project ID
  AIM.</p>
</sec>
<sec id="license">
  <title>License</title>
  <p>DeepTrees is distributed under the MIT license.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-freudenberg2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Freudenberg</surname><given-names>Maximilian</given-names></name>
        <name><surname>Magdon</surname><given-names>Paul</given-names></name>
        <name><surname>Nölke</surname><given-names>Nils</given-names></name>
      </person-group>
      <article-title>Individual tree crown delineation in high-resolution remote sensing images based on u-net</article-title>
      <source>Neural Computing and Applications</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>34</volume>
      <issue>24</issue>
      <pub-id pub-id-type="doi">10.1007/s00521-022-07640-4</pub-id>
      <fpage>22197</fpage>
      <lpage>22207</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhao2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhao</surname><given-names>Haotian</given-names></name>
        <name><surname>Morgenroth</surname><given-names>Justin</given-names></name>
        <name><surname>Pearse</surname><given-names>Grant</given-names></name>
        <name><surname>Schindler</surname><given-names>Jan</given-names></name>
      </person-group>
      <article-title>A systematic review of individual tree crown detection and delineation with convolutional neural networks (CNN)</article-title>
      <source>Current Forestry Reports</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>9</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1007/s40725-023-00184-3</pub-id>
      <fpage>149</fpage>
      <lpage>170</lpage>
    </element-citation>
  </ref>
  <ref id="ref-weinstein2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weinstein</surname><given-names>Ben G</given-names></name>
        <name><surname>Marconi</surname><given-names>Sergio</given-names></name>
        <name><surname>Bohlman</surname><given-names>Stephanie</given-names></name>
        <name><surname>Zare</surname><given-names>Alina</given-names></name>
        <name><surname>White</surname><given-names>Ethan</given-names></name>
      </person-group>
      <article-title>Individual tree-crown detection in RGB imagery using semi-supervised deep learning neural networks</article-title>
      <source>Remote Sensing</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>11</volume>
      <issue>11</issue>
      <pub-id pub-id-type="doi">10.3390/rs11111309</pub-id>
      <fpage>1309</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-weinstein2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weinstein</surname><given-names>Ben G</given-names></name>
        <name><surname>Marconi</surname><given-names>Sergio</given-names></name>
        <name><surname>Bohlman</surname><given-names>Stephanie A</given-names></name>
        <name><surname>Zare</surname><given-names>Alina</given-names></name>
        <name><surname>White</surname><given-names>Ethan P</given-names></name>
      </person-group>
      <article-title>Cross-site learning in deep learning RGB tree crown detection</article-title>
      <source>Ecological Informatics</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>56</volume>
      <pub-id pub-id-type="doi">10.1016/j.ecoinf.2020.101061</pub-id>
      <fpage>101061</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-cong2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cong</surname><given-names>Peichao</given-names></name>
        <name><surname>Zhou</surname><given-names>Jiachao</given-names></name>
        <name><surname>Li</surname><given-names>Shanda</given-names></name>
        <name><surname>Lv</surname><given-names>Kunfeng</given-names></name>
        <name><surname>Feng</surname><given-names>Hao</given-names></name>
      </person-group>
      <article-title>Citrus tree crown segmentation of orchard spraying robot based on RGB-d image and improved mask r-CNN</article-title>
      <source>Applied Sciences</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>13</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.3390/app13010164</pub-id>
      <fpage>164</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-sun2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sun</surname><given-names>Chenxin</given-names></name>
        <name><surname>Huang</surname><given-names>Chengwei</given-names></name>
        <name><surname>Zhang</surname><given-names>Huaiqing</given-names></name>
        <name><surname>Chen</surname><given-names>Bangqian</given-names></name>
        <name><surname>An</surname><given-names>Feng</given-names></name>
        <name><surname>Wang</surname><given-names>Liwen</given-names></name>
        <name><surname>Yun</surname><given-names>Ting</given-names></name>
      </person-group>
      <article-title>Individual tree crown segmentation and crown width extraction from a heightmap derived from aerial laser scanning data using a deep learning framework</article-title>
      <source>Frontiers in Plant Science</source>
      <publisher-name>Frontiers Media SA</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>13</volume>
      <pub-id pub-id-type="doi">10.3389/fpls.2022.914974</pub-id>
      <fpage>914974</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-moussaid2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Moussaid</surname><given-names>Abdellatif</given-names></name>
        <name><surname>Fkihi</surname><given-names>Sanaa El</given-names></name>
        <name><surname>Zennayi</surname><given-names>Yahya</given-names></name>
      </person-group>
      <article-title>Tree crowns segmentation and classification in overlapping orchards based on satellite images and unsupervised learning algorithms</article-title>
      <source>Journal of Imaging</source>
      <publisher-name>MDPI</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>7</volume>
      <issue>11</issue>
      <pub-id pub-id-type="doi">10.3390/jimaging7110241</pub-id>
      <fpage>241</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-zheng2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zheng</surname><given-names>Juepeng</given-names></name>
        <name><surname>Yuan</surname><given-names>Shuai</given-names></name>
        <name><surname>Li</surname><given-names>Weijia</given-names></name>
        <name><surname>Fu</surname><given-names>Haohuan</given-names></name>
        <name><surname>Yu</surname><given-names>Le</given-names></name>
        <name><surname>Huang</surname><given-names>Jianxi</given-names></name>
      </person-group>
      <article-title>A review of individual tree crown detection and delineation from optical remote sensing images: Current progress and future</article-title>
      <source>IEEE Geoscience and Remote Sensing Magazine</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1109/MGRS.2024.3479871</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-tolan2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tolan</surname><given-names>Jamie</given-names></name>
        <name><surname>Yang</surname><given-names>Hung-I</given-names></name>
        <name><surname>Nosarzewski</surname><given-names>Benjamin</given-names></name>
        <name><surname>Couairon</surname><given-names>Guillaume</given-names></name>
        <name><surname>Vo</surname><given-names>Huy V</given-names></name>
        <name><surname>Brandt</surname><given-names>John</given-names></name>
        <name><surname>Spore</surname><given-names>Justine</given-names></name>
        <name><surname>Majumdar</surname><given-names>Sayantan</given-names></name>
        <name><surname>Haziza</surname><given-names>Daniel</given-names></name>
        <name><surname>Vamaraju</surname><given-names>Janaki</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar</article-title>
      <source>Remote Sensing of Environment</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>300</volume>
      <pub-id pub-id-type="doi">10.1016/j.rse.2023.113888</pub-id>
      <fpage>113888</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-fayad2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fayad</surname><given-names>Ibrahim</given-names></name>
        <name><surname>Ciais</surname><given-names>Philippe</given-names></name>
        <name><surname>Schwartz</surname><given-names>Martin</given-names></name>
        <name><surname>Wigneron</surname><given-names>Jean-Pierre</given-names></name>
        <name><surname>Baghdadi</surname><given-names>Nicolas</given-names></name>
        <name><surname>Truchis</surname><given-names>Aurélien de</given-names></name>
        <name><surname>d’ Aspremont</surname><given-names>Alexandre</given-names></name>
        <name><surname>Frappart</surname><given-names>Frederic</given-names></name>
        <name><surname>Saatchi</surname><given-names>Sassan</given-names></name>
        <name><surname>Sean</surname><given-names>Ewan</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Hy-TeC: A hybrid vision transformer model for high-resolution and large-scale mapping of canopy height</article-title>
      <source>Remote Sensing of Environment</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>302</volume>
      <pub-id pub-id-type="doi">10.1016/j.rse.2023.113945</pub-id>
      <fpage>113945</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-pan2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pan</surname><given-names>Yude</given-names></name>
        <name><surname>Birdsey</surname><given-names>Richard A</given-names></name>
        <name><surname>Phillips</surname><given-names>Oliver L</given-names></name>
        <name><surname>Houghton</surname><given-names>Richard A</given-names></name>
        <name><surname>Fang</surname><given-names>Jingyun</given-names></name>
        <name><surname>Kauppi</surname><given-names>Pekka E</given-names></name>
        <name><surname>Keith</surname><given-names>Heather</given-names></name>
        <name><surname>Kurz</surname><given-names>Werner A</given-names></name>
        <name><surname>Ito</surname><given-names>Akihiko</given-names></name>
        <name><surname>Lewis</surname><given-names>Simon L</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>The enduring world forest carbon sink</article-title>
      <source>Nature</source>
      <publisher-name>Nature Publishing Group UK London</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>631</volume>
      <issue>8021</issue>
      <pub-id pub-id-type="doi">10.1038/s41586-024-07602-x</pub-id>
      <fpage>563</fpage>
      <lpage>569</lpage>
    </element-citation>
  </ref>
  <ref id="ref-sharma2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sharma</surname><given-names>Sheenu</given-names></name>
        <name><surname>Hussain</surname><given-names>Sabir</given-names></name>
        <name><surname>Kumar</surname><given-names>Pardeep</given-names></name>
        <name><surname>Singh</surname><given-names>Anand Narain</given-names></name>
      </person-group>
      <article-title>Urban trees’ potential for regulatory services in the urban environment: An exploration of carbon sequestration</article-title>
      <source>Environmental Monitoring and Assessment</source>
      <publisher-name>Springer International Publishing Cham</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>196</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1007/s10661-024-12634-x</pub-id>
      <fpage>504</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-taimur_khan_2025">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Taimur Khan</string-name>
      </person-group>
      <article-title>DeepTrees_halle (revision 0c528b9)</article-title>
      <publisher-name>Hugging Face</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <uri> https://huggingface.co/datasets/thisistaimur/DeepTrees_Halle </uri>
      <pub-id pub-id-type="doi">10.57967/hf/4213</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wu2022">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Jiaxi</given-names></name>
        <name><surname>Chen</surname><given-names>Jiaxin</given-names></name>
        <name><surname>Huang</surname><given-names>Di</given-names></name>
      </person-group>
      <article-title>Entropy-based active learning for object detection with progressive diversity constraint</article-title>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2204.07965</pub-id>
      <fpage>9397</fpage>
      <lpage>9406</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PyTorchLightning24">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Falcon</surname><given-names>William</given-names></name>
        <string-name>The PyTorch Lightning team</string-name>
      </person-group>
      <article-title>PyTorch Lightning</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://github.com/Lightning-AI/lightning</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.3828935</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-fao2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Food</surname></name>
        <name><surname>United Nations</surname><given-names>Agriculture Organization of the</given-names></name>
      </person-group>
      <article-title>Global forest resources assessment 2022</article-title>
      <publisher-name>FAO</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.4060/cb9360en</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
