<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7341</article-id>
<article-id pub-id-type="doi">10.21105/joss.07341</article-id>
<title-group>
<article-title>TorchSurv: A Lightweight Package for Deep Survival
Analysis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6448-2051</contrib-id>
<name>
<surname>Monod</surname>
<given-names>Mélodie</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0003-2541-5181</contrib-id>
<name>
<surname>Krusche</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cao</surname>
<given-names>Qian</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sahiner</surname>
<given-names>Berkman</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Petrick</surname>
<given-names>Nicholas</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ohlssen</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7662-8724</contrib-id>
<name>
<surname>Coroller</surname>
<given-names>Thibaud</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Novartis Pharma AG, Switzerland</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Center for Devices and Radiological Health, Food and Drug
Administration, MD, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Novartis Pharmaceuticals Corporation, NJ, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-07-29">
<day>29</day>
<month>7</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>104</issue>
<fpage>7341</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Deep Learning</kwd>
<kwd>Survival Analysis</kwd>
<kwd>PyTorch</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>TorchSurv</monospace> is a Python
  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/torchsurv/">package</ext-link>
  that serves as a companion tool to perform deep survival modeling
  within the <monospace>PyTorch</monospace> environment
  (<xref alt="Paszke et al., 2019" rid="ref-paszke2019pytorch" ref-type="bibr">Paszke
  et al., 2019</xref>). With its lightweight design, minimal input
  requirements, full <monospace>PyTorch</monospace> backend, and freedom
  from restrictive parameterizations, <monospace>TorchSurv</monospace>
  facilitates efficient deep survival model implementation and is
  particularly beneficial for high-dimensional and complex data
  analyses. At its core, <monospace>TorchSurv</monospace> features
  calculations of log-likelihoods for prominent survival models (Cox
  proportional hazards model
  (<xref alt="Cox, 1972" rid="ref-Cox1972" ref-type="bibr">Cox,
  1972</xref>), Weibull Accelerated Time Failure (AFT) model
  (<xref alt="Carroll, 2003" rid="ref-Carroll2003" ref-type="bibr">Carroll,
  2003</xref>)) and offers evaluation metrics, including the
  time-dependent Area Under the Receiver Operating Characteristic (ROC)
  curve (AUC), the Concordance index (C-index) and the Brier Score.
  <monospace>TorchSurv</monospace> has been rigorously
  <ext-link ext-link-type="uri" xlink:href="https://opensource.nibr.com/torchsurv/benchmarks.html">tested</ext-link>
  using both open-source and synthetically generated survival data,
  against R and Python packages. The package is thoroughly documented
  and includes illustrative examples. The latest documentation for
  TorchSurv can be found on our
  <ext-link ext-link-type="uri" xlink:href="https://opensource.nibr.com/torchsurv/">website</ext-link>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Survival analysis plays a crucial role in various domains, such as
  medicine, economics or engineering. Sophisticated survival analysis
  using deep learning, often referred to as “deep survival analysis,”
  unlocks new opportunities to leverage new data types and uncover
  intricate relationships. However, performing comprehensive deep
  survival analysis remains challenging. Key issues include the lack of
  flexibility in existing tools to define survival model parameters with
  custom architectures and limitations in handling complex,
  high-dimensional datasets. Indeed, existing frameworks often lack the
  computational efficiency necessary to process large datasets
  efficiently, making them less suitable for real-world applications
  where time and resource constraints are paramount.</p>
  <p>To address these gaps, we propose a library that allows users to
  define survival model parameters using custom
  <monospace>PyTorch</monospace>-based neural network architectures. By
  combining computational efficiency with ease of use, this toolbox
  opens new opportunities to advance deep survival analysis research and
  application.
  <xref alt="[tab:bibliography]" rid="tabU003Abibliography">[tab:bibliography]</xref>
  compares the functionalities of <monospace>TorchSurv</monospace> with
  those of <monospace>auton-survival</monospace>
  (<xref alt="Nagpal et al., 2022" rid="ref-nagpal2022auton" ref-type="bibr">Nagpal
  et al., 2022</xref>), <monospace>pycox</monospace>
  (<xref alt="Kvamme et al., 2019" rid="ref-Kvamme2019pycox" ref-type="bibr">Kvamme
  et al., 2019</xref>), <monospace>torchlife</monospace>
  (<xref alt="Abeywardana, 2021" rid="ref-torchlifeAbeywardana" ref-type="bibr">Abeywardana,
  2021</xref>), <monospace>scikit-survival</monospace>
  (<xref alt="Pölsterl, 2020" rid="ref-polsterl2020scikit" ref-type="bibr">Pölsterl,
  2020</xref>), <monospace>lifelines</monospace>
  (<xref alt="Davidson-Pilon, 2019" rid="ref-davidson2019lifelines" ref-type="bibr">Davidson-Pilon,
  2019</xref>), and <monospace>deepsurv</monospace>
  (<xref alt="Katzman et al., 2018" rid="ref-katzman2018deepsurv" ref-type="bibr">Katzman
  et al., 2018</xref>). We notice that existing libraries constrain
  users to predefined functional forms for defining the parameters
  (e.g., linear function of covariates). Additionally, while there exist
  log-likelihood functions in the libraries, they cannot be leveraged.
  The limitations on the log-likelihood functions include protected
  functions (locked model architecture), specialized input requirements
  (format or class type), and reliance on external libraries like
  <monospace>NumPy</monospace> or <monospace>Pandas</monospace>.
  Dependence on external libraries hinders automatic gradient
  calculation within <monospace>PyTorch</monospace>. Additionally, the
  implementation of likelihood functions instead of log-likelihood
  functions, as done by some packages, introduces numerical
  instability.</p>
  <fig>
    <caption><p><bold>Survival analysis libraries in Python.</bold>
    <inline-formula><alternatives>
    <tex-math><![CDATA[^1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>1</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Nagpal et al., 2022" rid="ref-nagpal2022auton" ref-type="bibr">Nagpal
    et al., 2022</xref>), <inline-formula><alternatives>
    <tex-math><![CDATA[^{2}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Kvamme et al., 2019" rid="ref-Kvamme2019pycox" ref-type="bibr">Kvamme
    et al., 2019</xref>), <inline-formula><alternatives>
    <tex-math><![CDATA[^{3}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>3</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Abeywardana, 2021" rid="ref-torchlifeAbeywardana" ref-type="bibr">Abeywardana,
    2021</xref>), <inline-formula><alternatives>
    <tex-math><![CDATA[^{4}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>4</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Pölsterl, 2020" rid="ref-polsterl2020scikit" ref-type="bibr">Pölsterl,
    2020</xref>), <inline-formula><alternatives>
    <tex-math><![CDATA[^{5}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>5</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Davidson-Pilon, 2019" rid="ref-davidson2019lifelines" ref-type="bibr">Davidson-Pilon,
    2019</xref>), <inline-formula><alternatives>
    <tex-math><![CDATA[^{6}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mn>6</mml:mn></mml:msup></mml:math></alternatives></inline-formula>(<xref alt="Katzman et al., 2018" rid="ref-katzman2018deepsurv" ref-type="bibr">Katzman
    et al., 2018</xref>). A green tick indicates a fully supported
    feature, a red cross indicates an unsupported feature, a blue
    crossed tick indicates a partially supported feature. For computing
    the concordance index, <monospace>pycox</monospace> requires using
    the estimated survival function as the risk score and does not
    support other types of time-dependent risk scores.
    <monospace>scikit-survival</monospace> does not support
    time-dependent risk scores neither for the concordance index nor for
    the AUC computation. Additionally, both <monospace>pycox</monospace>
    and <monospace>scikit-survival</monospace> impose the use of inverse
    probability of censoring weighting (IPCW) for subject-specific
    weights. <monospace>scikit-survival</monospace> only offers the
    Breslow approximation of the Cox partial log-likelihood in case of
    ties in event
    time.<styled-content id="tabU003Abibliography"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="table_1.png" />
  </fig>
</sec>
<sec id="functionality">
  <title>Functionality</title>
  <sec id="loss-functions">
    <title>Loss functions</title>
    <p><bold>Cox loss function.</bold> The Cox loss function is defined
    as the negative of the Cox proportional hazards model’s partial
    log-likelihood
    (<xref alt="Cox, 1972" rid="ref-Cox1972" ref-type="bibr">Cox,
    1972</xref>). The function requires the subject-specific log
    relative hazards and the survival response (i.e., event indicator
    and time-to-event or time-to-censoring). The log relative hazards
    should be obtained from a <monospace>PyTorch</monospace>-based model
    pre-specified by the user. In case of ties in the event times, the
    user can choose between the Breslow method
    (<xref alt="Breslow, 1975" rid="ref-Breslow1975" ref-type="bibr">Breslow,
    1975</xref>) and the Efron method
    (<xref alt="Efron, 1977" rid="ref-Efron1977" ref-type="bibr">Efron,
    1977</xref>) to approximate the Cox partial log-likelihood.</p>
    <code language="python">from torchsurv.loss import cox

# PyTorch model outputs one log hazard per observation
my_cox_model = MyPyTorchCoxModel()

for data in dataloader:
    x, event, time = data  # covariate, event indicator, time
    log_hzs = my_cox_model(x)  # torch.Size([64, 1]), if batch size is 64 
    loss = cox.neg_partial_log_likelihood(log_hzs, event, time)
    loss.backward()  # native torch backend</code>
    <p><bold>Weibull loss function.</bold> The Weibull loss function is
    defined as the negative of the Weibull AFT’s log-likelihood
    (<xref alt="Carroll, 2003" rid="ref-Carroll2003" ref-type="bibr">Carroll,
    2003</xref>). The function requires the subject-specific log scale
    and log shape of the Weibull distribution and the survival response.
    The log parameters of the Weibull distribution should be obtained
    from a <monospace>PyTorch</monospace>-based model pre-specified by
    the user.</p>
    <code language="python">from torchsurv.loss import weibull

# PyTorch model outputs two Weibull parameters per observation
my_weibull_model = MyPyTorchWeibullModel() 

for data in dataloader:
    x, event, time = data
    log_params = my_weibull_model(x)  # torch.Size([64, 2]), if batch size is 64 
    loss = weibull.neg_log_likelihood(log_params, event, time)
    loss.backward()

# Log hazard can be obtained from Weibull parameters
log_hzs = weibull.log_hazard(log_params, time)</code>
    <p><bold>Momentum.</bold> Momentum helps train the model when the
    batch size is greatly limited by computational resources (i.e.,
    large files). This impacts the stability of model optimization,
    especially when rank-based loss is used. Inspired by MoCO
    (<xref alt="He et al., 2020" rid="ref-he2020momentum" ref-type="bibr">He
    et al., 2020</xref>), we implemented a momentum loss that decouples
    batch size from survival loss, increasing the effective batch size
    and allowing robust training of a model, even when using a very
    limited batch size (e.g., <inline-formula><alternatives>
    <tex-math><![CDATA[\leq 16]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).</p>
    <code language="python">from torchsurv.loss import Momentum

my_cox_model = MyPyTorchCoxModel()  
my_cox_loss = cox.neg_partial_log_likelihood  # works with any TorchSurv loss
model_momentum = Momentum(backbone=my_cox_model, loss=my_cox_loss)

for data in dataloader:
    x, event, time = data
    loss = model_momentum(x, event, time)  # torch.Size([16, 1])
    loss.backward()

# Inference is computed with target network (k)
log_hzs = model_momentum.infer(x)  # torch.Size([16, 1])</code>
  </sec>
  <sec id="evaluation-metrics-functions">
    <title>Evaluation Metrics Functions</title>
    <p>The <monospace>TorchSurv</monospace> package offers a
    comprehensive set of metrics to evaluate the predictive performance
    of survival models, including the AUC, C-index, and Brier score. The
    inputs of the evaluation metrics functions are the subject-specific
    risk score estimated on the test set and the survival response of
    the test set. The risk score measures the risk (or a proxy thereof)
    that a subject has an event. We provide definitions for each metric
    and demonstrate their use through illustrative code snippets.</p>
    <p><bold>AUC.</bold> The AUC measures the discriminatory capacity of
    the survival model at a given time <inline-formula><alternatives>
    <tex-math><![CDATA[t]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>,
    specifically the ability to reliably rank times-to-event based on
    estimated subject-specific risk scores
    (<xref alt="Blanche et al., 2013" rid="ref-Blanche2013" ref-type="bibr">Blanche
    et al., 2013</xref>;
    <xref alt="Heagerty &amp; Zheng, 2005" rid="ref-Heagerty2005" ref-type="bibr">Heagerty
    &amp; Zheng, 2005</xref>;
    <xref alt="Uno et al., 2007" rid="ref-Uno2007" ref-type="bibr">Uno
    et al., 2007</xref>).</p>
    <code language="python">from torchsurv.metrics.auc import Auc
auc = Auc()
auc(log_hzs, event, time)  # AUC at each time 
auc(log_hzs, event, time, new_time=torch.tensor(10.))  # AUC at time 10</code>
    <p><bold>C-index.</bold> The C-index is a generalization of the AUC
    that represents the assessment of the discriminatory capacity of the
    survival model across the entire time period
    (<xref alt="Harrell et al., 1996" rid="ref-Harrell1996" ref-type="bibr">Harrell
    et al., 1996</xref>;
    <xref alt="Uno et al., 2011" rid="ref-Uno_2011" ref-type="bibr">Uno
    et al., 2011</xref>).</p>
    <code language="python">from torchsurv.metrics.cindex import ConcordanceIndex
cindex = ConcordanceIndex()
cindex(log_hzs, event, time)</code>
    <p><bold>Brier Score.</bold> The Brier score evaluates the accuracy
    of a model at a given time <inline-formula><alternatives>
    <tex-math><![CDATA[t]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>
    (<xref alt="Graf et al., 1999" rid="ref-Graf_1999" ref-type="bibr">Graf
    et al., 1999</xref>). It represents the average squared distance
    between the observed survival status and the predicted survival
    probability. The Brier score cannot be obtained for the Cox
    proportional hazards model because the survival function is not
    estimated, but it can be obtained for the Weibull AFT model.</p>
    <code language="python">from torchsurv.metrics.brier_score import BrierScore
surv = weibull.survival_function(log_params, time) 
brier = Brier()
brier(surv, event, time)  # Brier score at each time
brier.integral()  # Integrated Brier score over time</code>
    <p><bold>Additional features.</bold> In
    <monospace>TorchSurv</monospace>, the evaluation metrics can be
    obtained for risk scores that are time-dependent and
    time-independent (e.g., for proportional and non-proportional
    hazards). Additionally, subjects can optionally be weighted (e.g.,
    by the inverse probability of censoring weighting (IPCW)). Lastly,
    functionalities including the confidence interval, a one-sample
    hypothesis test to determine whether the metric is better than that
    of a random predictor, and a two-sample hypothesis test to compare
    evaluation metrics obtained from two different models are
    implemented. The following code snippet exemplifies the
    aforementioned functionalities for the C-index.</p>
    <code language="python">cindex.confidence_interval()  # CI, default alpha=.05
cindex.p_value(alternative='greater')  # pvalue, H0:c=0.5, HA:c&gt;0.5
cindex.compare(cindex_other)  # pvalue, H0:c1=c2, HA:c1&gt;c2</code>
  </sec>
</sec>
<sec id="comprehensive-example-fitting-a-cox-proportional-hazards-model-with-torchsurv">
  <title>Comprehensive Example: Fitting a Cox Proportional Hazards Model
  with TorchSurv</title>
  <p>In this section, we provide a reproducible code example to
  demonstrate how to use <monospace>TorchSurv</monospace> for fitting a
  Cox proportional hazards model. We simulate data where each
  observations is associated with 10 features, a time-to-event that
  depends linearly on these features, and a time-to-censoring. The
  observable time is the minimum between the time-to-event and
  time-to-censoring, representing the first event that occurs.
  Subsequently, we fit a Cox proportional hazards model using maximum
  likelihood estimation and assess the model’s predictive performance
  through the AUC and the C-index. To facilitate rapid execution, we use
  a simple linear backend model in PyTorch to define the log relative
  hazards. For more comprehensive examples using real data, we encourage
  readers to visit the <monospace>Torchsurv</monospace> website.</p>
  <code language="python">import torch
from torch.utils.data import DataLoader, Dataset
from torchsurv.loss import cox
from torchsurv.metrics.cindex import ConcordanceIndex
from torchsurv.metrics.auc import Auc

torch.manual_seed(42)

# 1. Simulate response
n_features = 10  # int, number of features per observation
time_end = torch.tensor(
    2000.0
)  # float, end of observational period after which all observations are censored
weights = (
    torch.randn(n_features) * 5
)  # float, weights associated with the features ~ normal(0, 5^2)

# Define the survival response generator function
def tte_generator(batch_size: int):
    while True:
        x = torch.randn(batch_size, n_features)  # features
        mean_event_time, mean_censoring_time = 1000.0 + x @ weights, 1000.0

        event_time = (
            mean_event_time + torch.randn(batch_size) * 50
        )  # event time ~ normal(mean_event_time, 50^2)
        censoring_time = torch.distributions.Exponential(
            1 / mean_censoring_time
        ).sample(
            (batch_size,)
        )  # censoring time ~ Exponential(mean = mean_censoring_time)
        censoring_time = torch.minimum(
            censoring_time, time_end
        )  # truncate censoring time to time_end

        event = (event_time &lt;= censoring_time).bool()  # event indicator
        time = torch.minimum(event_time, censoring_time)  # observed time

        yield x, event, time

# 2. Define the PyTorch dataset class
class TTE_dataset(Dataset):
    def __init__(self, generator: callable, batch_size: int):
        self.batch_size = batch_size
        self.generatated_data = generator(batch_size=batch_size)

    def __len__(self):
        return self.batch_size

    def __getitem__(self, index):
        return next(self.generatated_data)

# 3. Define the backbone model on the log hazards.
class MyPyTorchCoxModel(torch.nn.Module):
    def __init__(self):
        super(MyPyTorchCoxModel, self).__init__()
        self.fc = torch.nn.Linear(n_features, 1, bias=False)  # Simple linear model

    def forward(self, x):
        return self.fc(x)

# 4. Instantiate the model, optimizer, dataset and dataloader
cox_model = MyPyTorchCoxModel()
optimizer = torch.optim.Adam(cox_model.parameters(), lr=0.01)
batch_size = 64  # int, batch size
dataset = TTE_dataset(tte_generator, batch_size=batch_size)
dataloader = DataLoader(
    dataset, batch_size=1, shuffle=True
)  # Batch size of 1 because dataset yields batches

# 5. Training loop
for epoch in range(100):
    for i, batch in enumerate(dataloader):
        x, event, time = [t.squeeze() for t in batch]  
        optimizer.zero_grad()
        log_hzs = cox_model(x)  # torch.Size([batch_size, 1])
        loss = cox.neg_partial_log_likelihood(log_hzs, event, time)
        loss.backward()
        optimizer.step()

# 6. Evaluate the model
n_samples_test = 1000  # int, number of observations in test set
data_test = next(tte_generator(batch_size=n_samples_test))
x, event, time = [t.squeeze() for t in data_test]  # test set
log_hzs = cox_model(x)  # log relative hazards evaluated on test set

# AUC at time point 1000
auc = Auc()
print(
    &quot;AUC:&quot;, auc(log_hzs, event, time, new_time=torch.tensor(1000.0))
)  # tensor([0.5902])
print(&quot;AUC Confidence Interval:&quot;, auc.confidence_interval())  # tensor([0.5623, 0.6180])
print(&quot;AUC p-value:&quot;, auc.p_value(alternative=&quot;greater&quot;))  # tensor([0.])

# C-index
cindex = ConcordanceIndex()
print(&quot;C-Index:&quot;, cindex(log_hzs, event, time))  # tensor(0.5774)
print(
    &quot;C-Index Confidence Interval:&quot;, cindex.confidence_interval()
)  # tensor([0.5086, 0.6463])
print(&quot;C-Index p-value:&quot;, cindex.p_value(alternative=&quot;greater&quot;))  # tensor(0.0138)</code>
</sec>
<sec id="conflicts-of-interest">
  <title>Conflicts of interest</title>
  <p>MM, PK, DO and TC are employees and stockholders of Novartis, a
  global pharmaceutical company.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-davidson2019lifelines">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Davidson-Pilon</surname><given-names>Cameron</given-names></name>
      </person-group>
      <article-title>Lifelines: Survival analysis in python</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2019">2019</year>
      <volume>4</volume>
      <issue>40</issue>
      <pub-id pub-id-type="doi">10.21105/joss.01317</pub-id>
      <fpage>1317</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-paszke2019pytorch">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
        <name><surname>Köpf</surname><given-names>Andreas</given-names></name>
        <name><surname>Yang</surname><given-names>Edward</given-names></name>
        <name><surname>DeVito</surname><given-names>Zach</given-names></name>
        <name><surname>Raison</surname><given-names>Martin</given-names></name>
        <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
        <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
        <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
        <name><surname>Fang</surname><given-names>Lu</given-names></name>
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <year iso-8601-date="2019">2019</year>
      <uri>https://arxiv.org/abs/1912.01703</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.01703</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-polsterl2020scikit">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pölsterl</surname><given-names>Sebastian</given-names></name>
      </person-group>
      <article-title>Scikit-survival: A library for time-to-event analysis built on top of scikit-learn</article-title>
      <source>The Journal of Machine Learning Research</source>
      <publisher-name>JMLRORG</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>21</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.5281/zenodo.3352342</pub-id>
      <fpage>8747</fpage>
      <lpage>8752</lpage>
    </element-citation>
  </ref>
  <ref id="ref-he2020momentum">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>He</surname><given-names>Kaiming</given-names></name>
        <name><surname>Fan</surname><given-names>Haoqi</given-names></name>
        <name><surname>Wu</surname><given-names>Yuxin</given-names></name>
        <name><surname>Xie</surname><given-names>Saining</given-names></name>
        <name><surname>Girshick</surname><given-names>Ross</given-names></name>
      </person-group>
      <article-title>Momentum contrast for unsupervised visual representation learning</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.1109/cvpr42600.2020.00975</pub-id>
      <fpage>9729</fpage>
      <lpage>9738</lpage>
    </element-citation>
  </ref>
  <ref id="ref-katzman2018deepsurv">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Katzman</surname><given-names>Jared L</given-names></name>
        <name><surname>Shaham</surname><given-names>Uri</given-names></name>
        <name><surname>Cloninger</surname><given-names>Alexander</given-names></name>
        <name><surname>Bates</surname><given-names>Jonathan</given-names></name>
        <name><surname>Jiang</surname><given-names>Tingting</given-names></name>
        <name><surname>Kluger</surname><given-names>Yuval</given-names></name>
      </person-group>
      <article-title>DeepSurv: Personalized treatment recommender system using a cox proportional hazards deep neural network</article-title>
      <source>BMC medical research methodology</source>
      <publisher-name>BioMed Central</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>18</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1186/s12874-018-0482-1</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Kvamme2019pycox">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kvamme</surname><given-names>Håvard</given-names></name>
        <name><surname>Borgan</surname></name>
        <name><surname>Scheel</surname><given-names>Ida</given-names></name>
      </person-group>
      <article-title>Time-to-event prediction with neural networks and cox regression</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2019">2019</year>
      <volume>20</volume>
      <issue>129</issue>
      <uri>http://jmlr.org/papers/v20/18-424.html</uri>
      <fpage>1</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nagpal2022auton">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Nagpal</surname><given-names>Chirag</given-names></name>
        <name><surname>Potosnak</surname><given-names>Willa</given-names></name>
        <name><surname>Dubrawski</surname><given-names>Artur</given-names></name>
      </person-group>
      <article-title>Auton-survival: An open-source package for regression, counterfactual estimation, evaluation and phenotyping with censored time-to-event data</article-title>
      <source>Machine learning for healthcare conference</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2204.07276</pub-id>
      <fpage>585</fpage>
      <lpage>608</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Cox1972">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cox</surname><given-names>D. R.</given-names></name>
      </person-group>
      <article-title>Regression models and life‐tables</article-title>
      <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="1972-01">1972</year><month>01</month>
      <volume>34</volume>
      <issue>2</issue>
      <issn>2517-6161</issn>
      <pub-id pub-id-type="doi">10.1007/978-1-4612-4380-9_37</pub-id>
      <fpage>187</fpage>
      <lpage>202</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Carroll2003">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Carroll</surname><given-names>Kevin J.</given-names></name>
      </person-group>
      <article-title>On the use and utility of the weibull model in the analysis of survival data</article-title>
      <source>Controlled Clinical Trials</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2003-12">2003</year><month>12</month>
      <volume>24</volume>
      <issue>6</issue>
      <issn>0197-2456</issn>
      <uri>http://dx.doi.org/10.1016/S0197-2456(03)00072-2</uri>
      <pub-id pub-id-type="doi">10.1016/s0197-2456(03)00072-2</pub-id>
      <fpage>682</fpage>
      <lpage>701</lpage>
    </element-citation>
  </ref>
  <ref id="ref-torchlifeAbeywardana">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Abeywardana</surname><given-names>Sachinthaka</given-names></name>
      </person-group>
      <source>Torchlife: Survival analysis using pytorch</source>
      <year iso-8601-date="2021">2021</year>
      <uri>https://sachinruk.github.io/torchlife//index.html</uri>
      <pub-id pub-id-type="doi">10.32614/CRAN.package.survival</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Heagerty2005">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heagerty</surname><given-names>Patrick J.</given-names></name>
        <name><surname>Zheng</surname><given-names>Yingye</given-names></name>
      </person-group>
      <article-title>Survival model predictive accuracy and ROC curves</article-title>
      <source>Biometrics</source>
      <publisher-name>Oxford University Press (OUP)</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <volume>61</volume>
      <issue>1</issue>
      <issn>1541-0420</issn>
      <uri>http://dx.doi.org/10.1111/j.0006-341x.2005.030814.x</uri>
      <pub-id pub-id-type="doi">10.1111/j.0006-341x.2005.030814.x</pub-id>
      <fpage>92</fpage>
      <lpage>105</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Blanche2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blanche</surname><given-names>Paul</given-names></name>
        <name><surname>Dartigues</surname><given-names>Jean‐François</given-names></name>
        <name><surname>Jacqmin‐Gadda</surname><given-names>Hélène</given-names></name>
      </person-group>
      <article-title>Review and comparison of ROC curve estimators for a time‐dependent outcome with marker‐dependent censoring</article-title>
      <source>Biometrical Journal</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2013-06">2013</year><month>06</month>
      <volume>55</volume>
      <issue>5</issue>
      <issn>1521-4036</issn>
      <uri>http://dx.doi.org/10.1002/bimj.201200045</uri>
      <pub-id pub-id-type="doi">10.1002/bimj.201200045</pub-id>
      <fpage>687</fpage>
      <lpage>704</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Uno2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Uno</surname><given-names>Hajime</given-names></name>
        <name><surname>Cai</surname><given-names>Tianxi</given-names></name>
        <name><surname>Tian</surname><given-names>Lu</given-names></name>
        <name><surname>Wei</surname><given-names>L. J</given-names></name>
      </person-group>
      <article-title>Evaluating prediction rules fort-year survivors with censored regression models</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Informa UK Limited</publisher-name>
      <year iso-8601-date="2007-06">2007</year><month>06</month>
      <volume>102</volume>
      <issue>478</issue>
      <issn>1537-274X</issn>
      <uri>http://dx.doi.org/10.1198/016214507000000149</uri>
      <pub-id pub-id-type="doi">10.1198/016214507000000149</pub-id>
      <fpage>527</fpage>
      <lpage>537</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Uno_2011">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Uno</surname><given-names>Hajime</given-names></name>
        <name><surname>Cai</surname><given-names>Tianxi</given-names></name>
        <name><surname>Pencina</surname><given-names>Michael J.</given-names></name>
        <name><surname>D’Agostino</surname><given-names>Ralph B.</given-names></name>
        <name><surname>Wei</surname><given-names>L. J.</given-names></name>
      </person-group>
      <article-title>On the c‐statistics for evaluating overall adequacy of risk prediction procedures with censored survival data</article-title>
      <source>Statistics in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>30</volume>
      <issue>10</issue>
      <issn>1097-0258</issn>
      <uri>http://dx.doi.org/10.1002/sim.4154</uri>
      <pub-id pub-id-type="doi">10.1002/sim.4154</pub-id>
      <fpage>1105</fpage>
      <lpage>1117</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Harrell1996">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harrell</surname><given-names>Frank E.</given-names></name>
        <name><surname>Lee</surname><given-names>Kerry L.</given-names></name>
        <name><surname>Mark</surname><given-names>Daniel B.</given-names></name>
      </person-group>
      <article-title>Multivariate prognostic models: Issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors</article-title>
      <source>Statistics in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="1996">1996</year>
      <volume>15</volume>
      <issue>4</issue>
      <issn>1097-0258</issn>
      <uri>http://dx.doi.org/10.1002/(SICI)1097-0258(19960229)15:4&lt;361::AID-SIM168&gt;3.0.CO;2-4</uri>
      <pub-id pub-id-type="doi">10.1002/(sici)1097-0258(19960229)15:4&lt;361::aid-sim168&gt;3.0.co;2-4</pub-id>
      <fpage>361</fpage>
      <lpage>387</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Graf_1999">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Graf</surname><given-names>Erika</given-names></name>
        <name><surname>Schmoor</surname><given-names>Claudia</given-names></name>
        <name><surname>Sauerbrei</surname><given-names>Willi</given-names></name>
        <name><surname>Schumacher</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Assessment and comparison of prognostic classification schemes for survival data</article-title>
      <source>Statistics in Medicine</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="1999">1999</year>
      <volume>18</volume>
      <issue>17–18</issue>
      <issn>1097-0258</issn>
      <uri>http://dx.doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18&lt;2529::AID-SIM274&gt;3.0.CO;2-5</uri>
      <pub-id pub-id-type="doi">10.1002/(sici)1097-0258(19990915/30)18:17/18&lt;2529::aid-sim274&gt;3.0.co;2-5</pub-id>
      <fpage>2529</fpage>
      <lpage>2545</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Efron1977">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Efron</surname><given-names>Bradley</given-names></name>
      </person-group>
      <article-title>The efficiency of cox’s likelihood function for censored data</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Informa UK Limited</publisher-name>
      <year iso-8601-date="1977-09">1977</year><month>09</month>
      <volume>72</volume>
      <issue>359</issue>
      <issn>1537-274X</issn>
      <uri>http://dx.doi.org/10.1080/01621459.1977.10480613</uri>
      <pub-id pub-id-type="doi">10.1080/01621459.1977.10480613</pub-id>
      <fpage>557</fpage>
      <lpage>565</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Breslow1975">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Breslow</surname><given-names>N. E.</given-names></name>
      </person-group>
      <article-title>Analysis of survival data under the proportional hazards model</article-title>
      <source>International Statistical Review / Revue Internationale de Statistique</source>
      <publisher-name>JSTOR</publisher-name>
      <year iso-8601-date="1975-04">1975</year><month>04</month>
      <volume>43</volume>
      <issue>1</issue>
      <issn>0306-7734</issn>
      <uri>http://dx.doi.org/10.2307/1402659</uri>
      <pub-id pub-id-type="doi">10.2307/1402659</pub-id>
      <fpage>45</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
