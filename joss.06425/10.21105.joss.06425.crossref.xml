<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20240503T073524-eed3b0c9c94cb1d53f1df49cc3d05257281c77d4</doi_batch_id>
    <timestamp>20240503073524</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>05</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>97</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>JeFaPaTo - A joint toolbox for blinking analysis and
facial features extraction</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Tim</given_name>
            <surname>Büchner</surname>
            <ORCID>https://orcid.org/0000-0002-6879-552X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Oliver</given_name>
            <surname>Mothes</surname>
            <ORCID>https://orcid.org/0000-0002-2294-3670</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Orlando</given_name>
            <surname>Guntinas-Lichius</surname>
            <ORCID>https://orcid.org/0000-0001-9671-0784</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Joachim</given_name>
            <surname>Denzler</surname>
            <ORCID>https://orcid.org/0000-0002-3193-3300</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>05</month>
          <day>03</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>6425</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06425</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.11085954</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6425</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06425</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06425</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06425.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="soukupovaRealTimeEyeBlink2016">
            <article_title>Real-Time Eye Blink Detection using Facial
Landmarks</article_title>
            <author>Soukupova</author>
            <cYear>2016</cYear>
            <unstructured_citation>Soukupova, T. (2016). Real-Time Eye
Blink Detection using Facial Landmarks. 8.
https://api.semanticscholar.org/CorpusID:35923299</unstructured_citation>
          </citation>
          <citation key="lugaresiMediaPipeFrameworkBuilding2019">
            <article_title>MediaPipe: A framework for perceiving and
processing reality</article_title>
            <author>Lugaresi</author>
            <journal_title>Third workshop on computer vision for AR/VR
at IEEE computer vision and pattern recognition (CVPR)
2019</journal_title>
            <doi>10.48550/arXiv.1906.08172</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Lugaresi, C., Tang, J., Nash, H.,
McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C.-L., Yong,
M., Lee, J., Chang, W.-T., Hua, W., Georg, M., &amp; Grundmann, M.
(2019). MediaPipe: A framework for perceiving and processing reality.
Third Workshop on Computer Vision for AR/VR at IEEE Computer Vision and
Pattern Recognition (CVPR) 2019.
https://doi.org/10.48550/arXiv.1906.08172</unstructured_citation>
          </citation>
          <citation key="kartynnikRealtimeFacialSurface2019a">
            <article_title>Real-time Facial Surface Geometry from
Monocular Video on Mobile GPUs</article_title>
            <author>Kartynnik</author>
            <journal_title>ArXiv</journal_title>
            <volume>abs/1907.06724</volume>
            <doi>10.48550/arXiv.1907.06724</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Kartynnik, Y., Ablavatski, A.,
Grishchenko, I., &amp; Grundmann, M. (2019). Real-time Facial Surface
Geometry from Monocular Video on Mobile GPUs. ArXiv, abs/1907.06724.
https://doi.org/10.48550/arXiv.1907.06724</unstructured_citation>
          </citation>
          <citation key="virtanenSciPyFundamentalAlgorithms2020">
            <article_title>SciPy 1.0: Fundamental algorithms for
scientific computing in Python</article_title>
            <author>Virtanen</author>
            <journal_title>Nature Methods</journal_title>
            <issue>3</issue>
            <volume>17</volume>
            <doi>10.1038/s41592-019-0686-2</doi>
            <issn>1548-7091</issn>
            <cYear>2020</cYear>
            <unstructured_citation>Virtanen, P., Gommers, R., Oliphant,
T. E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson,
P., Weckesser, W., Bright, J., van der Walt, S. J., Brett, M., Wilson,
J., Millman, K. J., Mayorov, N., Nelson, A. R. J., Jones, E., Kern, R.,
Larson, E., … Vázquez-Baeza, Y. (2020). SciPy 1.0: Fundamental
algorithms for scientific computing in Python. Nature Methods, 17(3),
261–272.
https://doi.org/10.1038/s41592-019-0686-2</unstructured_citation>
          </citation>
          <citation key="pyqtgraph">
            <article_title>PyQtGraph: Scientific graphics and GUI
library for python</article_title>
            <author>Campagnola</author>
            <journal_title>GitHub repository</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Campagnola, L. (2020). PyQtGraph:
Scientific graphics and GUI library for python. In GitHub repository.
GitHub. https://github.com/pyqtgraph/pyqtgraph</unstructured_citation>
          </citation>
          <citation key="qt6">
            <article_title>Qt</article_title>
            <author>The Qt Componany</author>
            <cYear>2023</cYear>
            <unstructured_citation>The Qt Componany. (2023). Qt.
https://www.qt.io/</unstructured_citation>
          </citation>
          <citation key="pyqt6">
            <article_title>PyQt6</article_title>
            <author>Riverbank Computing Limited</author>
            <cYear>2023</cYear>
            <unstructured_citation>Riverbank Computing Limited. (2023).
PyQt6.
https://www.riverbankcomputing.com/software/pyqt/</unstructured_citation>
          </citation>
          <citation key="anaconda">
            <article_title>Anaconda software
distribution</article_title>
            <journal_title>Anaconda Documentation</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Anaconda software distribution.
(2020). In Anaconda Documentation (Vers. 2-2.4.0). Anaconda Inc.
https://docs.anaconda.com/</unstructured_citation>
          </citation>
          <citation key="python">
            <volume_title>Python 3 reference manual</volume_title>
            <author>Van Rossum</author>
            <isbn>1441412697</isbn>
            <cYear>2009</cYear>
            <unstructured_citation>Van Rossum, G., &amp; Drake, F. L.
(2009). Python 3 reference manual. CreateSpace.
ISBN: 1441412697</unstructured_citation>
          </citation>
          <citation key="otsu">
            <article_title>A threshold selection method from gray-level
histograms</article_title>
            <author>Otsu</author>
            <journal_title>IEEE Transactions on Systems, Man, and
Cybernetics</journal_title>
            <issue>1</issue>
            <volume>9</volume>
            <doi>10.1109/TSMC.1979.4310076</doi>
            <cYear>1979</cYear>
            <unstructured_citation>Otsu, N. (1979). A threshold
selection method from gray-level histograms. IEEE Transactions on
Systems, Man, and Cybernetics, 9(1), 62–66.
https://doi.org/10.1109/TSMC.1979.4310076</unstructured_citation>
          </citation>
          <citation key="kwonHighspeedCameraCharacterization2013">
            <article_title>High-speed camera characterization of
voluntary eye blinking kinematics</article_title>
            <author>Kwon</author>
            <journal_title>Journal of the Royal Society,
Interface</journal_title>
            <issue>85</issue>
            <volume>10</volume>
            <doi>10.1098/rsif.2013.0227</doi>
            <issn>1742-5662</issn>
            <cYear>2013</cYear>
            <unstructured_citation>Kwon, K.-A., Shipley, R. J.,
Edirisinghe, M., Ezra, D. G., Rose, G., Best, S. M., &amp; Cameron, R.
E. (2013). High-speed camera characterization of voluntary eye blinking
kinematics. Journal of the Royal Society, Interface, 10(85), 20130227.
https://doi.org/10.1098/rsif.2013.0227</unstructured_citation>
          </citation>
          <citation key="vanderwerfBlinkRecoveryPatients2007">
            <article_title>Blink Recovery in Patients with Bell’s Palsy:
A Neurophysiological and Behavioral Longitudinal Study</article_title>
            <author>VanderWerf</author>
            <journal_title>Investigative Ophthalmology &amp; Visual
Science</journal_title>
            <issue>1</issue>
            <volume>48</volume>
            <doi>10.1167/iovs.06-0499</doi>
            <issn>1552-5783</issn>
            <cYear>2007</cYear>
            <unstructured_citation>VanderWerf, F., Reits, D., Smit, A.
E., &amp; Metselaar, M. (2007). Blink Recovery in Patients with Bell’s
Palsy: A Neurophysiological and Behavioral Longitudinal Study.
Investigative Ophthalmology &amp; Visual Science, 48(1), 203–213.
https://doi.org/10.1167/iovs.06-0499</unstructured_citation>
          </citation>
          <citation key="nuuttilaDiagnosticAccuracyGlabellar2021">
            <article_title>Diagnostic accuracy of glabellar tap sign for
Parkinson’s disease</article_title>
            <author>Nuuttila</author>
            <journal_title>Journal of Neural
Transmission</journal_title>
            <issue>11</issue>
            <volume>128</volume>
            <doi>10.1007/s00702-021-02391-3</doi>
            <issn>0300-9564</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Nuuttila, S., Eklund, M., Joutsa, J.,
Jaakkola, E., Mäkinen, E., Honkanen, E. A., Lindholm, K., Noponen, T.,
Ihalainen, T., Murtomäki, K., Nojonen, T., Levo, R., Mertsalmi, T.,
Scheperjans, F., &amp; Kaasinen, V. (2021). Diagnostic accuracy of
glabellar tap sign for Parkinson’s disease. Journal of Neural
Transmission, 128(11), 1655–1661.
https://doi.org/10.1007/s00702-021-02391-3</unstructured_citation>
          </citation>
          <citation key="vanderwerfEyelidMovementsBehavioral2003">
            <article_title>Eyelid movements: Behavioral studies of
blinking in humans under different stimulus conditions</article_title>
            <author>VanderWerf</author>
            <journal_title>Journal of Neurophysiology</journal_title>
            <issue>5</issue>
            <volume>89</volume>
            <doi>10.1152/jn.00557.2002</doi>
            <issn>0022-3077</issn>
            <cYear>2003</cYear>
            <unstructured_citation>VanderWerf, F., Brassinga, P., Reits,
D., Aramideh, M., &amp; Ongerboer de Visser, B. (2003). Eyelid
movements: Behavioral studies of blinking in humans under different
stimulus conditions. Journal of Neurophysiology, 89(5), 2784–2796.
https://doi.org/10.1152/jn.00557.2002</unstructured_citation>
          </citation>
          <citation key="cruzSpontaneousEyeblinkActivity2011">
            <article_title>Spontaneous eyeblink activity</article_title>
            <author>Cruz</author>
            <journal_title>The Ocular Surface</journal_title>
            <issue>1</issue>
            <volume>9</volume>
            <doi>10.1016/s1542-0124(11)70007-6</doi>
            <issn>1542-0124</issn>
            <cYear>2011</cYear>
            <unstructured_citation>Cruz, A. A. V., Garcia, D. M., Pinto,
C. T., &amp; Cechetti, S. P. (2011). Spontaneous eyeblink activity. The
Ocular Surface, 9(1), 29–41.
https://doi.org/10.1016/s1542-0124(11)70007-6</unstructured_citation>
          </citation>
          <citation key="volkInitialSeverityMotor2017">
            <article_title>Initial severity of motor and non-motor
disabilities in patients with facial palsy: An assessment using
patient-reported outcome measures</article_title>
            <author>Volk</author>
            <journal_title>European archives of oto-rhino-laryngology:
official journal of the European Federation of Oto-Rhino-Laryngological
Societies (EUFOS): affiliated with the German Society for
Oto-Rhino-Laryngology - Head and Neck Surgery</journal_title>
            <issue>1</issue>
            <volume>274</volume>
            <doi>10.1007/s00405-016-4018-1</doi>
            <issn>1434-4726</issn>
            <cYear>2017</cYear>
            <unstructured_citation>Volk, G. F., Granitzka, T., Kreysa,
H., Klingner, C. M., &amp; Guntinas-Lichius, O. (2017). Initial severity
of motor and non-motor disabilities in patients with facial palsy: An
assessment using patient-reported outcome measures. European Archives of
Oto-Rhino-Laryngology: Official Journal of the European Federation of
Oto-Rhino-Laryngological Societies (EUFOS): Affiliated with the German
Society for Oto-Rhino-Laryngology - Head and Neck Surgery, 274(1),
45–52. https://doi.org/10.1007/s00405-016-4018-1</unstructured_citation>
          </citation>
          <citation key="louReviewAutomatedFacial2020">
            <article_title>A Review on Automated Facial Nerve Function
Assessment From Visual Face Capture</article_title>
            <author>Lou</author>
            <journal_title>IEEE Transactions on Neural Systems and
Rehabilitation Engineering</journal_title>
            <issue>2</issue>
            <volume>28</volume>
            <doi>10.1109/TNSRE.2019.2961244</doi>
            <issn>1558-0210</issn>
            <cYear>2020</cYear>
            <unstructured_citation>Lou, J., Yu, H., &amp; Wang, F.-Y.
(2020). A Review on Automated Facial Nerve Function Assessment From
Visual Face Capture. IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 28(2), 488–497.
https://doi.org/10.1109/TNSRE.2019.2961244</unstructured_citation>
          </citation>
          <citation key="hochreiterMachineLearningBasedDetectingEyelid2023">
            <article_title>Machine-Learning-Based Detecting of Eyelid
Closure and Smiling Using Surface Electromyography of Auricular Muscles
in Patients with Postparalytic Facial Synkinesis: A Feasibility
Study</article_title>
            <author>Hochreiter</author>
            <journal_title>Diagnostics</journal_title>
            <issue>3</issue>
            <volume>13</volume>
            <doi>10.3390/diagnostics13030554</doi>
            <issn>2075-4418</issn>
            <cYear>2023</cYear>
            <unstructured_citation>Hochreiter, J., Hoche, E., Janik, L.,
Volk, G. F., Leistritz, L., Anders, C., &amp; Guntinas-Lichius, O.
(2023). Machine-Learning-Based Detecting of Eyelid Closure and Smiling
Using Surface Electromyography of Auricular Muscles in Patients with
Postparalytic Facial Synkinesis: A Feasibility Study. Diagnostics,
13(3), 554.
https://doi.org/10.3390/diagnostics13030554</unstructured_citation>
          </citation>
          <citation key="chenSmartphoneBasedArtificialIntelligenceAssisted2021">
            <article_title>Smartphone-Based Artificial
Intelligence-Assisted Prediction for Eyelid Measurements: Algorithm
Development and Observational Validation Study</article_title>
            <author>Chen</author>
            <journal_title>JMIR mHealth and uHealth</journal_title>
            <issue>10</issue>
            <volume>9</volume>
            <doi>10.2196/32444</doi>
            <issn>2291-5222</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Chen, H.-C., Tzeng, S.-S., Hsiao,
Y.-C., Chen, R.-F., Hung, E.-C., &amp; Lee, O. K. (2021).
Smartphone-Based Artificial Intelligence-Assisted Prediction for Eyelid
Measurements: Algorithm Development and Observational Validation Study.
JMIR mHealth and uHealth, 9(10), e32444.
https://doi.org/10.2196/32444</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
