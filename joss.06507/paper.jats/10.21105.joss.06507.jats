<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6507</article-id>
<article-id pub-id-type="doi">10.21105/joss.06507</article-id>
<title-group>
<article-title>PyXAB - A Python Library for
<inline-formula><alternatives>
<tex-math><![CDATA[\mathcal{X}]]></tex-math>
<mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-Armed
Bandit and Online Blackbox Optimization Algorithms</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1872-4595</contrib-id>
<name>
<surname>Li</surname>
<given-names>Wenjie</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Li</surname>
<given-names>Haoze</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Song</surname>
<given-names>Qifan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Honorio</surname>
<given-names>Jean</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Statistics, Purdue University,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>School of Computing and Information Systems, The University
of Melbourne, Australia</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-10-04">
<day>4</day>
<month>10</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>102</issue>
<fpage>6507</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>$\mathcal{X}$-Armed Bandit</kwd>
<kwd>Online Blackbox Optimization</kwd>
<kwd>Lipschitz Bandit</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We introduce a Python open-source library for
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit and online blackbox optimization named PyXAB. PyXAB contains
  the implementations of more than 10 <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit algorithms, such as <monospace>Zooming</monospace>,
  <monospace>StoSOO</monospace>, <monospace>HCT</monospace>, and the
  most recent works such as <monospace>GPO</monospace> and
  <monospace>VHCT</monospace>. PyXAB also provides the most
  commonly-used synthetic objectives to evaluate the performance of
  different algorithms and the various choices of the hierarchical
  partitions on the parameter space. The online documentation for PyXAB
  includes clear instructions for installation, straightforward
  examples, detailed feature descriptions, and a complete reference of
  the API. PyXAB is released under the MIT license in order to promote
  both academic and industrial usage. The library can be directly
  installed from PyPI with its source code available at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/WilliamLwj/PyXAB">https://github.com/WilliamLwj/PyXAB</ext-link>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Online blackbox optimization has become a heated research topic due
  to the recent popularity of machine learning models and thus the
  increasing demand for hyper-parameter tuning algorithms
  (<xref alt="L. Li et al., 2018" rid="ref-Li2018Hyperband" ref-type="bibr">L.
  Li et al., 2018</xref>;
  <xref alt="W. Li, Song, &amp; Honorio, 2024" rid="ref-Li2024Personalized" ref-type="bibr">W.
  Li, Song, &amp; Honorio, 2024</xref>;
  <xref alt="Shang et al., 2019" rid="ref-shang2019general" ref-type="bibr">Shang
  et al., 2019</xref>;
  <xref alt="Wang et al., 2023" rid="ref-wang2023federated" ref-type="bibr">Wang
  et al., 2023</xref>). Other applications, such as neural architecture
  search, federated learning, and personal investment portfolio designs,
  also contribute to its prosperity nowadays
  (<xref alt="W. Li et al., 2023" rid="ref-li2021optimumstatistical" ref-type="bibr">W.
  Li et al., 2023</xref>;
  <xref alt="W. Li, Song, Honorio, &amp; Lin, 2024" rid="ref-Li2022Federated" ref-type="bibr">W.
  Li, Song, Honorio, &amp; Lin, 2024</xref>). Different online blackbox
  optimization algorithms, e.g., Bayesian Optimization algorithms
  (<xref alt="Shahriari et al., 2016" rid="ref-Shahriari2016Taking" ref-type="bibr">Shahriari
  et al., 2016</xref>) and two-point evaluation methods
  (<xref alt="Duchi et al., 2015" rid="ref-DuchiOptimal" ref-type="bibr">Duchi
  et al., 2015</xref>;
  <xref alt="Shamir, 2015" rid="ref-Shamir2015An" ref-type="bibr">Shamir,
  2015</xref>) have been proposed.</p>
  <p>Apart from the aforementioned works, another very famous line of
  research is <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit, also known as Lipschitz bandit, global optimization or
  bandit-based blackbox optimization
  (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
  et al., 2019</xref>;
  <xref alt="Bubeck et al., 2011" rid="ref-bubeck2011X" ref-type="bibr">Bubeck
  et al., 2011</xref>;
  <xref alt="Grill et al., 2015" rid="ref-Grill2015Blackbox" ref-type="bibr">Grill
  et al., 2015</xref>;
  <xref alt="Kleinberg et al., 2008" rid="ref-kleinberg2008multi-armed" ref-type="bibr">Kleinberg
  et al., 2008</xref>). In this field, researchers split the parameter
  domain <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>
  into smaller and smaller sub-domains (commonly known as nodes)
  hierarchically, and treat each sub-domain to be an un-evaluated arm as
  in the multi-armed bandit problems
  (<xref alt="Azar et al., 2014" rid="ref-azar2014online" ref-type="bibr">Azar
  et al., 2014</xref>;
  <xref alt="Bubeck et al., 2011" rid="ref-bubeck2011X" ref-type="bibr">Bubeck
  et al., 2011</xref>). However, such <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit problems are much harder than their multi-armed counterparts,
  since the number of sub-domains increases exponentially as the
  partition grows, and the hierarchical structure/Lipschitzness
  assumption implies internal correlations between the ‚Äúarms‚Äù.
  Therefore, directly applying multi-armed bandit algorithms to such
  problems would be infeasible and more complicated algorithms are
  developed
  (<xref alt="Grill et al., 2015" rid="ref-Grill2015Blackbox" ref-type="bibr">Grill
  et al., 2015</xref>;
  <xref alt="W. Li et al., 2023" rid="ref-li2021optimumstatistical" ref-type="bibr">W.
  Li et al., 2023</xref>;
  <xref alt="Shang et al., 2019" rid="ref-shang2019general" ref-type="bibr">Shang
  et al., 2019</xref>).</p>
  <p>Despite the popularity of this area, most of the algorithms
  proposed by the researchers are either not open-sourced or implemented
  in different programming languages in disjoint packages. For example,
  <monospace>StoSOO</monospace>(<xref alt="Valko et al., 2013" rid="ref-Valko13Stochastic" ref-type="bibr">Valko
  et al., 2013</xref>) is implemented in MATLAB and
  C<xref ref-type="fn" rid="fn1">1</xref>, whereas
  <monospace>HOO</monospace>
  (<xref alt="Bubeck et al., 2011" rid="ref-bubeck2011X" ref-type="bibr">Bubeck
  et al., 2011</xref>) is implemented in
  Python<xref ref-type="fn" rid="fn2">2</xref>. For most of the other
  algorithms, no open-sourced implementations could be found on the
  internet. We believe the lack of such resources results from the
  following two main reasons.</p>
  <list list-type="bullet">
    <list-item>
      <p>The algorithms are long and intrinsically hard to implement due
      to the heavy usage of hierarchical partitions, node sampling, and
      the exploration-exploitation strategies that involve building,
      maintaining, and expanding complicated tree structures. It is
      hence time-consuming to implement and test one single
      algorithm.</p>
    </list-item>
    <list-item>
      <p>The problem settings for the algorithms could be slightly
      different. Some algorithms such as <monospace>HOO</monospace>
      (<xref alt="Bubeck et al., 2011" rid="ref-bubeck2011X" ref-type="bibr">Bubeck
      et al., 2011</xref>) and <monospace>HCT</monospace>
      (<xref alt="Azar et al., 2014" rid="ref-azar2014online" ref-type="bibr">Azar
      et al., 2014</xref>) are designed for the setting where the
      function evaluations can be noisy, while
      <monospace>SequOOL</monospace>
      (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
      et al., 2019</xref>) is proposed for the noiseless case. Some
      algorithms focus on cumulative-regret optimization whereas some
      only care about the last-point regret or the simple
      regret<xref ref-type="fn" rid="fn3">3</xref>. Therefore,
      experimental comparisons often focus on a small subset of
      algorithms, see e.g.,
      (<xref alt="Azar et al., 2014" rid="ref-azar2014online" ref-type="bibr">Azar
      et al., 2014</xref>),
      (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
      et al., 2019</xref>). The unavailability of a general package only
      deteriorates the situation.</p>
    </list-item>
  </list>
  <p>In Table
  <xref alt="[tab:summary]" rid="tabU003Asummary">[tab:summary]</xref>,
  we provide the comparison among some of the algorithms implemented in
  PyXAB, including <monospace>HOO</monospace>
  (<xref alt="Bubeck et al., 2011" rid="ref-bubeck2011X" ref-type="bibr">Bubeck
  et al., 2011</xref>), <monospace>DOO</monospace>
  (<xref alt="Munos, 2011" rid="ref-Munos2011Optimistic" ref-type="bibr">Munos,
  2011</xref>), <monospace>StoSOO</monospace>
  (<xref alt="Valko et al., 2013" rid="ref-Valko13Stochastic" ref-type="bibr">Valko
  et al., 2013</xref>), <monospace>HCT</monospace>
  (<xref alt="Azar et al., 2014" rid="ref-azar2014online" ref-type="bibr">Azar
  et al., 2014</xref>), <monospace>POO</monospace>
  (<xref alt="Grill et al., 2015" rid="ref-Grill2015Blackbox" ref-type="bibr">Grill
  et al., 2015</xref>) <monospace>GPO</monospace>
  (<xref alt="Shang et al., 2019" rid="ref-shang2019general" ref-type="bibr">Shang
  et al., 2019</xref>), <monospace>SequOOL</monospace>
  (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
  et al., 2019</xref>), <monospace>StroquOOL</monospace>
  (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
  et al., 2019</xref>), <monospace>VROOM</monospace>
  (<xref alt="Ammar et al., 2020" rid="ref-ammar20derivative" ref-type="bibr">Ammar
  et al., 2020</xref>). and <monospace>VHCT</monospace>
  (<xref alt="W. Li et al., 2023" rid="ref-li2021optimumstatistical" ref-type="bibr">W.
  Li et al., 2023</xref>).</p>
  <boxed-text id="tabU003Asummary">
    <table-wrap>
      <caption>
        <p>Selected examples of <inline-formula><alternatives>
        <tex-math><![CDATA[\mathcal{X}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
        bandit algorithms implemented in our library.
        <italic>Cumulative</italic>: whether the algorithm focuses on
        optimizing cumulative regret or simple regret.
        <italic>Stochastic</italic>: whether the algorithm deals with
        noisy rewards. <italic>Open-sourced?</italic>: the code
        availability before the development of PyXAB.</p>
      </caption>
      <table>
        <thead>
          <tr>
            <th align="left"><inline-formula><alternatives>
            <tex-math><![CDATA[\mathcal{X}]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-Armed
            Bandit Algorithm</th>
            <th align="center">Cumulative</th>
            <th align="center">Stochastic</th>
            <th align="center">Open-sourced?</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left"><monospace>HOO</monospace></td>
            <td align="center">yes</td>
            <td align="center">yes</td>
            <td align="center">yes (Python)</td>
          </tr>
          <tr>
            <td align="left"><monospace>DOO</monospace></td>
            <td align="center">no</td>
            <td align="center">no</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>StoSOO</monospace></td>
            <td align="center">no</td>
            <td align="center">yes</td>
            <td align="center">yes (MATLAB, C)</td>
          </tr>
          <tr>
            <td align="left"><monospace>HCT</monospace></td>
            <td align="center">yes</td>
            <td align="center">yes</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>POO</monospace></td>
            <td align="center">no</td>
            <td align="center">yes</td>
            <td align="center">yes (Python, R)</td>
          </tr>
          <tr>
            <td align="left"><monospace>GPO</monospace></td>
            <td align="center">no</td>
            <td align="center">yes</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>SequOOL</monospace></td>
            <td align="center">no</td>
            <td align="center">no</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>StroquOOL</monospace></td>
            <td align="center">no</td>
            <td align="center">yes</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>VROOM</monospace></td>
            <td align="center">no</td>
            <td align="center">no</td>
            <td align="center">no</td>
          </tr>
          <tr>
            <td align="left"><monospace>VHCT</monospace></td>
            <td align="center">yes</td>
            <td align="center">yes</td>
            <td align="center">no</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </boxed-text>
  <p><styled-content id="tabU003Asummary"></styled-content></p>
  <p>To remove the barriers for future research in this area, we have
  developed PyXAB, a Python library of the existing popular
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit algorithms. To the best of our knowledge, this is the first
  comprehensive library for <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit, with clear documentations and user-friendly API
  references.</p>
</sec>
<sec id="library-design-and-usage">
  <title>Library Design and Usage</title>
  <fig>
    <caption><p>An overview of the PyXAB library
    structure.<styled-content id="figU003AU0020overview"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="Presentation1.pdf" />
  </fig>
  <p>The API of PyXAB is designed to follow the
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit learning paradigm and to allow the maximum freedom of usage. We
  provide an overview of the library in Figure
  <xref alt="[fig: overview]" rid="figU003AU0020overview">[fig: overview]</xref>.</p>
  <p><bold>Algorithm</bold>. All the algorithms inherit the abstract
  class <monospace>Algorithm</monospace>. Each algorithm will implement
  two kinds of actions via: (1) a <monospace>pull()</monospace> function
  that returns the chosen point to be evaluated by the objective; (2) a
  <monospace>receive_reward()</monospace> function to collect the
  evaluation result and update the algorithm behavior.</p>
  <p><bold>Partition</bold>. Given any parameter domain, the user is
  able to choose any partition of the domain as part of the input of the
  optimization algorithm. All implemented partitions inherit the
  <monospace>Partition</monospace> class, which has useful base
  functions such as <monospace>deepen</monospace> and
  <monospace>get_node_list</monospace>. Each specific partition class
  needs to implement a unique <monospace>make_children()</monospace>
  function that split one parent node into the children nodes and
  maintain the tree structure. For implementation convenience, the
  package also provides a few built-in choices such as
  <monospace>BinaryPartition</monospace> and
  <monospace>RandomBinaryPartition</monospace>.</p>
  <p><bold>Node</bold>. The base node class used in any partition is
  <monospace>P_node</monospace>, which contains useful helper functions
  to store domain information and maintain the partition structure.
  However, we allow the algorithms to overwrite the node choices in any
  partition so that node-wise operations are allowed. For example, the
  <monospace>StoSOO</monospace> algorithm needs to compute and store the
  <inline-formula><alternatives>
  <tex-math><![CDATA[b_{h,i}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>-value
  for each node
  (<xref alt="Valko et al., 2013" rid="ref-Valko13Stochastic" ref-type="bibr">Valko
  et al., 2013</xref>). The <monospace>StroquOOL</monospace> algorithm
  needs to record the number of times a node is opened
  (<xref alt="Bartlett et al., 2019" rid="ref-bartlett2019simple" ref-type="bibr">Bartlett
  et al., 2019</xref>). Therefore, different node classes are
  implemented for these algorithms.</p>
  <p><bold>Objective</bold>. For all the objectives implemented in this
  package, they all inherit the <monospace>Objective</monospace> class
  and all have a function <monospace>f()</monospace> that returns the
  evaluation result of a given point. We also provide the commonly used
  synthetic objectives which are used to evaluate the performance of
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùí≥</mml:mi></mml:math></alternatives></inline-formula>-armed
  bandit algorithms in research papers, such as
  <monospace>Garland</monospace>, <monospace>DoubleSine</monospace>, and
  <monospace>Himmelblau</monospace>.</p>
  <p>The usage of the PyXAB library is rather straightforward. Given the
  number of rounds, the objective function, and the parameter domain,
  the learner would choose the partition of the parameter space and the
  bandit algorithm. Then in each round, the learner obtains one point
  from the algorithm, evaluate it on the objective, and return the
  reward to the algorithm. The following snippet of code provides an
  example of optimizing the Garland synthetic objective on the domain
  <inline-formula><alternatives>
  <tex-math><![CDATA[[[0, 1]]]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
  by running the <monospace>HCT</monospace> algorithm with
  <monospace>BinaryPartition</monospace> for 1000 iterations. As can be
  observed, only about ten lines of code are needed for the optimization
  process apart from the import statements.</p>
  <code language="python">from PyXAB.synthetic_obj.Garland import Garland
from PyXAB.algos.HCT import HCT

# Define the number of rounds, target, domain, and algorithm
T = 1000
target = Garland()
domain = [[0, 1]]
algo = HCT(domain=domain)

# Run the algorithm HCT
for t in range(1, T+1):
    point = algo.pull(t)
    reward = target.f(point)
    algo.receive_reward(t, reward)</code>
</sec>
<sec id="code-quality-and-documentations">
  <title>Code Quality and Documentations</title>
  <p>In order to ensure high code quality, we follow the
  <monospace>PEP8</monospace> style and format all of our code using the
  <monospace>black</monospace>
  package<xref ref-type="fn" rid="fn4">4</xref>. We use the
  <monospace>pytest</monospace> package to test our implementations with
  different corner cases. More than 99% of our code is covered by the
  tests and Github workflows automatically generate a coverage report
  upon each push or pull request on the main
  branch<xref ref-type="fn" rid="fn5">5</xref>.</p>
  <p>We provide detailed API documentations for each of the implemented
  classes and functions through numpy docstrings. The documentation is
  fully available online on
  ReadTheDocs<xref ref-type="fn" rid="fn6">6</xref>. On the same
  website, we also provide installation guides, algorithm introductions,
  both elementary and advanced examples of using our package, as well as
  detailed contributing instructions and new feature implementation
  examples to encourage future contributions.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Li2018Hyperband">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Lisha</given-names></name>
        <name><surname>Jamieson</surname><given-names>Kevin</given-names></name>
        <name><surname>DeSalvo</surname><given-names>Giulia</given-names></name>
        <name><surname>Rostamizadeh</surname><given-names>Afshin</given-names></name>
        <name><surname>Talwalkar</surname><given-names>Ameet</given-names></name>
      </person-group>
      <article-title>Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2018">2018</year>
      <volume>18</volume>
      <issue>185</issue>
      <fpage>1</fpage>
      <lpage>52</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ammar20derivative">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ammar</surname><given-names>Haitham</given-names></name>
        <name><surname>Gabillon</surname><given-names>Victor</given-names></name>
        <name><surname>Tutunov</surname><given-names>Rasul</given-names></name>
        <name><surname>Valko</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>Derivative-free order-robust optimisation</article-title>
      <source>Proceedings of the twenty third international conference on artificial intelligence and statistics</source>
      <person-group person-group-type="editor">
        <name><surname>Chiappa</surname><given-names>Silvia</given-names></name>
        <name><surname>Calandra</surname><given-names>Roberto</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>108</volume>
      <fpage>2293</fpage>
      <lpage>2303</lpage>
    </element-citation>
  </ref>
  <ref id="ref-shang2019general">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Shang</surname><given-names>Xuedong</given-names></name>
        <name><surname>Kaufmann</surname><given-names>Emilie</given-names></name>
        <name><surname>Valko</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>General parallel optimization a without metric</article-title>
      <source>Algorithmic learning theory</source>
      <year iso-8601-date="2019">2019</year>
      <fpage>762</fpage>
      <lpage>788</lpage>
    </element-citation>
  </ref>
  <ref id="ref-azar2014online">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Azar</surname><given-names>Mohammad Gheshlaghi</given-names></name>
        <name><surname>Lazaric</surname><given-names>Alessandro</given-names></name>
        <name><surname>Brunskill</surname><given-names>Emma</given-names></name>
      </person-group>
      <article-title>Online stochastic optimization under correlated bandit feedback</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <fpage>1557</fpage>
      <lpage>1565</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bubeck2011X">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bubeck</surname><given-names>S√©bastien</given-names></name>
        <name><surname>Munos</surname><given-names>R√©mi</given-names></name>
        <name><surname>Stoltz</surname><given-names>Gilles</given-names></name>
        <name><surname>Szepesv√°ri</surname><given-names>Csaba</given-names></name>
      </person-group>
      <article-title>\chi-armed bandits</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2011">2011</year>
      <volume>12</volume>
      <issue>46</issue>
      <fpage>1655</fpage>
      <lpage>1695</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Grill2015Blackbox">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Grill</surname><given-names>Jean-Bastien</given-names></name>
        <name><surname>Valko</surname><given-names>Michal</given-names></name>
        <name><surname>Munos</surname><given-names>Remi</given-names></name>
        <name><surname>Munos</surname><given-names>Remi</given-names></name>
      </person-group>
      <article-title>Black-box optimization of noisy functions with unknown smoothness</article-title>
      <source>Advances in neural information processing systems</source>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-bartlett2019simple">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bartlett</surname><given-names>Peter L.</given-names></name>
        <name><surname>Gabillon</surname><given-names>Victor</given-names></name>
        <name><surname>Valko</surname><given-names>Michal</given-names></name>
      </person-group>
      <article-title>A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption</article-title>
      <source>30th international conference on algorithmic learning theory</source>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-Munos2011Optimistic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Munos</surname><given-names>R√©mi</given-names></name>
      </person-group>
      <article-title>Optimistic optimization of a deterministic function without the knowledge of its smoothness</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name>
        <name><surname>Zemel</surname><given-names>R.</given-names></name>
        <name><surname>Bartlett</surname><given-names>P.</given-names></name>
        <name><surname>Pereira</surname><given-names>F.</given-names></name>
        <name><surname>Weinberger</surname><given-names>K. Q.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>24</volume>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Valko13Stochastic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Valko</surname><given-names>Michal</given-names></name>
        <name><surname>Carpentier</surname><given-names>Alexandra</given-names></name>
        <name><surname>Munos</surname><given-names>R√©mi</given-names></name>
      </person-group>
      <article-title>Stochastic simultaneous optimistic optimization</article-title>
      <source>Proceedings of the 30th international conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <volume>28</volume>
      <fpage>19</fpage>
      <lpage>27</lpage>
    </element-citation>
  </ref>
  <ref id="ref-li2021optimumstatistical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Wenjie</given-names></name>
        <name><surname>Wang</surname><given-names>Chi-Hua</given-names></name>
        <name><surname>Cheng</surname><given-names>Guang</given-names></name>
        <name><surname>Song</surname><given-names>Qifan</given-names></name>
      </person-group>
      <article-title>Optimum-statistical collaboration towards general and efficient black-box optimization</article-title>
      <source>Transactions on Machine Learning Research</source>
      <year iso-8601-date="2023">2023</year>
      <issn>2835-8856</issn>
      <uri>https://openreview.net/forum?id=ClIcmwdlxn</uri>
    </element-citation>
  </ref>
  <ref id="ref-kleinberg2008multi-armed">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Kleinberg</surname><given-names>Robert</given-names></name>
        <name><surname>Slivkins</surname><given-names>Aleksandrs</given-names></name>
        <name><surname>Upfal</surname><given-names>Eli</given-names></name>
      </person-group>
      <article-title>Multi-armed bandits in metric spaces</article-title>
      <source>Proceedings of the fortieth annual ACM symposium on theory of computing</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2008">2008</year>
      <isbn>9781605580470</isbn>
      <pub-id pub-id-type="doi">10.1145/1374376.1374475</pub-id>
      <fpage>681</fpage>
      <lpage>690</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Shahriari2016Taking">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Shahriari</surname><given-names>Bobak</given-names></name>
        <name><surname>Swersky</surname><given-names>Kevin</given-names></name>
        <name><surname>Wang</surname><given-names>Ziyu</given-names></name>
        <name><surname>Adams</surname><given-names>Ryan P.</given-names></name>
        <name><surname>Freitas</surname><given-names>Nando de</given-names></name>
      </person-group>
      <article-title>Taking the human out of the loop: A review of bayesian optimization</article-title>
      <source>Proceedings of the IEEE</source>
      <year iso-8601-date="2016">2016</year>
      <volume>104</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1109/JPROC.2015.2494218</pub-id>
      <fpage>148</fpage>
      <lpage>175</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2023federated">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Chi-Hua</given-names></name>
        <name><surname>Li</surname><given-names>Wenjie</given-names></name>
        <name><surname>Lin</surname><given-names>Guang</given-names></name>
      </person-group>
      <article-title>Federated high-dimensional online decision making</article-title>
      <source>Transactions on Machine Learning Research</source>
      <year iso-8601-date="2023">2023</year>
      <issn>2835-8856</issn>
      <uri>https://openreview.net/forum?id=TjaMO63fc9</uri>
    </element-citation>
  </ref>
  <ref id="ref-DuchiOptimal">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Duchi</surname><given-names>John C.</given-names></name>
        <name><surname>Jordan</surname><given-names>Michael I.</given-names></name>
        <name><surname>Wainwright</surname><given-names>Martin J.</given-names></name>
        <name><surname>Wibisono</surname><given-names>Andre</given-names></name>
      </person-group>
      <article-title>Optimal rates for zero-order convex optimization: The power of two function evaluations</article-title>
      <source>IEEE Transactions on Information Theory</source>
      <year iso-8601-date="2015">2015</year>
      <volume>61</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1109/TIT.2015.2409256</pub-id>
      <fpage>2788</fpage>
      <lpage>2806</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Shamir2015An">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Shamir</surname><given-names>Ohad</given-names></name>
      </person-group>
      <article-title>An optimal algorithm for bandit and zero-order convex optimization with two-point feedback</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2015-07">2015</year><month>07</month>
      <volume>18</volume>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Li2022Federated">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Wenjie</given-names></name>
        <name><surname>Song</surname><given-names>Qifan</given-names></name>
        <name><surname>Honorio</surname><given-names>Jean</given-names></name>
        <name><surname>Lin</surname><given-names>Guang</given-names></name>
      </person-group>
      <article-title>Federated x-armed bandit</article-title>
      <source>Proceedings of the AAAI Conference on Artificial Intelligence</source>
      <year iso-8601-date="2024">2024</year>
      <volume>38</volume>
      <issue>12</issue>
      <uri>https://ojs.aaai.org/index.php/AAAI/article/view/29267</uri>
      <pub-id pub-id-type="doi">10.1609/aaai.v38i12.29267</pub-id>
      <fpage>13628</fpage>
      <lpage>13636</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Li2024Personalized">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Wenjie</given-names></name>
        <name><surname>Song</surname><given-names>Qifan</given-names></name>
        <name><surname>Honorio</surname><given-names>Jean</given-names></name>
      </person-group>
      <article-title>Personalized federated X-armed bandit</article-title>
      <source>Proceedings of the 27th international conference on artificial intelligence and statistics</source>
      <person-group person-group-type="editor">
        <name><surname>Dasgupta</surname><given-names>Sanjoy</given-names></name>
        <name><surname>Mandt</surname><given-names>Stephan</given-names></name>
        <name><surname>Li</surname><given-names>Yingzhen</given-names></name>
      </person-group>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>238</volume>
      <uri>https://proceedings.mlr.press/v238/li24a.html</uri>
      <fpage>37</fpage>
      <lpage>45</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p><ext-link ext-link-type="uri" xlink:href="https://team.inria.fr/sequel/software/">https://team.inria.fr/sequel/software/</ext-link></p>
  </fn>
  <fn id="fn2">
    <label>2</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/ardaegeunlu/X-armed-Bandits">https://github.com/ardaegeunlu/X-armed-Bandits</ext-link></p>
  </fn>
  <fn id="fn3">
    <label>3</label><p>A more detailed discussion on simple regret and
    cumulative regret can be found in [@bubeck2011X]</p>
  </fn>
  <fn id="fn4">
    <label>4</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/psf/black">https://github.com/psf/black</ext-link></p>
  </fn>
  <fn id="fn5">
    <label>5</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/WilliamLwj/PyXAB">https://github.com/WilliamLwj/PyXAB</ext-link></p>
  </fn>
  <fn id="fn6">
    <label>6</label><p><ext-link ext-link-type="uri" xlink:href="https://pyxab.readthedocs.io/">https://pyxab.readthedocs.io/</ext-link></p>
  </fn>
</fn-group>
</back>
</article>
