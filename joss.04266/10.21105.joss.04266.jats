<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4266</article-id>
<article-id pub-id-type="doi">10.21105/joss.04266</article-id>
<title-group>
<article-title>OTTO: A Python package to simulate, solve and visualize
the source-tracking POMDP</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">0000-0002-8089-8636</contrib-id>
<name>
<surname>Loisy</surname>
<given-names>Aurore</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">0000-0003-4114-7263</contrib-id>
<name>
<surname>Eloy</surname>
<given-names>Christophe</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-2"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Aix Marseille Univ, CNRS, Centrale Marseille, IRPHE,
Marseille, France</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
<corresp id="cor-2">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-03-07">
<day>7</day>
<month>3</month>
<year>2022</year>
</pub-date>
<volume>7</volume>
<issue>74</issue>
<fpage>4266</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>olfactory search</kwd>
<kwd>source tracking</kwd>
<kwd>POMDP</kwd>
<kwd>reinforcement learning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The source-tracking problem is a POMDP (partially observable Markov
  decision process) designed by Vergassola et al.
  (<xref alt="2007" rid="ref-Vergassola2007" ref-type="bibr">2007</xref>)
  to mimic the problem of searching for a source of odor in a turbulent
  flow. Far from being a “toy” POMDP, it incorporates physical models of
  odor dispersion and detection that reproduce the major features of
  olfactory searches in turbulence. Solutions to this problem, even
  approximate, have direct applications to sniffer robots used to track
  chemicals emitted by explosives, drugs or chemical leaks
  (<xref alt="Marques &amp; Almeida, 2006" rid="ref-Marques2006" ref-type="bibr">Marques
  &amp; Almeida, 2006</xref>;
  <xref alt="Russell, 1999" rid="ref-Russell1999" ref-type="bibr">Russell,
  1999</xref>). They may also shed light on how cognitive animals use
  olfaction to search for food and mates
  (<xref alt="Reddy et al., 2022" rid="ref-Reddy2022" ref-type="bibr">Reddy
  et al., 2022</xref>;
  <xref alt="Vickers, 2000" rid="ref-Vickers2000" ref-type="bibr">Vickers,
  2000</xref>).</p>
  <p>In the source-tracking POMDP, the agent must find a source of odor
  hidden in a grid world. At each step, the agent moves to a neighbor
  cell. Once in a new cell, the agent receives an observation (odor
  detection) that provides some noisy information on its current
  distance to the source. The search terminates when the agent enters
  the cell containing the source. Solving the POMDP means finding the
  optimal way of choosing moves (policy) so as to reach the source in
  the smallest possible number of steps.</p>
  <p>Computing the optimal policy is not possible, and the challenge
  resides in finding good approximate solutions. A strong baseline is
  provided by “infotaxis”, a heuristic policy devised by Vergassola et
  al.
  (<xref alt="2007" rid="ref-Vergassola2007" ref-type="bibr">2007</xref>).
  It has become popular in robotics
  (<xref alt="Lochmatter, 2010" rid="ref-Lochmatter2010thesis" ref-type="bibr">Lochmatter,
  2010</xref>;
  <xref alt="Moraud &amp; Martinez, 2010" rid="ref-Moraud2010" ref-type="bibr">Moraud
  &amp; Martinez, 2010</xref>) and to interpret animal searches
  (<xref alt="Calhoun et al., 2014" rid="ref-Calhoun2014" ref-type="bibr">Calhoun
  et al., 2014</xref>;
  <xref alt="Vergassola et al., 2007" rid="ref-Vergassola2007" ref-type="bibr">Vergassola
  et al., 2007</xref>;
  <xref alt="Voges et al., 2014" rid="ref-Voges2014" ref-type="bibr">Voges
  et al., 2014</xref>).</p>
  <p>Several variants have been proposed since
  (<xref alt="Chen et al., 2020" rid="ref-Chen2020" ref-type="bibr">Chen
  et al., 2020</xref>;
  <xref alt="Hutchinson et al., 2018" rid="ref-Hutchinson2018" ref-type="bibr">Hutchinson
  et al., 2018</xref>;
  <xref alt="Karpas et al., 2017" rid="ref-Karpas2017" ref-type="bibr">Karpas
  et al., 2017</xref>;
  <xref alt="Masson, 2013" rid="ref-Masson2013" ref-type="bibr">Masson,
  2013</xref>;
  <xref alt="Ristic et al., 2016" rid="ref-Ristic2016" ref-type="bibr">Ristic
  et al., 2016</xref>), but the quest for better policies has been
  hindered by the lack of a trustable, open-source implementation of the
  source-tracking POMDP. Existing comparisons suffer from this lack of a
  common implementation. Besides, the recent successes of reinforcement
  learning for solving complex navigation problems in turbulence
  (<xref alt="Alageshan et al., 2020" rid="ref-Alageshan2020" ref-type="bibr">Alageshan
  et al., 2020</xref>;
  <xref alt="Reddy et al., 2016" rid="ref-Reddy2016" ref-type="bibr">Reddy
  et al., 2016</xref>) calls for an adaptation of these methods to the
  source-tracking POMDP.</p>
  <p>The target audience of OTTO consists of researchers in biophysics,
  applied mathematics and robotics working on optimal strategies for
  olfactory searches in turbulent flows.</p>
</sec>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>OTTO</monospace> (short for Odor-based Target Tracking
  Optimization) is a Python package to learn, evaluate and visualize
  strategies for odor-based searches. It is primarily designed to
  rigorously study the statistical properties of near-optimal strategies
  and of their heuristic approximations.</p>
  <p><monospace>OTTO</monospace> provides:</p>
  <list list-type="order">
    <list-item>
      <p>a simulator of the source-tracking POMDP for any number of
      space dimensions, domain sizes and source intensities, together
      with a rendering tool in 1D, 2D and 3D;</p>
    </list-item>
    <list-item>
      <p>an implementation of several heuristic policies including
      “infotaxis”
      (<xref alt="Vergassola et al., 2007" rid="ref-Vergassola2007" ref-type="bibr">Vergassola
      et al., 2007</xref>) and its recently proposed “space-aware”
      variant
      (<xref alt="Loisy &amp; Eloy, 2022b" rid="ref-Loisy2022" ref-type="bibr">Loisy
      &amp; Eloy, 2022b</xref>);</p>
    </list-item>
    <list-item>
      <p>a parallelized algorithm to evaluate policies (probability of
      finding the source, distribution of search times, etc.) using a
      rigorous, well-defined protocol;</p>
    </list-item>
    <list-item>
      <p>a custom model-based deep reinforcement learning algorithm for
      training neural-network policies, together with a library (“zoo”)
      of trained neural networks that achieve near-optimal
      performance;</p>
    </list-item>
    <list-item>
      <p>a wrapper of the source-tracking POMDP that follows the OpenAI
      Gym interface.</p>
    </list-item>
  </list>
  <p><monospace>OTTO</monospace> aims at facilitating future
  research:</p>
  <list list-type="order">
    <list-item>
      <p>New heuristic policies can easily be implemented, visualized,
      and evaluated. To facilitate comparison to existing baselines, the
      performance of several policies (including infotaxis and
      near-optimal) is reported in a freely available dataset generated
      with <monospace>OTTO</monospace>
      (<xref alt="Loisy &amp; Eloy, 2022a" rid="ref-dataset" ref-type="bibr">Loisy
      &amp; Eloy, 2022a</xref>).</p>
    </list-item>
    <list-item>
      <p>The gym wrapper makes the source-tracking POMDP easily
      accessible to the reinforcement learning community. OpenAI Gym
      (<xref alt="Brockman et al., 2016" rid="ref-gym" ref-type="bibr">Brockman
      et al., 2016</xref>) is the <italic>de facto</italic> standard for
      simulators. It is compatible with most general-purpose model-free
      reinforcement learning libraries (e.g., Stable Baselines
      (<xref alt="Raffin et al., 2021" rid="ref-stable-baselines3" ref-type="bibr">Raffin
      et al., 2021</xref>), OpenAI-Baselines
      (<xref alt="Dhariwal et al., 2017" rid="ref-openai-baselines" ref-type="bibr">Dhariwal
      et al., 2017</xref>), RLlib
      (<xref alt="Liang et al., 2018" rid="ref-RLlib" ref-type="bibr">Liang
      et al., 2018</xref>), CleanRL
      (<xref alt="Huang et al., 2021" rid="ref-CleanRL" ref-type="bibr">Huang
      et al., 2021</xref>), ChainerRL/PFRL
      (<xref alt="Fujita et al., 2021" rid="ref-PFRL" ref-type="bibr">Fujita
      et al., 2021</xref>)).</p>
    </list-item>
  </list>
</sec>
<sec id="mentions">
  <title>Mentions</title>
  <p>The methodological aspects of <monospace>OTTO</monospace>
  (generalization of the POMDP to an arbitrary number of space
  dimensions, policy evaluation protocol, model-based reinforcement
  learning algorithm) have been developed as part of a publication by
  its authors
  (<xref alt="Loisy &amp; Eloy, 2022b" rid="ref-Loisy2022" ref-type="bibr">Loisy
  &amp; Eloy, 2022b</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This project has received funding from the European Research
  Council (ERC) under the European Union’s Horizon 2020 research and
  innovation programme (grant agreement No 834238).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Alageshan2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alageshan</surname><given-names>J. K.</given-names></name>
        <name><surname>Verma</surname><given-names>A. K.</given-names></name>
        <name><surname>Bec</surname><given-names>J.</given-names></name>
        <name><surname>Pandit</surname><given-names>R.</given-names></name>
      </person-group>
      <article-title>Machine learning strategies for path-planning microswimmers in turbulent flows</article-title>
      <source>Physical Review E</source>
      <publisher-name>American Physical Society</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>101</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1103/PhysRevE.101.043110</pub-id>
      <fpage>043110</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Calhoun2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Calhoun</surname><given-names>A. J.</given-names></name>
        <name><surname>Chalasani</surname><given-names>S. H.</given-names></name>
        <name><surname>Sharpee</surname><given-names>T. O.</given-names></name>
      </person-group>
      <article-title>Maximally informative foraging by Caenorhabditis elegans</article-title>
      <source>eLife</source>
      <year iso-8601-date="2014">2014</year>
      <volume>3</volume>
      <pub-id pub-id-type="doi">10.7554/eLife.04220</pub-id>
      <fpage>e04220</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Chen2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>C.</given-names></name>
        <name><surname>Murphey</surname><given-names>T. D.</given-names></name>
        <name><surname>MacIver</surname><given-names>M. A.</given-names></name>
      </person-group>
      <article-title>Tuning movement for sensing in an uncertain world</article-title>
      <source>eLife</source>
      <year iso-8601-date="2020">2020</year>
      <volume>9</volume>
      <issn>2050-084X</issn>
      <pub-id pub-id-type="doi">10.7554/elife.52371</pub-id>
      <fpage>e52371</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Karpas2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Karpas</surname><given-names>E. D.</given-names></name>
        <name><surname>Shklarsh</surname><given-names>A.</given-names></name>
        <name><surname>Schneidman</surname><given-names>E.</given-names></name>
      </person-group>
      <article-title>Information socialtaxis and efficient collective behavior emerging in groups of information-seeking agents</article-title>
      <source>Proceedings of the National Academy of Sciences</source>
      <publisher-name>National Academy of Sciences</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>114</volume>
      <issue>22</issue>
      <issn>0027-8424</issn>
      <pub-id pub-id-type="doi">10.1073/pnas.1618055114</pub-id>
      <fpage>5589</fpage>
      <lpage>5594</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Lochmatter2010thesis">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Lochmatter</surname><given-names>T.</given-names></name>
      </person-group>
      <article-title>Bio-inspired and probabilistic algorithms for distributed odor source localization using mobile robots</article-title>
      <publisher-name>EPFL</publisher-name>
      <publisher-loc>Lausanne</publisher-loc>
      <year iso-8601-date="2010">2010</year>
    </element-citation>
  </ref>
  <ref id="ref-Loisy2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Loisy</surname><given-names>A.</given-names></name>
        <name><surname>Eloy</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Searching for a source without gradients: How good is infotaxis and how to beat it</article-title>
      <source>Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>
      <year iso-8601-date="2022">2022</year>
      <volume>478</volume>
      <issue>2262</issue>
      <pub-id pub-id-type="doi">10.1098/rspa.2022.0118</pub-id>
      <fpage>20220118</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hutchinson2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hutchinson</surname><given-names>M.</given-names></name>
        <name><surname>Oh</surname><given-names>H.</given-names></name>
        <name><surname>Chen</surname><given-names>W.-H.</given-names></name>
      </person-group>
      <article-title>Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions</article-title>
      <source>Information Fusion</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>42</volume>
      <pub-id pub-id-type="doi">10.1016/J.INFFUS.2017.10.009</pub-id>
      <fpage>179</fpage>
      <lpage>189</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Masson2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Masson</surname><given-names>J.-B.</given-names></name>
      </person-group>
      <article-title>Olfactory searches with limited space perception</article-title>
      <source>Proceedings of the National Academy of Sciences of the United States of America</source>
      <publisher-name>National Academy of Sciences</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <volume>110</volume>
      <issue>28</issue>
      <pub-id pub-id-type="doi">10.1073/pnas.1221091110</pub-id>
      <fpage>11261</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Marques2006">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Marques</surname><given-names>L.</given-names></name>
        <name><surname>Almeida</surname><given-names>A. de</given-names></name>
      </person-group>
      <article-title>Mobile robot olfaction</article-title>
      <source>Autonomous Robots</source>
      <publisher-name>Springer Nature BV</publisher-name>
      <year iso-8601-date="2006">2006</year>
      <volume>20</volume>
      <pub-id pub-id-type="doi">10.1007/s10514-006-7536-7</pub-id>
      <fpage>183</fpage>
      <lpage>184</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Moraud2010">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Moraud</surname><given-names>E. M.</given-names></name>
        <name><surname>Martinez</surname><given-names>D.</given-names></name>
      </person-group>
      <article-title>Effectiveness and robustness of robot infotaxis for searching in dilute conditions</article-title>
      <source>Frontiers in Neurorobotics</source>
      <publisher-name>Frontiers</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>4</volume>
      <issn>1662-5218</issn>
      <pub-id pub-id-type="doi">10.3389/fnbot.2010.00001</pub-id>
      <fpage>1</fpage>
      <lpage>8</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Reddy2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Reddy</surname><given-names>G.</given-names></name>
        <name><surname>Celani</surname><given-names>A.</given-names></name>
        <name><surname>Sejnowski</surname><given-names>T. J.</given-names></name>
        <name><surname>Vergassola</surname><given-names>M.</given-names></name>
      </person-group>
      <article-title>Learning to soar in turbulent environments</article-title>
      <source>Proceedings of the National Academy of Sciences of the United States of America</source>
      <publisher-name>National Academy of Sciences</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>113</volume>
      <issue>33</issue>
      <pub-id pub-id-type="doi">10.1073/pnas.1606075113</pub-id>
      <fpage>E4877</fpage>
      <lpage>84</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Reddy2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Reddy</surname><given-names>G.</given-names></name>
        <name><surname>Murthy</surname><given-names>V. N.</given-names></name>
        <name><surname>Vergassola</surname><given-names>M.</given-names></name>
      </person-group>
      <article-title>Olfactory Sensing and Navigation in Turbulent Environments</article-title>
      <source>Annual Review of Condensed Matter Physics</source>
      <year iso-8601-date="2022">2022</year>
      <volume>13</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1146/annurev-conmatphys-031720-032754</pub-id>
      <fpage>191</fpage>
      <lpage>213</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Ristic2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ristic</surname><given-names>B.</given-names></name>
        <name><surname>Skvortsov</surname><given-names>A.</given-names></name>
        <name><surname>Gunatilaka</surname><given-names>A.</given-names></name>
      </person-group>
      <article-title>A study of cognitive strategies for an autonomous search</article-title>
      <source>Information Fusion</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>28</volume>
      <pub-id pub-id-type="doi">10.1016/J.INFFUS.2015.06.008</pub-id>
      <fpage>1</fpage>
      <lpage>9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Russell1999">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Russell</surname><given-names>R. A.</given-names></name>
      </person-group>
      <source>Odour detection by mobile robots</source>
      <publisher-name>World Scientific</publisher-name>
      <year iso-8601-date="1999">1999</year>
      <pub-id pub-id-type="doi">10.1142/4042</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Vickers2000">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Vickers</surname><given-names>N. J.</given-names></name>
      </person-group>
      <article-title>Mechanisms of animal navigation in odor plumes</article-title>
      <source>The Biological Bulletin</source>
      <publisher-name>The University of Chicago Press</publisher-name>
      <year iso-8601-date="2000">2000</year>
      <volume>198</volume>
      <issue>2</issue>
      <issn>0006-3185</issn>
      <pub-id pub-id-type="doi">10.2307/1542524</pub-id>
      <fpage>203</fpage>
      <lpage>212</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Vergassola2007">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Vergassola</surname><given-names>M.</given-names></name>
        <name><surname>Villermaux</surname><given-names>E.</given-names></name>
        <name><surname>Shraiman</surname><given-names>B. I.</given-names></name>
      </person-group>
      <article-title>&quot;Infotaxis&quot; as a strategy for searching without gradients</article-title>
      <source>Nature</source>
      <year iso-8601-date="2007">2007</year>
      <volume>445</volume>
      <issue>7126</issue>
      <pub-id pub-id-type="doi">10.1038/nature05464</pub-id>
      <fpage>406</fpage>
      <lpage>409</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Voges2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Voges</surname><given-names>N.</given-names></name>
        <name><surname>Chaffiol</surname><given-names>A.</given-names></name>
        <name><surname>Lucas</surname><given-names>P.</given-names></name>
        <name><surname>Martinez</surname><given-names>D.</given-names></name>
      </person-group>
      <article-title>Reactive Searching and Infotaxis in Odor Source Localization</article-title>
      <source>PLOS Computational Biology</source>
      <publisher-name>Public Library of Science</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>10</volume>
      <issue>10</issue>
      <issn>1553-7358</issn>
      <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003861</pub-id>
      <fpage>e1003861</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gym">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Brockman</surname><given-names>G.</given-names></name>
        <name><surname>Cheung</surname><given-names>V.</given-names></name>
        <name><surname>Pettersson</surname><given-names>L.</given-names></name>
        <name><surname>Schneider</surname><given-names>J.</given-names></name>
        <name><surname>Schulman</surname><given-names>J.</given-names></name>
        <name><surname>Tang</surname><given-names>J.</given-names></name>
        <name><surname>Zaremba</surname><given-names>W.</given-names></name>
      </person-group>
      <article-title>OpenAI gym</article-title>
      <year iso-8601-date="2016">2016</year>
      <uri>https://arxiv.org/abs/1606.01540</uri>
    </element-citation>
  </ref>
  <ref id="ref-stable-baselines3">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Raffin</surname><given-names>A.</given-names></name>
        <name><surname>Hill</surname><given-names>A.</given-names></name>
        <name><surname>Gleave</surname><given-names>A.</given-names></name>
        <name><surname>Kanervisto</surname><given-names>A.</given-names></name>
        <name><surname>Ernestus</surname><given-names>M.</given-names></name>
        <name><surname>Dormann</surname><given-names>N.</given-names></name>
      </person-group>
      <article-title>Stable-Baselines3: Reliable reinforcement learning implementations</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2021">2021</year>
      <volume>22</volume>
      <issue>268</issue>
      <uri>http://jmlr.org/papers/v22/20-1364.html</uri>
      <fpage>1</fpage>
      <lpage>8</lpage>
    </element-citation>
  </ref>
  <ref id="ref-openai-baselines">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Dhariwal</surname><given-names>P.</given-names></name>
        <name><surname>Hesse</surname><given-names>C.</given-names></name>
        <name><surname>Klimov</surname><given-names>O.</given-names></name>
        <name><surname>Nichol</surname><given-names>A.</given-names></name>
        <name><surname>Plappert</surname><given-names>M.</given-names></name>
        <name><surname>Radford</surname><given-names>A.</given-names></name>
        <name><surname>Schulman</surname><given-names>J.</given-names></name>
        <name><surname>Sidor</surname><given-names>S.</given-names></name>
        <name><surname>Wu</surname><given-names>Y.</given-names></name>
        <name><surname>Zhokhov</surname><given-names>P.</given-names></name>
      </person-group>
      <article-title>OpenAI baselines</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/openai/baselines; GitHub</publisher-name>
      <year iso-8601-date="2017">2017</year>
    </element-citation>
  </ref>
  <ref id="ref-PFRL">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fujita</surname><given-names>Y.</given-names></name>
        <name><surname>Nagarajan</surname><given-names>P.</given-names></name>
        <name><surname>Kataoka</surname><given-names>T.</given-names></name>
        <name><surname>Ishikawa</surname><given-names>T.</given-names></name>
      </person-group>
      <article-title>ChainerRL: A deep reinforcement learning library</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2021">2021</year>
      <volume>22</volume>
      <issue>77</issue>
      <uri>http://jmlr.org/papers/v22/20-376.html</uri>
      <fpage>1</fpage>
      <lpage>14</lpage>
    </element-citation>
  </ref>
  <ref id="ref-RLlib">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Liang</surname><given-names>E.</given-names></name>
        <name><surname>Liaw</surname><given-names>R.</given-names></name>
        <name><surname>Nishihara</surname><given-names>R.</given-names></name>
        <name><surname>Moritz</surname><given-names>P.</given-names></name>
        <name><surname>Fox</surname><given-names>R.</given-names></name>
        <name><surname>Goldberg</surname><given-names>K.</given-names></name>
        <name><surname>Gonzalez</surname><given-names>J.</given-names></name>
        <name><surname>Jordan</surname><given-names>M.</given-names></name>
        <name><surname>Stoica</surname><given-names>I.</given-names></name>
      </person-group>
      <article-title>RLlib: Abstractions for distributed reinforcement learning</article-title>
      <source>Proceedings of the 35th international conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>80</volume>
      <uri>https://proceedings.mlr.press/v80/liang18b.html</uri>
      <fpage>3053</fpage>
      <lpage>3062</lpage>
    </element-citation>
  </ref>
  <ref id="ref-CleanRL">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Huang</surname><given-names>S.</given-names></name>
        <name><surname>Dossa</surname><given-names>R. F. J.</given-names></name>
        <name><surname>Ye</surname><given-names>C.</given-names></name>
        <name><surname>Braga</surname><given-names>J.</given-names></name>
      </person-group>
      <article-title>CleanRL: High-quality single-file implementations of deep reinforcement learning algorithms</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/2111.08819</uri>
    </element-citation>
  </ref>
  <ref id="ref-dataset">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Loisy</surname><given-names>A.</given-names></name>
        <name><surname>Eloy</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Dataset for &quot;Searching for a source without gradients: how good is infotaxis and how to beat it&quot;</article-title>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.6125391</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
