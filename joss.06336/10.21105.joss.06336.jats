<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6336</article-id>
<article-id pub-id-type="doi">10.21105/joss.06336</article-id>
<title-group>
<article-title>Thresholdmann: A Web tool for interactively creating
adaptive thresholds to segment MRI data.</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7237-0196</contrib-id>
<name>
<surname>Heuer</surname>
<given-names>Katja</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3277-6316</contrib-id>
<name>
<surname>Traut</surname>
<given-names>Nicolas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6671-858X</contrib-id>
<name>
<surname>Toro</surname>
<given-names>Roberto</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institut Pasteur, Université Paris Cité, Unité de
Neuroanatomie Appliquée et Théorique, F-75015 Paris,
France</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-11-20">
<day>20</day>
<month>11</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>97</issue>
<fpage>6336</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Neuroscience</kwd>
<kwd>Neuroanatomy</kwd>
<kwd>Neuroimaging</kwd>
<kwd>Nifti</kwd>
<kwd>JavaScript</kwd>
<kwd>Web tool</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Brain extraction and segmentation are the first step for most
  neuroimaging analyses. Automatic methods work well in adult human
  brains, but produce unreliable results in non-human data, due to
  muscle tissue, skull, and luminosity gradients. Thresholdmann
  (<ext-link ext-link-type="uri" xlink:href="https://neuroanatomy.github.io/thresholdmann">https://neuroanatomy.github.io/thresholdmann</ext-link>)
  is an open source Web tool for the interactive application of
  space-varying thresholds to Nifti volumes. No download or installation
  are required and all processing is done on the user’s computer. Nifti
  volumes are dragged and dropped onto the Web app and become available
  for visual exploration in a stereotaxic viewer. A space-varying
  threshold is then created by setting control points, each with their
  own local threshold. Each point can be repositioned or removed, and
  each local threshold can be adjusted in real time using sliders or
  entering their values numerically. The threshold direction can be
  switched to allow segmentation of the structure of interest in
  different imaging modalities, such as T1 and T2 weighted contrasts.
  The opacity of the mask and the brightness and contrast of the MRI
  image can be adjusted via sliders. A 3D model of the thresholded mask
  can be computed to inspect the result in an interactive 3D render.
  Finally, the thresholded mask, the space varying threshold and the
  list of control points can be saved for later use in scripted
  workflows, able to reproduce the thresholded volume from the original
  data.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Brain extraction and segmentation are required for most analyses of
  neuroimaging data. Obtaining appropriate masks can be particularly
  difficult in non-human brain imaging, as standard automatic tools
  struggle with the surrounding muscle tissue, skull, and strong
  luminosity gradients. A simple interactive threshold is intuitive and
  fast to apply, and can often provide a rather good initial guess.
  However, because of luminosity gradients, the threshold that works for
  one brain region is likely to fail in another.</p>
  <p>Thresholdmann complements the variety of existing brain
  segmentation tools, providing an easy interface to manually control
  the segmentation on a local scale across different brain imaging
  modalities and image contrast gradients. The masks produced by
  Thresholdmann can serve as a starting point for more detailed manual
  editing using tools such as BrainBox
  (<ext-link ext-link-type="uri" xlink:href="https://brainbox.pasteur.fr">https://brainbox.pasteur.fr</ext-link>)
  (<xref alt="Heuer et al., 2016" rid="ref-BrainBox" ref-type="bibr">Heuer
  et al., 2016</xref>) or ITK-SNAP
  (<ext-link ext-link-type="uri" xlink:href="http://www.itksnap.org">http://www.itksnap.org</ext-link>)
  (<xref alt="Yushkevich et al., 2006" rid="ref-itkSNAP" ref-type="bibr">Yushkevich
  et al., 2006</xref>). This interactive approach is especially valuable
  for non-human brain imaging data, where automatic approaches often
  require extensive manual adjustment anyway
  (<xref alt="Messinger et al., 2020" rid="ref-PrimeRE" ref-type="bibr">Messinger
  et al., 2020</xref>;
  <xref alt="Milham et al., 2020" rid="ref-PrimeDE" ref-type="bibr">Milham
  et al., 2020</xref>,
  <xref alt="2022" rid="ref-PrimeDE2" ref-type="bibr">2022</xref>). We
  have used Thresholdmann successfully to create initial brain masks for
  a variety of vertebrate brains – including many non-human primate
  datasets
  (<xref alt="Heuer et al., 2019" rid="ref-34primates" ref-type="bibr">Heuer
  et al., 2019</xref>;
  <xref alt="Magielse et al., 2023" rid="ref-cerebella" ref-type="bibr">Magielse
  et al., 2023</xref>) – as well as developmental data. Small Web tools,
  such as Thresholdmann or Reorient
  (<ext-link ext-link-type="uri" xlink:href="https://neuroanatomy.github.io/reorient">https://neuroanatomy.github.io/reorient</ext-link>)
  (<xref alt="Heuer &amp; Toro, 2020" rid="ref-Reorient" ref-type="bibr">Heuer
  &amp; Toro, 2020</xref>), focused on solving a single problem, can
  become helpful additions to the methodological toolbox of
  neuroimagers.</p>
</sec>
<sec id="methods">
  <title>Methods</title>
  <p>The spatially-varying threshold is computed from a number of
  control points. Each control point has a position
  <inline-formula><alternatives>
  <tex-math><![CDATA[x_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  and a threshold value <inline-formula><alternatives>
  <tex-math><![CDATA[v_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  that can be adjusted interactively. At each point
  <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  of the volume, the local threshold is computed as a weighted function
  of the control points. The weight associated to the
  <inline-formula><alternatives>
  <tex-math><![CDATA[i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>-th
  control point at position <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  is given by:
  <disp-formula><alternatives>
  <tex-math><![CDATA[w_i \left( x \right) = \frac 1 {\left( x-x_i \right)^2+\epsilon} ,]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[\epsilon]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ϵ</mml:mi></mml:math></alternatives></inline-formula>
  is a small number used to prevent a division by 0 at the exact
  position of control points. The value of the threshold at position
  <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  is the obtained as:
  <disp-formula><alternatives>
  <tex-math><![CDATA[v \left( x \right) = \frac{ \sum\limits_i^n v_i w_i \left( x \right)} {W \left( x \right)} ,]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[W(x)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is the sum of all weights, given by:
  <disp-formula><alternatives>
  <tex-math><![CDATA[W \left( x \right) = \sum_i^n w_i \left( x \right) .]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>Additionally, we add a “background” threshold value which makes the
  action of the control points localised. The background value is
  independent of the distance and is given a small constant weight. In
  that manner, positions far from all control points get the background
  threshold value.</p>
  <p>Thresholdmann was coded in JavaScript and runs from a GitHub page.
  Code style was verified using ESLint
  (<ext-link ext-link-type="uri" xlink:href="https://eslint.org">https://eslint.org</ext-link>).
  Unit tests and end-to-end tests were implemented using Mocha
  (<ext-link ext-link-type="uri" xlink:href="https://mochajs.org">https://mochajs.org</ext-link>)
  and Playwright
  (<ext-link ext-link-type="uri" xlink:href="https://playwright.dev">https://playwright.dev</ext-link>).
  Modifications in the code are continuously tested using CircleCI
  (<ext-link ext-link-type="uri" xlink:href="https://circleci.com">https://circleci.com</ext-link>).</p>
</sec>
<sec id="figures">
  <title>Figures</title>
  <fig>
    <caption><p><bold>Interface and 3D viewer.</bold> The <bold>left
    panel</bold> allows to select different control point actions, set
    the thresholding direction, switch between the threshold mask or
    value view, open the 3D viewer, load or save the work, change the
    opacity of the mask, the brightness and contrast of the MRI, and
    information about the imaging data. The <bold>central panel</bold>
    is a stereotaxic viewer which allows the user to move through the
    slices using the slider at the bottom, to switch between the 3
    stereotaxic planes, and to interactively set, move or remove control
    points. Users can view the threshold mask, or the corresponding
    threshold value space. The <bold>right panel</bold> shows for each
    control point the stereotaxic coordinates, an adjustment slider to
    change the local threshold, and the threshold value. The selected
    control point is highlighted in the panel and the viewer jumps to
    the corresponding slice. The <bold>interactive 3D viewer</bold>
    opens in a separate browser
    window.<styled-content id="figU003Athresholdmann1"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/848eaf98ca21d2875f01ec78480949341269dfa4.png" />
  </fig>
  <fig>
    <caption><p><bold>Usage example: Placing control points.</bold>
    Control points (blue dots) are added by clicking at the desired
    position in the viewer. This adds a slider to the right, which can
    be used to locally adapt the threshold. The figure describes the
    progressive addition of control points to create a mask of the brain
    for a macaque from Prime-DE site “amu”
    (<xref alt="Brochier et al., 2019" rid="ref-Brochier_etal2019" ref-type="bibr">Brochier
    et al., 2019</xref>;
    <xref alt="Milham et al., 2020" rid="ref-PrimeDE" ref-type="bibr">Milham
    et al.,
    2020</xref>).<styled-content id="figU003Athresholdmann2"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/60365d839dc63cbb1c1b97968cfa08e815e42e92.png" />
  </fig>
  <fig>
    <caption><p><bold>Usage example: Resulting mask and space-varying
    threshold.</bold> Threshold mask and corresponding threshold value.
    These volumes are updated in real time and can both be inspected
    interactively. The set of control points and the mask can be
    downloaded.<styled-content id="figU003Athresholdmann3"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/e97fc74ca6a40dfe0230682bf4c9303a943c7665.png" />
  </fig>
  <fig>
    <caption><p><bold>Usage example: Final mask.</bold> We downloaded
    the mask presented above based on the shown set of eight control
    points. The brain region was sufficiently disjoint from the rest of
    the head so that a mathematical morphology closing was enough to
    completely separate it. The figure shows stereotaxic planes and a
    surface reconstruction of the
    mask.<styled-content id="figU003Athresholdmann4"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/c40abb6b800cacf81e64b6d37d0f42bd15a754ed.png" />
  </fig>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank Demian Wassermann for discussions about radial basis
  functions that inspired the first version of our tool. Funded by
  project DMOBE (ANR-21-CE45-0016) and the European Union’s Horizon 2020
  research and innovation programme under the Marie Skłodowska-Curie
  grant agreement No101033485 (KH Individual Fellowship).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-34primates">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heuer</surname><given-names>Katja</given-names></name>
        <name><surname>Gulban</surname><given-names>Omer Faruk</given-names></name>
        <name><surname>Bazin</surname><given-names>Pierre-Louis</given-names></name>
        <name><surname>Osoianu</surname><given-names>Anastasia</given-names></name>
        <name><surname>Valabregue</surname><given-names>Romain</given-names></name>
        <name><surname>Santin</surname><given-names>Mathieu</given-names></name>
        <name><surname>Herbin</surname><given-names>Marc</given-names></name>
        <name><surname>Toro</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Evolution of neocortical folding: A phylogenetic comparative analysis of MRI from 34 primate species</article-title>
      <source>Cortex</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2019-09">2019</year><month>09</month>
      <volume>118</volume>
      <uri>http://dx.doi.org/10.1016/j.cortex.2019.04.011</uri>
      <pub-id pub-id-type="doi">10.1016/j.cortex.2019.04.011</pub-id>
      <fpage>275</fpage>
      <lpage>291</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cerebella">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Magielse</surname><given-names>Neville</given-names></name>
        <name><surname>Toro</surname><given-names>Roberto</given-names></name>
        <name><surname>Steigauf</surname><given-names>Vanessa</given-names></name>
        <name><surname>Abbaspour</surname><given-names>Mahta</given-names></name>
        <name><surname>Eickhoff</surname><given-names>Simon B.</given-names></name>
        <name><surname>Heuer</surname><given-names>Katja</given-names></name>
        <name><surname>Valk</surname><given-names>Sofie L.</given-names></name>
      </person-group>
      <article-title>Phylogenetic comparative analysis of the cerebello-cerebral system in 34 species highlights primate-general expansion of cerebellar crura i-II</article-title>
      <source>Communications Biology</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2023-11">2023</year><month>11</month>
      <volume>6</volume>
      <uri>https://www.nature.com/articles/s42003-023-05553-z</uri>
      <pub-id pub-id-type="doi">10.1038/s42003-023-05553-z</pub-id>
      <fpage>1188</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-BrainBox">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heuer</surname><given-names>Katja</given-names></name>
        <name><surname>Ghosh</surname><given-names>Satrajit</given-names></name>
        <name><surname>Robinson Sterling</surname><given-names>Amy</given-names></name>
        <name><surname>Toro</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Open neuroimaging laboratory</article-title>
      <source>Research Ideas and Outcomes</source>
      <publisher-name>Pensoft Publishers</publisher-name>
      <year iso-8601-date="2016-05">2016</year><month>05</month>
      <volume>2</volume>
      <uri>http://dx.doi.org/10.3897/rio.2.e9113</uri>
      <pub-id pub-id-type="doi">10.3897/rio.2.e9113</pub-id>
      <fpage>e9113</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Reorient">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heuer</surname><given-names>Katja</given-names></name>
        <name><surname>Toro</surname><given-names>Roberto</given-names></name>
      </person-group>
      <article-title>Reorient: A web tool for reorienting and cropping MRI data.</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>55</issue>
      <uri>https://doi.org/10.21105/joss.02670</uri>
      <pub-id pub-id-type="doi">10.21105/joss.02670</pub-id>
      <fpage>2670</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-itkSNAP">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yushkevich</surname><given-names>Paul A.</given-names></name>
        <name><surname>Piven</surname><given-names>Joseph</given-names></name>
        <name><surname>Hazlett</surname><given-names>Heather Cody</given-names></name>
        <name><surname>Smith</surname><given-names>Rachel Gimpel</given-names></name>
        <name><surname>Ho</surname><given-names>Sean</given-names></name>
        <name><surname>Gee</surname><given-names>James C.</given-names></name>
        <name><surname>Gerig</surname><given-names>Guido</given-names></name>
      </person-group>
      <article-title>User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability</article-title>
      <source>NeuroImage</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2006-07">2006</year><month>07</month>
      <volume>31</volume>
      <issue>3</issue>
      <uri>http://dx.doi.org/10.1016/j.neuroimage.2006.01.015</uri>
      <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.015</pub-id>
      <fpage>1116</fpage>
      <lpage>1128</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PrimeDE">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Milham</surname><given-names>Michael</given-names></name>
        <name><surname>Petkov</surname><given-names>Christopher I.</given-names></name>
        <name><surname>Margulies</surname><given-names>Daniel S.</given-names></name>
        <name><surname>Schroeder</surname><given-names>Charles E.</given-names></name>
        <name><surname>Basso</surname><given-names>Michele A.</given-names></name>
        <name><surname>Belin</surname><given-names>Pascal</given-names></name>
        <name><surname>Fair</surname><given-names>Damien A.</given-names></name>
        <name><surname>Fox</surname><given-names>Andrew</given-names></name>
        <name><surname>Kastner</surname><given-names>Sabine</given-names></name>
        <name><surname>Mars</surname><given-names>Rogier B.</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Accelerating the evolution of nonhuman primate neuroimaging</article-title>
      <source>Neuron</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2020-02">2020</year><month>02</month>
      <volume>105</volume>
      <issue>4</issue>
      <uri>http://dx.doi.org/10.1016/j.neuron.2019.12.023</uri>
      <pub-id pub-id-type="doi">10.1016/j.neuron.2019.12.023</pub-id>
      <fpage>600</fpage>
      <lpage>603</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PrimeDE2">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Milham</surname><given-names>Michael</given-names></name>
        <name><surname>Petkov</surname><given-names>Christopher I.</given-names></name>
        <name><surname>Belin</surname><given-names>Pascal</given-names></name>
        <name><surname>Ben Hamed</surname><given-names>Suliann</given-names></name>
        <name><surname>Evrard</surname><given-names>Henry</given-names></name>
        <name><surname>Fair</surname><given-names>Damien</given-names></name>
        <name><surname>Fox</surname><given-names>Andrew</given-names></name>
        <name><surname>Froudist-Walsh</surname><given-names>Sean</given-names></name>
        <name><surname>Hayashi</surname><given-names>Takuya</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Toward next-generation primate neuroscience: A collaboration-based strategic plan for integrative neuroimaging</article-title>
      <source>Neuron</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2022-01">2022</year><month>01</month>
      <volume>110</volume>
      <issue>1</issue>
      <uri>https://www.sciencedirect.com/science/article/pii/S0896627321007832</uri>
      <pub-id pub-id-type="doi">10.1016/j.neuron.2021.10.015</pub-id>
      <fpage>16</fpage>
      <lpage>20</lpage>
    </element-citation>
  </ref>
  <ref id="ref-PrimeRE">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Messinger</surname><given-names>Adam</given-names></name>
        <name><surname>Sirmpilatze</surname><given-names>Nikoloz</given-names></name>
        <name><surname>Heuer</surname><given-names>Katja</given-names></name>
        <name><surname>Loh</surname><given-names>Kep Kee</given-names></name>
        <name><surname>Mars</surname><given-names>Rogier B.</given-names></name>
        <name><surname>Sein</surname><given-names>Julien</given-names></name>
        <name><surname>Xu</surname><given-names>Ting</given-names></name>
        <name><surname>Glen</surname><given-names>Daniel</given-names></name>
        <name><surname>Jung</surname><given-names>Benjamin</given-names></name>
        <name><surname>Seidlitz</surname><given-names>Jakob</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>A collaborative resource platform for non-human primate neuroimaging</article-title>
      <source>NeuroImage</source>
      <publisher-name>Elsevier BV</publisher-name>
      <year iso-8601-date="2020-11">2020</year><month>11</month>
      <volume>226</volume>
      <uri>https://www.sciencedirect.com/science/article/pii/S1053811920310041</uri>
      <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117519</pub-id>
      <fpage>117519</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Brochier_etal2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Brochier</surname><given-names>Thomas</given-names></name>
        <name><surname>Belin</surname><given-names>Pascal</given-names></name>
        <name><surname>Chavanne</surname><given-names>Frédéric</given-names></name>
        <name><surname>Velly</surname><given-names>Lionel</given-names></name>
        <name><surname>Bodin</surname><given-names>Clémentine</given-names></name>
        <name><surname>Renaud</surname><given-names>Luc</given-names></name>
        <name><surname>Martin</surname><given-names>Marc</given-names></name>
        <name><surname>Boes</surname><given-names>Laurence</given-names></name>
        <name><surname>Sein</surname><given-names>Julien</given-names></name>
        <name><surname>Nazarian</surname><given-names>Bruno</given-names></name>
        <name><surname>al.</surname></name>
      </person-group>
      <article-title>Macaca mulatta structural and diffusion weighted MRI data</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2019-09">2019</year><month>09</month>
      <uri>https://zenodo.org/record/3402456</uri>
      <pub-id pub-id-type="doi">10.5281/ZENODO.3402456</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
