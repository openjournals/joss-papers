<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20251119210813-3e59ba289f62b36c7689852175bc005c6b9638e5</doi_batch_id>
    <timestamp>20251119210813</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>11</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>115</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>DeepInverse: A Python package for solving imaging inverse problems with deep learning</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Julián</given_name>
            <surname>Tachella</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS de Lyon, France</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0003-3878-9142</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Matthieu</given_name>
            <surname>Terris</surname>
            <affiliations>
              <institution><institution_name>Université Paris-Saclay, Inria, CEA, Palaiseau, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Samuel</given_name>
            <surname>Hurault</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS Paris, PSL, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Andrew</given_name>
            <surname>Wang</surname>
            <affiliations>
              <institution><institution_name>University of Edinburgh, UK</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0003-0838-7986</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Leo</given_name>
            <surname>Davy</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jérémy</given_name>
            <surname>Scanvic</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Victor</given_name>
            <surname>Sechaud</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Romain</given_name>
            <surname>Vo</surname>
            <affiliations>
              <institution><institution_name>CNRS, ENS de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Thomas</given_name>
            <surname>Moreau</surname>
            <affiliations>
              <institution><institution_name>Université Paris-Saclay, Inria, CEA, Palaiseau, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Thomas</given_name>
            <surname>Davies</surname>
            <affiliations>
              <institution><institution_name>University of Edinburgh, UK</institution_name></institution>
              <institution><institution_name>Heriot-Watt University, Edinburgh, UK</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Dongdong</given_name>
            <surname>Chen</surname>
            <affiliations>
              <institution><institution_name>Heriot-Watt University, Edinburgh, UK</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Nils</given_name>
            <surname>Laurent</surname>
            <affiliations>
              <institution><institution_name>Universidad Industrial de Santander, Bucaramanga, Colombia</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Brayan</given_name>
            <surname>Monroy</surname>
            <affiliations>
              <institution><institution_name>Universidad Industrial de Santander, Bucaramanga, Colombia</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jonathan</given_name>
            <surname>Dong</surname>
            <affiliations>
              <institution><institution_name>EPFL, Lausanne, Switzerland</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Zhiyuan</given_name>
            <surname>Hu</surname>
            <affiliations>
              <institution><institution_name>EPFL, Lausanne, Switzerland</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Minh-Hai</given_name>
            <surname>Nguyen</surname>
            <affiliations>
              <institution><institution_name>IRIT, CBI, CNRS, Université de Toulouse, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Florian</given_name>
            <surname>Sarron</surname>
            <affiliations>
              <institution><institution_name>IRIT, CBI, CNRS, Université de Toulouse, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Pierre</given_name>
            <surname>Weiss</surname>
            <affiliations>
              <institution><institution_name>IRIT, CBI, CNRS, Université de Toulouse, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Paul</given_name>
            <surname>Escande</surname>
            <affiliations>
              <institution><institution_name>IMT, CNRS, Université de Toulouse, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Mathurin</given_name>
            <surname>Massias</surname>
            <affiliations>
              <institution><institution_name>Inria, ENS de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Thibaut</given_name>
            <surname>Modrzyk</surname>
            <affiliations>
              <institution><institution_name>INSA de Lyon, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Brett</given_name>
            <surname>Levac</surname>
            <affiliations>
              <institution><institution_name>University of Texas at Austin, USA</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Tobías I.</given_name>
            <surname>Liaudat</surname>
            <affiliations>
              <institution><institution_name>IRFU, CEA, Université Paris-Saclay, Gif-sur-Yvette, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Maxime</given_name>
            <surname>Song</surname>
            <affiliations>
              <institution><institution_name>CNRS UAR 851, Université Paris-Saclay Orsay, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Johannes</given_name>
            <surname>Hertrich</surname>
            <affiliations>
              <institution><institution_name>Université Paris Dauphine - PSL, Paris, France</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Sebastian</given_name>
            <surname>Neumayer</surname>
            <affiliations>
              <institution><institution_name>Chemnitz University of Technology, Chemnitz, Germany</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Georg</given_name>
            <surname>Schramm</surname>
            <affiliations>
              <institution><institution_name>Department of Imaging and Pathology, KU Leuven, Belgium</institution_name></institution>
            </affiliations>
            <ORCID>https://orcid.org/0000-0002-2251-3195</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>11</month>
          <day>19</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>8923</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.08923</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.17565657</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/8923</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.08923</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.08923</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.08923.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="paszke2019pytorch">
            <article_title>PyTorch: An imperative style, high-performance deep learning library</article_title>
            <author>Paszke</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>32</volume>
            <doi>10.48550/arXiv.1912.01703</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., &amp; others. (2019). PyTorch: An imperative style, high-performance deep learning library. Advances in Neural Information Processing Systems, 32. https://doi.org/10.48550/arXiv.1912.01703</unstructured_citation>
          </citation>
          <citation key="chung2023parallel">
            <article_title>Parallel diffusion models of operator and image for blind inverse problems</article_title>
            <author>Chung</author>
            <journal_title>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/cvpr52729.2023.00587</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Chung, H., Kim, J., Kim, S., &amp; Ye, J. C. (2023). Parallel diffusion models of operator and image for blind inverse problems. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 6059–6069. https://doi.org/10.1109/cvpr52729.2023.00587</unstructured_citation>
          </citation>
          <citation key="debarnot2024deep">
            <article_title>Deep-blur: Blind identification and deblurring with convolutional neural networks</article_title>
            <author>Debarnot</author>
            <journal_title>Biological Imaging</journal_title>
            <volume>4</volume>
            <doi>10.1017/s2633903x24000096</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Debarnot, V., &amp; Weiss, P. (2024). Deep-blur: Blind identification and deblurring with convolutional neural networks. Biological Imaging, 4, e13. https://doi.org/10.1017/s2633903x24000096</unstructured_citation>
          </citation>
          <citation key="terris2023meta">
            <article_title>Meta-prior: Meta learning for adaptive inverse problem solvers</article_title>
            <author>Terris</author>
            <journal_title>arXiv preprint arXiv:2311.18710</journal_title>
            <doi>10.48550/arXiv.2311.18710</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Terris, M., &amp; Moreau, T. (2023). Meta-prior: Meta learning for adaptive inverse problem solvers. arXiv Preprint arXiv:2311.18710. https://doi.org/10.48550/arXiv.2311.18710</unstructured_citation>
          </citation>
          <citation key="gossard2024training">
            <article_title>Training adaptive reconstruction networks for blind inverse problems</article_title>
            <author>Gossard</author>
            <journal_title>SIAM Journal on Imaging Sciences</journal_title>
            <issue>2</issue>
            <volume>17</volume>
            <doi>10.1137/23m1545628</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Gossard, A., &amp; Weiss, P. (2024). Training adaptive reconstruction networks for blind inverse problems. SIAM Journal on Imaging Sciences, 17(2), 1314–1346. https://doi.org/10.1137/23m1545628</unstructured_citation>
          </citation>
          <citation key="lazarus2019sparkling">
            <article_title>SPARKLING: Variable-density k-space filling curves for accelerated T2*-weighted MRI</article_title>
            <author>Lazarus</author>
            <journal_title>Magnetic resonance in medicine</journal_title>
            <issue>6</issue>
            <volume>81</volume>
            <doi>10.1002/mrm.27678</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Lazarus, C., Weiss, P., Chauffert, N., Mauconduit, F., El Gueddari, L., Destrieux, C., Zemmoura, I., Vignaud, A., &amp; Ciuciu, P. (2019). SPARKLING: Variable-density k-space filling curves for accelerated T2*-weighted MRI. Magnetic Resonance in Medicine, 81(6), 3643–3661. https://doi.org/10.1002/mrm.27678</unstructured_citation>
          </citation>
          <citation key="nehme2020deepstorm3d">
            <article_title>DeepSTORM3D: Dense 3D localization microscopy and PSF design by deep learning</article_title>
            <author>Nehme</author>
            <journal_title>Nature methods</journal_title>
            <issue>7</issue>
            <volume>17</volume>
            <doi>10.1038/s41592-020-0853-5</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Nehme, E., Freedman, D., Gordon, R., Ferdman, B., Weiss, L. E., Alalouf, O., Naor, T., Orange, R., Michaeli, T., &amp; Shechtman, Y. (2020). DeepSTORM3D: Dense 3D localization microscopy and PSF design by deep learning. Nature Methods, 17(7), 734–740. https://doi.org/10.1038/s41592-020-0853-5</unstructured_citation>
          </citation>
          <citation key="soubies2019pocket">
            <article_title>Pocket guide to solve inverse problems with GlobalBioIm</article_title>
            <author>Soubies</author>
            <journal_title>Inverse Problems</journal_title>
            <issue>10</issue>
            <volume>35</volume>
            <doi>10.1088/1361-6420/ab2ae9</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Soubies, E., Soulez, F., McCann, M. T., Pham, T., Donati, L., Debarre, T., Sage, D., &amp; Unser, M. (2019). Pocket guide to solve inverse problems with GlobalBioIm. Inverse Problems, 35(10), 104006. https://doi.org/10.1088/1361-6420/ab2ae9</unstructured_citation>
          </citation>
          <citation key="gazzola2019ir">
            <article_title>IR tools: A MATLAB package of iterative regularization methods and large-scale test problems</article_title>
            <author>Gazzola</author>
            <journal_title>Numerical Algorithms</journal_title>
            <issue>3</issue>
            <volume>81</volume>
            <doi>10.1007/s11075-018-0570-7</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Gazzola, S., Hansen, P. C., &amp; Nagy, J. G. (2019). IR tools: A MATLAB package of iterative regularization methods and large-scale test problems. Numerical Algorithms, 81(3), 773–811. https://doi.org/10.1007/s11075-018-0570-7</unstructured_citation>
          </citation>
          <citation key="blau2018perception">
            <article_title>The perception-distortion tradeoff</article_title>
            <author>Blau</author>
            <journal_title>Proceedings of the IEEE conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/CVPR.2018.00652</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Blau, Y., &amp; Michaeli, T. (2018). The perception-distortion tradeoff. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 6228–6237. https://doi.org/10.1109/CVPR.2018.00652</unstructured_citation>
          </citation>
          <citation key="zhang2018unreasonable">
            <article_title>The unreasonable effectiveness of deep features as a perceptual metric</article_title>
            <author>Zhang</author>
            <journal_title>Proceedings of the IEEE conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/cvpr.2018.00068</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Zhang, R., Isola, P., Efros, A. A., Shechtman, E., &amp; Wang, O. (2018). The unreasonable effectiveness of deep features as a perceptual metric. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 586–595. https://doi.org/10.1109/cvpr.2018.00068</unstructured_citation>
          </citation>
          <citation key="yeganeh2012objective">
            <article_title>Objective quality assessment of tone-mapped images</article_title>
            <author>Yeganeh</author>
            <journal_title>IEEE Transactions on Image processing</journal_title>
            <issue>2</issue>
            <volume>22</volume>
            <doi>10.1109/TIP.2012.2221725</doi>
            <cYear>2012</cYear>
            <unstructured_citation>Yeganeh, H., &amp; Wang, Z. (2012). Objective quality assessment of tone-mapped images. IEEE Transactions on Image Processing, 22(2), 657–667. https://doi.org/10.1109/TIP.2012.2221725</unstructured_citation>
          </citation>
          <citation key="chen2023imaging">
            <article_title>Imaging With Equivariant Deep Learning: From unrolled network design to fully unsupervised learning</article_title>
            <author>Chen</author>
            <journal_title>IEEE Signal Processing Magazine</journal_title>
            <volume>40</volume>
            <doi>10.1109/MSP.2022.3205430</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Chen, D., Davies, M., Ehrhardt, M. J., Schönlieb, C.-B., Sherry, F., &amp; Tachella, J. (2023). Imaging With Equivariant Deep Learning: From unrolled network design to fully unsupervised learning. IEEE Signal Processing Magazine, 40, 134–147. https://doi.org/10.1109/MSP.2022.3205430</unstructured_citation>
          </citation>
          <citation key="chambolle2016introduction">
            <article_title>An introduction to continuous optimization for imaging</article_title>
            <author>Chambolle</author>
            <journal_title>Acta Numerica</journal_title>
            <volume>25</volume>
            <doi>10.1017/s096249291600009x</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Chambolle, A., &amp; Pock, T. (2016). An introduction to continuous optimization for imaging. Acta Numerica, 25, 161–319. https://doi.org/10.1017/s096249291600009x</unstructured_citation>
          </citation>
          <citation key="candes2008introduction">
            <article_title>An introduction to compressive sampling</article_title>
            <author>Candès</author>
            <journal_title>IEEE signal processing magazine</journal_title>
            <issue>2</issue>
            <volume>25</volume>
            <doi>10.1109/MSP.2007.914731</doi>
            <cYear>2008</cYear>
            <unstructured_citation>Candès, E. J., &amp; Wakin, M. B. (2008). An introduction to compressive sampling. IEEE Signal Processing Magazine, 25(2), 21–30. https://doi.org/10.1109/MSP.2007.914731</unstructured_citation>
          </citation>
          <citation key="chung2022diffusion">
            <article_title>Diffusion posterior sampling for general noisy inverse problems</article_title>
            <author>Chung</author>
            <journal_title>The eleventh international conference on learning representations</journal_title>
            <doi>10.48550/arXiv.2209.14687</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Chung, H., Kim, J., Mccann, M. T., Klasky, M. L., &amp; Ye, J. C. (2023). Diffusion posterior sampling for general noisy inverse problems. The Eleventh International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2209.14687</unstructured_citation>
          </citation>
          <citation key="zhu2023denoising">
            <article_title>Denoising diffusion models for plug-and-play image restoration</article_title>
            <author>Zhu</author>
            <journal_title>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/cvprw59228.2023.00129</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Zhu, Y., Zhang, K., Liang, J., Cao, J., Wen, B., Timofte, R., &amp; Van Gool, L. (2023). Denoising diffusion models for plug-and-play image restoration. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 1219–1229. https://doi.org/10.1109/cvprw59228.2023.00129</unstructured_citation>
          </citation>
          <citation key="kawar2022denoising">
            <article_title>Denoising diffusion restoration models</article_title>
            <author>Kawar</author>
            <journal_title>Advances in Neural Information Processing Systems</journal_title>
            <volume>35</volume>
            <doi>10.48550/arXiv.2201.11793</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Kawar, B., Elad, M., Ermon, S., &amp; Song, J. (2022). Denoising diffusion restoration models. Advances in Neural Information Processing Systems, 35, 23593–23606. https://doi.org/10.48550/arXiv.2201.11793</unstructured_citation>
          </citation>
          <citation key="laumont2022bayesian">
            <article_title>Bayesian imaging using plug &amp; play priors: When Langevin meets Tweedie</article_title>
            <author>Laumont</author>
            <journal_title>SIAM Journal on Imaging Sciences</journal_title>
            <issue>2</issue>
            <volume>15</volume>
            <doi>10.1137/21M1406349</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Laumont, R., Bortoli, V. D., Almansa, A., Delon, J., Durmus, A., &amp; Pereyra, M. (2022). Bayesian imaging using plug &amp; play priors: When Langevin meets Tweedie. SIAM Journal on Imaging Sciences, 15(2), 701–737. https://doi.org/10.1137/21M1406349</unstructured_citation>
          </citation>
          <citation key="zhang2021plug">
            <article_title>Plug-and-play image restoration with deep denoiser prior</article_title>
            <author>Zhang</author>
            <journal_title>IEEE Transactions on Pattern Analysis and Machine Intelligence</journal_title>
            <issue>10</issue>
            <volume>44</volume>
            <doi>10.1109/TPAMI.2021.3088914</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Zhang, K., Li, Y., Zuo, W., Zhang, L., Van Gool, L., &amp; Timofte, R. (2021). Plug-and-play image restoration with deep denoiser prior. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(10), 6360–6376. https://doi.org/10.1109/TPAMI.2021.3088914</unstructured_citation>
          </citation>
          <citation key="bora2018ambientgan">
            <article_title>AmbientGAN: Generative models from lossy measurements</article_title>
            <author>Bora</author>
            <journal_title>International conference on learning representations</journal_title>
            <cYear>2018</cYear>
            <unstructured_citation>Bora, A., Price, E., &amp; Dimakis, A. G. (2018). AmbientGAN: Generative models from lossy measurements. International Conference on Learning Representations. https://openreview.net/forum?id=Hy7fDog0b</unstructured_citation>
          </citation>
          <citation key="bora2017compressed">
            <article_title>Compressed sensing using generative models</article_title>
            <author>Bora</author>
            <journal_title>International conference on machine learning</journal_title>
            <doi>10.48550/arXiv.1703.03208</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Bora, A., Jalal, A., Price, E., &amp; Dimakis, A. G. (2017). Compressed sensing using generative models. International Conference on Machine Learning, 537–546. https://doi.org/10.48550/arXiv.1703.03208</unstructured_citation>
          </citation>
          <citation key="bendel2023gan">
            <article_title>A regularized conditional GAN for posterior sampling in image recovery problems</article_title>
            <author>Bendel</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>36</volume>
            <doi>10.48550/arXiv.2210.13389</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Bendel, M., Ahmad, R., &amp; Schniter, P. (2023). A regularized conditional GAN for posterior sampling in image recovery problems. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, &amp; S. Levine (Eds.), Advances in neural information processing systems (Vol. 36, pp. 68673–68684). Curran Associates, Inc. https://doi.org/10.48550/arXiv.2210.13389</unstructured_citation>
          </citation>
          <citation key="park2025plug">
            <article_title>Plug-and-play priors as a score-based method</article_title>
            <author>Park</author>
            <journal_title>2025 IEEE international conference on image processing (ICIP)</journal_title>
            <doi>10.1109/ICIP55913.2025.11084503</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Park, C. Y., Hu, Y., McCann, M. T., Garcia-Cardona, C., Wohlberg, B., &amp; Kamilov, U. S. (2025). Plug-and-play priors as a score-based method. 2025 IEEE International Conference on Image Processing (ICIP), 49–54. https://doi.org/10.1109/ICIP55913.2025.11084503</unstructured_citation>
          </citation>
          <citation key="terris2024equivariant">
            <article_title>Equivariant plug-and-play image reconstruction</article_title>
            <author>Terris</author>
            <journal_title>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/cvpr52733.2024.02386</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Terris, M., Moreau, T., Pustelnik, N., &amp; Tachella, J. (2024). Equivariant plug-and-play image reconstruction. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 25255–25264. https://doi.org/10.1109/cvpr52733.2024.02386</unstructured_citation>
          </citation>
          <citation key="ulyanov2018deep">
            <article_title>Deep image prior</article_title>
            <author>Ulyanov</author>
            <journal_title>Proceedings of the IEEE conference on computer vision and pattern recognition</journal_title>
            <doi>10.1109/CVPR.2018.00984</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Ulyanov, D., Vedaldi, A., &amp; Lempitsky, V. (2018). Deep image prior. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 9446–9454. https://doi.org/10.1109/CVPR.2018.00984</unstructured_citation>
          </citation>
          <citation key="jin2017deep">
            <article_title>Deep convolutional neural network for inverse problems in imaging</article_title>
            <author>Jin</author>
            <journal_title>IEEE transactions on image processing</journal_title>
            <issue>9</issue>
            <volume>26</volume>
            <doi>10.1109/TIP.2017.2713099</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Jin, K. H., McCann, M. T., Froustey, E., &amp; Unser, M. (2017). Deep convolutional neural network for inverse problems in imaging. IEEE Transactions on Image Processing, 26(9), 4509–4522. https://doi.org/10.1109/TIP.2017.2713099</unstructured_citation>
          </citation>
          <citation key="ravasi2019pylops">
            <article_title>PyLops–a linear-operator Python library for large scale optimization</article_title>
            <author>Ravasi</author>
            <journal_title>arXiv preprint arXiv:1907.12349</journal_title>
            <doi>10.48550/arXiv.1907.12349</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Ravasi, M., &amp; Vasconcelos, I. (2019). PyLops–a linear-operator Python library for large scale optimization. arXiv Preprint arXiv:1907.12349. https://doi.org/10.48550/arXiv.1907.12349</unstructured_citation>
          </citation>
          <citation key="polson2025pytomography">
            <article_title>Pytomography: A Python library for medical image reconstruction</article_title>
            <author>Polson</author>
            <journal_title>SoftwareX</journal_title>
            <volume>29</volume>
            <doi>10.2139/ssrn.4865134</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Polson, L. A., Fedrigo, R., Li, C., Sabouri, M., Dzikunu, O., Ahamed, S., Karakatsanis, N., Kurkowska, S., Sheikhzadeh, P., Esquinas, P., &amp; others. (2025). Pytomography: A Python library for medical image reconstruction. SoftwareX, 29, 102020. https://doi.org/10.2139/ssrn.4865134</unstructured_citation>
          </citation>
          <citation key="dossal2024optimizationorderalgorithms">
            <article_title>Optimization with first order algorithms</article_title>
            <author>Dossal</author>
            <journal_title>arXiv preprint arXiv:2410.19506</journal_title>
            <doi>10.48550/arXiv.2410.19506</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Dossal, C., Hurault, S., &amp; Papadakis, N. (2024). Optimization with first order algorithms. arXiv Preprint arXiv:2410.19506. https://doi.org/10.48550/arXiv.2410.19506</unstructured_citation>
          </citation>
          <citation key="venkatakrishnan2013plug">
            <article_title>Plug-and-play priors for model based reconstruction</article_title>
            <author>Venkatakrishnan</author>
            <journal_title>2013 IEEE global conference on signal and information processing</journal_title>
            <doi>10.1109/globalsip.2013.6737048</doi>
            <cYear>2013</cYear>
            <unstructured_citation>Venkatakrishnan, S. V., Bouman, C. A., &amp; Wohlberg, B. (2013). Plug-and-play priors for model based reconstruction. 2013 IEEE Global Conference on Signal and Information Processing, 945–948. https://doi.org/10.1109/globalsip.2013.6737048</unstructured_citation>
          </citation>
          <citation key="van2016astra">
            <article_title>Fast and flexible x-ray tomography using the ASTRA toolbox</article_title>
            <author>Van Aarle</author>
            <journal_title>Optics express</journal_title>
            <issue>22</issue>
            <volume>24</volume>
            <doi>10.1364/oe.24.025129</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Van Aarle, W., Palenstijn, W. J., Cant, J., Janssens, E., Bleichrodt, F., Dabravolski, A., De Beenhouwer, J., Joost Batenburg, K., &amp; Sijbers, J. (2016). Fast and flexible x-ray tomography using the ASTRA toolbox. Optics Express, 24(22), 25129–25147. https://doi.org/10.1364/oe.24.025129</unstructured_citation>
          </citation>
          <citation key="adler2018odl">
            <article_title>Odlgroup/odl: ODL 0.7.0</article_title>
            <author>Adler</author>
            <doi>10.5281/zenodo.1442734</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Adler, J., Kohr, H., Ringh, A., Moosmann, J., sbanert, Ehrhardt, M. J., Lee, G. R., niinimaki, bgris, Verdier, O., Karlsson, J., zickert, Palenstijn, W. J., Öktem, O., Chen, C., Loarca, H. A., &amp; Lohmann, M. (2018). Odlgroup/odl: ODL 0.7.0 (Version v0.7.0). Zenodo. https://doi.org/10.5281/zenodo.1442734</unstructured_citation>
          </citation>
          <citation key="yaman2020self">
            <article_title>Self-supervised learning of physics-guided reconstruction neural networks without fully sampled reference data</article_title>
            <author>Yaman</author>
            <journal_title>Magnetic resonance in medicine</journal_title>
            <issue>6</issue>
            <volume>84</volume>
            <doi>10.1002/mrm.28378</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Yaman, B., Hosseini, S. A. H., Moeller, S., Ellermann, J., Uğurbil, K., &amp; Akçakaya, M. (2020). Self-supervised learning of physics-guided reconstruction neural networks without fully sampled reference data. Magnetic Resonance in Medicine, 84(6), 3172–3191. https://doi.org/10.1002/mrm.28378</unstructured_citation>
          </citation>
          <citation key="simeoni2022pyxu">
            <article_title>Pyxu-org/pyxu: pyxu</article_title>
            <author>Simeoni</author>
            <doi>10.5281/zenodo.4486431</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Simeoni, M., Kashani, S., Rué-Queralt, J., &amp; Developers, P. (2024). Pyxu-org/pyxu: pyxu. Zenodo. https://doi.org/10.5281/zenodo.4486431</unstructured_citation>
          </citation>
          <citation key="balke2022scico">
            <article_title>Scientific computational imaging code (SCICO)</article_title>
            <author>Balke</author>
            <journal_title>Journal of Open Source Software</journal_title>
            <issue>78</issue>
            <volume>7</volume>
            <doi>10.21105/joss.04722</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Balke, T., Davis, F., Garcia-Cardona, C., Majee, S., McCann, M., Pfister, L., &amp; Wohlberg, B. (2022). Scientific computational imaging code (SCICO). Journal of Open Source Software, 7(78), 4722. https://doi.org/10.21105/joss.04722</unstructured_citation>
          </citation>
          <citation key="terris2025ram">
            <article_title>Reconstruct anything model: A lightweight foundation model for computational imaging</article_title>
            <author>Terris</author>
            <journal_title>arXiv preprint arXiv:2503.08915</journal_title>
            <doi>10.48550/arXiv.2503.08915</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Terris, M., Hurault, S., Song, M., &amp; Tachella, J. (2025). Reconstruct anything model: A lightweight foundation model for computational imaging. arXiv Preprint arXiv:2503.08915. https://doi.org/10.48550/arXiv.2503.08915</unstructured_citation>
          </citation>
          <citation key="gregor2010learning">
            <article_title>Learning fast approximations of sparse coding</article_title>
            <author>Gregor</author>
            <journal_title>Proceedings of the 27th international conference on international conference on machine learning</journal_title>
            <cYear>2010</cYear>
            <unstructured_citation>Gregor, K., &amp; LeCun, Y. (2010). Learning fast approximations of sparse coding. Proceedings of the 27th International Conference on International Conference on Machine Learning, 399–406. https://dl.acm.org/doi/10.5555/3104322.3104374</unstructured_citation>
          </citation>
          <citation key="altekruger2023patchnr">
            <article_title>PatchNR: Learning from very few images by patch normalizing flow regularization</article_title>
            <author>Altekrüger</author>
            <journal_title>Inverse Problems</journal_title>
            <issue>6</issue>
            <volume>39</volume>
            <doi>10.1088/1361-6420/acce5e</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Altekrüger, F., Denker, A., Hagemann, P., Hertrich, J., Maass, P., &amp; Steidl, G. (2023). PatchNR: Learning from very few images by patch normalizing flow regularization. Inverse Problems, 39(6), 064006. https://doi.org/10.1088/1361-6420/acce5e</unstructured_citation>
          </citation>
          <citation key="zoran2011epll">
            <article_title>From learning models of natural image patches to whole image restoration</article_title>
            <author>Zoran</author>
            <journal_title>2011 international conference on computer vision</journal_title>
            <doi>10.1109/ICCV.2011.6126278</doi>
            <cYear>2011</cYear>
            <unstructured_citation>Zoran, D., &amp; Weiss, Y. (2011). From learning models of natural image patches to whole image restoration. 2011 International Conference on Computer Vision, 479–486. https://doi.org/10.1109/ICCV.2011.6126278</unstructured_citation>
          </citation>
          <citation key="bai2019deep">
            <article_title>Deep equilibrium models</article_title>
            <author>Bai</author>
            <journal_title>Advances in neural information processing systems</journal_title>
            <volume>32</volume>
            <doi>10.48550/arXiv.1909.01377</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Bai, S., Kolter, J. Z., &amp; Koltun, V. (2019). Deep equilibrium models. Advances in Neural Information Processing Systems, 32. https://doi.org/10.48550/arXiv.1909.01377</unstructured_citation>
          </citation>
          <citation key="pereyra2020skrock">
            <article_title>Accelerating proximal Markov Chain Monte Carlo by using an explicit stabilized method</article_title>
            <author>Pereyra</author>
            <journal_title>SIAM Journal on Imaging Sciences</journal_title>
            <issue>2</issue>
            <volume>13</volume>
            <doi>10.1137/19M1283719</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Pereyra, M., Mieles, L. V., &amp; Zygalakis, K. C. (2020). Accelerating proximal Markov Chain Monte Carlo by using an explicit stabilized method. SIAM Journal on Imaging Sciences, 13(2), 905–935. https://doi.org/10.1137/19M1283719</unstructured_citation>
          </citation>
          <citation key="tachella2024equivariant">
            <article_title>Equivariant bootstrapping for uncertainty quantification in imaging inverse problems</article_title>
            <author>Tachella</author>
            <journal_title>27th international conference on artificial intelligence and statistics 2024</journal_title>
            <doi>10.48550/arXiv.2310.11838</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Tachella, J., &amp; Pereyra, M. (2024). Equivariant bootstrapping for uncertainty quantification in imaging inverse problems. 27th International Conference on Artificial Intelligence and Statistics 2024, 4141–4149. https://doi.org/10.48550/arXiv.2310.11838</unstructured_citation>
          </citation>
          <citation key="hu2025structured">
            <article_title>Structured random model for fast and robust phase retrieval</article_title>
            <author>Hu</author>
            <journal_title>ICASSP 2025-2025 IEEE international conference on acoustics, speech and signal processing (ICASSP)</journal_title>
            <doi>10.1109/ICASSP49660.2025.10889235</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Hu, Z., Tachella, J., Unser, M., &amp; Dong, J. (2025). Structured random model for fast and robust phase retrieval. ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1–5. https://doi.org/10.1109/ICASSP49660.2025.10889235</unstructured_citation>
          </citation>
          <citation key="biguri2025tigre">
            <article_title>TIGRE v3: Efficient and easy to use iterative computed tomographic reconstruction toolbox for real datasets</article_title>
            <author>Biguri</author>
            <journal_title>Engineering Research Express</journal_title>
            <issue>1</issue>
            <volume>7</volume>
            <doi>10.1088/2631-8695/adbb3a</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Biguri, A., Sadakane, T., Lindroos, R., Liu, Y., Landman, M. S., Du, Y., Lohvithee, M., Kaser, S., Hatamikia, S., Bryll, R., &amp; others. (2025). TIGRE v3: Efficient and easy to use iterative computed tomographic reconstruction toolbox for real datasets. Engineering Research Express, 7(1), 015011. https://doi.org/10.1088/2631-8695/adbb3a</unstructured_citation>
          </citation>
          <citation key="pesquet2021learning">
            <article_title>Learning maximally monotone operators for image recovery</article_title>
            <author>Pesquet</author>
            <journal_title>SIAM Journal on Imaging Sciences</journal_title>
            <issue>3</issue>
            <volume>14</volume>
            <doi>10.1137/20m1387961</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Pesquet, J.-C., Repetti, A., Terris, M., &amp; Wiaux, Y. (2021). Learning maximally monotone operators for image recovery. SIAM Journal on Imaging Sciences, 14(3), 1206–1237. https://doi.org/10.1137/20m1387961</unstructured_citation>
          </citation>
          <citation key="tachella2025unsure">
            <article_title>UNSURE: Self-supervised learning with Unknown Noise level and Stein’s Unbiased Risk Estimate</article_title>
            <author>Tachella</author>
            <journal_title>International conference on learning representations</journal_title>
            <doi>10.48550/arXiv.2409.01985</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Tachella, J., Davies, M., &amp; Jacques, L. (2025). UNSURE: Self-supervised learning with Unknown Noise level and Stein’s Unbiased Risk Estimate. International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2409.01985</unstructured_citation>
          </citation>
          <citation key="najera2023sphinxgallery">
            <article_title>Sphinx-gallery/sphinx-gallery: v0.12.2</article_title>
            <author>Najera</author>
            <doi>10.5281/zenodo.7716999</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Najera, O., Larson, E., Liu, L., Esteve, L., Varoquaux, G., Grobler, J., Andrade, E. S. de, Holdgraf, C., Gramfort, A., Jas, M., Nothman, J., Rehberg, S., Grisel, O., Varoquaux, N., Hiscocks, S., alexis, Gouillart, E., Hoffmann, T., Lee, A., … Kunzmann, P. (2023). Sphinx-gallery/sphinx-gallery: v0.12.2 (Version v0.12.2). Zenodo. https://doi.org/10.5281/zenodo.7716999</unstructured_citation>
          </citation>
          <citation key="riis2024cuqipy">
            <article_title>CUQIpy: I. Computational uncertainty quantification for inverse problems in Python</article_title>
            <author>Riis</author>
            <journal_title>Inverse Problems</journal_title>
            <issue>4</issue>
            <volume>40</volume>
            <doi>10.1088/1361-6420/ad22e7</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Riis, N. A., Alghamdi, A. M., Uribe, F., Christensen, S. L., Afkham, B. M., Hansen, P. C., &amp; Jørgensen, J. S. (2024). CUQIpy: I. Computational uncertainty quantification for inverse problems in Python. Inverse Problems, 40(4), 045009. https://doi.org/10.1088/1361-6420/ad22e7</unstructured_citation>
          </citation>
          <citation key="jorgensen2021core">
            <article_title>Core Imaging Library-part I: A versatile Python framework for tomographic imaging</article_title>
            <author>Jørgensen</author>
            <journal_title>Philosophical Transactions of the Royal Society A</journal_title>
            <issue>2204</issue>
            <volume>379</volume>
            <doi>10.1098/rsta.2020.0192</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Jørgensen, J. S., Ametova, E., Burca, G., Fardell, G., Papoutsellis, E., Pasca, E., Thielemans, K., Turner, M., Warr, R., Lionheart, W. R., &amp; others. (2021). Core Imaging Library-part I: A versatile Python framework for tomographic imaging. Philosophical Transactions of the Royal Society A, 379(2204), 20200192. https://doi.org/10.1098/rsta.2020.0192</unstructured_citation>
          </citation>
          <citation key="ong2019sigpy">
            <article_title>SigPy: A Python package for high performance iterative reconstruction</article_title>
            <author>Ong</author>
            <cYear>2019</cYear>
            <unstructured_citation>Ong, F., &amp; Lustig, M. (2019). SigPy: A Python package for high performance iterative reconstruction. ISMRM. https://archive.ismrm.org/2019/4819.html</unstructured_citation>
          </citation>
          <citation key="wang2025benchmarking">
            <article_title>Benchmarking self-supervised methods for accelerated MRI reconstruction</article_title>
            <author>Wang</author>
            <journal_title>arXiv preprint arXiv:2502.14009</journal_title>
            <doi>10.48550/arXiv.2502.14009</doi>
            <cYear>2025</cYear>
            <unstructured_citation>Wang, A., &amp; Davies, M. (2025). Benchmarking self-supervised methods for accelerated MRI reconstruction. arXiv Preprint arXiv:2502.14009. https://doi.org/10.48550/arXiv.2502.14009</unstructured_citation>
          </citation>
          <citation key="wang2024perspective">
            <article_title>Perspective-equivariance for unsupervised imaging with camera geometry</article_title>
            <author>Wang</author>
            <journal_title>IEEE/CVF European Conference on Computer Vision (ECCV) Workshop on Traditional Computer Vision in the Age of Deep Learning</journal_title>
            <doi>10.1007/978-3-031-91585-7_8</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Wang, A., &amp; Davies, M. (2024). Perspective-equivariance for unsupervised imaging with camera geometry. IEEE/CVF European Conference on Computer Vision (ECCV) Workshop on Traditional Computer Vision in the Age of Deep Learning. https://doi.org/10.1007/978-3-031-91585-7_8</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
