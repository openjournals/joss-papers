<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8923</article-id>
<article-id pub-id-type="doi">10.21105/joss.08923</article-id>
<title-group>
<article-title>DeepInverse: A Python package for solving imaging inverse
problems with deep learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3878-9142</contrib-id>
<name>
<surname>Tachella</surname>
<given-names>Juli√°n</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Terris</surname>
<given-names>Matthieu</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Hurault</surname>
<given-names>Samuel</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0838-7986</contrib-id>
<name>
<surname>Wang</surname>
<given-names>Andrew</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Davy</surname>
<given-names>Leo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Scanvic</surname>
<given-names>J√©r√©my</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sechaud</surname>
<given-names>Victor</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Vo</surname>
<given-names>Romain</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moreau</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Davies</surname>
<given-names>Thomas</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Dongdong</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Laurent</surname>
<given-names>Nils</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Monroy</surname>
<given-names>Brayan</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dong</surname>
<given-names>Jonathan</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hu</surname>
<given-names>Zhiyuan</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nguyen</surname>
<given-names>Minh-Hai</given-names>
</name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sarron</surname>
<given-names>Florian</given-names>
</name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Weiss</surname>
<given-names>Pierre</given-names>
</name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Escande</surname>
<given-names>Paul</given-names>
</name>
<xref ref-type="aff" rid="aff-9"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Massias</surname>
<given-names>Mathurin</given-names>
</name>
<xref ref-type="aff" rid="aff-10"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Modrzyk</surname>
<given-names>Thibaut</given-names>
</name>
<xref ref-type="aff" rid="aff-11"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Levac</surname>
<given-names>Brett</given-names>
</name>
<xref ref-type="aff" rid="aff-12"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liaudat</surname>
<given-names>Tob√≠as I.</given-names>
</name>
<xref ref-type="aff" rid="aff-13"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Song</surname>
<given-names>Maxime</given-names>
</name>
<xref ref-type="aff" rid="aff-14"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hertrich</surname>
<given-names>Johannes</given-names>
</name>
<xref ref-type="aff" rid="aff-15"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Neumayer</surname>
<given-names>Sebastian</given-names>
</name>
<xref ref-type="aff" rid="aff-16"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2251-3195</contrib-id>
<name>
<surname>Schramm</surname>
<given-names>Georg</given-names>
</name>
<xref ref-type="aff" rid="aff-17"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>CNRS, ENS de Lyon, France</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Universit√© Paris-Saclay, Inria, CEA, Palaiseau,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>CNRS, ENS Paris, PSL, France</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>University of Edinburgh, UK</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Heriot-Watt University, Edinburgh, UK</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Universidad Industrial de Santander, Bucaramanga,
Colombia</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>EPFL, Lausanne, Switzerland</institution>
</institution-wrap>
</aff>
<aff id="aff-8">
<institution-wrap>
<institution>IRIT, CBI, CNRS, Universit√© de Toulouse,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-9">
<institution-wrap>
<institution>IMT, CNRS, Universit√© de Toulouse, France</institution>
</institution-wrap>
</aff>
<aff id="aff-10">
<institution-wrap>
<institution>Inria, ENS de Lyon, France</institution>
</institution-wrap>
</aff>
<aff id="aff-11">
<institution-wrap>
<institution>INSA de Lyon, France</institution>
</institution-wrap>
</aff>
<aff id="aff-12">
<institution-wrap>
<institution>University of Texas at Austin, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-13">
<institution-wrap>
<institution>IRFU, CEA, Universit√© Paris-Saclay, Gif-sur-Yvette,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-14">
<institution-wrap>
<institution>CNRS UAR 851, Universit√© Paris-Saclay Orsay,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-15">
<institution-wrap>
<institution>Universit√© Paris Dauphine - PSL, Paris,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-16">
<institution-wrap>
<institution>Chemnitz University of Technology, Chemnitz,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-17">
<institution-wrap>
<institution>Department of Imaging and Pathology, KU Leuven,
Belgium</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-05-15">
<day>15</day>
<month>5</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>115</issue>
<fpage>8923</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>PyTorch</kwd>
<kwd>imaging inverse problems</kwd>
<kwd>computational imaging</kwd>
<kwd>deep learning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/">DeepInverse</ext-link>
  is an open-source PyTorch-based library for imaging inverse problems.
  DeepInverse implements all steps for image reconstruction, including
  efficient forward operators, defining and solving variational problems
  and designing and training advanced neural networks, for a wide set of
  domains (medical imaging, astronomical imaging, remote sensing,
  computational photography, compressed sensing and more).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Deep neural networks have become ubiquitous in various imaging
  inverse problems. Despite the ever-increasing research effort, most
  learning-based algorithms are built from scratch, are hard to
  generalize beyond their specific training setting, and the reported
  results are often hard to reproduce. DeepInverse overcomes these
  limitations by providing a modular unified framework, leveraging the
  popular PyTorch deep learning library
  (<xref alt="Paszke et al., 2019" rid="ref-paszke2019pytorch" ref-type="bibr">Paszke
  et al., 2019</xref>). For our audience of researchers (experts in
  optimization, deep learning etc.), practitioners (biologists,
  physicists etc.) and imaging software engineers, DeepInverse is:</p>
  <list list-type="order">
    <list-item>
      <p><bold>Accelerating research</bold> by enabling efficient
      testing, deployment and transfer of new ideas across imaging
      domains;</p>
    </list-item>
    <list-item>
      <p>Enlarging the <bold>adoption of deep learning in inverse
      problems</bold> by lowering the entrance bar to new users;</p>
    </list-item>
    <list-item>
      <p>Enhancing <bold>research reproducibility</bold> via a common
      modular framework of problems and algorithms.</p>
    </list-item>
  </list>
  <p>To the best of our knowledge, DeepInverse is the only library with
  a strong focus on and a wide set of modern learning-based methods
  across domains. SCICO
  (<xref alt="Balke et al., 2022" rid="ref-balke2022scico" ref-type="bibr">Balke
  et al., 2022</xref>) and Pyxu
  (<xref alt="Simeoni et al., 2024" rid="ref-simeoni2022pyxu" ref-type="bibr">Simeoni
  et al., 2024</xref>) focus on optimization-based methods. CUQIpy
  (<xref alt="Riis et al., 2024" rid="ref-riis2024cuqipy" ref-type="bibr">Riis
  et al., 2024</xref>) focuses on Bayesian uncertainty quantification.
  ASTRA
  (<xref alt="Van Aarle et al., 2016" rid="ref-van2016astra" ref-type="bibr">Van
  Aarle et al., 2016</xref>), pytomography
  (<xref alt="Polson et al., 2025" rid="ref-polson2025pytomography" ref-type="bibr">Polson
  et al., 2025</xref>), TIGRE
  (<xref alt="Biguri et al., 2025" rid="ref-biguri2025tigre" ref-type="bibr">Biguri
  et al., 2025</xref>), ODL
  (<xref alt="Adler et al., 2018" rid="ref-adler2018odl" ref-type="bibr">Adler
  et al., 2018</xref>) and CIL
  (<xref alt="J√∏rgensen et al., 2021" rid="ref-jorgensen2021core" ref-type="bibr">J√∏rgensen
  et al., 2021</xref>) focus on tomography, sigpy
  (<xref alt="Ong &amp; Lustig, 2019" rid="ref-ong2019sigpy" ref-type="bibr">Ong
  &amp; Lustig, 2019</xref>) on magnetic resonance imaging, and PyLops
  (<xref alt="Ravasi &amp; Vasconcelos, 2019" rid="ref-ravasi2019pylops" ref-type="bibr">Ravasi
  &amp; Vasconcelos, 2019</xref>) on certain linear operators. MATLAB
  libraries
  (<xref alt="Gazzola et al., 2019" rid="ref-gazzola2019ir" ref-type="bibr">Gazzola
  et al., 2019</xref>;
  <xref alt="Soubies et al., 2019" rid="ref-soubies2019pocket" ref-type="bibr">Soubies
  et al., 2019</xref>) are restricted to handcrafted methods without
  automatic differentiation.</p>
  <fig>
    <caption><p>Schematic of the modular DeepInverse
    framework.<styled-content id="figU003Aschematic"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="../docs/source/figures/deepinv_schematic.png" />
  </fig>
</sec>
<sec id="inverse-problems">
  <title>Inverse Problems</title>
  <p>Imaging inverse problems can be expressed as
  <named-content id="eqU003Aforward" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
  y = N_{\sigma}(A_{\xi}(x)),]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>œÉ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></named-content>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[x\in\mathcal{X}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>x</mml:mi><mml:mo>‚àà</mml:mo><mml:mi>ùí≥</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  is an image, <inline-formula><alternatives>
  <tex-math><![CDATA[y\in\mathcal{Y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>y</mml:mi><mml:mo>‚àà</mml:mo><mml:mi>ùí¥</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  are the measurements, <inline-formula><alternatives>
  <tex-math><![CDATA[A_{\xi}\colon\mathcal{X}\mapsto\mathcal{Y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mi>ùí≥</mml:mi><mml:mo>‚Ü¶</mml:mo><mml:mi>ùí¥</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  is a deterministic (linear or non-linear) operator capturing the
  physics of the acquisition and <inline-formula><alternatives>
  <tex-math><![CDATA[N_{\sigma}\colon\mathcal{Y}\mapsto \mathcal{Y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>œÉ</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mi>ùí¥</mml:mi><mml:mo>‚Ü¶</mml:mo><mml:mi>ùí¥</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  is a noise model parameterized by <inline-formula><alternatives>
  <tex-math><![CDATA[\sigma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>œÉ</mml:mi></mml:math></alternatives></inline-formula>.
  The
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/physics/intro.html"><monospace>physics</monospace>
  module</ext-link> provides a scalable and modular framework, writing
  the forward operation as
  <monospace>y = physics(x, **params)</monospace>, unifying the wide
  variety of forward operators across various domains.</p>
  <p>The library crucially introduces optional physics
  <monospace>params</monospace> <inline-formula><alternatives>
  <tex-math><![CDATA[(\xi,\sigma)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œæ</mml:mi><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
  allowing for advanced problems, including calibration, blind inverse
  problems
  (<xref alt="Chung, Kim, Kim, et al., 2023" rid="ref-chung2023parallel" ref-type="bibr">Chung,
  Kim, Kim, et al., 2023</xref>;
  <xref alt="Debarnot &amp; Weiss, 2024" rid="ref-debarnot2024deep" ref-type="bibr">Debarnot
  &amp; Weiss, 2024</xref>), co-design
  (<xref alt="Lazarus et al., 2019" rid="ref-lazarus2019sparkling" ref-type="bibr">Lazarus
  et al., 2019</xref>;
  <xref alt="Nehme et al., 2020" rid="ref-nehme2020deepstorm3d" ref-type="bibr">Nehme
  et al., 2020</xref>), and robust training
  (<xref alt="Gossard &amp; Weiss, 2024" rid="ref-gossard2024training" ref-type="bibr">Gossard
  &amp; Weiss, 2024</xref>;
  <xref alt="Terris &amp; Moreau, 2023" rid="ref-terris2023meta" ref-type="bibr">Terris
  &amp; Moreau, 2023</xref>).</p>
  <p>The current implemented physics, noise models, parameters
  <inline-formula><alternatives>
  <tex-math><![CDATA[\xi]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œæ</mml:mi></mml:math></alternatives></inline-formula>
  and tools for manipulating them are enumerated in the
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/physics/physics.html">documentation</ext-link>.</p>
</sec>
<sec id="reconstruction-methods">
  <title>Reconstruction Methods</title>
  <p>DeepInverse unifies the wide variety of commonly-used imaging
  solvers in the literature, written as:
  <named-content id="eqU003Asolver" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
  \hat{x} = \operatorname{R}_{\theta}(y, A_{\xi}, \sigma)]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">ÃÇ</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></named-content>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[\operatorname{R}_{\theta}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  is a reconstruction algorithm with optional trainable parameters
  <inline-formula><alternatives>
  <tex-math><![CDATA[\theta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œ∏</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\hat{x}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">ÃÇ</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  is the reconstructed image, written as
  <monospace>x_hat = model(y, physics)</monospace>. The current library
  of algorithms is enumerated in the
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/reconstruction/introduction.html">documentation</ext-link>,
  categorized as:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Optimization-based</bold> methods
      (<xref alt="Chambolle &amp; Pock, 2016" rid="ref-chambolle2016introduction" ref-type="bibr">Chambolle
      &amp; Pock, 2016</xref>) solve
      <named-content id="eqU003Avar" content-type="equation"><disp-formula><alternatives>
      <tex-math><![CDATA[
      \operatorname{R}_{\theta}(y, A_{\xi}, \sigma) \in \underset{x}{\operatorname{argmin}} f_{\sigma}(y,A_{\xi}(x)) + g(x).]]></tex-math>
      <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>‚àà</mml:mo><mml:munder><mml:mo>argmin</mml:mo><mml:mi>x</mml:mi></mml:munder><mml:msub><mml:mi>f</mml:mi><mml:mi>œÉ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></named-content></p>
      <p>The
      <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/reconstruction/optimization.html"><monospace>optim</monospace>
      module</ext-link> implements classical data fidelity terms
      <inline-formula><alternatives>
      <tex-math><![CDATA[f_{\sigma}\colon\mathcal{Y} \times \mathcal{Y} \mapsto \mathbb{R}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>œÉ</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mi>ùí¥</mml:mi><mml:mo>√ó</mml:mo><mml:mi>ùí¥</mml:mi><mml:mo>‚Ü¶</mml:mo><mml:mi>‚Ñù</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
      and a variety of regularization priors
      <inline-formula><alternatives>
      <tex-math><![CDATA[g\colon\mathcal{X}\mapsto\mathbb{R}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>g</mml:mi><mml:mo>:</mml:mo><mml:mi>ùí≥</mml:mi><mml:mo>‚Ü¶</mml:mo><mml:mi>‚Ñù</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
      including:</p>
      <list list-type="bullet">
        <list-item>
          <p>Traditional explicit priors
          (<xref alt="Cand√®s &amp; Wakin, 2008" rid="ref-candes2008introduction" ref-type="bibr">Cand√®s
          &amp; Wakin, 2008</xref>);</p>
        </list-item>
        <list-item>
          <p>Learned regularizers
          (<xref alt="Altekr√ºger et al., 2023" rid="ref-altekruger2023patchnr" ref-type="bibr">Altekr√ºger
          et al., 2023</xref>;
          <xref alt="Zoran &amp; Weiss, 2011" rid="ref-zoran2011epll" ref-type="bibr">Zoran
          &amp; Weiss, 2011</xref>);</p>
        </list-item>
        <list-item>
          <p>Plug-and-Play priors
          (<xref alt="Venkatakrishnan et al., 2013" rid="ref-venkatakrishnan2013plug" ref-type="bibr">Venkatakrishnan
          et al., 2013</xref>) using a pretrained denoiser
          <inline-formula><alternatives>
          <tex-math><![CDATA[\operatorname{D}_{\sigma}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mo>D</mml:mo><mml:mi>œÉ</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
          (<xref alt="K. Zhang et al., 2021" rid="ref-zhang2021plug" ref-type="bibr">K.
          Zhang et al., 2021</xref>).</p>
        </list-item>
      </list>
      <p>To solve these problems, <monospace>optim</monospace>
      includes:</p>
      <list list-type="bullet">
        <list-item>
          <p>Classical algorithms
          (<xref alt="Dossal et al., 2024" rid="ref-dossal2024optimizationorderalgorithms" ref-type="bibr">Dossal
          et al., 2024</xref>);</p>
        </list-item>
        <list-item>
          <p>Unfolded networks
          (<xref alt="Gregor &amp; LeCun, 2010" rid="ref-gregor2010learning" ref-type="bibr">Gregor
          &amp; LeCun, 2010</xref>), that unroll a fixed number of
          iterations of an optimization algorithm and train the
          parameters end-to-end;</p>
        </list-item>
        <list-item>
          <p>Deep equilibrium methods
          (<xref alt="Bai et al., 2019" rid="ref-bai2019deep" ref-type="bibr">Bai
          et al., 2019</xref>) that implicitly differentiate the fixed
          point of the algorithm.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p><bold>Sampling-based</bold> methods defined by differential
      equations: <disp-formula><alternatives>
      <tex-math><![CDATA[x_{t+1} \sim p(x_{t+1}|x_t, y, \operatorname{D}_{\sigma}, A_{\xi}, \sigma) \text{ for } t=0,\dots,T-1,]]></tex-math>
      <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>‚àº</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mo>D</mml:mo><mml:mi>œÉ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mspace width="0.333em"></mml:mspace><mml:mtext mathvariant="normal"> for </mml:mtext><mml:mspace width="0.333em"></mml:mspace></mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>‚àí</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
      such that <inline-formula><alternatives>
      <tex-math><![CDATA[x_{T}]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
      is approximately sampled from the posterior
      <inline-formula><alternatives>
      <tex-math><![CDATA[p(x|y)]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
      Sampling multiple times enables uncertainty quantification.</p>
      <p>The
      <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/reconstruction/sampling.html"><monospace>sampling</monospace>
      module</ext-link> implements generalized, modular frameworks
      for:</p>
      <list list-type="bullet">
        <list-item>
          <p>Diffusion model posterior sampling
          (<xref alt="Chung, Kim, Mccann, et al., 2023" rid="ref-chung2022diffusion" ref-type="bibr">Chung,
          Kim, Mccann, et al., 2023</xref>;
          <xref alt="Kawar et al., 2022" rid="ref-kawar2022denoising" ref-type="bibr">Kawar
          et al., 2022</xref>;
          <xref alt="Zhu et al., 2023" rid="ref-zhu2023denoising" ref-type="bibr">Zhu
          et al., 2023</xref>);</p>
        </list-item>
        <list-item>
          <p>Langevin-type algorithms
          (<xref alt="Laumont et al., 2022" rid="ref-laumont2022bayesian" ref-type="bibr">Laumont
          et al., 2022</xref>;
          <xref alt="Pereyra et al., 2020" rid="ref-pereyra2020skrock" ref-type="bibr">Pereyra
          et al., 2020</xref>) that sample using Markov Chain Monte
          Carlo.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p><bold>Non-iterative</bold>: The
      <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/reconstruction/introduction.html"><monospace>models</monospace>
      module</ext-link> implements:</p>
      <list list-type="bullet">
        <list-item>
          <p>Artifact removal models <inline-formula><alternatives>
          <tex-math><![CDATA[\operatorname{R}_{\theta}(y, A_{\xi}, \sigma) = \operatorname{D}_{\sigma}(A_{\xi}^{\top}y)]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo>D</mml:mo><mml:mi>œÉ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi><mml:mi>‚ä§</mml:mi></mml:msubsup><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
          which simply backproject <inline-formula><alternatives>
          <tex-math><![CDATA[y]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>
          to the image domain and apply an image-to-image denoiser
          <inline-formula><alternatives>
          <tex-math><![CDATA[\operatorname{D}_{\sigma}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mo>D</mml:mo><mml:mi>œÉ</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
          (<xref alt="Jin et al., 2017" rid="ref-jin2017deep" ref-type="bibr">Jin
          et al., 2017</xref>);</p>
        </list-item>
        <list-item>
          <p>Conditional/unconditional generative networks
          (<xref alt="Bendel et al., 2023" rid="ref-bendel2023gan" ref-type="bibr">Bendel
          et al., 2023</xref>;
          <xref alt="Bora et al., 2018" rid="ref-bora2018ambientgan" ref-type="bibr">Bora
          et al., 2018</xref>;
          <xref alt="Ulyanov et al., 2018" rid="ref-ulyanov2018deep" ref-type="bibr">Ulyanov
          et al., 2018</xref>) that add a latent
          <inline-formula><alternatives>
          <tex-math><![CDATA[z]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>z</mml:mi></mml:math></alternatives></inline-formula>
          to a generator <inline-formula><alternatives>
          <tex-math><![CDATA[\operatorname{R}_{\theta}(y,z)\colon\mathcal{Y}\times\mathcal{Z}\mapsto \mathcal{X}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mi>ùí¥</mml:mi><mml:mo>√ó</mml:mo><mml:mi>ùíµ</mml:mi><mml:mo>‚Ü¶</mml:mo><mml:mi>ùí≥</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>;</p>
        </list-item>
        <list-item>
          <p>Foundation models
          (<xref alt="Terris et al., 2025" rid="ref-terris2025ram" ref-type="bibr">Terris
          et al., 2025</xref>), trained end-to-end across a wide variety
          of <inline-formula><alternatives>
          <tex-math><![CDATA[(A_{\xi},N_{\sigma})]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>Œæ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>œÉ</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
          and can be finetuned to new problems.</p>
        </list-item>
      </list>
    </list-item>
  </list>
</sec>
<sec id="training">
  <title>Training</title>
  <p>Reconstruction networks <inline-formula><alternatives>
  <tex-math><![CDATA[\operatorname{R}_{\theta}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mo>R</mml:mo><mml:mi>Œ∏</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  can be trained using the modular
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/trainer.html"><monospace>Trainer</monospace>
  class</ext-link>.</p>
  <sec id="losses">
    <title>Losses</title>
    <p>The
    <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/loss.html"><monospace>loss</monospace>
    module</ext-link> framework unifies training loss functions that are
    widely used across various domains. Losses are written as
    <monospace>loss(x_hat, x, y, physics, model)</monospace> and are
    enumerated in the
    <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/loss.html">documentation</ext-link>:</p>
    <list list-type="bullet">
      <list-item>
        <p>Supervised loss between <inline-formula><alternatives>
        <tex-math><![CDATA[x]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
        and <inline-formula><alternatives>
        <tex-math><![CDATA[y]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>;</p>
      </list-item>
      <list-item>
        <p>Self-supervised losses which only use
        <inline-formula><alternatives>
        <tex-math><![CDATA[y]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>
        (<xref alt="Wang &amp; Davies, 2025" rid="ref-wang2025benchmarking" ref-type="bibr">Wang
        &amp; Davies, 2025</xref>;
        <xref alt="Yaman et al., 2020" rid="ref-yaman2020self" ref-type="bibr">Yaman
        et al., 2020</xref>);</p>
      </list-item>
      <list-item>
        <p>Network regularization losses
        (<xref alt="Pesquet et al., 2021" rid="ref-pesquet2021learning" ref-type="bibr">Pesquet
        et al., 2021</xref>);</p>
      </list-item>
      <list-item>
        <p>Adversarial losses
        (<xref alt="Bora et al., 2017" rid="ref-bora2017compressed" ref-type="bibr">Bora
        et al., 2017</xref>,
        <xref alt="2018" rid="ref-bora2018ambientgan" ref-type="bibr">2018</xref>).</p>
      </list-item>
    </list>
    <p>The
    <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/transforms.html"><monospace>transform</monospace>
    module</ext-link> implements geometric image transforms for data
    augmentation and equivariance
    (<xref alt="Chen et al., 2023" rid="ref-chen2023imaging" ref-type="bibr">Chen
    et al., 2023</xref>;
    <xref alt="Wang &amp; Davies, 2024" rid="ref-wang2024perspective" ref-type="bibr">Wang
    &amp; Davies, 2024</xref>).</p>
  </sec>
  <sec id="datasets">
    <title>Datasets</title>
    <p>The
    <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/datasets.html"><monospace>datasets</monospace>
    module</ext-link> implements a variety of domain-specific datasets
    that return ground-truth and measurements pairs
    <inline-formula><alternatives>
    <tex-math><![CDATA[\{(x_i,y_i)\}_{i=1}^{N}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:msubsup><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>
    and optional parameters <inline-formula><alternatives>
    <tex-math><![CDATA[\xi_i]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œæ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
    and allows simulating paired datasets given
    <inline-formula><alternatives>
    <tex-math><![CDATA[\{x_i\}_{i=1}^{N}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>
    and physics <inline-formula><alternatives>
    <tex-math><![CDATA[A_{\xi_i}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>A</mml:mi><mml:msub><mml:mi>Œæ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math></alternatives></inline-formula>.</p>
  </sec>
</sec>
<sec id="evaluation">
  <title>Evaluation</title>
  <p>The
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide/training/metric.html#metric"><monospace>metric</monospace>
  module</ext-link> provides metrics for evaluating reconstruction
  methods. These are written as
  <monospace>m = metric(x_hat, x)</monospace> (full-reference), or
  <monospace>m = metric(x_hat)</monospace> (no-reference)
  (<xref alt="Yeganeh &amp; Wang, 2012" rid="ref-yeganeh2012objective" ref-type="bibr">Yeganeh
  &amp; Wang, 2012</xref>), including distortion
  (<xref alt="R. Zhang et al., 2018" rid="ref-zhang2018unreasonable" ref-type="bibr">R.
  Zhang et al., 2018</xref>) and perceptual
  (<xref alt="Blau &amp; Michaeli, 2018" rid="ref-blau2018perception" ref-type="bibr">Blau
  &amp; Michaeli, 2018</xref>) metrics.</p>
</sec>
<sec id="documentation-testing-and-coding-practices">
  <title>Documentation, Testing, and Coding Practices</title>
  <p>The library provides a
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/user_guide.html"><bold>user
  guide</bold></ext-link>, which also serves as a tutorial on
  computational imaging,
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/quickstart.html">quickstart</ext-link>
  and in-depth
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/auto_examples/index.html"><bold>examples</bold></ext-link>
  for all levels of user, and individual
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/API.html">API
  documentation</ext-link> for classes. The documentation is generated
  using Sphinx and Sphinx-Gallery
  (<xref alt="Najera et al., 2023" rid="ref-najera2023sphinxgallery" ref-type="bibr">Najera
  et al., 2023</xref>), tested using <monospace>doctest</monospace>, and
  uses consistent mathematical notation throughout. DeepInverse is
  written in Python following modern test-driven practices, see
  <ext-link ext-link-type="uri" xlink:href="https://deepinv.github.io/deepinv/contributing.html">contributing
  guidelines</ext-link> for more information.</p>
</sec>
<sec id="research-use">
  <title>Research Use</title>
  <p>DeepInverse has been used in various recent computational imaging
  works, including self-supervised learning
  (<xref alt="Tachella et al., 2025" rid="ref-tachella2025unsure" ref-type="bibr">Tachella
  et al., 2025</xref>;
  <xref alt="Wang &amp; Davies, 2024" rid="ref-wang2024perspective" ref-type="bibr">Wang
  &amp; Davies, 2024</xref>), plug-and-play methods
  (<xref alt="Park et al., 2025" rid="ref-park2025plug" ref-type="bibr">Park
  et al., 2025</xref>;
  <xref alt="Terris et al., 2024" rid="ref-terris2024equivariant" ref-type="bibr">Terris
  et al., 2024</xref>), foundation models
  (<xref alt="Terris et al., 2025" rid="ref-terris2025ram" ref-type="bibr">Terris
  et al., 2025</xref>), phase-retrieval
  (<xref alt="Hu et al., 2025" rid="ref-hu2025structured" ref-type="bibr">Hu
  et al., 2025</xref>), uncertainty quantification
  (<xref alt="Tachella &amp; Pereyra, 2024" rid="ref-tachella2024equivariant" ref-type="bibr">Tachella
  &amp; Pereyra, 2024</xref>) and benchmarking
  (<xref alt="Wang &amp; Davies, 2025" rid="ref-wang2025benchmarking" ref-type="bibr">Wang
  &amp; Davies, 2025</xref>).</p>
</sec>
<sec id="perspectives">
  <title>Perspectives</title>
  <p>DeepInverse is a dynamic and evolving project and this paper is
  merely a snapshot of ongoing progress. The community is continuously
  contributing more methods reflecting state-of-the-art in imaging with
  deep learning, addressing the needs and interests of researchers and
  practitioners.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>J. Tachella acknowledges support by the French ANR grant UNLIP
  (ANR-23-CE23-0013) and the CNRS PNRIA DeepInverse project. M. Terris
  acknowledges support by the BrAIN grant (ANR-20-CHIA-0016). F. Sarron,
  P. Weiss, M.H. Nguyen were supported by ANR Micro-Blind
  ANR-21-CE48-0008. T. Moreau was supported by the ExaDoST project under
  NumPEx PEPR (ANR-22-EXNU-0004). J. Hertrich is supported by DFG
  (project 530824055). Z. Hu acknowledges funding from the Swiss
  National Science Foundation (grant PZ00P2_216211). T. Davies is
  supported by UKRI EPSRC (grants EP/V006134/1, EP/V006177/1). S.
  Neumayer acknowledges funding from DFG (project 543939932). We thank
  the
  <ext-link ext-link-type="uri" xlink:href="https://basp.site.hw.ac.uk/">BASP
  Laboratory at Heriot-Watt University</ext-link> for insightful
  discussions and contributions to the radioastronomy application. The
  authors acknowledge the Jean-Zay HPC (GENCI-IDRIS grants
  2021-AD011012210, 2024-AD011015191).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-paszke2019pytorch">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>Gross</surname><given-names>Sam</given-names></name>
        <name><surname>Massa</surname><given-names>Francisco</given-names></name>
        <name><surname>Lerer</surname><given-names>Adam</given-names></name>
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
        <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
        <name><surname>Lin</surname><given-names>Zeming</given-names></name>
        <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
        <name><surname>Antiga</surname><given-names>Luca</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>32</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1912.01703</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chung2023parallel">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Chung</surname><given-names>Hyungjin</given-names></name>
        <name><surname>Kim</surname><given-names>Jeongsol</given-names></name>
        <name><surname>Kim</surname><given-names>Sehui</given-names></name>
        <name><surname>Ye</surname><given-names>Jong Chul</given-names></name>
      </person-group>
      <article-title>Parallel diffusion models of operator and image for blind inverse problems</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/cvpr52729.2023.00587</pub-id>
      <fpage>6059</fpage>
      <lpage>6069</lpage>
    </element-citation>
  </ref>
  <ref id="ref-debarnot2024deep">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Debarnot</surname><given-names>Valentin</given-names></name>
        <name><surname>Weiss</surname><given-names>Pierre</given-names></name>
      </person-group>
      <article-title>Deep-blur: Blind identification and deblurring with convolutional neural networks</article-title>
      <source>Biological Imaging</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>4</volume>
      <pub-id pub-id-type="doi">10.1017/s2633903x24000096</pub-id>
      <fpage>e13</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-terris2023meta">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Terris</surname><given-names>Matthieu</given-names></name>
        <name><surname>Moreau</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>Meta-prior: Meta learning for adaptive inverse problem solvers</article-title>
      <source>arXiv preprint arXiv:2311.18710</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2311.18710</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gossard2024training">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gossard</surname><given-names>Alban</given-names></name>
        <name><surname>Weiss</surname><given-names>Pierre</given-names></name>
      </person-group>
      <article-title>Training adaptive reconstruction networks for blind inverse problems</article-title>
      <source>SIAM Journal on Imaging Sciences</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>17</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/23m1545628</pub-id>
      <fpage>1314</fpage>
      <lpage>1346</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lazarus2019sparkling">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lazarus</surname><given-names>Carole</given-names></name>
        <name><surname>Weiss</surname><given-names>Pierre</given-names></name>
        <name><surname>Chauffert</surname><given-names>Nicolas</given-names></name>
        <name><surname>Mauconduit</surname><given-names>Franck</given-names></name>
        <name><surname>El Gueddari</surname><given-names>Loubna</given-names></name>
        <name><surname>Destrieux</surname><given-names>Christophe</given-names></name>
        <name><surname>Zemmoura</surname><given-names>Ilyess</given-names></name>
        <name><surname>Vignaud</surname><given-names>Alexandre</given-names></name>
        <name><surname>Ciuciu</surname><given-names>Philippe</given-names></name>
      </person-group>
      <article-title>SPARKLING: Variable-density k-space filling curves for accelerated T2*-weighted MRI</article-title>
      <source>Magnetic resonance in medicine</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>81</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1002/mrm.27678</pub-id>
      <fpage>3643</fpage>
      <lpage>3661</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nehme2020deepstorm3d">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nehme</surname><given-names>Elias</given-names></name>
        <name><surname>Freedman</surname><given-names>Daniel</given-names></name>
        <name><surname>Gordon</surname><given-names>Racheli</given-names></name>
        <name><surname>Ferdman</surname><given-names>Boris</given-names></name>
        <name><surname>Weiss</surname><given-names>Lucien E</given-names></name>
        <name><surname>Alalouf</surname><given-names>Onit</given-names></name>
        <name><surname>Naor</surname><given-names>Tal</given-names></name>
        <name><surname>Orange</surname><given-names>Reut</given-names></name>
        <name><surname>Michaeli</surname><given-names>Tomer</given-names></name>
        <name><surname>Shechtman</surname><given-names>Yoav</given-names></name>
      </person-group>
      <article-title>DeepSTORM3D: Dense 3D localization microscopy and PSF design by deep learning</article-title>
      <source>Nature methods</source>
      <publisher-name>Nature Publishing Group US New York</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>17</volume>
      <issue>7</issue>
      <pub-id pub-id-type="doi">10.1038/s41592-020-0853-5</pub-id>
      <fpage>734</fpage>
      <lpage>740</lpage>
    </element-citation>
  </ref>
  <ref id="ref-soubies2019pocket">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Soubies</surname><given-names>Emmanuel</given-names></name>
        <name><surname>Soulez</surname><given-names>Ferr√©ol</given-names></name>
        <name><surname>McCann</surname><given-names>Michael T</given-names></name>
        <name><surname>Pham</surname><given-names>Thanh-an</given-names></name>
        <name><surname>Donati</surname><given-names>Laur√®ne</given-names></name>
        <name><surname>Debarre</surname><given-names>Thomas</given-names></name>
        <name><surname>Sage</surname><given-names>Daniel</given-names></name>
        <name><surname>Unser</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>Pocket guide to solve inverse problems with GlobalBioIm</article-title>
      <source>Inverse Problems</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>35</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1088/1361-6420/ab2ae9</pub-id>
      <fpage>104006</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-gazzola2019ir">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gazzola</surname><given-names>Silvia</given-names></name>
        <name><surname>Hansen</surname><given-names>Per Christian</given-names></name>
        <name><surname>Nagy</surname><given-names>James G</given-names></name>
      </person-group>
      <article-title>IR tools: A MATLAB package of iterative regularization methods and large-scale test problems</article-title>
      <source>Numerical Algorithms</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>81</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1007/s11075-018-0570-7</pub-id>
      <fpage>773</fpage>
      <lpage>811</lpage>
    </element-citation>
  </ref>
  <ref id="ref-blau2018perception">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Blau</surname><given-names>Yochai</given-names></name>
        <name><surname>Michaeli</surname><given-names>Tomer</given-names></name>
      </person-group>
      <article-title>The perception-distortion tradeoff</article-title>
      <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1109/CVPR.2018.00652</pub-id>
      <fpage>6228</fpage>
      <lpage>6237</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhang2018unreasonable">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Richard</given-names></name>
        <name><surname>Isola</surname><given-names>Phillip</given-names></name>
        <name><surname>Efros</surname><given-names>Alexei A</given-names></name>
        <name><surname>Shechtman</surname><given-names>Eli</given-names></name>
        <name><surname>Wang</surname><given-names>Oliver</given-names></name>
      </person-group>
      <article-title>The unreasonable effectiveness of deep features as a perceptual metric</article-title>
      <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1109/cvpr.2018.00068</pub-id>
      <fpage>586</fpage>
      <lpage>595</lpage>
    </element-citation>
  </ref>
  <ref id="ref-yeganeh2012objective">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yeganeh</surname><given-names>Hojatollah</given-names></name>
        <name><surname>Wang</surname><given-names>Zhou</given-names></name>
      </person-group>
      <article-title>Objective quality assessment of tone-mapped images</article-title>
      <source>IEEE Transactions on Image processing</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>22</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1109/TIP.2012.2221725</pub-id>
      <fpage>657</fpage>
      <lpage>667</lpage>
    </element-citation>
  </ref>
  <ref id="ref-chen2023imaging">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>Dongdong</given-names></name>
        <name><surname>Davies</surname><given-names>Mike</given-names></name>
        <name><surname>Ehrhardt</surname><given-names>Matthias J.</given-names></name>
        <name><surname>Sch√∂nlieb</surname><given-names>Carola-Bibiane</given-names></name>
        <name><surname>Sherry</surname><given-names>Ferdia</given-names></name>
        <name><surname>Tachella</surname><given-names>Juli√°n</given-names></name>
      </person-group>
      <article-title>Imaging With Equivariant Deep Learning: From unrolled network design to fully unsupervised learning</article-title>
      <source>IEEE Signal Processing Magazine</source>
      <year iso-8601-date="2023-01">2023</year><month>01</month>
      <volume>40</volume>
      <pub-id pub-id-type="doi">10.1109/MSP.2022.3205430</pub-id>
      <fpage>134</fpage>
      <lpage>147</lpage>
    </element-citation>
  </ref>
  <ref id="ref-chambolle2016introduction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chambolle</surname><given-names>Antonin</given-names></name>
        <name><surname>Pock</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>An introduction to continuous optimization for imaging</article-title>
      <source>Acta Numerica</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>25</volume>
      <pub-id pub-id-type="doi">10.1017/s096249291600009x</pub-id>
      <fpage>161</fpage>
      <lpage>319</lpage>
    </element-citation>
  </ref>
  <ref id="ref-candes2008introduction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cand√®s</surname><given-names>Emmanuel J</given-names></name>
        <name><surname>Wakin</surname><given-names>Michael B</given-names></name>
      </person-group>
      <article-title>An introduction to compressive sampling</article-title>
      <source>IEEE signal processing magazine</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2008">2008</year>
      <volume>25</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1109/MSP.2007.914731</pub-id>
      <fpage>21</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-chung2022diffusion">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Chung</surname><given-names>Hyungjin</given-names></name>
        <name><surname>Kim</surname><given-names>Jeongsol</given-names></name>
        <name><surname>Mccann</surname><given-names>Michael Thompson</given-names></name>
        <name><surname>Klasky</surname><given-names>Marc Louis</given-names></name>
        <name><surname>Ye</surname><given-names>Jong Chul</given-names></name>
      </person-group>
      <article-title>Diffusion posterior sampling for general noisy inverse problems</article-title>
      <source>The eleventh international conference on learning representations</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://openreview.net/forum?id=OnD9zGAGT0k</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2209.14687</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-zhu2023denoising">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Zhu</surname><given-names>Yuanzhi</given-names></name>
        <name><surname>Zhang</surname><given-names>Kai</given-names></name>
        <name><surname>Liang</surname><given-names>Jingyun</given-names></name>
        <name><surname>Cao</surname><given-names>Jiezhang</given-names></name>
        <name><surname>Wen</surname><given-names>Bihan</given-names></name>
        <name><surname>Timofte</surname><given-names>Radu</given-names></name>
        <name><surname>Van Gool</surname><given-names>Luc</given-names></name>
      </person-group>
      <article-title>Denoising diffusion models for plug-and-play image restoration</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/cvprw59228.2023.00129</pub-id>
      <fpage>1219</fpage>
      <lpage>1229</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kawar2022denoising">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kawar</surname><given-names>Bahjat</given-names></name>
        <name><surname>Elad</surname><given-names>Michael</given-names></name>
        <name><surname>Ermon</surname><given-names>Stefano</given-names></name>
        <name><surname>Song</surname><given-names>Jiaming</given-names></name>
      </person-group>
      <article-title>Denoising diffusion restoration models</article-title>
      <source>Advances in Neural Information Processing Systems</source>
      <year iso-8601-date="2022">2022</year>
      <volume>35</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.2201.11793</pub-id>
      <fpage>23593</fpage>
      <lpage>23606</lpage>
    </element-citation>
  </ref>
  <ref id="ref-laumont2022bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Laumont</surname><given-names>R√©mi</given-names></name>
        <name><surname>Bortoli</surname><given-names>Valentin De</given-names></name>
        <name><surname>Almansa</surname><given-names>Andr√©s</given-names></name>
        <name><surname>Delon</surname><given-names>Julie</given-names></name>
        <name><surname>Durmus</surname><given-names>Alain</given-names></name>
        <name><surname>Pereyra</surname><given-names>Marcelo</given-names></name>
      </person-group>
      <article-title>Bayesian imaging using plug &amp; play priors: When Langevin meets Tweedie</article-title>
      <source>SIAM Journal on Imaging Sciences</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>15</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/21M1406349</pub-id>
      <fpage>701</fpage>
      <lpage>737</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zhang2021plug">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Kai</given-names></name>
        <name><surname>Li</surname><given-names>Yawei</given-names></name>
        <name><surname>Zuo</surname><given-names>Wangmeng</given-names></name>
        <name><surname>Zhang</surname><given-names>Lei</given-names></name>
        <name><surname>Van Gool</surname><given-names>Luc</given-names></name>
        <name><surname>Timofte</surname><given-names>Radu</given-names></name>
      </person-group>
      <article-title>Plug-and-play image restoration with deep denoiser prior</article-title>
      <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>44</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1109/TPAMI.2021.3088914</pub-id>
      <fpage>6360</fpage>
      <lpage>6376</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bora2018ambientgan">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bora</surname><given-names>Ashish</given-names></name>
        <name><surname>Price</surname><given-names>Eric</given-names></name>
        <name><surname>Dimakis</surname><given-names>Alexandros G.</given-names></name>
      </person-group>
      <article-title>AmbientGAN: Generative models from lossy measurements</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2018">2018</year>
      <uri>https://openreview.net/forum?id=Hy7fDog0b</uri>
    </element-citation>
  </ref>
  <ref id="ref-bora2017compressed">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bora</surname><given-names>Ashish</given-names></name>
        <name><surname>Jalal</surname><given-names>Ajil</given-names></name>
        <name><surname>Price</surname><given-names>Eric</given-names></name>
        <name><surname>Dimakis</surname><given-names>Alexandros G</given-names></name>
      </person-group>
      <article-title>Compressed sensing using generative models</article-title>
      <source>International conference on machine learning</source>
      <publisher-name>PMLR</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1703.03208</pub-id>
      <fpage>537</fpage>
      <lpage>546</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bendel2023gan">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Bendel</surname><given-names>Matthew</given-names></name>
        <name><surname>Ahmad</surname><given-names>Rizwan</given-names></name>
        <name><surname>Schniter</surname><given-names>Philip</given-names></name>
      </person-group>
      <article-title>A regularized conditional GAN for posterior sampling in image recovery problems</article-title>
      <source>Advances in neural information processing systems</source>
      <person-group person-group-type="editor">
        <name><surname>Oh</surname><given-names>A.</given-names></name>
        <name><surname>Naumann</surname><given-names>T.</given-names></name>
        <name><surname>Globerson</surname><given-names>A.</given-names></name>
        <name><surname>Saenko</surname><given-names>K.</given-names></name>
        <name><surname>Hardt</surname><given-names>M.</given-names></name>
        <name><surname>Levine</surname><given-names>S.</given-names></name>
      </person-group>
      <publisher-name>Curran Associates, Inc.</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>36</volume>
      <uri>https://proceedings.neurips.cc/paper_files/paper/2023/file/d8b29f07599fecdba93d87ed27a65524-Paper-Conference.pdf</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2210.13389</pub-id>
      <fpage>68673</fpage>
      <lpage>68684</lpage>
    </element-citation>
  </ref>
  <ref id="ref-park2025plug">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Park</surname><given-names>Chicago Y</given-names></name>
        <name><surname>Hu</surname><given-names>Yuyang</given-names></name>
        <name><surname>McCann</surname><given-names>Michael T</given-names></name>
        <name><surname>Garcia-Cardona</surname><given-names>Cristina</given-names></name>
        <name><surname>Wohlberg</surname><given-names>Brendt</given-names></name>
        <name><surname>Kamilov</surname><given-names>Ulugbek S</given-names></name>
      </person-group>
      <article-title>Plug-and-play priors as a score-based method</article-title>
      <source>2025 IEEE international conference on image processing (ICIP)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.1109/ICIP55913.2025.11084503</pub-id>
      <fpage>49</fpage>
      <lpage>54</lpage>
    </element-citation>
  </ref>
  <ref id="ref-terris2024equivariant">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Terris</surname><given-names>Matthieu</given-names></name>
        <name><surname>Moreau</surname><given-names>Thomas</given-names></name>
        <name><surname>Pustelnik</surname><given-names>Nelly</given-names></name>
        <name><surname>Tachella</surname><given-names>Julian</given-names></name>
      </person-group>
      <article-title>Equivariant plug-and-play image reconstruction</article-title>
      <source>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1109/cvpr52733.2024.02386</pub-id>
      <fpage>25255</fpage>
      <lpage>25264</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ulyanov2018deep">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ulyanov</surname><given-names>Dmitry</given-names></name>
        <name><surname>Vedaldi</surname><given-names>Andrea</given-names></name>
        <name><surname>Lempitsky</surname><given-names>Victor</given-names></name>
      </person-group>
      <article-title>Deep image prior</article-title>
      <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1109/CVPR.2018.00984</pub-id>
      <fpage>9446</fpage>
      <lpage>9454</lpage>
    </element-citation>
  </ref>
  <ref id="ref-jin2017deep">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jin</surname><given-names>Kyong Hwan</given-names></name>
        <name><surname>McCann</surname><given-names>Michael T</given-names></name>
        <name><surname>Froustey</surname><given-names>Emmanuel</given-names></name>
        <name><surname>Unser</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>Deep convolutional neural network for inverse problems in imaging</article-title>
      <source>IEEE transactions on image processing</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>26</volume>
      <issue>9</issue>
      <pub-id pub-id-type="doi">10.1109/TIP.2017.2713099</pub-id>
      <fpage>4509</fpage>
      <lpage>4522</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ravasi2019pylops">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ravasi</surname><given-names>Matteo</given-names></name>
        <name><surname>Vasconcelos</surname><given-names>Ivan</given-names></name>
      </person-group>
      <article-title>PyLops‚Äìa linear-operator Python library for large scale optimization</article-title>
      <source>arXiv preprint arXiv:1907.12349</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1907.12349</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-polson2025pytomography">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Polson</surname><given-names>Lucas A</given-names></name>
        <name><surname>Fedrigo</surname><given-names>Roberto</given-names></name>
        <name><surname>Li</surname><given-names>Chenguang</given-names></name>
        <name><surname>Sabouri</surname><given-names>Maziar</given-names></name>
        <name><surname>Dzikunu</surname><given-names>Obed</given-names></name>
        <name><surname>Ahamed</surname><given-names>Shadab</given-names></name>
        <name><surname>Karakatsanis</surname><given-names>Nicolas</given-names></name>
        <name><surname>Kurkowska</surname><given-names>Sara</given-names></name>
        <name><surname>Sheikhzadeh</surname><given-names>Peyman</given-names></name>
        <name><surname>Esquinas</surname><given-names>Pedro</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Pytomography: A Python library for medical image reconstruction</article-title>
      <source>SoftwareX</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <volume>29</volume>
      <pub-id pub-id-type="doi">10.2139/ssrn.4865134</pub-id>
      <fpage>102020</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-dossal2024optimizationorderalgorithms">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dossal</surname><given-names>Charles</given-names></name>
        <name><surname>Hurault</surname><given-names>Samuel</given-names></name>
        <name><surname>Papadakis</surname><given-names>Nicolas</given-names></name>
      </person-group>
      <article-title>Optimization with first order algorithms</article-title>
      <source>arXiv preprint arXiv:2410.19506</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://arxiv.org/abs/2410.19506</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2410.19506</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-venkatakrishnan2013plug">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Venkatakrishnan</surname><given-names>Singanallur V</given-names></name>
        <name><surname>Bouman</surname><given-names>Charles A</given-names></name>
        <name><surname>Wohlberg</surname><given-names>Brendt</given-names></name>
      </person-group>
      <article-title>Plug-and-play priors for model based reconstruction</article-title>
      <source>2013 IEEE global conference on signal and information processing</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <pub-id pub-id-type="doi">10.1109/globalsip.2013.6737048</pub-id>
      <fpage>945</fpage>
      <lpage>948</lpage>
    </element-citation>
  </ref>
  <ref id="ref-van2016astra">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Van Aarle</surname><given-names>Wim</given-names></name>
        <name><surname>Palenstijn</surname><given-names>Willem Jan</given-names></name>
        <name><surname>Cant</surname><given-names>Jeroen</given-names></name>
        <name><surname>Janssens</surname><given-names>Eline</given-names></name>
        <name><surname>Bleichrodt</surname><given-names>Folkert</given-names></name>
        <name><surname>Dabravolski</surname><given-names>Andrei</given-names></name>
        <name><surname>De Beenhouwer</surname><given-names>Jan</given-names></name>
        <name><surname>Joost Batenburg</surname><given-names>K</given-names></name>
        <name><surname>Sijbers</surname><given-names>Jan</given-names></name>
      </person-group>
      <article-title>Fast and flexible x-ray tomography using the ASTRA toolbox</article-title>
      <source>Optics express</source>
      <publisher-name>Optical Society of America</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>24</volume>
      <issue>22</issue>
      <pub-id pub-id-type="doi">10.1364/oe.24.025129</pub-id>
      <fpage>25129</fpage>
      <lpage>25147</lpage>
    </element-citation>
  </ref>
  <ref id="ref-adler2018odl">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Adler</surname><given-names>Jonas</given-names></name>
        <name><surname>Kohr</surname><given-names>Holger</given-names></name>
        <name><surname>Ringh</surname><given-names>Axel</given-names></name>
        <name><surname>Moosmann</surname><given-names>Julian</given-names></name>
        <name><surname>sbanert</surname></name>
        <name><surname>Ehrhardt</surname><given-names>Matthias J.</given-names></name>
        <name><surname>Lee</surname><given-names>Gregory R.</given-names></name>
        <name><surname>niinimaki</surname></name>
        <name><surname>bgris</surname></name>
        <name><surname>Verdier</surname><given-names>Olivier</given-names></name>
        <name><surname>Karlsson</surname><given-names>Johan</given-names></name>
        <name><surname>zickert</surname></name>
        <name><surname>Palenstijn</surname><given-names>Willem Jan</given-names></name>
        <name><surname>√ñktem</surname><given-names>Ozan</given-names></name>
        <name><surname>Chen</surname><given-names>Chong</given-names></name>
        <name><surname>Loarca</surname><given-names>Hector Andrade</given-names></name>
        <name><surname>Lohmann</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>Odlgroup/odl: ODL 0.7.0</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2018-09">2018</year><month>09</month>
      <uri>https://doi.org/10.5281/zenodo.1442734</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.1442734</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-yaman2020self">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yaman</surname><given-names>Burhaneddin</given-names></name>
        <name><surname>Hosseini</surname><given-names>Seyed Amir Hossein</given-names></name>
        <name><surname>Moeller</surname><given-names>Steen</given-names></name>
        <name><surname>Ellermann</surname><given-names>Jutta</given-names></name>
        <name><surname>Uƒüurbil</surname><given-names>K√¢mil</given-names></name>
        <name><surname>Ak√ßakaya</surname><given-names>Mehmet</given-names></name>
      </person-group>
      <article-title>Self-supervised learning of physics-guided reconstruction neural networks without fully sampled reference data</article-title>
      <source>Magnetic resonance in medicine</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>84</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1002/mrm.28378</pub-id>
      <fpage>3172</fpage>
      <lpage>3191</lpage>
    </element-citation>
  </ref>
  <ref id="ref-simeoni2022pyxu">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Simeoni</surname><given-names>Matthieu</given-names></name>
        <name><surname>Kashani</surname><given-names>Sepand</given-names></name>
        <name><surname>Ru√©-Queralt</surname><given-names>Joan</given-names></name>
        <name><surname>Developers</surname><given-names>Pyxu</given-names></name>
      </person-group>
      <article-title>Pyxu-org/pyxu: pyxu</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <uri>https://doi.org/10.5281/zenodo.4486431</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.4486431</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-balke2022scico">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Balke</surname><given-names>Thilo</given-names></name>
        <name><surname>Davis</surname><given-names>Fernando</given-names></name>
        <name><surname>Garcia-Cardona</surname><given-names>Cristina</given-names></name>
        <name><surname>Majee</surname><given-names>Soumendu</given-names></name>
        <name><surname>McCann</surname><given-names>Michael</given-names></name>
        <name><surname>Pfister</surname><given-names>Luke</given-names></name>
        <name><surname>Wohlberg</surname><given-names>Brendt</given-names></name>
      </person-group>
      <article-title>Scientific computational imaging code (SCICO)</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>7</volume>
      <issue>78</issue>
      <uri>https://doi.org/10.21105/joss.04722</uri>
      <pub-id pub-id-type="doi">10.21105/joss.04722</pub-id>
      <fpage>4722</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-terris2025ram">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Terris</surname><given-names>Matthieu</given-names></name>
        <name><surname>Hurault</surname><given-names>Samuel</given-names></name>
        <name><surname>Song</surname><given-names>Maxime</given-names></name>
        <name><surname>Tachella</surname><given-names>Julian</given-names></name>
      </person-group>
      <article-title>Reconstruct anything model: A lightweight foundation model for computational imaging</article-title>
      <source>arXiv preprint arXiv:2503.08915</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2503.08915</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gregor2010learning">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Gregor</surname><given-names>Karol</given-names></name>
        <name><surname>LeCun</surname><given-names>Yann</given-names></name>
      </person-group>
      <article-title>Learning fast approximations of sparse coding</article-title>
      <source>Proceedings of the 27th international conference on international conference on machine learning</source>
      <year iso-8601-date="2010">2010</year>
      <uri>https://dl.acm.org/doi/10.5555/3104322.3104374</uri>
      <fpage>399</fpage>
      <lpage>406</lpage>
    </element-citation>
  </ref>
  <ref id="ref-altekruger2023patchnr">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Altekr√ºger</surname><given-names>Fabian</given-names></name>
        <name><surname>Denker</surname><given-names>Alexander</given-names></name>
        <name><surname>Hagemann</surname><given-names>Paul</given-names></name>
        <name><surname>Hertrich</surname><given-names>Johannes</given-names></name>
        <name><surname>Maass</surname><given-names>Peter</given-names></name>
        <name><surname>Steidl</surname><given-names>Gabriele</given-names></name>
      </person-group>
      <article-title>PatchNR: Learning from very few images by patch normalizing flow regularization</article-title>
      <source>Inverse Problems</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>39</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1088/1361-6420/acce5e</pub-id>
      <fpage>064006</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-zoran2011epll">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Zoran</surname><given-names>Daniel</given-names></name>
        <name><surname>Weiss</surname><given-names>Yair</given-names></name>
      </person-group>
      <article-title>From learning models of natural image patches to whole image restoration</article-title>
      <source>2011 international conference on computer vision</source>
      <year iso-8601-date="2011">2011</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/ICCV.2011.6126278</pub-id>
      <fpage>479</fpage>
      <lpage>486</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bai2019deep">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bai</surname><given-names>Shaojie</given-names></name>
        <name><surname>Kolter</surname><given-names>J Zico</given-names></name>
        <name><surname>Koltun</surname><given-names>Vladlen</given-names></name>
      </person-group>
      <article-title>Deep equilibrium models</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>32</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1909.01377</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-pereyra2020skrock">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pereyra</surname><given-names>Marcelo</given-names></name>
        <name><surname>Mieles</surname><given-names>Luis Vargas</given-names></name>
        <name><surname>Zygalakis</surname><given-names>Konstantinos C.</given-names></name>
      </person-group>
      <article-title>Accelerating proximal Markov Chain Monte Carlo by using an explicit stabilized method</article-title>
      <source>SIAM Journal on Imaging Sciences</source>
      <year iso-8601-date="2020">2020</year>
      <volume>13</volume>
      <issue>2</issue>
      <uri>https://doi.org/10.1137/19M1283719</uri>
      <pub-id pub-id-type="doi">10.1137/19M1283719</pub-id>
      <fpage>905</fpage>
      <lpage>935</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tachella2024equivariant">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Tachella</surname><given-names>Juli√°n</given-names></name>
        <name><surname>Pereyra</surname><given-names>Marcelo</given-names></name>
      </person-group>
      <article-title>Equivariant bootstrapping for uncertainty quantification in imaging inverse problems</article-title>
      <source>27th international conference on artificial intelligence and statistics 2024</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.11838</pub-id>
      <fpage>4141</fpage>
      <lpage>4149</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hu2025structured">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hu</surname><given-names>Zhiyuan</given-names></name>
        <name><surname>Tachella</surname><given-names>Juli√°n</given-names></name>
        <name><surname>Unser</surname><given-names>Michael</given-names></name>
        <name><surname>Dong</surname><given-names>Jonathan</given-names></name>
      </person-group>
      <article-title>Structured random model for fast and robust phase retrieval</article-title>
      <source>ICASSP 2025-2025 IEEE international conference on acoustics, speech and signal processing (ICASSP)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.1109/ICASSP49660.2025.10889235</pub-id>
      <fpage>1</fpage>
      <lpage>5</lpage>
    </element-citation>
  </ref>
  <ref id="ref-biguri2025tigre">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Biguri</surname><given-names>Ander</given-names></name>
        <name><surname>Sadakane</surname><given-names>Tomoyuki</given-names></name>
        <name><surname>Lindroos</surname><given-names>Reuben</given-names></name>
        <name><surname>Liu</surname><given-names>Yi</given-names></name>
        <name><surname>Landman</surname><given-names>Malena Sabat√©</given-names></name>
        <name><surname>Du</surname><given-names>Yi</given-names></name>
        <name><surname>Lohvithee</surname><given-names>Manasavee</given-names></name>
        <name><surname>Kaser</surname><given-names>Stefanie</given-names></name>
        <name><surname>Hatamikia</surname><given-names>Sepideh</given-names></name>
        <name><surname>Bryll</surname><given-names>Robert</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>TIGRE v3: Efficient and easy to use iterative computed tomographic reconstruction toolbox for real datasets</article-title>
      <source>Engineering Research Express</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <volume>7</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1088/2631-8695/adbb3a</pub-id>
      <fpage>015011</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-pesquet2021learning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pesquet</surname><given-names>Jean-Christophe</given-names></name>
        <name><surname>Repetti</surname><given-names>Audrey</given-names></name>
        <name><surname>Terris</surname><given-names>Matthieu</given-names></name>
        <name><surname>Wiaux</surname><given-names>Yves</given-names></name>
      </person-group>
      <article-title>Learning maximally monotone operators for image recovery</article-title>
      <source>SIAM Journal on Imaging Sciences</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>14</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1137/20m1387961</pub-id>
      <fpage>1206</fpage>
      <lpage>1237</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tachella2025unsure">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Tachella</surname><given-names>Juli√°n</given-names></name>
        <name><surname>Davies</surname><given-names>Mike</given-names></name>
        <name><surname>Jacques</surname><given-names>Laurent</given-names></name>
      </person-group>
      <article-title>UNSURE: Self-supervised learning with Unknown Noise level and Stein‚Äôs Unbiased Risk Estimate</article-title>
      <source>International conference on learning representations</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2409.01985</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-najera2023sphinxgallery">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Najera</surname><given-names>Oscar</given-names></name>
        <name><surname>Larson</surname><given-names>Eric</given-names></name>
        <name><surname>Liu</surname><given-names>Lucy</given-names></name>
        <name><surname>Esteve</surname><given-names>Loic</given-names></name>
        <name><surname>Varoquaux</surname><given-names>Gael</given-names></name>
        <name><surname>Grobler</surname><given-names>Jaques</given-names></name>
        <name><surname>Andrade</surname><given-names>Elliott Sales de</given-names></name>
        <name><surname>Holdgraf</surname><given-names>Chris</given-names></name>
        <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
        <name><surname>Jas</surname><given-names>Mainak</given-names></name>
        <name><surname>Nothman</surname><given-names>Joel</given-names></name>
        <name><surname>Rehberg</surname><given-names>Steffen</given-names></name>
        <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
        <name><surname>Varoquaux</surname><given-names>Nelle</given-names></name>
        <name><surname>Hiscocks</surname><given-names>Steven</given-names></name>
        <name><surname>alexis</surname></name>
        <name><surname>Gouillart</surname><given-names>Emmanuelle</given-names></name>
        <name><surname>Hoffmann</surname><given-names>Tim</given-names></name>
        <name><surname>Lee</surname><given-names>Antony</given-names></name>
        <name><surname>Uberti</surname><given-names>Gavin</given-names></name>
        <name><surname>Luessi</surname><given-names>Martin</given-names></name>
        <name><surname>Shih</surname><given-names>Albert Y.</given-names></name>
        <name><surname>Vanderplas</surname><given-names>Jake</given-names></name>
        <name><surname>Klymak</surname><given-names>Jody</given-names></name>
        <name><surname>Rockhill</surname><given-names>Alex</given-names></name>
        <name><surname>Muradeli</surname><given-names>John</given-names></name>
        <name><surname>Caswell</surname><given-names>Thomas A</given-names></name>
        <name><surname>Sullivan</surname><given-names>Bane</given-names></name>
        <name><surname>Batula</surname><given-names>Alyssa</given-names></name>
        <name><surname>Kunzmann</surname><given-names>Patrick</given-names></name>
      </person-group>
      <article-title>Sphinx-gallery/sphinx-gallery: v0.12.2</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2023-03">2023</year><month>03</month>
      <uri>https://doi.org/10.5281/zenodo.7716999</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.7716999</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-riis2024cuqipy">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Riis</surname><given-names>Nicolai AB</given-names></name>
        <name><surname>Alghamdi</surname><given-names>Amal MA</given-names></name>
        <name><surname>Uribe</surname><given-names>Felipe</given-names></name>
        <name><surname>Christensen</surname><given-names>Silja L</given-names></name>
        <name><surname>Afkham</surname><given-names>Babak M</given-names></name>
        <name><surname>Hansen</surname><given-names>Per Christian</given-names></name>
        <name><surname>J√∏rgensen</surname><given-names>Jakob S</given-names></name>
      </person-group>
      <article-title>CUQIpy: I. Computational uncertainty quantification for inverse problems in Python</article-title>
      <source>Inverse Problems</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>40</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1088/1361-6420/ad22e7</pub-id>
      <fpage>045009</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jorgensen2021core">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>J√∏rgensen</surname><given-names>Jakob S</given-names></name>
        <name><surname>Ametova</surname><given-names>Evelina</given-names></name>
        <name><surname>Burca</surname><given-names>Genoveva</given-names></name>
        <name><surname>Fardell</surname><given-names>Gemma</given-names></name>
        <name><surname>Papoutsellis</surname><given-names>Evangelos</given-names></name>
        <name><surname>Pasca</surname><given-names>Edoardo</given-names></name>
        <name><surname>Thielemans</surname><given-names>Kris</given-names></name>
        <name><surname>Turner</surname><given-names>Martin</given-names></name>
        <name><surname>Warr</surname><given-names>Ryan</given-names></name>
        <name><surname>Lionheart</surname><given-names>William RB</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Core Imaging Library-part I: A versatile Python framework for tomographic imaging</article-title>
      <source>Philosophical Transactions of the Royal Society A</source>
      <publisher-name>The Royal Society Publishing</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>379</volume>
      <issue>2204</issue>
      <pub-id pub-id-type="doi">10.1098/rsta.2020.0192</pub-id>
      <fpage>20200192</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ong2019sigpy">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ong</surname><given-names>Frank</given-names></name>
        <name><surname>Lustig</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>SigPy: A Python package for high performance iterative reconstruction</article-title>
      <publisher-name>ISMRM</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <uri>https://archive.ismrm.org/2019/4819.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-wang2025benchmarking">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Andrew</given-names></name>
        <name><surname>Davies</surname><given-names>Mike</given-names></name>
      </person-group>
      <article-title>Benchmarking self-supervised methods for accelerated MRI reconstruction</article-title>
      <source>arXiv preprint arXiv:2502.14009</source>
      <year iso-8601-date="2025">2025</year>
      <uri>https://arxiv.org/abs/2502.14009</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2502.14009</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wang2024perspective">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Andrew</given-names></name>
        <name><surname>Davies</surname><given-names>Mike</given-names></name>
      </person-group>
      <article-title>Perspective-equivariance for unsupervised imaging with camera geometry</article-title>
      <source>IEEE/CVF European Conference on Computer Vision (ECCV) Workshop on Traditional Computer Vision in the Age of Deep Learning</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1007/978-3-031-91585-7_8</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
