<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9088</article-id>
<article-id pub-id-type="doi">10.21105/joss.09088</article-id>
<title-group>
<article-title>TMMax: High-performance modeling of multilayer thin-film
structures using transfer matrix method with JAX</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0002-9880-0446</contrib-id>
<name>
<surname>Danis</surname>
<given-names>Bahrem Serhat</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5887-0293</contrib-id>
<name>
<surname>Zayim</surname>
<given-names>Esra</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Electrical and Electronics Engineering, Ko√ß
University, Istanbul, 34450, Turkey</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Physics Engineering Department, Istanbul Technical
University, Istanbul, 34469, Turkey</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-07-03">
<day>3</day>
<month>7</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>9088</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>JAX</kwd>
<kwd>Optics</kwd>
<kwd>Photonics</kwd>
<kwd>Multilayer Thin-Film</kwd>
<kwd>Transfer Matrix Method</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Optical multilayer thin-films are fundamental components that
  enable the precise control of reflectance, transmittance, and phase
  shift in the design of photonic systems. Rapid and accessible
  simulation of these structures holds critical importance for designing
  and analyzing complex coatings. While researchers commonly use the
  traditional transfer matrix method for designing these structures, its
  scalar approach to wavelength and angle of incidence causes redundant
  recalculations and inefficiencies in large-scale simulations.
  Furthermore, traditional method implementations do not support
  automatic differentiation, which limits their applicability in
  gradient-based inverse design approaches. Here, we present TMMax, a
  Python library that fully vectorizes and accelerates transfer matrix
  method using the high-performance machine learning library JAX. TMMax
  supports CPU, GPU, and TPU hardware, and includes a publicly available
  material database. Our approach, demonstrated through benchmarking,
  allows us to model thin-film stacks with hundreds of layers within
  seconds. This illustrates that our method achieves a simulation
  speedup of x100s over a baseline NumPy implementation, enabling
  optical engineers and thin-film researchers in optics and photonics to
  efficiently design complex dielectric multilayer structures through
  rapid and scalable simulations.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The Transfer Matrix Method (TMM) models multilayer optical thin
  films by applying Snell‚Äôs law for light propagation and Fresnel
  equations to compute interface transmittance and reflectance.</p>
  <p><disp-formula><alternatives>
  <tex-math><![CDATA[
  \mathbf{M} = \prod_{i=0}^{N-2} \mathbf{M}_i \tag{1}
  ]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>ùêå</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>‚àè</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>‚àí</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>ùêå</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>In TMM, the optical behavior of an N-layer multilayer structure
  composed of dielectric materials is obtained by computing the system
  matrix <inline-formula><alternatives>
  <tex-math><![CDATA[\mathbf{M}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ùêå</mml:mi></mml:math></alternatives></inline-formula>,
  as shown in Equation (1). This matrix calculation, commonly referred
  to as the Abeles TMM
  (<xref alt="Abel√®s, Florin, 1950" rid="ref-refId0" ref-type="bibr">Abel√®s,
  Florin, 1950</xref>), results from the successive multiplication of
  the transfer matrices of each layer (<inline-formula><alternatives>
  <tex-math><![CDATA[\mathbf{M}_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>ùêå</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
  (<xref alt="Katsidis &amp; Siapkas, 2002" rid="ref-katsidis2002general" ref-type="bibr">Katsidis
  &amp; Siapkas, 2002</xref>).</p>
  <fig>
    <caption><p>Schematic of two strategies for calculating
    transmission, reflection, and absorption in multilayer thin-film
    simulations. The system (a) is modeled either by sequentially
    multiplying 2√ó2 transfer matrices for each wavelength and incidence
    angle (b) or by vectorizing these operations across both axes
    (c).</p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="figure1.pdf" />
  </fig>
  <p>In traditional TMM implementations, the stack of layers in Figure
  1a is simulated using a single wavelength and angle of incidence, as
  shown in Figure 1b, and nested loops over wavelengths and angles lead
  to redundant calculations
  (<xref alt="Byrnes, 2020" rid="ref-byrnes2020multilayeropticalcalculations" ref-type="bibr">Byrnes,
  2020</xref>). TMMax removes these redundancies by vectorizing
  wavelengths and angles and all intermediate TMM operations via JAX
  (<xref alt="Bradbury et al., 2018" rid="ref-jax2018github" ref-type="bibr">Bradbury
  et al., 2018</xref>). As seen in the schematic of the vectorized
  implementation in Figure 1c, we vectorize all intermediate operations
  in TMM and subsequently apply JAX‚Äôs just-in-time (JIT) decorator.
  Instead of running the mapped TMM code sequentially over each batch
  element of wavelength and angle of incidence, jax.jit fuses all
  operations across the batch into a single XLA-compiled
  (<xref alt="OpenXLA Team, 2023" rid="ref-xla2023github" ref-type="bibr">OpenXLA
  Team, 2023</xref>) kernel. This reduces function call overhead and
  provides a faster TMM implementation. TMMax replaces the conventional
  for-loop system-matrix calculation
  (<xref alt="Nishida et al., 2011" rid="ref-6131837" ref-type="bibr">Nishida
  et al., 2011</xref>) with JAX‚Äôs lax.scan, enabling JIT compilation and
  eliminating interpreter bottlenecks, while running efficiently on
  CPUs, GPUs, and TPUs without code changes.</p>
  <p>TMMax supports deep learning‚Äìbased inverse design by keeping all
  computations on the GPU, avoiding costly CPU‚ÄìGPU data transfers
  (<xref alt="Hegde, 2019" rid="ref-10.1117U002F1.OE.58.6.065103" ref-type="bibr">Hegde,
  2019</xref>). Whereas NumPy-based
  (<xref alt="Harris et al., 2020" rid="ref-2020NumPy-Array" ref-type="bibr">Harris
  et al., 2020</xref>) TMM packages that lack native gradients and
  require Autograd
  (<xref alt="Maclaurin et al., 2015" rid="ref-maclaurin2015autograd" ref-type="bibr">Maclaurin
  et al., 2015</xref>), TMMax natively computes gradients. Additionally,
  TMMax integrates a curated database of 30 extensively used dielectric
  materials, sourced from refractiveindex.info
  (<xref alt="Polyanskiy, 2024" rid="ref-polyanskiy2024refractiveindex" ref-type="bibr">Polyanskiy,
  2024</xref>), thereby enabling optical engineers and thin-film
  researchers in optics and photonics to efficiently simulate complex
  multilayer structures through a scalable, JAX-accelerated
  implementation.</p>
</sec>
<sec id="benchmarks">
  <title>Benchmarks</title>
  <p>Runtime in TMM scales naturally with the number of layers, as well
  as the lengths of the wavelength and incidence-angle arrays, due to
  the increased number of transfer matrix multiplications. To benchmark
  TMMax, we used tmm library
  (<xref alt="Byrnes, 2020" rid="ref-byrnes2020multilayeropticalcalculations" ref-type="bibr">Byrnes,
  2020</xref>) as a reference.</p>
  <fig>
    <caption><p> Run time vs. layer count comparing tmm (orange) and
    TMMax (blue).</p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="figure2.pdf" />
  </fig>
  <p>To assess how layer count affects computational performance, we
  sampled 20 multilayer structures ranging from 2 to 400 layers, with
  each layer randomly assigned one of seven materials and thicknesses
  between 100‚Äì500‚ÄØnm. Spectral and angular domains were fixed at 20
  points each, spanning 500‚Äì1000‚ÄØnm and 0‚ÄìœÄ/2‚ÄØradians, respectively.
  Figure‚ÄØ2 shows that while tmm runtime grows rapidly, TMMax scales
  efficiently, remaining nearly constant (~1.0‚Äì1.2‚ÄØs) for low-layer
  structures and achieving speedups from 18√ó (2 layers) to 700√ó (400
  layers).</p>
  <fig>
    <caption><p>The colormaps show the runtime performance of tmm and
    TMMax across varying simulation grid sizes, comparing 8- and
    80-layer stacks in (a) and (b), respectively.</p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="figure3.pdf" />
  </fig>
  <p>We benchmarked the effects of wavelength and incident angle array
  sizes by sampling 20 values from 2 to 100, generating simulation grids
  from 2√ó2 to 100√ó100 for an 8-layer structure (Figure 3a). tmm runtime
  rises sharply with grid size, reaching ~138‚ÄØs for 100√ó100, whereas
  TMMax remains below 3‚ÄØs. For the smallest 2√ó2 grid, tmm is faster
  (~0.1‚ÄØs vs.¬†~0.6‚ÄØs) due to NumPy‚Äôs low overhead, while JAX incurs
  higher initialization costs. As layers increase to 80 (Figure 3b), tmm
  exceeds 760‚ÄØs, but TMMax stays under 8‚ÄØs, demonstrating superior
  efficiency and stability against both problem size and structural
  complexity.</p>
  <p>We used Python‚Äôs timeit module to benchmark each simulation 50
  times, with all comparisons run on a single Intel Core i9 core without
  GPU or multicore use for fairness.</p>
</sec>
<sec id="installation">
  <title>Installation</title>
  <p>TMMax can be readily installed from the Python Package Index using
  <monospace>pip install tmmax</monospace>, which automatically handles
  all dependencies. For detailed installation instructions and platform
  compatibility, please refer to the
  <ext-link ext-link-type="uri" xlink:href="https://tmmax.readthedocs.io/en/latest/index.html">TMMax
  Documentation</ext-link>.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the Scientific and Technological
  Research Council of T√ºrkiye (TUBITAK) under the 2209-A Research
  Project Support Programme for Undergraduate Students, 2022 First-Term
  Call.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-refId0">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>Abel√®s, Florin</string-name>
      </person-group>
      <article-title>Recherches sur la propagation des ondes √©lectromagn√©tiques sinuso√Ødales dans les milieux stratifi√©s - application aux couches minces</article-title>
      <source>Ann. Phys.</source>
      <year iso-8601-date="1950">1950</year>
      <volume>12</volume>
      <issue>5</issue>
      <uri>https://doi.org/10.1051/anphys/195012050596</uri>
      <pub-id pub-id-type="doi">10.1051/anphys/195012050596</pub-id>
      <fpage>596</fpage>
      <lpage>640</lpage>
    </element-citation>
  </ref>
  <ref id="ref-katsidis2002general">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Katsidis</surname><given-names>Charalambos C</given-names></name>
        <name><surname>Siapkas</surname><given-names>Dimitrios I</given-names></name>
      </person-group>
      <article-title>General transfer-matrix method for optical multilayer systems with coherent, partially coherent, and incoherent interference</article-title>
      <source>Applied Optics</source>
      <publisher-name>Optical Society of America</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <volume>41</volume>
      <issue>19</issue>
      <uri>https://doi.org/10.1364/AO.41.003978</uri>
      <pub-id pub-id-type="doi">10.1364/AO.41.003978</pub-id>
      <fpage>3978</fpage>
      <lpage>3987</lpage>
    </element-citation>
  </ref>
  <ref id="ref-6131837">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Nishida</surname><given-names>Kazufumi</given-names></name>
        <name><surname>Ito</surname><given-names>Yasuaki</given-names></name>
        <name><surname>Nakano</surname><given-names>Koji</given-names></name>
      </person-group>
      <article-title>Accelerating the dynamic programming for the matrix chain product on the GPU</article-title>
      <source>2011 second international conference on networking and computing</source>
      <year iso-8601-date="2011">2011</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/ICNC.2011.62</pub-id>
      <fpage>320</fpage>
      <lpage>326</lpage>
    </element-citation>
  </ref>
  <ref id="ref-byrnes2020multilayeropticalcalculations">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Byrnes</surname><given-names>Steven J.</given-names></name>
      </person-group>
      <article-title>Multilayer optical calculations</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://arxiv.org/abs/1603.02720</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1603.02720</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-10.1117U002F1.OE.58.6.065103">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hegde</surname><given-names>Ravi S.</given-names></name>
      </person-group>
      <article-title>Accelerating optics design optimizations with deep learning</article-title>
      <source>Optical Engineering</source>
      <publisher-name>SPIE</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>58</volume>
      <issue>6</issue>
      <uri>https://doi.org/10.1117/1.OE.58.6.065103</uri>
      <pub-id pub-id-type="doi">10.1117/1.OE.58.6.065103</pub-id>
      <fpage>065103</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-polyanskiy2024refractiveindex">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Polyanskiy</surname><given-names>Mikhail N.</given-names></name>
      </person-group>
      <article-title>Refractiveindex.info database of optical constants</article-title>
      <source>Scientific Data</source>
      <year iso-8601-date="2024">2024</year>
      <volume>11</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1038/s41597-023-02898-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41597-023-02898-2</pub-id>
      <fpage>94</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jax2018github">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Hawkins</surname><given-names>Peter</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew James</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Necula</surname><given-names>George</given-names></name>
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Wanderman-Milne</surname><given-names>Skye</given-names></name>
        <name><surname>Zhang</surname><given-names>Qiao</given-names></name>
      </person-group>
      <article-title>JAX: Composable transformations of Python+NumPy programs</article-title>
      <year iso-8601-date="2018">2018</year>
      <uri>http://github.com/jax-ml/jax</uri>
    </element-citation>
  </ref>
  <ref id="ref-2020NumPy-Array">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Charles R.</given-names></name>
        <name><surname>Millman</surname><given-names>K. Jarrod</given-names></name>
        <name><surname>Walt</surname><given-names>St√©fan J van der</given-names></name>
        <name><surname>Gommers</surname><given-names>Ralf</given-names></name>
        <name><surname>Virtanen</surname><given-names>Pauli</given-names></name>
        <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        <name><surname>Wieser</surname><given-names>Eric</given-names></name>
        <name><surname>Taylor</surname><given-names>Julian</given-names></name>
        <name><surname>Berg</surname><given-names>Sebastian</given-names></name>
        <name><surname>Smith</surname><given-names>Nathaniel J.</given-names></name>
        <name><surname>Kern</surname><given-names>Robert</given-names></name>
        <name><surname>Picus</surname><given-names>Matti</given-names></name>
        <name><surname>Hoyer</surname><given-names>Stephan</given-names></name>
        <name><surname>Kerkwijk</surname><given-names>Marten H. van</given-names></name>
        <name><surname>Brett</surname><given-names>Matthew</given-names></name>
        <name><surname>Haldane</surname><given-names>Allan</given-names></name>
        <name><surname>Fern√°ndez del R√≠o</surname><given-names>Jaime</given-names></name>
        <name><surname>Wiebe</surname><given-names>Mark</given-names></name>
        <name><surname>Peterson</surname><given-names>Pearu</given-names></name>
        <name><surname>G√©rard-Marchant</surname><given-names>Pierre</given-names></name>
        <name><surname>Sheppard</surname><given-names>Kevin</given-names></name>
        <name><surname>Reddy</surname><given-names>Tyler</given-names></name>
        <name><surname>Weckesser</surname><given-names>Warren</given-names></name>
        <name><surname>Abbasi</surname><given-names>Hameer</given-names></name>
        <name><surname>Gohlke</surname><given-names>Christoph</given-names></name>
        <name><surname>Oliphant</surname><given-names>Travis E.</given-names></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <year iso-8601-date="2020">2020</year>
      <volume>585</volume>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
  <ref id="ref-xla2023github">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>OpenXLA Team</string-name>
      </person-group>
      <article-title>XLA: Accelerated Linear Algebra Compiler for Machine Learning</article-title>
      <publisher-name>https://github.com/openxla/xla</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/openxla/xla</uri>
    </element-citation>
  </ref>
  <ref id="ref-maclaurin2015autograd">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Duvenaud</surname><given-names>David</given-names></name>
        <name><surname>Adams</surname><given-names>Ryan P</given-names></name>
      </person-group>
      <article-title>Autograd: Effortless gradients in numpy</article-title>
      <source>ICML 2015 AutoML workshop</source>
      <publisher-name>CNRS</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>238</volume>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
