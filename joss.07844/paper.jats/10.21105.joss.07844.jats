<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7844</article-id>
<article-id pub-id-type="doi">10.21105/joss.07844</article-id>
<title-group>
<article-title>BenchmarkDataNLP.jl: Synthetic Data Generation for NLP
Benchmarking</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0026-5725</contrib-id>
<name>
<surname>Mantzaris</surname>
<given-names>Alexander V.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Statistics and Data Science, University of
Central Florida (UCF), USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-01-25">
<day>25</day>
<month>1</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>109</issue>
<fpage>7844</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>NLP</kwd>
<kwd>benchmarking</kwd>
<kwd>data generation</kwd>
<kwd>language models</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><bold>BenchmarkDataNLP.jl</bold> is a package written in Julia Lang
  for generating synthetic text corpora that can be used to
  systematically benchmark and evaluate Natural Language Processing
  (NLP) models such as Recurrent Neural Networks (RNNs), Long Short-Term
  Memory (LSTMs), and Large Language Models (LLMs). By enabling users to
  control core linguistic parameters such as the alphabet size
  (characters selected from the Unicode Hangul block, Korean Language),
  vocabulary size, grammatical expansion complexity, and semantic
  structures this library can help users test, evaluate, and debug NLP
  models. Instead of exposing many parameters to the user, it is kept at
  minimum, so that users do not have to focus on how to correctly
  configure the generation process. The key parameter is the
  <italic>complexity</italic> (integer value), which controls the size
  of the alphabet, vocabulary, and grammar expansions. This parameter
  accepts an integer in the range 1 to <bold>100</bold>. For example, at
  <monospace>complexity = 1</monospace> (simplest value), there are 5
  letters in the alphabet and 10 words used in the vocabulary with 2
  grammar roles when a Context Free Grammar generator is select. At
  <monospace>complexity = 100</monospace> there is a vocabulary of
  10,000 words and 50 alphabet characters. Users can choose how many
  independent grammar productions are desired, which are each supplied
  as entries in a .jsonl file. The defaults provided in the
  documentation should suffice for most use cases.</p>
  <p>The generator methods are:</p>
  <list list-type="bullet">
    <list-item>
      <p>Context Free Grammar
      (<xref alt="van Vugt, 1996" rid="ref-van1996generalized" ref-type="bibr">van
      Vugt, 1996</xref>)</p>
    </list-item>
    <list-item>
      <p>Resource Description Framework (RDF, triple store)
      (<xref alt="Faye et al., 2012" rid="ref-faye2012survey" ref-type="bibr">Faye
      et al., 2012</xref>)</p>
    </list-item>
    <list-item>
      <p>Finite State Machine
      (<xref alt="Maletti, 2017" rid="ref-maletti2017survey" ref-type="bibr">Maletti,
      2017</xref>)</p>
    </list-item>
    <list-item>
      <p>Template Strings
      (<xref alt="Copestake, 1996" rid="ref-copestake1996applying" ref-type="bibr">Copestake,
      1996</xref>)</p>
    </list-item>
  </list>
  <p>Each method offers different options to the user. With the Finite
  State Machine approach, the function
  <italic>generate_fsm_corpus</italic> produces a deterministic set of
  corpora so that upon successful training accuracies of 100% can be
  achieved. This can be used, e.g., to test the computational
  requirements for various models, for a particular value of complexity.
  The four approaches listed above, cover a wide range of text expansion
  production methods that does not have parameter estimations as part of
  their usage requirements. Hangul syllables in Unicode start at code
  point 0xAC00 (decimal 44 032), sampling characters from this region
  offers conveniences and a long continuous block. The reason for this
  choice is that Hangul Syllables block is one of the largest continuous
  blocks in the Unicode standard. It contains over 11,000 characters
  without interruption allowing for large alphabet and punctuation
  subsets to be selected.</p>
  <p>This package also hopes to bring down the costs (financial, time,
  and computational) required when training different models and
  architectures on large natural language datasets
  (<xref alt="Samsi et al., 2023" rid="ref-samsi2023words" ref-type="bibr">Samsi
  et al., 2023</xref>). Risks of wasted expense training on suboptimal
  models can often be expected when exploring novel approaches.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Performance evaluation of NLP systems often hinges on realistic
  datasets that capture the target domain’s linguistic nuances. However,
  training on large-scale text corpora can be expensive or impractical,
  especially when testing some particular aspects of language complexity
  or model robustness. Synthetic data generation helps bridge these gaps
  by:</p>
  <list list-type="order">
    <list-item>
      <p><bold>Reproducibility</bold>: Controlled parameters (e.g.,
      sentence length, grammar depth, or concept re-use) allow
      reproducible experiments.</p>
    </list-item>
    <list-item>
      <p><bold>Customization</bold>: Researchers can stress-test models
      by systematically varying language properties, such as the number
      of roles in a grammar or the frequency of filler tokens.</p>
    </list-item>
    <list-item>
      <p><bold>Scalability</bold>: Large-scale data can be generated for
      benchmarking advanced architectures without the need for
      extensive, real-world data collection.</p>
    </list-item>
    <list-item>
      <p><bold>Targeted Evaluation</bold>: By manipulating semantic
      structures (for example, adding context continuity with RDF
      triples or specialized placeholders), researchers can investigate
      whether models capture specific linguistic or contextual
      features.</p>
    </list-item>
  </list>
  <p>Although several libraries and benchmarks (e.g., GLUE
  (<xref alt="Wang et al., 2018" rid="ref-wang2018glue" ref-type="bibr">Wang
  et al., 2018</xref>), SuperGLUE
  (<xref alt="Wang et al., 2020" rid="ref-wang2019superglue" ref-type="bibr">Wang
  et al., 2020</xref>)) provide curated datasets,
  <bold>BenchmarkDataNLP.jl</bold> offers a unique approach by allowing
  <italic>fine-grained control</italic> of the underlying complexity of
  a synthetic corpus generation process. This capability is especially
  valuable when exploring model failure modes or for rapid prototyping
  of new model architectures that require specialized text patterns. It
  is hoped that this will bring down the cost for initial prototyping of
  new model architectures and allow a greater exploration. This can also
  help compare different modeling approaches.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank the Julia community for their continued support of
  open-source scientific computing.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-copestake1996applying">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Copestake</surname><given-names>Ann</given-names></name>
      </person-group>
      <article-title>Applying natural language processing techniques to speech prostheses</article-title>
      <source>Working notes of the 1996 AAAI fall symposium on developing assistive technology for people with disabilities</source>
      <year iso-8601-date="1996">1996</year>
    </element-citation>
  </ref>
  <ref id="ref-maletti2017survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Maletti</surname><given-names>Andreas</given-names></name>
      </person-group>
      <article-title>Survey: Finite-state technology in natural language processing</article-title>
      <source>Theoretical Computer Science</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>679</volume>
      <pub-id pub-id-type="doi">10.1016/j.tcs.2016.05.030</pub-id>
      <fpage>2</fpage>
      <lpage>17</lpage>
    </element-citation>
  </ref>
  <ref id="ref-faye2012survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Faye</surname><given-names>David C</given-names></name>
        <name><surname>Cure</surname><given-names>Olivier</given-names></name>
        <name><surname>Blin</surname><given-names>Guillaume</given-names></name>
      </person-group>
      <article-title>A survey of RDF storage approaches</article-title>
      <source>Revue Africaine de Recherche en Informatique et Mathématiques Appliquées</source>
      <publisher-name>Episciences. org</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>15</volume>
      <pub-id pub-id-type="doi">10.46298/arima.1956</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-van1996generalized">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>van Vugt</surname><given-names>Nikè</given-names></name>
      </person-group>
      <article-title>Generalized context-free grammars</article-title>
      <source>Internal Report</source>
      <publisher-name>Citeseer</publisher-name>
      <year iso-8601-date="1996">1996</year>
    </element-citation>
  </ref>
  <ref id="ref-samsi2023words">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Samsi</surname><given-names>Siddharth</given-names></name>
        <name><surname>Zhao</surname><given-names>Dan</given-names></name>
        <name><surname>McDonald</surname><given-names>Joseph</given-names></name>
        <name><surname>Li</surname><given-names>Baolin</given-names></name>
        <name><surname>Michaleas</surname><given-names>Adam</given-names></name>
        <name><surname>Jones</surname><given-names>Michael</given-names></name>
        <name><surname>Bergeron</surname><given-names>William</given-names></name>
        <name><surname>Kepner</surname><given-names>Jeremy</given-names></name>
        <name><surname>Tiwari</surname><given-names>Devesh</given-names></name>
        <name><surname>Gadepally</surname><given-names>Vijay</given-names></name>
      </person-group>
      <article-title>From words to watts: Benchmarking the energy costs of large language model inference</article-title>
      <source>2023 IEEE high performance extreme computing conference (HPEC)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/HPEC58863.2023.10363447</pub-id>
      <fpage>1</fpage>
      <lpage>9</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2019superglue">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Alex</given-names></name>
        <name><surname>Pruksachatkun</surname><given-names>Yada</given-names></name>
        <name><surname>Nangia</surname><given-names>Nikita</given-names></name>
        <name><surname>Singh</surname><given-names>Amanpreet</given-names></name>
        <name><surname>Michael</surname><given-names>Julian</given-names></name>
        <name><surname>Hill</surname><given-names>Felix</given-names></name>
        <name><surname>Levy</surname><given-names>Omer</given-names></name>
        <name><surname>Bowman</surname><given-names>Samuel R.</given-names></name>
      </person-group>
      <article-title>SuperGLUE: A stickier benchmark for general-purpose language understanding systems</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://arxiv.org/abs/1905.00537</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1905.00537</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-wang2018glue">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Alex</given-names></name>
        <name><surname>Singh</surname><given-names>Amanpreet</given-names></name>
        <name><surname>Michael</surname><given-names>Julian</given-names></name>
        <name><surname>Hill</surname><given-names>Felix</given-names></name>
        <name><surname>Levy</surname><given-names>Omer</given-names></name>
        <name><surname>Bowman</surname><given-names>Samuel R</given-names></name>
      </person-group>
      <article-title>GLUE: A multi-task benchmark and analysis platform for natural language understanding</article-title>
      <source>arXiv preprint arXiv:1804.07461</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.18653/v1/W18-5446</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
