<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5091</article-id>
<article-id pub-id-type="doi">10.21105/joss.05091</article-id>
<title-group>
<article-title><monospace>Biosiglive</monospace>: an Open-Source Python
Package for Real-time Biosignal Processing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7854-9410</contrib-id>
<name>
<surname>Ceglia</surname>
<given-names>Amedeo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2486-3444</contrib-id>
<name>
<surname>Verdugo</surname>
<given-names>Felipe</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4107-9160</contrib-id>
<name>
<surname>Begon</surname>
<given-names>Mickael</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institute of Biomedical Engineering, Faculty of Medicine,
University of Montreal, Canada</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Faculty of Music, University of Montreal,
Canada</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-12-02">
<day>2</day>
<month>12</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>83</issue>
<fpage>5091</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>python</kwd>
<kwd>biomechanics</kwd>
<kwd>electromyography</kwd>
<kwd>kinematics</kwd>
<kwd>dynamics</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>biosiglive</monospace> aims to provide a simple and
  efficient way to access and process biomechanical data in real time.
  It was conceived as user-friendly software aimed for both non-expert
  and expert programmers. The library uses interfaces to access data
  from several sources, such as motion capture software or any Python
  software development kit (SDK). Some interfaces are already
  implemented for Vicon Nexus motion capture (Oxford, UK) and Delsys
  electromyography SDK (EMG) (Boston, USA). That say, any additional
  interface can be added as custom interface using the abstract class.
  <monospace>biosiglive</monospace> was designed for biosignals,
  therefore, existing classes represent data collected from standard
  acquisition systems in biomechanics, such as markers for motion
  capture or EMG. Methods are available to process in real-time any
  input signal. Data can be saved in a binary file at each time frame to
  avoid any data loss in case of system shutdown. Data can also be
  displayed using the LivePlot class, which is based on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/pyqtgraph/pyqtgraph">PyQtGraph</ext-link>
  (C++ core) and allows, therefore, fast real-time displaying. Finally,
  ‘biosiglive’ was conceived as a flexible real-time data processing and
  streaming tool adaptable to various set-ups, software, and systems.
  Therefore, a TCP/IP connection module was implemented to send data to
  a distant port to be used by any other system.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Biosignals such as electromyography (EMG) or marker kinematic data
  are often used to assess human movement in clinical, sports, or
  artistic contexts. However, the analysis is often time-consuming and
  requires a good knowledge of programming languages such as MATLAB
  (Mathworks LCC, Natick, USA) or Python. In the last decade, some
  open-source tools have emerged to facilitate the analysis of these
  signals, like <monospace>biomechanical toolkit</monospace>
  (<xref alt="Barre &amp; Armand, 2014" rid="ref-barre2014biomechanical" ref-type="bibr">Barre
  &amp; Armand, 2014</xref>), <monospace>biomechzoo</monospace>
  (<xref alt="Dixon et al., 2017" rid="ref-dixon2017biomechzoo" ref-type="bibr">Dixon
  et al., 2017</xref>), <monospace>pyomeca</monospace>
  (<xref alt="Martinez et al., 2020" rid="ref-martinez2020pyomeca" ref-type="bibr">Martinez
  et al., 2020</xref>), or <monospace>Kinetics toolkit</monospace>
  (<xref alt="Chénier, 2021" rid="ref-chenier2021kinetics" ref-type="bibr">Chénier,
  2021</xref>). Since <monospace>biomechzoo</monospace> relies on
  MATLAB, a closed-source software , not every biomechanist can benefit
  from this tool. The Python environment is, on the other hand, entirely
  free and allows anyone to use the package without any cost.
  <monospace>pyomeca</monospace> and
  <monospace>Kinetics toolkit</monospace> both provide efficient methods
  to analyze biosignals, but are designed to work offline. However,
  real-time use of these signals is often required to provide task
  feedback to the user
  (<xref alt="Giggins et al., 2013" rid="ref-giggins2013biofeedback" ref-type="bibr">Giggins
  et al., 2013</xref>) or to control a device
  (<xref alt="Cozean et al., 1988" rid="ref-cozean1988biofeedback" ref-type="bibr">Cozean
  et al., 1988</xref>). In this type of use, access to biosignals easily
  and in real-time is a crucial point. To our knowledge, no tool
  dedicated to biomechanical data is available to provide real-time
  access and processing of these signals. Also, there is numerous
  platforms where data can come from. So, a package able to stream data
  from any of these sources should help the use of biosignals on a
  larger scale (in clinical, rehabilitation, pedagogical, sport, and
  artistic activities). We have developed
  <monospace>biosiglive</monospace> to facilitate the use of biosignals
  in real-time. It was achieved by pre-implementing standard data
  processing and data retrieving from several sources such as Nexus
  software for motion capture and analogical signals. Pre-implemented
  processing methods are customizable (i.e. filters cutoff frequency or
  moving average window size), the user can also develop his/her own
  method inside the program. Users can also add an interface module to
  make ‘biosiglive’ work with the desired acquisition system. Examples
  are provided to guide the user and documentation is available.</p>
</sec>
<sec id="features">
  <title>Features</title>
  <p><monospace>biosiglive</monospace> is divided into five independent
  modules. The main features are:</p>
  <list list-type="bullet">
    <list-item>
      <p><monospace>Processing</monospace>: real-time and offline data
      processing.</p>
    </list-item>
    <list-item>
      <p><monospace>Interfaces</monospace>: interfaces of standard
      software such as Vicon Nexus (Oxford, UK) or Delsys Trigno
      Community (Boston, USA).</p>
    </list-item>
    <list-item>
      <p><monospace>Visualization</monospace>: real-time signal
      visualization,</p>
    </list-item>
    <list-item>
      <p><monospace>Streaming pipeline</monospace>: pipeline to stream,
      process, disseminate and save data in real time.</p>
    </list-item>
    <list-item>
      <p><monospace>File I/O</monospace>: saving data in binary format
      at every time frame.</p>
    </list-item>
  </list>
  <sec id="a-biomechanical-example-electromyographic-pipeline">
    <title>A Biomechanical example: Electromyographic pipeline</title>
    <p><monospace>biosiglive</monospace> provides examples for different
    biomechanical tasks such as getting and processing EMG signals or
    any generic analog devices from Nexus, compute live cadence from a
    treadmill, or applying a calibration matrix to raw signals. More
    advanced examples are available such as computing and showing 3D
    joint kinematics from a marker set.</p>
    <p>The following example shows how to stream, process, display, and
    save EMG signals from Nexus software.</p>
    <code language="python">from biosiglive import LivePlot, save , ViconClient, RealTimeProcessingMethod, PlotType

# Define the system from which you want to get the data.
interface = ViconClient(ip=&quot;localhost&quot;, system_rate=100)
n_electrodes = 4
raw_emg = None
muscle_names = [
    &quot;Pectoralis major&quot;,
    &quot;Deltoid anterior&quot;,
    &quot;Deltoid medial&quot;,
    &quot;Deltoid posterior&quot;
]

# Add device to Vicon interface
interface.add_device(
    nb_channels=n_electrodes,
    device_type=&quot;emg&quot;,
    name=&quot;emg&quot;,
    rate=2000,
    method=RealTimeProcessingMethod.ProcessEmg,
    moving_average_window=600
)

# Add plots
emg_plot = LivePlot(
    name=&quot;emg&quot;,
    rate=100,
    plot_type=PlotType.Curve,
    nb_subplots=n_electrodes,
    channel_names=muscle_names
)
emg_plot.init(plot_windows=500, y_labels=&quot;Processed EMG (mV)&quot;)
emg_raw_plot = LivePlot(
    name=&quot;emg_raw&quot;,
    rate=100,
    plot_type=PlotType.Curve,
    nb_subplots=n_electrodes,
    channel_names=muscle_names
)
emg_raw_plot.init(plot_windows=10000, colors=(255, 0, 0), y_labels=&quot;EMG (mV)&quot;)

while True:
    # Get data from Vicon interface and process it.
    raw_emg = interface.get_device_data(device_name=&quot;emg&quot;)
    emg_proc = interface.devices[0].process()
    # Update plots.
    emg_plot.update(emg_proc[:, -1:])
    emg_raw_plot.update(raw_emg)   
    # Add data to the binary file.    
    save({&quot;raw_emg&quot;: raw_emg, &quot;process_emg&quot;:emg_proc[:, -1]}, &quot;emg.bio&quot;)</code>
    <p>The live plot is shown in the following figure:</p>
    <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="media/EMG_plot.png">
      <alt-text>Real-time display of processed and raw EMG signals for a
      5-second window.</alt-text>
    </inline-graphic> <italic>Live display of processed (left) ad raw
    (right) EMG signals for a 5-second window.</italic></p>
  </sec>
</sec>
<sec id="research-projects-using-biosiglive">
  <title>Research Projects Using
  <monospace>biosiglive</monospace></title>
  <p>(<xref alt="Verdugo et al., 2022" rid="ref-Verdugo2022Feeling" ref-type="bibr">Verdugo
  et al., 2022</xref>)</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the Natural Sciences and Engineering
  Research Council of Canada (NSERC) through the CREATE OPSIDIAN
  program, the NSERC discovery of M. Begon, and the Pôle lavallois
  d’enseignement supérieur en arts numériques et économie créative ,
  Appel à projet 2020 - projet eMusicorps.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-chenier2021kinetics">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chénier</surname><given-names>Félix</given-names></name>
      </person-group>
      <article-title>Kinetics toolkit: An open-source python package to facilitate research in biomechanics</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2021">2021</year>
      <volume>6</volume>
      <issue>66</issue>
      <pub-id pub-id-type="doi">10.21105/joss.03714</pub-id>
      <fpage>3714</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-dixon2017biomechzoo">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dixon</surname><given-names>Philippe C</given-names></name>
        <name><surname>Loh</surname><given-names>Jonathan J</given-names></name>
        <name><surname>Michaud-Paquette</surname><given-names>Yannick</given-names></name>
        <name><surname>Pearsall</surname><given-names>David J</given-names></name>
      </person-group>
      <article-title>biomechZoo: An open-source toolbox for the processing, analysis, and visualization of biomechanical movement data</article-title>
      <source>Computer Methods and Programs in Biomedicine</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>140</volume>
      <pub-id pub-id-type="doi">10.1016/j.cmpb.2016.11.007</pub-id>
      <fpage>1</fpage>
      <lpage>10</lpage>
    </element-citation>
  </ref>
  <ref id="ref-martinez2020pyomeca">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Martinez</surname><given-names>Romain</given-names></name>
        <name><surname>Michaud</surname><given-names>Benjamin</given-names></name>
        <name><surname>Begon</surname><given-names>Mickael</given-names></name>
      </person-group>
      <article-title>Pyomeca: An open-source framework for biomechanical analysis</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>53</issue>
      <pub-id pub-id-type="doi">10.21105/joss.02431</pub-id>
      <fpage>2431</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-Verdugo2022Feeling">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Verdugo</surname><given-names>Felipe</given-names></name>
        <name><surname>Ceglia</surname><given-names>Amedeo</given-names></name>
        <name><surname>Frisson</surname><given-names>Christian</given-names></name>
        <name><surname>Burton</surname><given-names>Alexandre</given-names></name>
        <name><surname>Begon</surname><given-names>Mickael</given-names></name>
        <name><surname>Gibet</surname><given-names>Sylvie</given-names></name>
        <name><surname>Wanderley</surname><given-names>Marcelo M.</given-names></name>
      </person-group>
      <article-title>Feeling the Effort of Classical Musicians - A Pipeline from Electromyography to Smartphone Vibration for Live Music Performance</article-title>
      <source>NIME 2022</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.21428/92fbeb44.3ce22588</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-barre2014biomechanical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Barre</surname><given-names>Arnaud</given-names></name>
        <name><surname>Armand</surname><given-names>Stéphane</given-names></name>
      </person-group>
      <article-title>Biomechanical ToolKit: Open-source framework to visualize and process biomechanical data</article-title>
      <source>Computer methods and programs in biomedicine</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>114</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1016/j.cmpb.2014.01.012</pub-id>
      <fpage>80</fpage>
      <lpage>87</lpage>
    </element-citation>
  </ref>
  <ref id="ref-giggins2013biofeedback">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Giggins</surname><given-names>Oonagh M</given-names></name>
        <name><surname>Persson</surname><given-names>Ulrik McCarthy</given-names></name>
        <name><surname>Caulfield</surname><given-names>Brian</given-names></name>
      </person-group>
      <article-title>Biofeedback in rehabilitation</article-title>
      <source>Journal of neuroengineering and rehabilitation</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2013">2013</year>
      <volume>10</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1186/1743-0003-10-60</pub-id>
      <fpage>1</fpage>
      <lpage>11</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cozean1988biofeedback">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cozean</surname><given-names>CD</given-names></name>
        <name><surname>Pease</surname><given-names>William S</given-names></name>
        <name><surname>Hubbell</surname><given-names>SL</given-names></name>
      </person-group>
      <article-title>Biofeedback and functional electric stimulation in stroke rehabilitation.</article-title>
      <source>Archives of physical medicine and rehabilitation</source>
      <year iso-8601-date="1988">1988</year>
      <volume>69</volume>
      <issue>6</issue>
      <fpage>401</fpage>
      <lpage>405</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
