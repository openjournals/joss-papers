<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6461</article-id>
<article-id pub-id-type="doi">10.21105/joss.06461</article-id>
<title-group>
<article-title>pivmet: an R package proposing pivotal methods for
consensus clustering and mixture modelling</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3211-905X</contrib-id>
<name>
<surname>Egidi</surname>
<given-names>Leonardo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4852-0561</contrib-id>
<name>
<surname>Pappada</surname>
<given-names>Roberta</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7982-3514</contrib-id>
<name>
<surname>Pauli</surname>
<given-names>Francesco</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9523-5336</contrib-id>
<name>
<surname>Torelli</surname>
<given-names>Nicola</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Economics, Business, Mathematics, and
Statistics ‚ÄòBruno de Finetti‚Äô, University of Trieste</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-02-06">
<day>6</day>
<month>2</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>98</issue>
<fpage>6461</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>statistics</kwd>
<kwd>consensus clustering</kwd>
<kwd>mixture models</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We introduce the <monospace>R</monospace> package
  <monospace>pivmet</monospace>, a software that performs different
  pivotal methods for identifying, extracting, and using the so-called
  pivotal units that are chosen from a partition of data points to
  represent the groups to which they belong. Such units turn out be very
  useful in both unsupervised and supervised learning frameworks such as
  clustering, classification and mixture modelling.</p>
  <p>More specifically, applications of pivotal methods include, among
  the others: a Markov-Chain Monte Carlo (MCMC) relabelling procedure to
  deal with the well-known label-switching problem occurring during
  Bayesian estimation of mixture models
  (<xref alt="Egidi et al., 2018" rid="ref-egidi2018relabelling" ref-type="bibr">Egidi
  et al., 2018</xref>;
  <xref alt="Fr√ºhwirth-Schnatter, 2001" rid="ref-fruhwirth2001markov" ref-type="bibr">Fr√ºhwirth-Schnatter,
  2001</xref>;
  <xref alt="Richardson &amp; Green, 1997" rid="ref-richardson1997bayesian" ref-type="bibr">Richardson
  &amp; Green, 1997</xref>;
  <xref alt="Stephens, 2000" rid="ref-stephens2000dealing" ref-type="bibr">Stephens,
  2000</xref>); model-based clustering through sparse finite mixture
  models (SFMM)
  (<xref alt="Fr√ºhwirth-Schnatter &amp; Malsiner-Walli, 2019" rid="ref-fruhwirth2019here" ref-type="bibr">Fr√ºhwirth-Schnatter
  &amp; Malsiner-Walli, 2019</xref>;
  <xref alt="Malsiner-Walli et al., 2016" rid="ref-malsiner2016model" ref-type="bibr">Malsiner-Walli
  et al., 2016</xref>); consensus clustering
  (<xref alt="Strehl &amp; Ghosh, 2002" rid="ref-JMLR02" ref-type="bibr">Strehl
  &amp; Ghosh, 2002</xref>), which may allow to improve classical
  clustering techniques‚Äîe.g.¬†the classical
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means‚Äîvia
  a careful seeding; and Dirichlet process mixture models (DPMM) in
  Bayesian nonparametrics
  (<xref alt="Escobar &amp; West, 1995" rid="ref-escobar1995bayesian" ref-type="bibr">Escobar
  &amp; West, 1995</xref>;
  <xref alt="Ferguson, 1973" rid="ref-ferguson1973bayesian" ref-type="bibr">Ferguson,
  1973</xref>;
  <xref alt="Neal, 2000" rid="ref-neal2000markov" ref-type="bibr">Neal,
  2000</xref>).</p>
</sec>
<sec id="installation">
  <title>Installation</title>
  <p>The stable version of the package can be installed from the
  <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=pivmet">Comprehensive
  R Archive Network (CRAN)</ext-link>:</p>
  <preformat>install.packages(&quot;pivmet&quot;)
library(pivmet)</preformat>
  <p>However, before installing the package, the user should make sure
  to download the JAGS program at
  <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/mcmc-jags/">https://sourceforge.net/projects/mcmc-jags/</ext-link>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>In the modern <italic>big-data</italic> and <italic>machine
  learning</italic> age, summarizing some essential information from a
  dataset is often relevant and can help simplifying the data
  pre-processing steps. The advantage of identifying representative
  units of a group‚Äîhereafter <italic>pivotal units</italic> or
  <italic>pivots</italic>‚Äîchosen in such a way that they are as far as
  possible from units in the other groups and/or as similar as possible
  to the units in the same group, is that they may convey relevant
  information about the group they belong to while saving wasteful
  operations.</p>
  <p>Despite the lack of a strict theoretical framework behind their
  characterization, the pivots may be beneficial in many machine
  learning frameworks, such as clustering, classification, and mixture
  modelling when the interest is in deriving reliable estimates in
  mixture models and/or finding a partition of the data points. The
  theoretical framework concerning the pivotal methods implemented in
  the <monospace>pivmet</monospace> package is provided in Egidi et al.
  (<xref alt="2018" rid="ref-egidi2018relabelling" ref-type="bibr">2018</xref>).</p>
  <p>The <monospace>pivmet</monospace> package for
  <monospace>R</monospace> is available from the Comprehensive
  <monospace>R</monospace> Archive Network (CRAN) at
  <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=pivmet">http://CRAN.R-project.org/package=pivmet</ext-link>
  (<xref alt="Egidi et al., 2024" rid="ref-pivmet" ref-type="bibr">Egidi
  et al., 2024</xref>) and implements various pivotal selection criteria
  to deal with, but not limited to: (i) mixture model Bayesian
  estimation‚Äîeither via the JAGS software
  (<xref alt="Plummer, 2022" rid="ref-rjags" ref-type="bibr">Plummer,
  2022</xref>) using Gibbs sampling or the Stan
  (<xref alt="Stan Development Team, 2022" rid="ref-rstan" ref-type="bibr">Stan
  Development Team, 2022</xref>) software performing Hamiltonian Monte
  Carlo (HMC)‚Äîto tackle the so-called <italic>label switching</italic>
  problem; (ii) consensus clustering, where a variant of the
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
  algorithm is available; (iii) Dirichlet Process Mixture Models
  (DPPM).</p>
  <p>As far as we know from reviewing the scientific and statistical
  literature, the <monospace>pivmet</monospace> package is the only
  software designed to search pivotal units in a modern machine learning
  framework. However, since its large applicability, it exhibits some
  deep connections with some existing <monospace>R</monospace> packages
  commonly used for Bayesian statistics and clustering. In particular,
  the <monospace>pivmet</monospace> package:</p>
  <list list-type="bullet">
    <list-item>
      <p>extends the <monospace>bayesmix</monospace> package
      (<xref alt="Gruen, 2015" rid="ref-bayesmix" ref-type="bibr">Gruen,
      2015</xref>), which allows to fit univariate Gaussian mixtures, by
      allowing for sparse Gaussian univariate/multivariate mixtures;</p>
    </list-item>
    <list-item>
      <p>is naturally connected with the
      <monospace>label.switching</monospace> package
      (<xref alt="Papastamoulis, 2016" rid="ref-papastamoulis2016label" ref-type="bibr">Papastamoulis,
      2016</xref>) that offers many methods to fix label switching in
      Bayesian mixture models;</p>
    </list-item>
    <list-item>
      <p>in terms of computational MCMC methods, depends on the
      <monospace>rstan</monospace> package
      (<xref alt="Stan Development Team, 2022" rid="ref-rstan" ref-type="bibr">Stan
      Development Team, 2022</xref>) to perform Hamiltonian Monte Carlo
      sampling and on the <monospace>rjags</monospace> package
      (<xref alt="Plummer, 2022" rid="ref-rjags" ref-type="bibr">Plummer,
      2022</xref>) to perform Gibbs sampling;</p>
    </list-item>
    <list-item>
      <p>extends the classical <monospace>kmeans</monospace> function by
      allowing for a robust initial seeding.</p>
    </list-item>
  </list>
  <p>Compared to the aforementioned packages, the
  <monospace>pivmet</monospace> package offers a novel way to retrieve
  pivotal units. Moreover, it contains functions to exploit the pivotal
  units to efficiently estimate univariate and multivariate Gaussian
  mixtures, by relying on pre-compiled JAGS/Stan models, and to perform
  a robustified version of the <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
  algorithm.</p>
</sec>
<sec id="overview-and-main-functions">
  <title>Overview and main functions</title>
  <p>The package architecture strongly relies on three main
  functions:</p>
  <list list-type="bullet">
    <list-item>
      <p>The function <monospace>piv_MCMC()</monospace> is used to fit a
      Bayesian Gaussian mixture model with underlying Gibbs sampling or
      Hamiltonian Monte Carlo algorithm. The user can specify distinct
      prior distributions with the argument
      <monospace>priors</monospace> and the selected pivotal criterion
      via the argument <monospace>piv.criterion</monospace>.</p>
    </list-item>
    <list-item>
      <p>The function <monospace>piv_rel()</monospace> takes in input
      the model fit returned by <monospace>piv_MCMC</monospace> and
      implements the relabelling step as outlined by
      (<xref alt="Egidi et al., 2018" rid="ref-egidi2018relabelling" ref-type="bibr">Egidi
      et al., 2018</xref>).</p>
    </list-item>
    <list-item>
      <p>The function <monospace>piv_KMeans()</monospace> performs a
      robust consensus clustering based on distinct
      <inline-formula><alternatives>
      <tex-math><![CDATA[k]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
      partitions. The user can specify some options, such as the number
      of consensus partitions.</p>
    </list-item>
  </list>
</sec>
<sec id="example-1-relabelling-for-dealing-with-label-switching">
  <title>Example 1: relabelling for dealing with label switching</title>
  <p>The Fishery dataset in the <monospace>bayesmix</monospace>
  (<xref alt="Gruen, 2015" rid="ref-bayesmix" ref-type="bibr">Gruen,
  2015</xref>) package has been previously used by Titterington et al.
  (<xref alt="1985" rid="ref-titterington1985statistical" ref-type="bibr">1985</xref>)
  and Papastamoulis
  (<xref alt="2016" rid="ref-papastamoulis2016label" ref-type="bibr">2016</xref>).
  It consists of 256 snapper length measurements‚Äîsee
  <xref alt="[fig:example1]" rid="figU003Aexample1">[fig:example1]</xref>
  for the data histogram, along with an estimated kernel density.
  Analogously to some previous works, we assume a Gaussian mixture model
  with <inline-formula><alternatives>
  <tex-math><![CDATA[k=5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  groups, where <inline-formula><alternatives>
  <tex-math><![CDATA[\mu_j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œº</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[\sigma_j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>œÉ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\eta_j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œ∑</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  are respectively the mean, the standard deviation and the weight of
  group <inline-formula><alternatives>
  <tex-math><![CDATA[j = 1, \dots, k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.
  We fit our model by simulating <inline-formula><alternatives>
  <tex-math><![CDATA[15000]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>15000</mml:mn></mml:math></alternatives></inline-formula>
  samples from the posterior distribution of
  <inline-formula><alternatives>
  <tex-math><![CDATA[(\mathbf{z}, \boldsymbol{\mu}, \boldsymbol{\sigma}, \boldsymbol{\eta})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>ùê≥</mml:mi><mml:mo>,</mml:mo><mml:mi>ùõç</mml:mi><mml:mo>,</mml:mo><mml:mi>ùõî</mml:mi><mml:mo>,</mml:mo><mml:mi>ùõà</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
  by selecting the default argument
  <monospace>software=&quot;rjags&quot;</monospace>; for univariate
  mixtures, the MCMC Gibbs sampling is returned by the function
  <monospace>JAGSrun</monospace> in the package
  <monospace>bayesmix</monospace>. Alternatively, one could fit the
  model according to HMC sampling and with underlying Stan ecosystem by
  typing <monospace>software=&quot;rstan&quot;</monospace>. By default,
  the burn-in period is set equal to half of the total number of MCMC
  iterations. Here below we include the relevant
  <monospace>R</monospace> code.</p>
  <preformat># required packages
library(bayesmix)
set.seed(100)

# load data
data(fish)
y &lt;- fish[,1]
k &lt;- 5
nMC &lt;- 15000

# fit the mixture model for univariate data and find the pivots
res &lt;- piv_MCMC(y = y, k = k, nMC = nMC, burn = 7500, software = &quot;rjags&quot;)

# relabel the chains: figure 
rel &lt;- piv_rel(mcmc=res)
piv_plot(y = y, mcmc = res, rel_est = rel, type=&quot;chains&quot;)

# use Stan
res_stan &lt;- piv_MCMC(y = y, k = k, nMC = 5000, burn = 2500, software =&quot;rstan&quot;)
cat(res_stan$model)</preformat>
  <fig>
    <caption><p>Histograms of the Fishery data. The blue line represents
    the estimated kernel density.
    <styled-content id="figU003Aexample1"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="fish_hist.pdf" />
  </fig>
  <p><xref alt="[fig:example2]" rid="figU003Aexample2">[fig:example2]</xref>
  displays the traceplots for the parameters
  <inline-formula><alternatives>
  <tex-math><![CDATA[(\mu, \sigma, \eta)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œº</mml:mi><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ∑</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
  From the first row showing the raw MCMC outputs as given by the Gibbs
  sampling, we note that label switching clearly occurred. Our algorithm
  is able to fix label-switching and reorder the means
  <inline-formula><alternatives>
  <tex-math><![CDATA[\mu_j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œº</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  and the weights <inline-formula><alternatives>
  <tex-math><![CDATA[\eta_j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>Œ∑</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
  for <inline-formula><alternatives>
  <tex-math><![CDATA[j=1,\ldots,k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
  as emerged from the second row of the plot.</p>
  <fig>
    <caption><p>Fishery dataset: traceplots of the parameters
    <inline-formula><alternatives>
    <tex-math><![CDATA[(\mu, \sigma, \eta)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œº</mml:mi><mml:mo>,</mml:mo><mml:mi>œÉ</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ∑</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
    obtained via the <monospace>rjags</monospace> option for the
    <monospace>piv_MCMC</monospace> function (Gibbs sampling, 15000 MCMC
    iterations). Top row: Raw MCMC outputs. Bottom row: relabelled MCMC
    samples.
    <styled-content id="figU003Aexample2"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="fish_chains.pdf" />
  </fig>
</sec>
<sec id="example-2-consensus-clustering">
  <title>Example 2: consensus clustering</title>
  <p>As widely known, one of the drawbacks of the
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
  algorithm is represented by its inefficiency in distinguishing between
  groups of unbalanced sizes. The recent literature on clustering
  methods has explored some approaches to combine several partitions via
  a consensus clustering, which may improve the solution obtained from a
  single run of a clustering algorithm.
  Here, we consider a consensus clustering technique based on
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
  and pivotal methods used for a careful initial pivotal seeding.</p>
  <p>For illustration purposes, we simulate three bivariate Gaussian
  distributions with 20, 100 and 500 observations, respectively‚Äîsee
  <xref alt="[fig:example3]" rid="figU003Aexample3">[fig:example3]</xref>.
  The plots refer to the pivotal criteria <monospace>MUS</monospace>,
  <monospace>maxsumint</monospace>, and
  <monospace>maxsumdiff</monospace>; moreover, we consider Partitioning
  Around Medoids (PAM) method via the <monospace>pam</monospace>
  function of the <monospace>cluster</monospace> package and
  agglomerative hierarchical clustering (agnes), with average, single,
  and complete linkage. Group centers and pivots are marked via
  asterisks and triangles symbols, respectively. As can be seen, pivotal
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>-means
  methods are able to satisfactorily detect the true data partition and
  outperform the alternative approaches in most of the cases. Here below
  we include the relevant <monospace>R</monospace> code.</p>
  <preformat>library(mvtnorm)

# simulate data
set.seed(123)
n=620
k=3
n1=20
n2=100
n3=500
x=matrix(NA, n,2)
gruppovero=c( rep(1,n1), rep(2, n2), rep(3, n3))

x[1:n1,]=rmvnorm(n1, c(1,5), sigma=diag(2))
x[(n1+1):(n1+n2),]=rmvnorm(n2, c(4,0), sigma=diag(2))
x[(n1+n2+1):(n1+n2+n3),]=rmvnorm(n3, c(6,6), sigma=diag(2))


kmeans_res &lt;- kmeans(x, centers=k)

res &lt;- piv_KMeans(x, k, alg.type = &quot;hclust&quot;,
                   piv.criterion =&quot;maxsumdiff&quot;,
                   prec_par=n1)</preformat>
  <fig>
    <caption><p>Consensus clustering via the
    <monospace>piv_KMeans</monospace> function assuming three bivariate
    Gaussian distributions and three groups with 20, 100 and 500
    observations, respectively.
    <styled-content id="figU003Aexample3"></styled-content></p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="figure3.pdf" />
  </fig>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p>The <monospace>pivmet</monospace> package proposes various methods
  for identifying pivotal units in datasets with a grouping structure
  and uses them for improving inferential conclusions and clustering
  partitions. The package suits well for both supervised and
  unsupervised problems, by providing a valid alternative to existing
  functions for similar applications, and keeping low the computational
  effort. It is of future interest to include additional functions that
  may allow to deal with the estimation of the number of components in
  the data when this information is latent or unknown and provide more
  graphical tools to diagnose pivotal selection.</p>
</sec>
<sec id="reproducibility">
  <title>Reproducibility</title>
  <p>The <monospace>R</monospace> code required to generate the examples
  is available at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/LeoEgidi/pivmet/tree/master/paper/rcode">https://github.com/LeoEgidi/pivmet/tree/master/paper/rcode</ext-link>.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors thank Ioannis Ntzoufras and Dimitris Karlis from Athens
  University of Economics and Business (AUEB) for their valuable
  suggestions about the package structure.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-egidi2018relabelling">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Egidi</surname><given-names>Leonardo</given-names></name>
        <name><surname>Pappad√†</surname><given-names>Roberta</given-names></name>
        <name><surname>Pauli</surname><given-names>Francesco</given-names></name>
        <name><surname>Torelli</surname><given-names>Nicola</given-names></name>
      </person-group>
      <article-title>Relabelling in Bayesian mixture models by pivotal units</article-title>
      <source>Statistics and Computing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>28</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1007/s11222-017-9774-2</pub-id>
      <fpage>957</fpage>
      <lpage>969</lpage>
    </element-citation>
  </ref>
  <ref id="ref-JMLR02">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Strehl</surname><given-names>A.</given-names></name>
        <name><surname>Ghosh</surname><given-names>J.</given-names></name>
      </person-group>
      <article-title>Cluster ensembles - a knowledge reuse framework for combining multiple partitions</article-title>
      <source>Journal on Machine Learning Research</source>
      <year iso-8601-date="2002">2002</year>
      <volume>3</volume>
      <pub-id pub-id-type="doi">10.1162/153244303321897735</pub-id>
      <fpage>583</fpage>
      <lpage>617</lpage>
    </element-citation>
  </ref>
  <ref id="ref-stephens2000dealing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stephens</surname><given-names>Matthew</given-names></name>
      </person-group>
      <article-title>Dealing with label switching in mixture models</article-title>
      <source>Journal of the Royal Statistical Society: Series B</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2000">2000</year>
      <volume>62</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1111/1467-9868.00265</pub-id>
      <fpage>795</fpage>
      <lpage>809</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fruhwirth2001markov">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fr√ºhwirth-Schnatter</surname><given-names>Sylvia</given-names></name>
      </person-group>
      <article-title>Markov Chain Monte Carlo estimation of classical and dynamic switching and mixture models</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2001">2001</year>
      <volume>96</volume>
      <issue>453</issue>
      <pub-id pub-id-type="doi">10.1198/016214501750333063</pub-id>
      <fpage>194</fpage>
      <lpage>209</lpage>
    </element-citation>
  </ref>
  <ref id="ref-papastamoulis2016label">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papastamoulis</surname><given-names>Panagiotis</given-names></name>
      </person-group>
      <article-title>label.switching: An R package for dealing with the label switching problem in MCMC outputs</article-title>
      <source>Journal of Statistical Software, Code Snippets</source>
      <year iso-8601-date="2016">2016</year>
      <volume>69</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v069.c01</pub-id>
      <fpage>1</fpage>
      <lpage>24</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bayesmix">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Gruen</surname><given-names>Bettina</given-names></name>
      </person-group>
      <source>Bayesmix: Bayesian mixture models with JAGS</source>
      <year iso-8601-date="2015">2015</year>
      <uri>https://CRAN.R-project.org/package=bayesmix</uri>
    </element-citation>
  </ref>
  <ref id="ref-titterington1985statistical">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Titterington</surname><given-names>D Michael</given-names></name>
        <name><surname>Smith</surname><given-names>Adrian FM</given-names></name>
        <name><surname>Makov</surname><given-names>Udi E</given-names></name>
      </person-group>
      <source>Statistical analysis of finite mixture distributions</source>
      <publisher-name>Wiley, New York</publisher-name>
      <year iso-8601-date="1985">1985</year>
      <pub-id pub-id-type="doi">10.2307/2531224</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-richardson1997bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Richardson</surname><given-names>Sylvia</given-names></name>
        <name><surname>Green</surname><given-names>Peter J</given-names></name>
      </person-group>
      <article-title>On Bayesian analysis of mixtures with an unknown number of components (with discussion)</article-title>
      <source>Journal of the Royal Statistical Society: series B</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="1997">1997</year>
      <volume>59</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1111/1467-9868.00095</pub-id>
      <fpage>731</fpage>
      <lpage>792</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pivmet">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Egidi</surname><given-names>Leonardo</given-names></name>
        <name><surname>Pappad√†</surname><given-names>Roberta</given-names></name>
        <name><surname>Pauli</surname><given-names>Francesco</given-names></name>
        <name><surname>Torelli</surname><given-names>Nicola</given-names></name>
      </person-group>
      <source>Pivmet: Pivotal Methods for Bayesian Relabelling and k-means Clustering</source>
      <year iso-8601-date="2024">2024</year>
      <uri>https://CRAN.R-project.org/package=pivmet</uri>
    </element-citation>
  </ref>
  <ref id="ref-rstan">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Stan Development Team</string-name>
      </person-group>
      <article-title>RStan: The R interface to Stan</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>http://mc-stan.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-rjags">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Plummer</surname><given-names>Martyn</given-names></name>
      </person-group>
      <source>Rjags: Bayesian graphical models using MCMC</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=rjags</uri>
    </element-citation>
  </ref>
  <ref id="ref-neal2000markov">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Neal</surname><given-names>Radford M</given-names></name>
      </person-group>
      <article-title>Markov Chain sampling methods for Dirichlet process mixture models</article-title>
      <source>Journal of computational and graphical statistics</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2000">2000</year>
      <volume>9</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1080/10618600.2000.10474879</pub-id>
      <fpage>249</fpage>
      <lpage>265</lpage>
    </element-citation>
  </ref>
  <ref id="ref-escobar1995bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Escobar</surname><given-names>Michael D</given-names></name>
        <name><surname>West</surname><given-names>Mike</given-names></name>
      </person-group>
      <article-title>Bayesian density estimation and inference using mixtures</article-title>
      <source>Journal of the American Statistical Association</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="1995">1995</year>
      <volume>90</volume>
      <issue>430</issue>
      <pub-id pub-id-type="doi">10.1080/01621459.1995.10476550</pub-id>
      <fpage>577</fpage>
      <lpage>588</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ferguson1973bayesian">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ferguson</surname><given-names>Thomas S</given-names></name>
      </person-group>
      <article-title>A Bayesian analysis of some nonparametric problems</article-title>
      <source>The Annals of Statistics</source>
      <publisher-name>JSTOR</publisher-name>
      <year iso-8601-date="1973">1973</year>
      <fpage>209</fpage>
      <lpage>230</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fruhwirth2019here">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Fr√ºhwirth-Schnatter</surname><given-names>Sylvia</given-names></name>
        <name><surname>Malsiner-Walli</surname><given-names>Gertraud</given-names></name>
      </person-group>
      <article-title>From here to infinity: Sparse finite versus Dirichlet process mixtures in model-based clustering</article-title>
      <source>Advances in data analysis and classification</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>13</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1007/s11634-018-0329-y</pub-id>
      <fpage>33</fpage>
      <lpage>64</lpage>
    </element-citation>
  </ref>
  <ref id="ref-malsiner2016model">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Malsiner-Walli</surname><given-names>Gertraud</given-names></name>
        <name><surname>Fr√ºhwirth-Schnatter</surname><given-names>Sylvia</given-names></name>
        <name><surname>Gr√ºn</surname><given-names>Bettina</given-names></name>
      </person-group>
      <article-title>Model-based clustering based on sparse finite Gaussian mixtures</article-title>
      <source>Statistics and computing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>26</volume>
      <issue>1-2</issue>
      <pub-id pub-id-type="doi">10.1007/s11222-014-9500-2</pub-id>
      <fpage>303</fpage>
      <lpage>324</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
