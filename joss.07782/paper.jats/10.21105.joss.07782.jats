<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7782</article-id>
<article-id pub-id-type="doi">10.21105/joss.07782</article-id>
<title-group>
<article-title>Executorlib – Up-scaling Python workflows for
hierarchical heterogenous high-performance computing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9948-7119</contrib-id>
<name>
<surname>Janssen</surname>
<given-names>Jan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4327-2746</contrib-id>
<name>
<surname>Taylor</surname>
<given-names>Michael Gilbert</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4726-2860</contrib-id>
<name>
<surname>Yang</surname>
<given-names>Ping</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7903-2472</contrib-id>
<name>
<surname>Neugebauer</surname>
<given-names>Joerg</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3028-5249</contrib-id>
<name>
<surname>Perez</surname>
<given-names>Danny</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Max Planck Institute for Sustainable Materials, Düsseldorf,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Los Alamos National Laboratory, Los Alamos, NM, United
States of America</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-01-31">
<day>31</day>
<month>1</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>108</issue>
<fpage>7782</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>High Performance Computing</kwd>
<kwd>Task Scheduling</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Executorlib enables the execution of hierarchical Python workflows
  on heterogenous computing resources of high-performance computing
  (HPC) clusters. This is achieved by extending the Executor class of
  the Python standard library for asynchronously executing callables
  with an interface to HPC job schedulers. The initial release of
  Executorlib supports the Simple Linux Utility for Resource Management
  (SLURM) and the flux framework as HPC job schedulers to start Python
  processes with dedicated computing resources such as CPU cores,
  memory, or accelerators like GPUs. For heterogenous workflows,
  Executorlib enables the use of parallel computing frameworks like the
  message passing interface (MPI) or of dedicated GPU libraries on a per
  workflow step basis. Python workflows can be up-scaled with
  Executorlib from a laptop up to the latest Exascale HPC clusters with
  minimal code changes including support for hierarchical workflows.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The convergence of artificial intelligence (AI) and
  high-performance computing (HPC) workflows
  (<xref alt="Silva et al., 2021" rid="ref-workflows" ref-type="bibr">Silva
  et al., 2021</xref>) is one of the key drivers for the rise of Python
  workflows for HPC. To avoid intrusive code changes, interfaces to
  performance critical scientific software packages were traditionally
  implemented using file-based communication and control shell scripts,
  leading to poor maintainability, portability, and scalability. This
  approach is however losing ground to more efficient alternatives, such
  as the use of direct Python bindings, as their support is now
  increasingly common in scientific software packages and especially
  machine learning packages and AI frameworks. This enables the
  programmer to easily express complex workloads that require the
  orchestration of multiple codes. Still, Python workflows for HPC also
  come with challenges, like (1) safely terminating Python processes,
  (2) controlling the resources of Python processes and (3) the
  management of Python environments
  (<xref alt="Straßel et al., 2020" rid="ref-pythonhpc" ref-type="bibr">Straßel
  et al., 2020</xref>). The first two of these challenges can be
  addressed by developing strategies and tools to interface HPC job
  schedulers such as SLURM
  (<xref alt="Jette et al., 2002" rid="ref-slurm" ref-type="bibr">Jette
  et al., 2002</xref>) with Python in order to control the execution and
  manage the computational resources required to execute heterogenous
  HPC workflows. A number of Python workflow frameworks have been
  developed for both types of interfaces, ranging from domain-specific
  solutions for fields like high-throughput screening in computational
  materials science, e.g., fireworks
  (<xref alt="Jain et al., 2015" rid="ref-fireworks" ref-type="bibr">Jain
  et al., 2015</xref>), pyiron
  (<xref alt="Janssen et al., 2019" rid="ref-pyiron" ref-type="bibr">Janssen
  et al., 2019</xref>), and aiida
  (<xref alt="Huber et al., 2020" rid="ref-aiida" ref-type="bibr">Huber
  et al., 2020</xref>), to generalized Python interfaces for job
  schedulers, e.g., myqueue
  (<xref alt="Mortensen et al., 2020" rid="ref-myqueue" ref-type="bibr">Mortensen
  et al., 2020</xref>) and PSI/j
  (<xref alt="Hategan-Marandiuc et al., 2023" rid="ref-psij" ref-type="bibr">Hategan-Marandiuc
  et al., 2023</xref>), and task scheduling frameworks that implement
  their own task scheduling on top of the HPC job scheduler, e.g., dask
  (<xref alt="Rocklin, 2015" rid="ref-dask" ref-type="bibr">Rocklin,
  2015</xref>), parsl
  (<xref alt="Babuji et al., 2019" rid="ref-parsl" ref-type="bibr">Babuji
  et al., 2019</xref>), and jobflow
  (<xref alt="Rosen et al., 2024" rid="ref-jobflow" ref-type="bibr">Rosen
  et al., 2024</xref>). While these tools can be powerful, they
  introduce new constructs unfamiliar to most Python developers, adding
  complexity and creating a barrier to entry.</p>
</sec>
<sec id="features-and-implementation">
  <title>Features and Implementation</title>
  <p>To address this limitation while at the same time leveraging the
  powerful and novel hierarchical HPC resource managers like flux
  framework
  (<xref alt="Ahn et al., 2014" rid="ref-flux" ref-type="bibr">Ahn et
  al., 2014</xref>), we introduce Executorlib, which instead leverages
  and naturally extends the familiar Executor interface defined by the
  Python standard library from single-node shared-memory operation to
  multi-node distributed operation on HPC platforms.
  <xref alt="[fig:process]" rid="figU003Aprocess">[fig:process]</xref>
  illustrates the internal functionality of Executorlib.</p>
  <fig>
    <caption><p>Illustration of the communication between the
    Executorlib Executor, the job scheduler and the Python process to
    asynchronously execute the submitted Python function (on the
    right).<styled-content id="figU003Aprocess"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="process.png" />
  </fig>
  <p>Currently, Executorlib supports five different job schedulers
  implemented as different Executor classes. The first is the
  <monospace>SingleNodeExecutor</monospace> for rapid prototyping on a
  laptop or local workstation in a way that is functionally similar to
  the standard <monospace>ProcessPoolExecutor</monospace>. The second,
  <monospace>SlurmClusterExecutor</monospace>, submits Python functions
  as individual jobs to a SLURM job scheduler using the
  <monospace>sbatch</monospace> command, which can be useful for
  long-running tasks, e.g., that call a compute intensive legacy code.
  The third is the <monospace>SlurmJobExecutor</monospace>, which
  distributes Python functions in an existing SLURM job using the
  <monospace>srun</monospace> command. Analogously, the
  <monospace>FluxClusterExecutor</monospace> submits Python functions as
  individual jobs to a flux job scheduler and the
  <monospace>FluxJobExecutor</monospace> distributes Python functions in
  a flux job. Given the hierarchial approach of the flux scheduler there
  is no limit to the number of <monospace>FluxJobExecutor</monospace>
  instances which can be nested inside each other to construct
  hierarchical workflows.</p>
  <p>To assign dedicated computing resources to individual Python
  functions, the Executorlib Executor classes extend the submission
  function <monospace>submit()</monospace> to support not only the
  Python function and its inputs, but also a Python dictionary
  specifying the requested computing resources,
  <monospace>resource_dict</monospace>. The resource dictionary can
  define the number of compute cores, number of threads, number of GPUs,
  as well as job scheduler specific parameters like the working
  directory, maximum run time or the maximum memory. With this
  hierarchical approach, Executorlib allows the user to finely control
  the execution of each individual Python function, using parallel
  communication libraries like the Message Passing Interface (MPI) for
  Python
  (<xref alt="Dalcín et al., 2005" rid="ref-mpi4py" ref-type="bibr">Dalcín
  et al., 2005</xref>) or GPU-optimized libraries to aggressively
  optimize complex compute intensive tasks of heterogenous HPC that are
  best solved by tightly-coupled parallelization approaches, while
  offering a simple and easy to maintain approach to the orchestration
  of many such weakly-coupled tasks. This ability to seamlessly combine
  different programming models again accelerates the rapid prototyping
  of heterogenous HPC workflows without sacrificing performance of
  critical code components.</p>
</sec>
<sec id="usage-to-date">
  <title>Usage To-Date</title>
  <p>While initially developed in the US DOE Exascale Computing
  Project’s Exascale Atomistic Capability for Accuracy, Length and Time
  (EXAALT) to accelerate the development of computational materials
  science simulation workflows for the Exascale, Executorlib has since
  been generalized to support a wide-range of backends and HPC clusters
  at different scales. Based on this generalization, it is also been
  implemented in the pyiron workflow framework
  (<xref alt="Janssen et al., 2019" rid="ref-pyiron" ref-type="bibr">Janssen
  et al., 2019</xref>) as the primary task scheduling interface.</p>
</sec>
<sec id="additional-details">
  <title>Additional Details</title>
  <p>The full documentation including a number of examples for the
  individual features is available at
  <ext-link ext-link-type="uri" xlink:href="https://executorlib.readthedocs.io">executorlib.readthedocs.io</ext-link>
  with the corresponding source code at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/pyiron/executorlib">github.com/pyiron/executorlib</ext-link>.
  Executorlib is developed an as open-source library with a focus on
  stability.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>J.J. was supported by the Laboratory Directed Research and
  Development program of Los Alamos National Laboratory under project
  number 20220815PRD4. J.J. and D.P. acknowledge funding from the
  Exascale Computing Project (17-SC-20-SC), a collaborative effort of
  the U.S. Department of Energy Office of Science and the National
  Nuclear Security Administration, and the hospitality from the
  “Data-Driven Materials Informatics” program from the Institute of
  Mathematical and Statistical Innovation (IMSI). J.J. and J.N.
  acknowledge funding from the Deutsche Forschungsgemeinschaft (DFG)
  through the CRC1394 “Structural and Chemical Atomic Complexity – From
  Defect Phase Diagrams to Material Properties”, project ID 409476157.
  J.J., M.G.T., P.Y., J.N., and D.P. acknowledge the hospitality of the
  Institute of Pure and Applied math (IPAM) as part of the “New
  Mathematics for the Exascale: Applications to Materials Science” long
  program. M.G.T. and P.Y. acknowledge support of the U.S. Department of
  Energy (DOE), Office of Science, Office of Basic Energy Sciences,
  Heavy Element Chemistry Program (KC0302031) under contract number
  E3M2. Los Alamos National Laboratory is operated by Triad National
  Security LLC, for the National Nuclear Security administration of the
  U.S. DOE under Contract No. 89233218CNA0000001.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-workflows">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Silva</surname><given-names>Rafael Ferreira da</given-names></name>
        <name><surname>Casanova</surname><given-names>Henri</given-names></name>
        <name><surname>Chard</surname><given-names>Kyle</given-names></name>
        <name><surname>Altintas</surname><given-names>Ilkay</given-names></name>
        <name><surname>Badia</surname><given-names>Rosa M</given-names></name>
        <name><surname>Balis</surname><given-names>Bartosz</given-names></name>
        <name><surname>Coleman</surname><given-names>Taina</given-names></name>
        <name><surname>Coppens</surname><given-names>Frederik</given-names></name>
        <name><surname>Di Natale</surname><given-names>Frank</given-names></name>
        <name><surname>Enders</surname><given-names>Bjoern</given-names></name>
        <name><surname>Fahringer</surname><given-names>Thomas</given-names></name>
        <name><surname>Filgueira</surname><given-names>Rosa</given-names></name>
        <name><surname>Fursin</surname><given-names>Grigori</given-names></name>
        <name><surname>Garijo</surname><given-names>Daniel</given-names></name>
        <name><surname>Goble</surname><given-names>Carole</given-names></name>
        <name><surname>Howell</surname><given-names>Dorran</given-names></name>
        <name><surname>Jha</surname><given-names>Shantenu</given-names></name>
        <name><surname>Katz</surname><given-names>Daniel S.</given-names></name>
        <name><surname>Laney</surname><given-names>Daniel</given-names></name>
        <name><surname>Leser</surname><given-names>Ulf</given-names></name>
        <name><surname>Malawski</surname><given-names>Maciej</given-names></name>
        <name><surname>Mehta</surname><given-names>Kshitij</given-names></name>
        <name><surname>Pottier</surname><given-names>Loic</given-names></name>
        <name><surname>Ozik</surname><given-names>Jonathan</given-names></name>
        <name><surname>Peterson</surname><given-names>J. Luc</given-names></name>
        <name><surname>Ramakrishnan</surname><given-names>Lavanya</given-names></name>
        <name><surname>Soiland-Reyes</surname><given-names>Stian</given-names></name>
        <name><surname>Thain</surname><given-names>Douglas</given-names></name>
        <name><surname>Wolf</surname><given-names>Matthew</given-names></name>
      </person-group>
      <article-title>A community roadmap for scientific workflows research and development</article-title>
      <source>2021 IEEE workshop on workflows in support of large-scale science (WORKS)</source>
      <publisher-name>IEEE Computer Society</publisher-name>
      <publisher-loc>Los Alamitos, CA, USA</publisher-loc>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.1109/WORKS54523.2021.00016</pub-id>
      <fpage>81</fpage>
      <lpage>90</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pythonhpc">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Straßel</surname><given-names>Dominik</given-names></name>
        <name><surname>Reusch</surname><given-names>Philipp</given-names></name>
        <name><surname>Keuper</surname><given-names>Janis</given-names></name>
      </person-group>
      <article-title>Python workflows on HPC systems</article-title>
      <source>2020 IEEE/ACM 9th workshop on python for high-performance and scientific computing (PyHPC)</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.1109/PyHPC51966.2020.00009</pub-id>
      <fpage>32</fpage>
      <lpage>40</lpage>
    </element-citation>
  </ref>
  <ref id="ref-slurm">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Jette</surname><given-names>Morris A.</given-names></name>
        <name><surname>Yoo</surname><given-names>Andy B.</given-names></name>
        <name><surname>Grondona</surname><given-names>Mark</given-names></name>
      </person-group>
      <article-title>SLURM: Simple Linux utility for resource management</article-title>
      <source>In lecture notes in computer science: Proceedings of job scheduling strategies for parallel processing (JSSPP) 2003</source>
      <publisher-name>Springer-Verlag</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <pub-id pub-id-type="doi">10.1007/10968987_3</pub-id>
      <fpage>44</fpage>
      <lpage>60</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fireworks">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jain</surname><given-names>Anubhav</given-names></name>
        <name><surname>Ong</surname><given-names>Shyue Ping</given-names></name>
        <name><surname>Chen</surname><given-names>Wei</given-names></name>
        <name><surname>Medasani</surname><given-names>Bharat</given-names></name>
        <name><surname>Qu</surname><given-names>Xiaohui</given-names></name>
        <name><surname>Kocher</surname><given-names>Michael</given-names></name>
        <name><surname>Brafman</surname><given-names>Miriam</given-names></name>
        <name><surname>Petretto</surname><given-names>Guido</given-names></name>
        <name><surname>Rignanese</surname><given-names>Gian-Marco</given-names></name>
        <name><surname>Hautier</surname><given-names>Geoffroy</given-names></name>
        <name><surname>Gunter</surname><given-names>Daniel</given-names></name>
        <name><surname>Persson</surname><given-names>Kristin A.</given-names></name>
      </person-group>
      <article-title>FireWorks: A dynamic workflow system designed for high-throughput applications</article-title>
      <source>Concurrency and Computation: Practice and Experience</source>
      <year iso-8601-date="2015">2015</year>
      <volume>27</volume>
      <issue>17</issue>
      <pub-id pub-id-type="doi">10.1002/cpe.3505</pub-id>
      <fpage>5037</fpage>
      <lpage>5059</lpage>
    </element-citation>
  </ref>
  <ref id="ref-aiida">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Huber</surname><given-names>Sebastiaan P.</given-names></name>
        <name><surname>Zoupanos</surname><given-names>Spyros</given-names></name>
        <name><surname>Uhrin</surname><given-names>Martin</given-names></name>
        <name><surname>Talirz</surname><given-names>Leopold</given-names></name>
        <name><surname>Kahle</surname><given-names>Leonid</given-names></name>
        <name><surname>Häuselmann</surname><given-names>Rico</given-names></name>
        <name><surname>Gresch</surname><given-names>Dominik</given-names></name>
        <name><surname>Müller</surname><given-names>Tiziano</given-names></name>
        <name><surname>Yakutovich</surname><given-names>Aliaksandr V.</given-names></name>
        <name><surname>Andersen</surname><given-names>Francisco F.</given-names><suffix>Casper W. Ramirez</suffix></name>
        <name><surname>Adorf</surname><given-names>Carl S.</given-names></name>
        <name><surname>Gargiulo</surname><given-names>Fernando</given-names></name>
        <name><surname>Kumbhar</surname><given-names>Snehal</given-names></name>
        <name><surname>Passaro</surname><given-names>Elsa</given-names></name>
        <name><surname>Johnston</surname><given-names>Conrad</given-names></name>
        <name><surname>Merkys</surname><given-names>Andrius</given-names></name>
        <name><surname>Cepellotti</surname><given-names>Andrea</given-names></name>
        <name><surname>Mounet</surname><given-names>Nicolas</given-names></name>
        <name><surname>Marzari</surname><given-names>Nicola</given-names></name>
        <name><surname>Kozinsky</surname><given-names>Boris</given-names></name>
        <name><surname>Pizzi</surname><given-names>Giovanni</given-names></name>
      </person-group>
      <article-title>AiiDA 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance</article-title>
      <source>Scientific Data</source>
      <year iso-8601-date="2020">2020</year>
      <volume>7</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1038/s41597-020-00638-4</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-pyiron">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Janssen</surname><given-names>Jan</given-names></name>
        <name><surname>Surendralal</surname><given-names>Sudarsan</given-names></name>
        <name><surname>Lysogorskiy</surname><given-names>Yury</given-names></name>
        <name><surname>Todorova</surname><given-names>Mira</given-names></name>
        <name><surname>Hickel</surname><given-names>Tilmann</given-names></name>
        <name><surname>Drautz</surname><given-names>Ralf</given-names></name>
        <name><surname>Neugebauer</surname><given-names>Jörg</given-names></name>
      </person-group>
      <article-title>Pyiron: An integrated development environment for computational materials science</article-title>
      <source>Computational Materials Science</source>
      <year iso-8601-date="2019">2019</year>
      <volume>163</volume>
      <issn>0927-0256</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0927025618304786</uri>
      <pub-id pub-id-type="doi">10.1016/j.commatsci.2018.07.043</pub-id>
      <fpage>24</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-myqueue">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mortensen</surname><given-names>Jens Jørgen</given-names></name>
        <name><surname>Gjerding</surname><given-names>Morten</given-names></name>
        <name><surname>Thygesen</surname><given-names>Kristian Sommer</given-names></name>
      </person-group>
      <article-title>MyQueue: Task and workflow scheduling system</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>45</issue>
      <uri>https://doi.org/10.21105/joss.01844</uri>
      <pub-id pub-id-type="doi">10.21105/joss.01844</pub-id>
      <fpage>1844</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-psij">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hategan-Marandiuc</surname><given-names>Mihael</given-names></name>
        <name><surname>Merzky</surname><given-names>Andre</given-names></name>
        <name><surname>Collier</surname><given-names>Nicholson</given-names></name>
        <name><surname>Maheshwari</surname><given-names>Ketan</given-names></name>
        <name><surname>Ozik</surname><given-names>Jonathan</given-names></name>
        <name><surname>Turilli</surname><given-names>Matteo</given-names></name>
        <name><surname>Wilke</surname><given-names>Andreas</given-names></name>
        <name><surname>Wozniak</surname><given-names>Justin M.</given-names></name>
        <name><surname>Chard</surname><given-names>Kyle</given-names></name>
        <name><surname>Foster</surname><given-names>Ian</given-names></name>
        <name><surname>Silva</surname><given-names>Rafael Ferreira da</given-names></name>
        <name><surname>Jha</surname><given-names>Shantenu</given-names></name>
        <name><surname>Laney</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>PSI/j: A portable interface for submitting, monitoring, and managing jobs</article-title>
      <source>2023 IEEE 19th international conference on e-science (e-science)</source>
      <year iso-8601-date="2023">2023</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/e-Science58273.2023.10254912</pub-id>
      <fpage>1</fpage>
      <lpage>10</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dask">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Rocklin</surname><given-names>Matthew</given-names></name>
      </person-group>
      <article-title>Dask: Parallel computation with blocked algorithms and task scheduling</article-title>
      <source>Proceedings of the 14th Python in science conference</source>
      <person-group person-group-type="editor">
        <name><surname>Huff</surname><given-names>Kathryn</given-names></name>
        <name><surname>Bergstra</surname><given-names>James</given-names></name>
      </person-group>
      <year iso-8601-date="2015">2015</year>
      <pub-id pub-id-type="doi">10.25080/Majora-7b98e3ed-013</pub-id>
      <fpage>126 </fpage>
      <lpage> 132</lpage>
    </element-citation>
  </ref>
  <ref id="ref-parsl">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Babuji</surname><given-names>Yadu</given-names></name>
        <name><surname>Woodard</surname><given-names>Anna</given-names></name>
        <name><surname>Li</surname><given-names>Zhuozhao</given-names></name>
        <name><surname>Katz</surname><given-names>Daniel S.</given-names></name>
        <name><surname>Clifford</surname><given-names>Ben</given-names></name>
        <name><surname>Kumar</surname><given-names>Rohan</given-names></name>
        <name><surname>Lacinski</surname><given-names>Lukasz</given-names></name>
        <name><surname>Chard</surname><given-names>Ryan</given-names></name>
        <name><surname>Wozniak</surname><given-names>Justin M.</given-names></name>
        <name><surname>Foster</surname><given-names>Ian</given-names></name>
        <name><surname>Wilde</surname><given-names>Michael</given-names></name>
        <name><surname>Chard</surname><given-names>Kyle</given-names></name>
      </person-group>
      <article-title>Parsl: Pervasive parallel programming in Python</article-title>
      <source>Proceedings of the 28th international symposium on high-performance parallel and distributed computing</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2019">2019</year>
      <isbn>9781450366700</isbn>
      <uri>https://doi.org/10.1145/3307681.3325400</uri>
      <pub-id pub-id-type="doi">10.1145/3307681.3325400</pub-id>
      <fpage>25</fpage>
      <lpage>36</lpage>
    </element-citation>
  </ref>
  <ref id="ref-jobflow">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rosen</surname><given-names>Andrew S.</given-names></name>
        <name><surname>Gallant</surname><given-names>Max</given-names></name>
        <name><surname>George</surname><given-names>Janine</given-names></name>
        <name><surname>Riebesell</surname><given-names>Janosh</given-names></name>
        <name><surname>Sahasrabuddhe</surname><given-names>Hrushikesh</given-names></name>
        <name><surname>Shen</surname><given-names>Jimmy-Xuan</given-names></name>
        <name><surname>Wen</surname><given-names>Mingjian</given-names></name>
        <name><surname>Evans</surname><given-names>Matthew L.</given-names></name>
        <name><surname>Petretto</surname><given-names>Guido</given-names></name>
        <name><surname>Waroquiers</surname><given-names>David</given-names></name>
        <name><surname>Rignanese</surname><given-names>Gian-Marco</given-names></name>
        <name><surname>Persson</surname><given-names>Kristin A.</given-names></name>
        <name><surname>Jain</surname><given-names>Anubhav</given-names></name>
        <name><surname>Ganose</surname><given-names>Alex M.</given-names></name>
      </person-group>
      <article-title>Jobflow: Computational workflows made simple</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>9</volume>
      <issue>93</issue>
      <uri>https://doi.org/10.21105/joss.05995</uri>
      <pub-id pub-id-type="doi">10.21105/joss.05995</pub-id>
      <fpage>5995</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-flux">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ahn</surname><given-names>Dong H.</given-names></name>
        <name><surname>Garlick</surname><given-names>Jim</given-names></name>
        <name><surname>Grondona</surname><given-names>Mark</given-names></name>
        <name><surname>Lipari</surname><given-names>Don</given-names></name>
        <name><surname>Springmeyer</surname><given-names>Becky</given-names></name>
        <name><surname>Schulz</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Flux: A next-generation resource management framework for large HPC centers</article-title>
      <source>2014 43rd international conference on parallel processing workshops</source>
      <year iso-8601-date="2014">2014</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/ICPPW.2014.15</pub-id>
      <fpage>9</fpage>
      <lpage>17</lpage>
    </element-citation>
  </ref>
  <ref id="ref-mpi4py">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Dalcín</surname><given-names>Lisandro</given-names></name>
        <name><surname>Paz</surname><given-names>Rodrigo</given-names></name>
        <name><surname>Storti</surname><given-names>Mario</given-names></name>
      </person-group>
      <article-title>MPI for Python</article-title>
      <source>Journal of Parallel and Distributed Computing</source>
      <year iso-8601-date="2005">2005</year>
      <volume>65</volume>
      <issue>9</issue>
      <issn>0743-7315</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0743731505000560</uri>
      <pub-id pub-id-type="doi">10.1016/j.jpdc.2005.03.010</pub-id>
      <fpage>1108</fpage>
      <lpage>1115</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
