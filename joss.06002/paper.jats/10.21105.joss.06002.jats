<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6002</article-id>
<article-id pub-id-type="doi">10.21105/joss.06002</article-id>
<title-group>
<article-title>mei-friend: An Interactive Web-based Editor for Digital
Music Encodings</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1722-0718</contrib-id>
<name>
<surname>Goebl</surname>
<given-names>Werner</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1502-1528</contrib-id>
<name>
<surname>Weigl</surname>
<given-names>David M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Music Acoustics – Wiener Klangstil (IWK), mdw
– University of Music and Performing Arts Vienna, Austria</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-05-21">
<day>21</day>
<month>5</month>
<year>2024</year>
</pub-date>
<volume>9</volume>
<issue>98</issue>
<fpage>6002</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>MEI</kwd>
<kwd>Music Encoding Initiative</kwd>
<kwd>Linked Data</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Digital music encodings are machine-readable representations of
  music score documents. Beyond the visual information captured by score
  images or PDFs, music encodings explicitly capture the musical
  semantics of the score. This makes it possible to use them as research
  data objects for musicological analyses
  (<xref alt="Rizo &amp; Marsden, 2019" rid="ref-rizo2019mei" ref-type="bibr">Rizo
  &amp; Marsden, 2019</xref>) and to build digital score interfaces for
  applications in music scholarship, rehearsal, and performance
  (<xref alt="Pugin, 2018" rid="ref-Pugin2018interaction" ref-type="bibr">Pugin,
  2018</xref>).</p>
  <p>mei-friend is a friendly, interactive, browser-based editor for
  music encodings. It opens music encodings in a variety of formats and
  converts these to MEI, the XML-based format developed by the Music
  Encoding Initiative, a community of music scholars, librarians, and
  technologists. Alongside a rich set of interactive editing operations,
  mei-friend offers specialized functionalities targeted at music
  scholars, including panels to display facsimile score images and to
  author score annotations. Collaborative encoding practices are
  supported through integration with GitHub and Solid, and by remote
  configuration capabilities via hyperlink (URL parameters). Important
  MEI community resources are also integrated, supporting direct
  reference to documentation
  (<xref alt="Music Encoding Initiative, 2023" rid="ref-MEI_Guidelines_5" ref-type="bibr">Music
  Encoding Initiative, 2023</xref>) for currently-selected elements, and
  auto-completion and validation using the MEI-XML schema definitions.
  Also provided are curated links to openly-licensed reference music
  encodings.</p>
  <p>The editor targets an audience of music scholars, students,
  librarians, performers, and enthusiasts. It is not conceived as a
  replacement for commercial music notation software, but rather as a
  complement opening up the affordances of machine-readable semantic
  music encodings to a broader audience. Our tool is the only currently
  available editor with comprehensive, native MEI-editing support in
  Common Western Music Notation (CMN). Editing directly in MEI avoids
  conversion errors (due to bugs or inherent differences in supported
  features) from other formats while supporting interactive use of those
  capabilities of the MEI schema that other formats simply do not
  support, such as editorial markup, annotation, and facsimile
  integration.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Music encodings are well-suited for use in digital music research,
  cultural heritage preservation, and music rehearsal and performance
  (<xref alt="Geertinger, 2021" rid="ref-Geertinger_2021" ref-type="bibr">Geertinger,
  2021</xref>). MEI, the family of XML schemas promoted and developed by
  the community of the Music Encoding Initiative, provides a
  comprehensive representation of music semantics, including facilities
  for digital scholarly edition, analytical markup, and capturing
  catalogue-level metadata and source descriptions alongside the music
  content; and supports a variety of notations including tablatures,
  neumes, and mensural notation alongside common western music notation
  (<xref alt="Crawford &amp; Lewis, 2016" rid="ref-Crawford2016music" ref-type="bibr">Crawford
  &amp; Lewis, 2016</xref>). These capabilities set MEI apart for
  scholarly use from less elaborated but more widespread competitors
  such as MusicXML, which, unlike MEI, can be exported by most
  commercial notation software
  (<xref alt="Pugin, 2018" rid="ref-Pugin2018interaction" ref-type="bibr">Pugin,
  2018</xref>). Conversely, its retention of an XML basis, with
  advantages in terms of interoperability and addressability, speaks for
  MEI in favour of other research-focused formats such as Humdrum Kern
  in the context of FAIR data management
  (<xref alt="Weigl et al., 2021" rid="ref-Weigl_etal_EMR2021" ref-type="bibr">Weigl
  et al., 2021</xref>).</p>
  <fig>
    <caption><p>mei-friend interface: MEI encoding of Beethoven’s WoO 57
    (right panel), digital score rendering (top-left panel), and
    associated facsimile image of the source edition (bottom-left
    panel), with the currently selected measure highlighted in each
    modality.<styled-content id="figU003Aexample"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="mei-friend-WoO57-facsimile-3.png" />
  </fig>
  <p>These properties have led to the use of MEI as a de facto encoding
  standard in music scholarship and cultural heritage preservation in
  recent years, as evidenced by its adoption as a recommended
  preservation format for digital scores by the United States Library of
  Congress
  (<xref alt="2019" rid="ref-loc2019mei" ref-type="bibr">2019</xref>).
  However, the relatively scarce availability of high-quality,
  publicly-licensed music encodings remains a limiting factor, and the
  creation of such encodings, particularly at scale, is a high-effort
  activity with a relatively steep learning curve.</p>
  <p>mei-friend is a feature-rich music encoding editor that aims to
  alleviate the difficulty of learning and working with MEI. Initially
  implemented as a plugin for the Atom text editor
  (<xref alt="Goebl &amp; Weigl, 2022" rid="ref-Goebl_Weigl_MEC2021" ref-type="bibr">Goebl
  &amp; Weigl, 2022</xref>), it has been reworked as a
  cross-browser-compatible Web application using vanilla JavaScript,
  with optimised performance and an extended set of features. The
  interface exposes two main panels: an MEI-XML editor
  (<xref alt="[fig:example]" rid="figU003Aexample">[fig:example]</xref>,
  right panel) using CodeMirror 5
  (<xref alt="Haverbeke, 2015" rid="ref-codemirror" ref-type="bibr">Haverbeke,
  2015</xref>) and a panel for digital notation rendered from the
  MEI XML using the Verovio engraving tool
  (<xref alt="Pugin et al., 2014" rid="ref-pugin2014verovio" ref-type="bibr">Pugin
  et al., 2014</xref>) (top-left panel). These panels are interconnected
  such that navigating or selecting elements in one panel causes
  equivalent actions in the other. The application can open several
  different digital notation formats, including MusicXML and Kern,
  converting them to MEI on load. It exports MEI alongside SVG and MIDI
  renderings. Additional conveniences include a PDF-printing interface
  and a built-in MIDI player capable of interactive note-highlighting
  and page-turning during playback.</p>
  <p>The application provides editing functionalities to manipulate and
  insert notation elements, simultaneously updating the MEI-XML and
  digital notation panels with each action. All major functionalities
  are available through both a graphical interface and via keyboard
  shortcuts. Integrations for other Web services are provided, including
  GitHub for versioned encoding storage and access, and the Solid
  platform for Social Linked Data
  (<xref alt="Mansour et al., 2016" rid="ref-Mansour_etal_2016" ref-type="bibr">Mansour
  et al., 2016</xref>). Specialized functionalities supporting music
  scholarship include the display of facsimile score images referenced
  from the music encoding
  (<xref alt="[fig:example]" rid="figU003Aexample">[fig:example]</xref>,
  bottom-left panel), enabling the interactive association of reference
  image regions with encoded score elements; and, an annotation panel
  for authoring different types of score annotation, both within the MEI
  (using the <monospace>&lt;annot&gt;</monospace> element) and as
  stand-off Linked Data using the W3C Web Annotation Data Model and
  associated domain ontologies
  (<xref alt="Lewis et al., 2022" rid="ref-Lewis_DLfM2022" ref-type="bibr">Lewis
  et al., 2022</xref>). By exposing several internal variables as URL
  parameters, such as the encoding file URL, various layout and display
  settings, and the XML identifiers of elements to be preselected on
  load, mei-friend can be remotely configured via hyperlinks which can
  be distributed among collaborating users; an important feature for
  pedagogical and crowd-sourcing applications.</p>
  <p>The official application instance, available at
  <ext-link ext-link-type="uri" xlink:href="https://mei-friend.mdw.ac.at/">https://mei-friend.mdw.ac.at/</ext-link>,
  is sustainably hosted within the institutional repository of the
  <italic>mdw</italic> – University of Music and Performing Arts Vienna.
  The code base is licensed under the AGPL 3.0 open-source license and
  is published at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/mei-friend/mei-friend/">https://github.com/mei-friend/mei-friend/</ext-link>.
  Development of the editor and its comprehensive documentation,
  available
  <ext-link ext-link-type="uri" xlink:href="https://mei-friend.github.io/">https://mei-friend.github.io/</ext-link>,
  is ongoing, with feature proposals, bug reports, and code
  contributions provided by community members. The editor’s user
  interface is available in a growing number of languages, thus
  applicable for use in international contexts.</p>
  <p>The mei-friend development process operates over four distinct
  environments: <italic>production</italic>, served from the
  <monospace>main</monospace> branch of the mei-friend code repository;
  <italic>staging</italic>, served from the
  <monospace>staging</monospace> branch and accessible for public
  verification at
  <ext-link ext-link-type="uri" xlink:href="https://staging.mei-friend.mdw.ac.at">https://staging.mei-friend.mdw.ac.at</ext-link>
  before release; <italic>testing</italic>, served from the
  <monospace>testing</monospace> branch and used to coordinate the
  development of contributions by community members at
  <ext-link ext-link-type="uri" xlink:href="https://testing.mei-friend.mdw.ac.at">https://testing.mei-friend.mdw.ac.at</ext-link>;
  and <italic>develop</italic>, served from the
  <monospace>develop</monospace> branch. The application adjusts to its
  environment context, running tests when in <italic>develop</italic>
  and altering the logo to alert users when in <italic>staging</italic>
  or <italic>testing</italic>.</p>
  <p>The editor has seen significant and growing adoption by the MEI
  community, currently receiving more than six hundred distinct visitor
  sessions each month on its hosted instance. The predecessor Atom
  plugin was reviewed as part of editorial work for the <italic>Digital
  Interactive Mozart Edition</italic>
  (<xref alt="Sapov, 2022" rid="ref-Sapov_2022" ref-type="bibr">Sapov,
  2022</xref>) and used to edit a large collection of Beethoven
  solo-piano pieces
  (<xref alt="Weigl et al., 2019" rid="ref-weigl2019interweaving" ref-type="bibr">Weigl
  et al., 2019</xref>). The Web application is central to ongoing
  Digital Musicology research projects analysing and comparing
  orchestral performances aligned with digital score encodings
  (<xref alt="Weigl et al., 2023" rid="ref-Weigl_etal_DLfM2023" ref-type="bibr">Weigl
  et al., 2023</xref>) and establishing a digital edition of German lute
  tablatures of the 15th and 16th centuries
  (<xref alt="de Valk et al., 2023" rid="ref-elaute2023mec" ref-type="bibr">de
  Valk et al., 2023</xref>). A further community-based project is
  underway to extend mei-friend’s support for scholarly edition and
  markup activities
  (<xref alt="Plaksin, 2023" rid="ref-Plaksin_DLfM2023" ref-type="bibr">Plaksin,
  2023</xref>). mei-friend has been used to teach music encoding at
  universities in Boston, Vienna, and Würzburg; academic events,
  including the Digital Humanities @ Oxford Summer School and the
  <italic>Semana HD</italic> organized by South American Digital
  Humanities associations; and conferences, including the <italic>Music
  Encoding Conference</italic> (MEC), the <italic>Medieval and
  Renaissance Music Conference</italic> (MedRen), and the
  <italic>Extended Semantic Web Conference</italic> (ESWC).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge support from the Austrian Science Fund (FWF) through
  the projects “Signature Sound Vienna” P34664 and “E-LAUTE” I6019, and
  from the European Commission via the research and innovation action EU
  H2020 TROMPA – Towards Richer Online Music Public-domain Archives,
  grant no. 770376. Extensions for scholarly markup by Anna Plaksin are
  funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
  Foundation) under the National Research Data Infrastructure –
  441958017. We are grateful for contributions by members of the MEI
  community including Laurent Pugin, Thomas Weber, and many others.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Goebl_Weigl_MEC2021">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Goebl</surname><given-names>Werner</given-names></name>
        <name><surname>Weigl</surname><given-names>David M.</given-names></name>
      </person-group>
      <article-title>Alleviating the last mile of encoding: The mei-friend package for the Atom text editor</article-title>
      <source>Music Encoding Conference Proceedings 2021</source>
      <person-group person-group-type="editor">
        <name><surname>Münnich</surname><given-names>Stefan</given-names></name>
        <name><surname>Rizo</surname><given-names>David</given-names></name>
      </person-group>
      <publisher-name>University of Alicante</publisher-name>
      <publisher-loc>Allicante, Spain</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.17613/fc1c-mx52</pub-id>
      <fpage>31</fpage>
      <lpage>39</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Weigl_etal_EMR2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weigl</surname><given-names>David M.</given-names></name>
        <name><surname>Crawford</surname><given-names>Tim</given-names></name>
        <name><surname>Gkiokas</surname><given-names>Aggelos</given-names></name>
        <name><surname>Goebl</surname><given-names>Werner</given-names></name>
        <name><surname>Gómez</surname><given-names>Emilia</given-names></name>
        <name><surname>Gutierrez</surname><given-names>Nicolas F.</given-names></name>
        <name><surname>Liem</surname><given-names>Cynthia C. S.</given-names></name>
        <name><surname>Santos</surname><given-names>Patricia</given-names></name>
      </person-group>
      <article-title>FAIR interconnection and enrichment of public-domain music resources on the Web</article-title>
      <source>Empirical Musicology Review</source>
      <year iso-8601-date="2021">2021</year>
      <volume>16</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18061/emr.v16i1.7643</pub-id>
      <fpage>16</fpage>
      <lpage>33</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Weigl_etal_DLfM2023">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Weigl</surname><given-names>David M.</given-names></name>
        <name><surname>VanderHart</surname><given-names>Chanda</given-names></name>
        <name><surname>Rammler</surname><given-names>Delilah</given-names></name>
        <name><surname>Pescoller</surname><given-names>Matthäus</given-names></name>
        <name><surname>Goebl</surname><given-names>Werner</given-names></name>
      </person-group>
      <article-title>Listen Here! A Web-native digital musicology environment for machine-assisted close listening</article-title>
      <source>Proceedings of the 10th international conference on digital libraries for musicology (DLfM’23)</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>9798400708336</isbn>
      <uri>https://doi.org/10.1145/3625135.3625144</uri>
      <pub-id pub-id-type="doi">10.1145/3625135.3625144</pub-id>
      <fpage>109</fpage>
      <lpage>118</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Crawford2016music">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Crawford</surname><given-names>Tim</given-names></name>
        <name><surname>Lewis</surname><given-names>Richard</given-names></name>
      </person-group>
      <article-title>Music Encoding Initiative (Digital and Multimedia Scholarship)</article-title>
      <source>Journal of the American Musicological Society</source>
      <year iso-8601-date="2016">2016</year>
      <volume>69</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1525/JAMS.2016.69.1.273</pub-id>
      <fpage>273</fpage>
      <lpage>285</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Pugin2018interaction">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Pugin</surname><given-names>Laurent</given-names></name>
      </person-group>
      <article-title>Interaction perspectives for music notation applications</article-title>
      <source>SAAM’18: Proc. of the 1st Int. Workshop on Semantic Applications for Audio and Music</source>
      <publisher-name>Association for Computing Machinery Press</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1145/3243907.3243911</pub-id>
      <fpage>54</fpage>
      <lpage>58</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pugin2014verovio">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pugin</surname><given-names>Laurent</given-names></name>
        <name><surname>Zitellini</surname><given-names>Rodolfo</given-names></name>
        <name><surname>Roland</surname><given-names>Perry</given-names></name>
      </person-group>
      <article-title>Verovio: A library for engraving MEI music notation into SVG</article-title>
      <source>Proc. of the 15th Int. Society for Music Information Retrieval Conference (ISMIR 2014)</source>
      <year iso-8601-date="2014">2014</year>
      <uri>https://archives.ismir.net/ismir2014/paper/000221.pdf</uri>
      <fpage>107</fpage>
      <lpage>112</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rizo2019mei">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rizo</surname><given-names>David</given-names></name>
        <name><surname>Marsden</surname><given-names>Alan</given-names></name>
      </person-group>
      <article-title>An MEI-based standard encoding for hierarchical music analyses</article-title>
      <source>International Journal on Digital Libraries</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>20</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1007/s00799-018-0262-x</pub-id>
      <fpage>93</fpage>
      <lpage>105</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Geertinger_2021">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Geertinger</surname><given-names>Axel Teich</given-names></name>
      </person-group>
      <article-title>Digital encoding of music notation with MEI</article-title>
      <source>Notated music in the digital sphere. Possibilities and limitations</source>
      <person-group person-group-type="editor">
        <name><surname>Støkken Bue</surname><given-names>Margrethe</given-names></name>
        <name><surname>Rockenberger</surname><given-names>Annika</given-names></name>
      </person-group>
      <publisher-name>National Library of Norway</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>15</volume>
      <uri>https://issuu.com/nasjonalbiblioteket/docs/nota_bene_15_layout_issuu/35</uri>
      <fpage>35</fpage>
      <lpage>56</lpage>
    </element-citation>
  </ref>
  <ref id="ref-loc2019mei">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>United States Library of Congress</string-name>
      </person-group>
      <article-title>Music Encoding Initiative (MEI) format family</article-title>
      <publisher-name>https://www.loc.gov/preservation/digital/formats/fdd/fdd000502.shtml</publisher-name>
      <year iso-8601-date="2019-05">2019</year><month>05</month>
    </element-citation>
  </ref>
  <ref id="ref-codemirror">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Haverbeke</surname><given-names>Marijn</given-names></name>
      </person-group>
      <article-title>CodeMirror, version 5</article-title>
      <publisher-name>https://github.com/codemirror/codemirror5</publisher-name>
      <year iso-8601-date="2015">2015</year>
    </element-citation>
  </ref>
  <ref id="ref-Plaksin_DLfM2023">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Plaksin</surname><given-names>Anna</given-names></name>
      </person-group>
      <article-title>Understanding the needs of music editors in a digital world. Adding support for editorial markup to the mei-friend editor</article-title>
      <source>Proc. of the 10th int. Conference on digital libraries for musicology (DLfM’23)</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>9798400708336</isbn>
      <pub-id pub-id-type="doi">10.1145/3625135.3625149</pub-id>
      <fpage>40</fpage>
      <lpage>48</lpage>
    </element-citation>
  </ref>
  <ref id="ref-MEI_Guidelines_5">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Music Encoding Initiative</string-name>
      </person-group>
      <article-title>MEI Guidelines (5.0.0)</article-title>
      <publisher-name>https://music-encoding.org/guidelines/v5/</publisher-name>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-Lewis_DLfM2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Lewis</surname><given-names>David</given-names></name>
        <name><surname>Shibata</surname><given-names>Elisabete</given-names></name>
        <name><surname>Saccomano</surname><given-names>Mark</given-names></name>
        <name><surname>Rosendahl</surname><given-names>Lisa</given-names></name>
        <name><surname>Kepper</surname><given-names>Johannes</given-names></name>
        <name><surname>Hankinson</surname><given-names>Andrew</given-names></name>
        <name><surname>Siegert</surname><given-names>Christine</given-names></name>
        <name><surname>Page</surname><given-names>Kevin</given-names></name>
      </person-group>
      <article-title>A model for annotating musical versions and arrangements across multiple documents and media</article-title>
      <source>Proceedings of the 9th international conference on digital libraries for musicology (DLfM’22)</source>
      <publisher-name>Association for Computing Machinery</publisher-name>
      <publisher-loc>New York, NY, USA</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <isbn>9781450396684</isbn>
      <pub-id pub-id-type="doi">10.1145/3543882.3543891</pub-id>
      <fpage>10</fpage>
      <lpage>18</lpage>
    </element-citation>
  </ref>
  <ref id="ref-weigl2019interweaving">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Weigl</surname><given-names>David M.</given-names></name>
        <name><surname>Goebl</surname><given-names>Werner</given-names></name>
        <name><surname>Crawford</surname><given-names>Tim</given-names></name>
        <name><surname>Gkiokas</surname><given-names>Aggelos</given-names></name>
        <name><surname>F. Gutierrez</surname><given-names>Nicolas</given-names></name>
        <name><surname>Porter</surname><given-names>Alastair</given-names></name>
        <name><surname>Santos</surname><given-names>Patricia</given-names></name>
        <name><surname>Karreman</surname><given-names>Casper</given-names></name>
        <name><surname>Vroomen</surname><given-names>Ingmar</given-names></name>
        <name><surname>CS Liem</surname><given-names>Cynthia</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Interweaving and enriching digital music collections for scholarship, performance, and enjoyment</article-title>
      <source>Proceedings of the 6th international conference on digital libraries for musicology (DLfM’19)</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.1145/3358664.3358666</pub-id>
      <fpage>84</fpage>
      <lpage>88</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Mansour_etal_2016">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mansour</surname><given-names>Essam</given-names></name>
        <name><surname>Sambra</surname><given-names>Andrei Vlad</given-names></name>
        <name><surname>Hawke</surname><given-names>Sandro</given-names></name>
        <name><surname>Zereba</surname><given-names>Maged</given-names></name>
        <name><surname>Capadisli</surname><given-names>Sarven</given-names></name>
        <name><surname>Ghanem</surname><given-names>Abdurrahman</given-names></name>
        <name><surname>Aboulnaga</surname><given-names>Ashraf</given-names></name>
        <name><surname>Berners-Lee</surname><given-names>Tim</given-names></name>
      </person-group>
      <article-title>A demonstration of the Solid platform for social Web applications</article-title>
      <source>Proceedings of the 25th international conference companion on world wide web</source>
      <publisher-name>International World Wide Web Conferences Steering Committee</publisher-name>
      <publisher-loc>Republic; Canton of Geneva, CHE</publisher-loc>
      <year iso-8601-date="2016">2016</year>
      <isbn>9781450341448</isbn>
      <uri>https://doi.org/10.1145/2872518.2890529</uri>
      <pub-id pub-id-type="doi">10.1145/2872518.2890529</pub-id>
      <fpage>223</fpage>
      <lpage>226</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Sapov_2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sapov</surname><given-names>Oleksii</given-names></name>
      </person-group>
      <article-title>mei-friend. A viewer and last-mile editor for MEI score encodings</article-title>
      <source>RIDE – A review journal for digital editions and resources</source>
      <year iso-8601-date="2022">2022</year>
      <volume>15</volume>
      <pub-id pub-id-type="doi">10.18716/ride.a.15.2</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-elaute2023mec">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>de Valk</surname><given-names>Reinier</given-names></name>
        <name><surname>Schöning</surname><given-names>Kateryna</given-names></name>
        <name><surname>Weigl</surname><given-names>David M.</given-names></name>
        <name><surname>Lewis</surname><given-names>David</given-names></name>
        <name><surname>Crawford</surname><given-names>Tim</given-names></name>
        <name><surname>Lewon</surname><given-names>Marc</given-names></name>
        <name><surname>Overell</surname><given-names>Paul</given-names></name>
      </person-group>
      <article-title>“Ain schone kunstliche Underweisung”: Modelling German lute tablature in MEI</article-title>
      <source>Encoding Cultures: Joint MEC and TEI Conference 2023 Abstracts</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://teimec2023.uni-paderborn.de/contributions/188.html</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
