<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8858</article-id>
<article-id pub-id-type="doi">10.21105/joss.08858</article-id>
<title-group>
<article-title>PyMilo: A Python Library for ML I/O</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0000-0638-2263</contrib-id>
<name>
<surname>Rostami</surname>
<given-names>AmirHosein</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9450-2375</contrib-id>
<name>
<surname>Haghighi</surname>
<given-names>Sepand</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1047-2346</contrib-id>
<name>
<surname>Sabouri</surname>
<given-names>Sadra</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2367-8343</contrib-id>
<name>
<surname>Zolanvari</surname>
<given-names>Alireza</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Open Science Lab</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>University of Toronto, Toronto, Canada</institution>
<institution-id institution-id-type="ROR">03dbr7087</institution-id>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of Southern California, Los Angeles, United
States</institution>
<institution-id institution-id-type="ROR">03taz7m60</institution-id>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-06-24">
<day>24</day>
<month>6</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>116</issue>
<fpage>8858</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Machine Learning</kwd>
<kwd>Model Deployment</kwd>
<kwd>Model Serialization</kwd>
<kwd>Transparency</kwd>
<kwd>MLOPS</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>PyMilo is an open-source Python package that addresses the
  limitations of existing machine learning (ML) model storage formats by
  providing a transparent, reliable, end-to-end, and safe method for
  exporting and deploying trained models. Current tools rely on
  black-box or executable formats that obscure internal model
  structures, making them difficult to audit, verify, or safely share.
  Meanwhile, tensor-centric formats such as Safetensors
  (<xref alt="Hugging Face, 2025" rid="ref-huggingface_safetensors_2022" ref-type="bibr">Hugging
  Face, 2025</xref>) securely store and transfer numerical tensors but
  do not capture the internal and structural composition of classical
  machine-learning models (e.g., scikit-learn pipelines), which remain
  PyMilo’s primary focus. Others apply structural transformations during
  export that may degrade predictive performance and reduce the model to
  a limited inference-only interface. In contrast, PyMilo serializes
  models in a transparent human-readable format that preserves
  end-to-end model fidelity and enables reliable, safe, and
  interpretable exchange. Here, transparent refers to the ability to
  inspect model internals through a human-readable structure without
  execution, and end-to-end fidelity denotes that a model exported and
  re-imported with PyMilo retains the exact same signature,
  functionality, parameters, and internal structure as the original,
  ensuring complete behavioral and structural equivalence. This package
  is designed to make the preservation and reuse of trained ML models
  safer, more interpretable, and easier to manage across different
  stages of the ML workflow
  (<xref alt="[fig:overall]" rid="figU003Aoverall">[fig:overall]</xref>).</p>
  <fig>
    <caption><p>PyMilo is an end-to-end, transparent, and safe solution
    for transporting models from machine learning frameworks to the
    target devices. PyMilo preserves the original model’s structure
    while transferring, allowing it to be imported back as the exact
    same object in its native framework. Currently, PyMilo (v1.4)
    supports models built with scikit-learn. Support for PyTorch and
    TensorFlow is planned in upcoming
    releases.<styled-content id="figU003Aoverall"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="pymilo_outlook.png" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Modern machine learning development is largely centered around the
  Python ecosystem, which has become a dominant platform for building
  and training models due to its rich libraries and community support
  (<xref alt="Raschka et al., 2020" rid="ref-Raschka2020" ref-type="bibr">Raschka
  et al., 2020</xref>). However, once a model is trained, sharing or
  deploying it securely and transparently remains a significant
  challenge
  (<xref alt="Davis et al., 2023" rid="ref-davis2023reusing" ref-type="bibr">Davis
  et al., 2023</xref>;
  <xref alt="Parida et al., 2025" rid="ref-parida2025model" ref-type="bibr">Parida
  et al., 2025</xref>). This issue is especially important in
  high-stakes domains such as healthcare, where ensuring model
  accountability and integrity is critical
  (<xref alt="Garbin &amp; Marques, 2022" rid="ref-Garbin2022" ref-type="bibr">Garbin
  &amp; Marques, 2022</xref>). In such settings, any lack of clarity
  about a model’s internal logic or origin can reduce trust in its
  predictions. Researchers have increasingly emphasized that greater
  transparency in AI systems is critical for maintaining user trust and
  protecting privacy in machine learning applications
  (<xref alt="Bodimani, 2024" rid="ref-bodimani2024assessing" ref-type="bibr">Bodimani,
  2024</xref>).</p>
  <p>Despite ongoing concerns around transparency and safety, the
  dominant approach for exchanging pretrained models remains ad hoc
  binary serialization, most commonly through Python’s
  <monospace>pickle</monospace> module or its variant
  <monospace>joblib</monospace>. These formats allow developers to store
  complex model objects with minimal effort, but they were never
  designed with security or human interpretability in mind
  (<xref alt="Parida et al., 2025" rid="ref-parida2025model" ref-type="bibr">Parida
  et al., 2025</xref>). In fact, loading a pickle file may execute
  arbitrary code contained within it, a known vulnerability that can be
  exploited if the file is maliciously crafted
  (<xref alt="Brownlee, 2018" rid="ref-Brownlee2018" ref-type="bibr">Brownlee,
  2018</xref>;
  <xref alt="Python Software Foundation, 2024" rid="ref-PythonPickleDocs" ref-type="bibr">Python
  Software Foundation, 2024</xref>). While these methods preserve full
  model fidelity within the Python ecosystem, they pose serious security
  risks and lack transparency, as the serialized files are opaque binary
  blobs that cannot be inspected without loading. Furthermore,
  compatibility is fragile because pickled models often depend on
  specific library versions, which may hinder long-term reproducibility
  (<xref alt="Brownlee, 2018" rid="ref-Brownlee2018" ref-type="bibr">Brownlee,
  2018</xref>).</p>
  <p>To improve portability across environments, several standardized
  model interchange formats have been developed alongside
  <monospace>pickle</monospace>. Most notably, Open Neural Network
  Exchange (ONNX) and Predictive Model Markup Language (PMML) convert
  trained models into framework-agnostic representations
  (<xref alt="Bai et al., 2025" rid="ref-onnx" ref-type="bibr">Bai et
  al., 2025</xref>;
  <xref alt="Guazzelli et al., 2009" rid="ref-pmml" ref-type="bibr">Guazzelli
  et al., 2009</xref>), enabling deployment in diverse systems without
  relying on the original training code. ONNX uses a graph-based
  structure built from primitive operators (e.g., linear transforms,
  activations), while PMML provides an XML-based specification for
  traditional models like decision trees and regressions.</p>
  <p>Although these formats enhance security by avoiding executable
  serialization, they introduce compatibility and fidelity challenges.
  Exporting complex pipelines to ONNX or PMML often leads to structural
  approximations, missing metadata, or unsupported components,
  especially for customized models
  (<xref alt="Guazzelli et al., 2009" rid="ref-pmml" ref-type="bibr">Guazzelli
  et al., 2009</xref>). As a result, the exported model may differ in
  behavior, resulting in performance degradation or loss of accuracy
  (<xref alt="Jajal et al., 2023" rid="ref-jajal2023analysis" ref-type="bibr">Jajal
  et al., 2023</xref>). Jajal et al.
  (<xref alt="2023" rid="ref-jajal2023analysis" ref-type="bibr">2023</xref>)
  found that models exported to ONNX can produce incorrect predictions
  despite successful conversion, indicating semantic inconsistencies
  between the original and exported versions. This reflects predictive
  performance degradation and highlights the risks of silent behavioral
  drift in deployed systems.</p>
  <p>Beyond concerns about end-to-end model preservation, ONNX and PMML
  also present limitations in transparency, scope, and reversibility.
  ONNX uses a binary protocol buffer format that is not human-readable,
  which limits interpretability and makes auditing difficult. PMML,
  although XML-based and readable, is verbose and narrowly scoped,
  supporting only a limited subset of scikit-learn models. As noted by
  Cody et al.
  (<xref alt="2024" rid="ref-cody2024extending" ref-type="bibr">2024</xref>),
  both ONNX and PMML focus on static model specification rather than
  operational testing or lifecycle validation workflows. Moreover, PMML
  does not provide a mechanism to restore exported models into Python,
  making it a one-way format that limits reproducibility across ML
  workflows.</p>
  <p>Other tools have been developed to address specific use cases,
  though they remain limited in scope. For example, SKOPS improves the
  safety of scikit-learn model storage by enabling limited inspection of
  model internals without requiring code execution
  (<xref alt="skops-dev, 2024" rid="ref-skops" ref-type="bibr">skops-dev,
  2024</xref>). However, it supports only scikit-learn models, lacks
  compatibility with other frameworks, and does not provide a fully
  transparent or human-readable structure. TensorFlow.js targets
  JavaScript environments by converting TensorFlow or Keras models into
  a JSON configuration file and binary weight files for execution in the
  browser or Node.js
  (<xref alt="Smilkov et al., 2019" rid="ref-tfjs2019" ref-type="bibr">Smilkov
  et al., 2019</xref>). However, this process has been shown to
  introduce compatibility issues, performance degradation, and
  inconsistencies in inference behavior due to backend limitations and
  environment-specific faults
  (<xref alt="Quan et al., 2022" rid="ref-quan2022towards" ref-type="bibr">Quan
  et al., 2022</xref>). Models from other frameworks, such as
  scikit-learn or PyTorch, must be re-implemented or retrained in
  TensorFlow to be exported. Additionally, running complex models in
  JavaScript runtimes introduces memory and performance limitations,
  often making the deployment of large neural networks prohibitively
  slow or even infeasible in browser environments
  (<xref alt="Nerd Corner, 2025" rid="ref-NerdCorner2025" ref-type="bibr">Nerd
  Corner, 2025</xref>).</p>
  <p>In summary, current solutions force practitioners into trade-offs
  between security, transparency, end-to-end fidelity, and performance
  preservation. The machine learning community still lacks a safe and
  transparent end-to-end model serialization framework through which
  users can securely share models, inspect them easily, and accurately
  reconstruct them for use across diverse frameworks and
  environments.</p>
  <p>PyMilo is proposed to address the above gaps. It is an open-source
  Python library that provides an end-to-end solution for exporting and
  importing machine learning models in a safe, non-executable, and
  human-readable format such as JSON. PyMilo serializes trained models
  into a transparent format and fully reconstructs them without
  structural changes, preserving their original functionality and
  behavior. This process does not affect inference time or performance
  and imports models on any target device without additional
  dependencies, enabling seamless execution in inference mode. While
  PyMilo may import functions from widely used scientific libraries
  during deserialization to restore model behavior (for example, NumPy
  or SciPy), the JSON representation itself never contains executable
  code; any remaining security risk is therefore inherited from these
  already-trusted dependencies rather than introduced by PyMilo’s
  serialization mechanism. PyMilo benefits a wide range of stakeholders,
  including machine learning engineers, data scientists, and AI
  practitioners, by facilitating the development of more transparent and
  accountable AI systems. Furthermore, researchers working on
  transparent AI
  (<xref alt="Räuker et al., 2023" rid="ref-rauker2023toward" ref-type="bibr">Räuker
  et al., 2023</xref>), user privacy in ML
  (<xref alt="Bodimani, 2024" rid="ref-bodimani2024assessing" ref-type="bibr">Bodimani,
  2024</xref>), and safe AI
  (<xref alt="Macrae, 2019" rid="ref-macrae2019governing" ref-type="bibr">Macrae,
  2019</xref>) can use PyMilo as a framework that provides transparency
  and safety in the machine learning environment.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-Raschka2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Raschka</surname><given-names>Sebastian</given-names></name>
        <name><surname>Patterson</surname><given-names>Joshua</given-names></name>
        <name><surname>Nolet</surname><given-names>Corey</given-names></name>
      </person-group>
      <article-title>Machine learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence</article-title>
      <source>Information</source>
      <year iso-8601-date="2020">2020</year>
      <volume>11</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.3390/info11040193</pub-id>
      <fpage>193</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-parida2025model">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Parida</surname><given-names>Shreyas Kumar</given-names></name>
        <name><surname>Gerostathopoulos</surname><given-names>Ilias</given-names></name>
        <name><surname>Bogner</surname><given-names>Justus</given-names></name>
      </person-group>
      <article-title>How do model export formats impact the development of ML-enabled systems? A case study on model integration</article-title>
      <source>2025 IEEE/ACM 4th international conference on AI engineering – software engineering for AI (CAIN)</source>
      <year iso-8601-date="2025">2025</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/CAIN66642.2025.00014</pub-id>
      <fpage>48</fpage>
      <lpage>59</lpage>
    </element-citation>
  </ref>
  <ref id="ref-davis2023reusing">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Davis</surname><given-names>James C</given-names></name>
        <name><surname>Jajal</surname><given-names>Purvish</given-names></name>
        <name><surname>Jiang</surname><given-names>Wenxin</given-names></name>
        <name><surname>Schorlemmer</surname><given-names>Taylor R</given-names></name>
        <name><surname>Synovic</surname><given-names>Nicholas</given-names></name>
        <name><surname>Thiruvathukal</surname><given-names>George K</given-names></name>
      </person-group>
      <article-title>Reusing deep learning models: Challenges and directions in software engineering</article-title>
      <source>2023 IEEE john vincent atanasoff international symposium on modern computing (JVA)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/JVA60410.2023.00015</pub-id>
      <fpage>17</fpage>
      <lpage>30</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Garbin2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Garbin</surname><given-names>Cristina</given-names></name>
        <name><surname>Marques</surname><given-names>Osvaldo</given-names></name>
      </person-group>
      <article-title>Assessing methods and tools to improve reporting, increase transparency, and reduce failures in machine learning applications in health care</article-title>
      <source>Radiology: Artificial Intelligence</source>
      <year iso-8601-date="2022">2022</year>
      <volume>4</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1148/ryai.210127</pub-id>
      <fpage>e210127</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-bodimani2024assessing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bodimani</surname><given-names>Meghasai</given-names></name>
      </person-group>
      <article-title>Assessing the impact of transparent AI systems in enhancing user trust and privacy</article-title>
      <source>Journal of Science &amp; Technology</source>
      <year iso-8601-date="2024">2024</year>
      <volume>5</volume>
      <issue>1</issue>
      <uri>https://thesciencebrigade.com/jst/article/view/68</uri>
      <fpage>50</fpage>
      <lpage>67</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Brownlee2018">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Brownlee</surname><given-names>Jason</given-names></name>
      </person-group>
      <article-title>Save and load machine learning models in Python with scikit-learn</article-title>
      <publisher-name>https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/</publisher-name>
      <year iso-8601-date="2018">2018</year>
    </element-citation>
  </ref>
  <ref id="ref-PythonPickleDocs">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Python Software Foundation</string-name>
      </person-group>
      <article-title>pickle — Python object serialization</article-title>
      <publisher-name>https://docs.python.org/3/library/pickle.html#security</publisher-name>
      <year iso-8601-date="2024">2024</year>
    </element-citation>
  </ref>
  <ref id="ref-onnx">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bai</surname><given-names>Junjie</given-names></name>
        <name><surname>Lu</surname><given-names>Fang</given-names></name>
        <name><surname>Zhang</surname><given-names>Ke</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>ONNX (Open Neural Network Exchange)</article-title>
      <year iso-8601-date="2025-05-12">2025</year><month>05</month><day>12</day>
      <uri>https://github.com/onnx/onnx</uri>
    </element-citation>
  </ref>
  <ref id="ref-pmml">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Guazzelli</surname><given-names>Alex</given-names></name>
        <name><surname>Zeller</surname><given-names>Michael</given-names></name>
        <name><surname>Lin</surname><given-names>Wen-Ching</given-names></name>
        <name><surname>Williams</surname><given-names>Graham</given-names></name>
      </person-group>
      <article-title>PMML: An open standard for sharing models</article-title>
      <year iso-8601-date="2009">2009</year>
      <pub-id pub-id-type="doi">10.32614/RJ-2009-010</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jajal2023analysis">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jajal</surname><given-names>Purvish</given-names></name>
        <name><surname>Jiang</surname><given-names>Wenxin</given-names></name>
        <name><surname>Tewari</surname><given-names>Arav</given-names></name>
        <name><surname>Kocinare</surname><given-names>Erik</given-names></name>
        <name><surname>Woo</surname><given-names>Joseph</given-names></name>
        <name><surname>Sarraf</surname><given-names>Anusha</given-names></name>
        <name><surname>Lu</surname><given-names>Yung-Hsiang</given-names></name>
        <name><surname>Thiruvathukal</surname><given-names>George K</given-names></name>
        <name><surname>Davis</surname><given-names>James C</given-names></name>
      </person-group>
      <article-title>Analysis of failures and risks in deep learning model converters: A case study in the ONNX ecosystem</article-title>
      <source>arXiv preprint arXiv:2303.17708</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2303.17708</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-cody2024extending">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cody</surname><given-names>Tyler</given-names></name>
        <name><surname>Li</surname><given-names>Bingtong</given-names></name>
        <name><surname>Beling</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>On extending the Automatic Test Markup Language (ATML) for machine learning</article-title>
      <source>2024 IEEE international systems conference (SysCon)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1109/SysCon61195.2024.10553464</pub-id>
      <fpage>1</fpage>
      <lpage>8</lpage>
    </element-citation>
  </ref>
  <ref id="ref-skops">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>skops-dev</string-name>
      </person-group>
      <article-title>SKOPS</article-title>
      <year iso-8601-date="2024-12-10">2024</year><month>12</month><day>10</day>
      <uri>https://github.com/skops-dev/skops</uri>
    </element-citation>
  </ref>
  <ref id="ref-tfjs2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Smilkov</surname><given-names>Daniel</given-names></name>
        <name><surname>Thorat</surname><given-names>Nikhil</given-names></name>
        <name><surname>Assogba</surname><given-names>Yannick</given-names></name>
        <name><surname>Nicholson</surname><given-names>Charles</given-names></name>
        <name><surname>Kreeger</surname><given-names>Nick</given-names></name>
        <name><surname>Yu</surname><given-names>Ping</given-names></name>
        <name><surname>Cai</surname><given-names>Shanqing</given-names></name>
        <name><surname>Nielsen</surname><given-names>Eric</given-names></name>
        <name><surname>Soegel</surname><given-names>David</given-names></name>
        <name><surname>Bileschi</surname><given-names>Stan</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>TensorFlow.js: Machine learning for the web and beyond</article-title>
      <source>Proceedings of Machine Learning and Systems</source>
      <year iso-8601-date="2019">2019</year>
      <volume>1</volume>
      <pub-id pub-id-type="doi">10.48550/arXiv.1901.05350</pub-id>
      <fpage>309</fpage>
      <lpage>321</lpage>
    </element-citation>
  </ref>
  <ref id="ref-quan2022towards">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Quan</surname><given-names>Lili</given-names></name>
        <name><surname>Guo</surname><given-names>Qianyu</given-names></name>
        <name><surname>Xie</surname><given-names>Xiaofei</given-names></name>
        <name><surname>Chen</surname><given-names>Sen</given-names></name>
        <name><surname>Li</surname><given-names>Xiaohong</given-names></name>
        <name><surname>Liu</surname><given-names>Yang</given-names></name>
      </person-group>
      <article-title>Towards understanding the faults of JavaScript-based deep learning systems</article-title>
      <source>Proceedings of the 37th IEEE/ACM international conference on automated software engineering</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1145/3551349.3560427</pub-id>
      <fpage>1</fpage>
      <lpage>13</lpage>
    </element-citation>
  </ref>
  <ref id="ref-NerdCorner2025">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Nerd Corner</string-name>
      </person-group>
      <article-title>TensorFlow.js vs TensorFlow (Python)</article-title>
      <publisher-name>https://nerd-corner.com/tensorflow-js-vs-tensorflow-python/</publisher-name>
      <year iso-8601-date="2025-03">2025</year><month>03</month>
    </element-citation>
  </ref>
  <ref id="ref-rauker2023toward">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Räuker</surname><given-names>Tilman</given-names></name>
        <name><surname>Ho</surname><given-names>Anson</given-names></name>
        <name><surname>Casper</surname><given-names>Stephen</given-names></name>
        <name><surname>Hadfield-Menell</surname><given-names>Dylan</given-names></name>
      </person-group>
      <article-title>Toward transparent AI: A survey on interpreting the inner structures of deep neural networks</article-title>
      <source>2023 ieee conference on secure and trustworthy machine learning (satml)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1109/SaTML54575.2023.00039</pub-id>
      <fpage>464</fpage>
      <lpage>483</lpage>
    </element-citation>
  </ref>
  <ref id="ref-macrae2019governing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Macrae</surname><given-names>Carl</given-names></name>
      </person-group>
      <article-title>Governing the safety of artificial intelligence in healthcare</article-title>
      <source>BMJ quality &amp; safety</source>
      <publisher-name>BMJ Publishing Group Ltd</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>28</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1136/bmjqs-2019-009484</pub-id>
      <fpage>495</fpage>
      <lpage>498</lpage>
    </element-citation>
  </ref>
  <ref id="ref-huggingface_safetensors_2022">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <string-name>Hugging Face</string-name>
      </person-group>
      <article-title>Safetensors - ML safer for all</article-title>
      <year iso-8601-date="2025">2025</year>
      <uri>https://github.com/huggingface/safetensors</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
