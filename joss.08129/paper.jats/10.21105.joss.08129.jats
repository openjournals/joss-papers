<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8129</article-id>
<article-id pub-id-type="doi">10.21105/joss.08129</article-id>
<title-group>
<article-title>ginjax: E(d)-Equivariant CNN for Tensor
Images</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5511-0683</contrib-id>
<name>
<surname>Gregory</surname>
<given-names>Wilson G.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8432-7788</contrib-id>
<name>
<surname>Wong</surname>
<given-names>Kaze W. K.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2866-9403</contrib-id>
<name>
<surname>Hogg</surname>
<given-names>David W.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4968-3829</contrib-id>
<name>
<surname>Villar</surname>
<given-names>Soledad</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-6"/>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Applied Mathematics and Statistics, Johns
Hopkins University, Baltimore, MD, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Data Science and AI Institute, Johns Hopkins University,
Baltimore, MD, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Center for Cosmology and Particle Physics, Department of
Physics, New York University, New York, NY, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Max-Planck-Institut für Astronomie, Heidelberg,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Center for Computational Astrophysics, Flatiron Institute,
New York, NY, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Center for Computational Mathematics, Flatiron Institute,
New York, NY, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Mathematical Institute for Data Science, Johns Hopkins
University, Baltimore, MD, United States</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-03-25">
<day>25</day>
<month>3</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>112</issue>
<fpage>8129</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Jax</kwd>
<kwd>machine learning</kwd>
<kwd>E(d)-equivariance</kwd>
<kwd>tensor images</kwd>
<kwd>Equinox</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Many data sets encountered in machine learning exhibit symmetries
  that can be exploited to improve performance, a technique known as
  equivariant machine learning. The classical example is image
  translation equivariance that is respected by convolutional neural
  networks
  (<xref alt="LeCun et al., 1989" rid="ref-lecun1989backpropagation" ref-type="bibr">LeCun
  et al., 1989</xref>). For data sets in the physical sciences and other
  areas, we would also like equivariance to rotations and reflections.
  This Python package implements a convolutional neural network that is
  equivariant to translations, rotations of 90 degrees, and reflections.
  We implement this by <italic>geometric convolutions</italic>
  (<xref alt="Gregory et al., 2025" rid="ref-gregory2024ginet" ref-type="bibr">Gregory
  et al., 2025</xref>) which use tensor products and tensor
  contractions. This additionally enables us to perform functions on
  geometric images, or images where each pixel is a higher order tensor.
  These images appear as discretizations of fields in physics, such as
  velocity fields, vorticity fields, magnetic fields, polarization
  fields, and so on.</p>
  <p>The key features and use cases are summarized below.</p>
  <sec id="key-features">
    <title>Key Features</title>
    <list list-type="order">
      <list-item>
        <p>Create, visualize and perform mathematical operations on
        geometric images, including powerful <monospace>jax</monospace>
        (<xref alt="Bradbury et al., 2018" rid="ref-jax2018github" ref-type="bibr">Bradbury
        et al., 2018</xref>) features such as vmap.</p>
      </list-item>
      <list-item>
        <p>Combine geometric images of any tensor order or parity into a
        single <monospace>MultiImage</monospace> data structure.</p>
      </list-item>
      <list-item>
        <p>Build <monospace>equinox</monospace>
        (<xref alt="Kidger &amp; Garcia, 2021" rid="ref-kidger2021equinox" ref-type="bibr">Kidger
        &amp; Garcia, 2021</xref>) neural networks with our custom
        equivariant layers that process
        <monospace>MultiImages</monospace>.</p>
      </list-item>
      <list-item>
        <p><italic>Or</italic>, use one of our off-the-shelf models
        (UNet, ResNet, etc.) to start processing your geometric image
        datasets right away.</p>
      </list-item>
    </list>
  </sec>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The geometric convolutions introduced in Gregory et al.
  (<xref alt="2025" rid="ref-gregory2024ginet" ref-type="bibr">2025</xref>)
  are defined on geometric images – images where every pixel is a
  tensor. If <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>
  is a geometric image of tensor order <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  is a geometric image of tensor order <inline-formula><alternatives>
  <tex-math><![CDATA[k']]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
  then the value of <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>
  convolved with <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  at pixel <inline-formula><alternatives>
  <tex-math><![CDATA[\bar\imath]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mo>ı</mml:mo><mml:mo accent="true">‾</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  is given by:</p>
  <p><disp-formula><alternatives>
  <tex-math><![CDATA[
  (A \ast C)(\bar\imath) = \sum_{\bar a} A(\bar\imath - \bar a) \otimes C(\bar a) ~,
  ]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>A</mml:mi><mml:mo>*</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mo>ı</mml:mo><mml:mo accent="true">‾</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover></mml:munder><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mo>ı</mml:mo><mml:mo accent="true">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mspace width="0.222em"></mml:mspace><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>where the sum is over all pixels <inline-formula><alternatives>
  <tex-math><![CDATA[\bar a]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  of <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>,
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\bar\imath - \bar a]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mo>ı</mml:mo><mml:mo accent="true">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>
  is the translation of <inline-formula><alternatives>
  <tex-math><![CDATA[\bar\imath]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mo>ı</mml:mo><mml:mo accent="true">‾</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
  by <inline-formula><alternatives>
  <tex-math><![CDATA[\bar a]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>a</mml:mi><mml:mo accent="true">‾</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.
  The result is a geometric image of tensor order
  <inline-formula><alternatives>
  <tex-math><![CDATA[k+k']]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.
  To produce geometric images of smaller tensor order, a tensor
  contraction can be applied to each pixel. Convolution and contraction
  are combined into a single operation to form linear layers. By
  restricting the convolution filters <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  to rotation and reflection invariant filters, we can create linear
  layers which are rotation-, reflection-, and
  translation-equivariant.</p>
  <sec id="for-machine-learning-practitioners">
    <title>For machine learning practitioners</title>
    <p>The ginjax package can be used as a drop-in replacement for CNNs
    with minimal code changes required. We define equivariant versions
    for all the common CNN operations including convolutions, activation
    functions, group norms, pooling, and unpooling. Each of these layers
    require keeping track of the tensor order and parity of each
    geometric image, so we define a special data structure, the
    <monospace>MultiImage</monospace>, for these equivariant layers to
    operate on. We can then easily turn a non-equivariant CNN into an
    equivariant CNN by replacing the layers and converting the input to
    a <monospace>MultiImage</monospace>. We also provide full-fledged
    model implementations such as the UNet, ResNet, and Dilated
    ResNet.</p>
    <p>This package is the only one implementing geometric convolutions,
    but there are alternative methods for solving
    <inline-formula><alternatives>
    <tex-math><![CDATA[O(d)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>-equivariant
    image problems. One such package is
    <ext-link ext-link-type="uri" xlink:href="https://github.com/QUVA-Lab/escnn">escnn</ext-link>
    which uses Steerable CNNs
    (<xref alt="Cohen &amp; Welling, 2016" rid="ref-cohen2016steerablecnns" ref-type="bibr">Cohen
    &amp; Welling, 2016</xref>;
    <xref alt="Weiler &amp; Cesa, 2021" rid="ref-weiler2021steerable" ref-type="bibr">Weiler
    &amp; Cesa, 2021</xref>). Steerable CNNs use irreducible
    representations to derive a basis for <inline-formula><alternatives>
    <tex-math><![CDATA[O(d)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>-equivariant
    layers, but it is not straightforward to apply on higher-order
    tensor images.</p>
    <p>Other alternative methods are those based on Clifford Algebras,
    in particular Brandstetter et al.
    (<xref alt="2023" rid="ref-brandstetter2023clifford" ref-type="bibr">2023</xref>).
    This method has been implemented in the
    <ext-link ext-link-type="uri" xlink:href="https://github.com/microsoft/cliffordlayers">Clifford
    Layers</ext-link> package. Clifford based methods can process
    vectors and pseudovectors, but cannot handle higher-order tensors.
    Additionally, both these methods are built with pytorch, rather than
    <monospace>jax</monospace>.</p>
  </sec>
  <sec id="for-equivariance-researchers">
    <title>For equivariance researchers</title>
    <p>To allow researchers to explore the behavior of geometric images,
    we implement all the common operations such as addition, scaling,
    convolution, contraction, transposition, norms, rotations, and
    reflections. This makes it easy to generate group-invariant images
    and experiment with equivariant functions. We also provide
    visualization methods to easily follow along with the
    operations.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-gregory2024ginet">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gregory</surname><given-names>Wilson G.</given-names></name>
        <name><surname>Hogg</surname><given-names>David W.</given-names></name>
        <name><surname>Blum-Smith</surname><given-names>Ben</given-names></name>
        <name><surname>Arias</surname><given-names>Maria Teresa</given-names></name>
        <name><surname>Wong</surname><given-names>Kaze W. K.</given-names></name>
        <name><surname>Villar</surname><given-names>Soledad</given-names></name>
      </person-group>
      <article-title>Equivariant geometric convolutions for dynamical systems on vector and tensor images</article-title>
      <source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>
      <year iso-8601-date="2025">2025</year>
      <volume>383</volume>
      <issue>2298</issue>
      <uri>https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2024.0247</uri>
      <pub-id pub-id-type="doi">10.1098/rsta.2024.0247</pub-id>
      <fpage>20240247</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jax2018github">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bradbury</surname><given-names>James</given-names></name>
        <name><surname>Frostig</surname><given-names>Roy</given-names></name>
        <name><surname>Hawkins</surname><given-names>Peter</given-names></name>
        <name><surname>Johnson</surname><given-names>Matthew James</given-names></name>
        <name><surname>Leary</surname><given-names>Chris</given-names></name>
        <name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>
        <name><surname>Necula</surname><given-names>George</given-names></name>
        <name><surname>Paszke</surname><given-names>Adam</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Wanderman-Milne</surname><given-names>Skye</given-names></name>
        <name><surname>Zhang</surname><given-names>Qiao</given-names></name>
      </person-group>
      <article-title>JAX: Composable transformations of Python+NumPy programs</article-title>
      <year iso-8601-date="2018">2018</year>
      <uri>http://github.com/jax-ml/jax</uri>
    </element-citation>
  </ref>
  <ref id="ref-cohen2016steerablecnns">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Cohen</surname><given-names>Taco S.</given-names></name>
        <name><surname>Welling</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Steerable CNNs</article-title>
      <year iso-8601-date="2016">2016</year>
      <uri>https://arxiv.org/abs/1612.08498</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1612.08498</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-weiler2021steerable">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Weiler</surname><given-names>Maurice</given-names></name>
        <name><surname>Cesa</surname><given-names>Gabriele</given-names></name>
      </person-group>
      <article-title>General E(2)-equivariant steerable CNNs</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://arxiv.org/abs/1911.08251</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.1911.08251</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-brandstetter2023clifford">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Brandstetter</surname><given-names>Johannes</given-names></name>
        <name><surname>Berg</surname><given-names>Rianne van den</given-names></name>
        <name><surname>Welling</surname><given-names>Max</given-names></name>
        <name><surname>Gupta</surname><given-names>Jayesh K.</given-names></name>
      </person-group>
      <article-title>Clifford neural layers for PDE modeling</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2209.04934</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2209.04934</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lecun1989backpropagation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>LeCun</surname><given-names>Yann</given-names></name>
        <name><surname>Boser</surname><given-names>Bernhard</given-names></name>
        <name><surname>Denker</surname><given-names>John S</given-names></name>
        <name><surname>Henderson</surname><given-names>Donnie</given-names></name>
        <name><surname>Howard</surname><given-names>Richard E</given-names></name>
        <name><surname>Hubbard</surname><given-names>Wayne</given-names></name>
        <name><surname>Jackel</surname><given-names>Lawrence D</given-names></name>
      </person-group>
      <article-title>Backpropagation applied to handwritten zip code recognition</article-title>
      <source>Neural Computation</source>
      <publisher-name>MIT Press</publisher-name>
      <year iso-8601-date="1989">1989</year>
      <volume>1</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1162/neco.1989.1.4.541</pub-id>
      <fpage>541</fpage>
      <lpage>551</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kidger2021equinox">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kidger</surname><given-names>Patrick</given-names></name>
        <name><surname>Garcia</surname><given-names>Cristian</given-names></name>
      </person-group>
      <article-title>Equinox: Neural networks in JAX via callable PyTrees and filtered transformations</article-title>
      <source>Differentiable Programming workshop at Neural Information Processing Systems 2021</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2111.00254</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
