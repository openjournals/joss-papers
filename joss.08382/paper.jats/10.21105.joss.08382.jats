<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8382</article-id>
<article-id pub-id-type="doi">10.21105/joss.08382</article-id>
<title-group>
<article-title>baysc: An R package for Bayesian survey
clustering</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5110-8407</contrib-id>
<name>
<surname>Wu</surname>
<given-names>Stephanie M.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8894-1240</contrib-id>
<name>
<surname>Williams</surname>
<given-names>Matthew R.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1843-3106</contrib-id>
<name>
<surname>Savitsky</surname>
<given-names>Terrance D.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6147-1039</contrib-id>
<name>
<surname>Stephenson</surname>
<given-names>Briana J. K.</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Division of Psychiatry, UCL, London, U.K.</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>RTI International, Research Triangle Park, North Carolina,
U.S.A</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Office of Survey Methods Research, U.S. Bureau of Labor
Statistics, Washington, DC, U.S.A</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Department of Biostatistics, Harvard T.H. Chan School of
Public Health, Boston, Massachusetts, U.S.A</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-04-08">
<day>8</day>
<month>4</month>
<year>2024</year>
</pub-date>
<volume>11</volume>
<issue>118</issue>
<fpage>8382</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>Bayesian</kwd>
<kwd>survey</kwd>
<kwd>model-based clustering</kwd>
<kwd>dietary patterns</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Model-based clustering methods allow a large number of correlated
  variables to be summarized into underlying patterns, where each
  pattern describes a cluster and each individual is assigned to a
  cluster. Example applications include identifying dietary patterns
  from dietary intake data
  (<xref alt="Stephenson et al., 2020" rid="ref-stephenson2020empirically" ref-type="bibr">Stephenson
  et al., 2020</xref>) and creating profiles of health and development
  among children
  (<xref alt="Lanza &amp; Cooper, 2016" rid="ref-lanza2016latent" ref-type="bibr">Lanza
  &amp; Cooper, 2016</xref>). Bayesian formulations of such analyses
  allow the number of clusters to be determined by the data rather than
  through researcher post-hoc analyses.</p>
  <p>Interest may also lie in relating the identified clusters to an
  outcome, either through a secondary regression step or an all-in-one
  “supervised” approach that uses information from the outcome to inform
  the clustering process. When such clustering methods are applied to
  survey data, failure to account for the complex survey design and
  incorporate survey weights into the estimation leads to biased
  estimation and inference when the results are generalized to the
  population outside of the survey data.</p>
  <p>The <monospace>baysc</monospace> R package implements the methods
  proposed in Stephenson, Wu, &amp; Dominici
  (<xref alt="2023" rid="ref-stephenson2023identifying" ref-type="bibr">2023</xref>)
  and Wu, Williams, Savitsky, &amp; Stephenson
  (<xref alt="2024" rid="ref-wu2024derivation" ref-type="bibr">2024</xref>),
  providing functionality to allow for Bayesian clustering analyses –
  both unsupervised and supervised – to be performed while incorporating
  survey weights and design features that account for complex survey
  sampling designs. Asymptotically correct point estimates and credible
  intervals are produced with respect to the underlying population from
  which the observed sample was generated. This novel feature allows for
  application of latent class analysis (LCA) to datasets realized from
  surveys administered by government statistical agencies. The package
  uses methods derived from the LCA literature and focuses on clustering
  in the setting where the correlated variables are categorical and the
  outcome, where applicable, is binary. The package includes additional
  functions for plotting and summarizing output, as well as an example
  dataset from the National Health and Nutrition Examination Survey
  (NHANES) containing dietary intake and hypertension data among
  low-income women in the United States
  (<xref alt="National Center for Health Statistics, 2023" rid="ref-nchs2023homepage" ref-type="bibr">National
  Center for Health Statistics, 2023</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>A number of R packages provide functionality for model-based
  clustering in R. Frequentist approaches include
  <monospace>poLCA</monospace>
  (<xref alt="Linzer &amp; Lewis, 2011" rid="ref-linzer2011polca" ref-type="bibr">Linzer
  &amp; Lewis, 2011</xref>) for classical LCA,
  <monospace>randomLCA</monospace>
  (<xref alt="Beath, 2017" rid="ref-beath2017randomlca" ref-type="bibr">Beath,
  2017</xref>) for LCA with individual-specific random effects, and
  <monospace>mclust</monospace>
  (<xref alt="Scrucca, Fraley, Murphy, &amp; Raftery, 2023" rid="ref-scrucca2023model" ref-type="bibr">Scrucca,
  Fraley, Murphy, &amp; Raftery, 2023</xref>) and
  <monospace>tidyLPA</monospace>
  (<xref alt="Rosenberg, Beymer, Anderson, Van Lissa, &amp; Schmidt, 2019" rid="ref-rosenberg2019tidylpa" ref-type="bibr">Rosenberg,
  Beymer, Anderson, Van Lissa, &amp; Schmidt, 2019</xref>) for
  clustering of continuous variables. <monospace>BayesLCA</monospace>
  (<xref alt="White &amp; Murphy, 2014" rid="ref-white2014bayeslca" ref-type="bibr">White
  &amp; Murphy, 2014</xref>) and <monospace>BayesBinMix</monospace>
  (<xref alt="Papastamoulis &amp; Rattray, 2017" rid="ref-papastamoulis2017bayesbinmix" ref-type="bibr">Papastamoulis
  &amp; Rattray, 2017</xref>) use Bayesian approaches for categorical
  and binary data, respectively. <monospace>PReMiuM</monospace>
  (<xref alt="Liverani, Hastie, Azizi, Papathomas, &amp; Richardson, 2015" rid="ref-liverani2015premium" ref-type="bibr">Liverani,
  Hastie, Azizi, Papathomas, &amp; Richardson, 2015</xref>) fits a wide
  variety of supervised models that handle various types of discrete and
  continuous exposure and outcome data. However, these packages do not
  allow for survey weights and complex survey design to be incorporated
  to ensure valid estimation and inference when using survey data.</p>
  <p>The <monospace>baysc</monospace> package implements a weighted
  pseudo-likelihood approach proposed in Stephenson et al.
  (<xref alt="2023" rid="ref-stephenson2023identifying" ref-type="bibr">2023</xref>)
  and Wu et al.
  (<xref alt="2024" rid="ref-wu2024derivation" ref-type="bibr">2024</xref>)
  that can integrate survey sampling weights when performing cluster
  analysis using categorical or binary data. The models adjust for
  stratification, clustering, and informative sampling to provide
  accurate point and variance estimation. When interest lies in how
  clusters are related to additional variables, such as a binary
  outcome, users can either: 1) adopt a two-step approach where
  unsupervised clustering is performed and then a secondary regression
  is fit, or 2) use the all-in-one supervised approach that jointly
  models all variables, precisely propagating measurement error from the
  clustering analysis into the outcome regression model. The supervised
  approach also uses a mixture reference coding scheme to allow
  interaction effects between the clusters and the outcome to be
  captured. Detailed information about the functions and related
  statistical details can be found in the vignette,
  “<ext-link ext-link-type="uri" xlink:href="https://raw.githubusercontent.com/smwu/baysc/refs/heads/main/vignettes/baysc.pdf">An
  introduction to the baysc package</ext-link>,” and Wu et al.
  (<xref alt="2024" rid="ref-wu2024derivation" ref-type="bibr">2024</xref>).</p>
</sec>
<sec id="usage">
  <title>Usage</title>
  <sec id="package-installation">
    <title>1. Package Installation</title>
    <p>The <monospace>baysc</monospace> package can be installed from
    GitHub.</p>
    <code language="r script"># Install devtools for package loading 
install.packages(devtools)
library(devtools)
# Install baysc from GitHub
devtools::install_github(&quot;smwu/baysc&quot;)
library(baysc)
# Load other packages needed for the examples
library(dplyr)
library(ggplot2)
library(knitr)</code>
    <p>During installation, the following errors may arise:</p>
    <list list-type="bullet">
      <list-item>
        <p><italic>No package called ‘rstantools’</italic>: Please
        install the <monospace>rstantools</monospace> package using
        <monospace>install.packages(&quot;rstantools&quot;)</monospace>.</p>
      </list-item>
      <list-item>
        <p><italic>Library ‘gfortran’ not found</italic>: This is a
        compiler configuration issue that can arise when using Rcpp on
        Mac computers with Apple silicon (e.g., M1, M2, M3). Users may
        need to install Xcode, GNU Fortran, and OpenMP, and edit the
        <monospace>~/.R/Makevars</monospace> file. More details are
        provided in the GitHub README file.</p>
      </list-item>
    </list>
  </sec>
  <sec id="data-preparation">
    <title>2. Data preparation</title>
    <p><monospace>baysc</monospace> applies Bayesian latent class
    analysis using the following input data:</p>
    <list list-type="bullet">
      <list-item>
        <p>Multivariate categorical exposure:
        <inline-formula><alternatives>
        <tex-math><![CDATA[nxJ]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mi>x</mml:mi><mml:mi>J</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        matrix, where <inline-formula><alternatives>
        <tex-math><![CDATA[n]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>n</mml:mi></mml:math></alternatives></inline-formula>
        is the sample size and <inline-formula><alternatives>
        <tex-math><![CDATA[J]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>J</mml:mi></mml:math></alternatives></inline-formula>
        is the number of categorical item variables. Each item must be a
        categorical variable with levels 1, 2, etc.</p>
      </list-item>
      <list-item>
        <p>(Optional) survey design elements such as survey sampling
        weights, stratum indicators, and cluster indicators: each
        formatted as a <inline-formula><alternatives>
        <tex-math><![CDATA[nx1]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        vector.</p>
      </list-item>
      <list-item>
        <p>(Optional) binary outcome: <inline-formula><alternatives>
        <tex-math><![CDATA[nx1]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        vector</p>
      </list-item>
      <list-item>
        <p>(Optional) additional confounders to adjust for when
        evaluating the exposure-outcome association:
        <inline-formula><alternatives>
        <tex-math><![CDATA[nxQ]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mi>x</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        dataframe, where <inline-formula><alternatives>
        <tex-math><![CDATA[Q]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Q</mml:mi></mml:math></alternatives></inline-formula>
        is the number of additional confounders.</p>
      </list-item>
    </list>
    <p>We provide an example dataset from the National Health and
    Nutrition Examination Survey (NHANES) that includes multivariate
    categorical dietary intake data as well as binary hypertension data
    for low-income women in the United States. Survey sampling weights
    and information on stratification and clustering are included to
    allow for adjustment for survey design when conducting estimation
    and inference.</p>
    <sec id="load-dataset-and-define-categorical-item-variables">
      <title>Load dataset and define categorical item variables</title>
      <p>We begin by loading the example dataset included in the
      package. Then, we define the matrix of categorical variables that
      will be used for the clustering analysis. In this example, we have
      a sample size of <inline-formula><alternatives>
      <tex-math><![CDATA[n=2004]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2004</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      and consider <inline-formula><alternatives>
      <tex-math><![CDATA[J=28]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mn>28</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      food groups, each of which is a categorical variables with four
      levels of intake: 1, 2, 3, 4.</p>
      <code language="r script"># Load NHANES example dataset
data(&quot;data_nhanes&quot;)

# Exposure matrix of categorical intake for each individual across 
# 28 food groups
x_mat &lt;- data_nhanes[, c(&quot;citrus&quot;, &quot;oth_fruit&quot;, &quot;fruit_juice&quot;, &quot;dark_green&quot;, 
  &quot;tomatoes&quot;, &quot;oth_red&quot;, &quot;potatoes&quot;, &quot;oth_starchy&quot;, &quot;oth_veg&quot;, &quot;whole_grain&quot;, 
  &quot;ref_grain&quot;, &quot;meat&quot;, &quot;cured_meats&quot;, &quot;organ&quot;, &quot;poultry&quot;, &quot;seafood_high&quot;, 
  &quot;seafood_low&quot;, &quot;eggs&quot;, &quot;soybean&quot;, &quot;nuts&quot;, &quot;leg_protein&quot;, &quot;milk&quot;, &quot;yogurt&quot;, 
  &quot;cheese&quot;, &quot;oils&quot;, &quot;solid_fats&quot;, &quot;add_sugars&quot;, &quot;drinks&quot;)]
x_mat &lt;- as.matrix(x_mat)
# Dimensions of exposure matrix, n x J
dim(x_mat)</code>
      <preformat>[1] 2004   28</preformat>
      <code language="r script"># Categorical intake levels
table(x_mat[, &quot;citrus&quot;])</code>
      <preformat>   1    2    3    4 
1121  296  287  300 </preformat>
    </sec>
    <sec id="define-survey-design-variables">
      <title>Define survey design variables</title>
      <p>Next, we define the survey design variables specifying
      information on stratification, clustered sampling, and sampling
      weights that adjust for unequal sampling probabilities. For the
      cluster indicators, use indicators for the first stage of sampling
      and do not nest the indicators within strata. The variance
      computation will only use the first stage of clustering and will
      assume sampling to be with replacement at the first stage.</p>
      <p>If there is no survey design information, these variables can
      be left as <monospace>NULL</monospace> (default).</p>
      <code language="r script"># Survey stratum indicators
stratum_id &lt;- data_nhanes$stratum_id
# Survey cluster indicators
cluster_id &lt;- data_nhanes$cluster_id
# Survey sampling weights
sampling_wt &lt;- data_nhanes$sample_wt</code>
    </sec>
    <sec id="define-outcome-and-additional-regression-variables">
      <title>Define outcome and additional regression variables</title>
      <p>If desired, a binary outcome can be added to examine the
      association between the clusters and the outcome. In this example,
      the outcome is hypertension (i.e., high blood pressure;
      <monospace>BP_flag</monospace> variable), with 1 indicating
      hypertension and 0 indicating no hypertension.</p>
      <code language="r script"># Outcome data on hypertension 
y_all &lt;- data_nhanes$BP_flag</code>
      <p>If there are additional covariates that should be adjusted for
      in the exposure-outcome association, they can be specified in a
      dataframe of additional confounders to adjust for. Also define a
      regression formula for including these additional confounders. In
      this example, for the diet-hypertension outcome regression, we
      adjust for age, race/ethnicity, smoking status, and physical
      activity. Note that the regression formula here should be
      specified <italic>without</italic> including the outcome, unlike
      in other regression functions.</p>
      <code language="r script"># Create dataframe of additional confounders
V_data &lt;- data_nhanes %&gt;% select(age_cat, racethnic, smoker, physactive)
# Regression formula for additional confounders
glm_form &lt;- &quot;~ age_cat + racethnic + smoker + physactive&quot;</code>
    </sec>
  </sec>
  <sec id="model-fitting">
    <title>3. Model fitting</title>
    <p>Two options exist for running a survey-weighted Bayesian
    clustering analysis: 1) use just the categorical variables to
    perform unsupervised clustering, then decide later on whether these
    will be related to other variables (e.g., a binary outcome) via a
    regression model; 2) use a supervised clustering model that jointly
    models the categorical variables and a binary outcome to perform
    outcome-informed clustering while characterizing the cluster-outcome
    association simultaneously. The first model is called a Weighted
    Overfitted Latent Class Analysis (WOLCA), and the second option is
    called a Supervised Weighted Overfitted Latent Class Analysis
    (SWOLCA). See Wu et al.
    (<xref alt="2024" rid="ref-wu2024derivation" ref-type="bibr">2024</xref>)
    for statistical details of the models.</p>
    <p>In both options, parameter estimation for the clustering analysis
    is obtained via a Markov chain Monte Carlo (MCMC) Gibbs sampling
    algorithm. Sampling is implemented in two stages: an adaptive
    sampler followed by a fixed sampler. The adaptive sampler is used to
    determine the number of latent classes using a data-driven process
    with a sparsity-inducing Dirichlet prior. Once the number of latent
    classes is determined, the fixed sampler is run using the set number
    of classes and produces output for estimation and inference. Note
    that the final number of classes determined by the fixed sampler may
    be smaller than the number of classes obtained from the adaptive
    sampler.</p>
    <p>In the sections below, we provide examples of how to use the
    WOLCA and SWOLCA clustering methods in the package. Options are
    provided for the main input arguments, but additional parameters for
    prior specification and other customization are available — please
    see the documentation help pages for the functions.</p>
    <sec id="option-1-use-wolca-to-perform-unsupervised-clustering">
      <title>Option 1: Use WOLCA to perform unsupervised
      clustering</title>
      <sec id="clustering-analysis">
        <title>Clustering analysis</title>
        <p>If no outcome information is necessary when clustering, use
        the unsupervised WOLCA, implemented in the
        <monospace>wolca()</monospace> function, to obtain clusters and
        pattern profiles.</p>
        <p>In this example, we specify the categorical variables for
        clustering (<monospace>x_mat</monospace>) as well as the survey
        design variables (<monospace>sampling_wt</monospace>,
        <monospace>cluster_id</monospace>,
        <monospace>stratum_id</monospace>). We run the sampler for
        <monospace>n_runs = 300</monospace> iterations, discarding
        initial iterations as burn-in
        (<monospace>burn = 150</monospace>), thinning to every third
        iteration (<monospace>thin = 3</monospace>), and printing out a
        progress update every 20 iterations
        (<monospace>update = 20</monospace>). Typically, at least 20000
        iterations should be used for <monospace>wolca()</monospace>,
        corresponding to a runtime of around 2 hours.</p>
        <p>We run both the adaptive and fixed sampler
        (<monospace>run_sampler = &quot;both&quot;</monospace>) and set
        a seed (<monospace>adapt_seed = 111</monospace>). Other options
        are <monospace>&quot;adapt&quot;</monospace> for only the
        adaptive sampler, or <monospace>&quot;fixed&quot;</monospace>
        for only the fixed sampler when the number of latent classes is
        known a priori. The maximum number of latent classes is set to
        30 (<monospace>K_max = 30</monospace>). Typically, the true
        number will be much smaller and will be determined by the data
        through the sparsity-inducing Dirichet prior. The minimum size
        of each latent class is set to 5% of the population
        (<monospace>class_cutoff = 0.05</monospace>).</p>
        <p>We specify <monospace>save_res = FALSE</monospace> here
        because the results do not need to be saved for this example. If
        <monospace>save_res = TRUE</monospace> (default),
        <monospace>save_path</monospace> must also be specified and
        include both the desired directory and the beginning of the file
        name for the results (e.g.,
        <monospace>save_path = &quot;~/Documents/run&quot;</monospace>).</p>
        <code language="r script"># Run WOLCA to perform clustering analysis
res_wolca &lt;- wolca(x_mat = x_mat, sampling_wt = sampling_wt,
                   cluster_id = cluster_id, stratum_id = stratum_id,
                   run_sampler = &quot;both&quot;, K_max = 30, adapt_seed = 111, 
                   class_cutoff = 0.05, n_runs = 300, burn = 150, thin = 3, 
                   update = 20, save_res = FALSE)</code>
      </sec>
      <sec id="variance-adjustment">
        <title>Variance adjustment</title>
        <p>After performing the clustering analysis, the
        <monospace>wolca_var_adjust()</monospace> function can be used
        to apply a post-processing adjustment that allows for correct
        estimation of the variability of the parameter estimates. If
        this adjustment is not applied, the estimated variances will be
        too small. However, if the user is only interested in estimation
        of the patterns, these results will be valid regardless of
        whether this adjustment is applied.</p>
        <p>For this example, we set a random seed for reproducibility
        (<monospace>adjust_seed = 111</monospace>) and use 100 bootstrap
        replicates (<monospace>num_reps = 100</monospace>) to estimate
        variability in the sampling process. Again, we choose not to
        save results.</p>
        <p>Users can ignore the following warning messages: “the design
        is sampled with replacement and only the first stage is used”
        and “the number of chains being less than 1 and sampling not
        done.” Messages about negative variances and large (&gt;1)
        eigenvalue differences to the nearest positive definite matrix
        indicate instability in the variance adjustment matrix
        inversions. Methods to address this issue include running the
        sampler for more iterations or reducing the number of additional
        covariate terms in the outcome regression. One could also choose
        to forgo the variance adjustment and simply use the posterior
        distributions produced by <monospace>wolca()</monospace>,
        acknowledging that estimated variances will be slight
        underestimates.</p>
        <code language="r script"># Apply variance adjustment
res_wolca_adjust &lt;- wolca_var_adjust(res = res_wolca, adjust_seed = 111,
                                     num_reps = 100, save_res = FALSE)</code>
      </sec>
      <sec id="outcome-association">
        <title>Outcome association</title>
        <p>Next, we can use <monospace>wolca_svyglm()</monospace> to
        examine the association of pattern profiles with the binary
        outcome of hypertension through a subsequent regression model.
        This step involves a survey-weighted probit regression model
        using the <monospace>svyglm()</monospace> function in the
        <monospace>survey</monospace> package
        (<xref alt="Lumley, 2004" rid="ref-lumley2004analysis" ref-type="bibr">Lumley,
        2004</xref>). One word of caution: this approach can result in
        imprecise estimates and estimates that are attenuated due to the
        measurement error in the first classification step that is
        unaccounted for. See Nylund-Gibson, Grimm, &amp; Masyn
        (<xref alt="2019" rid="ref-nylund2019prediction" ref-type="bibr">2019</xref>)
        for more discussion of this issue. To resolve this issue, users
        can consider using multiple imputation approaches to draw from
        the posterior class probabilities. However, these are not yet
        implemented in the <monospace>baysc</monospace> package
        functionality.</p>
        <p>If models other than probit regression are of interest, users
        can take the <monospace>wolca()</monospace> or
        <monospace>wolca_var_adjust()</monospace> output and use the
        <monospace>svyglm()</monospace> function directly. This will
        allow specification of a broader range of survey-weighted
        regression models.</p>
        <p>In this example, we use the output from
        <monospace>wolca_var_adjust()</monospace>, along with the binary
        outcome and additional covariates, in order to run a probit
        regression model. We specify that survey-weighted confidence
        intervals should be evaluated at the 95% confidence level
        (<monospace>ci_level = 0.95</monospace>).</p>
        <p>A warning about negative residual degrees of freedom may
        arise when the survey design degrees of freedom is smaller than
        the number of covariates in the model. Confidence intervals and
        p-values are by default not reported in the
        <monospace>svyglm()</monospace> function. However, when the
        covariates are not cluster-level covariates, it is approximately
        reasonable to use the survey design degrees of freedom instead,
        which is what the <monospace>baysc</monospace> package does to
        calculate confidence intervals and p-values. Please see the
        <monospace>survey</monospace> package documentation for more
        discussion on this issue.</p>
        <code language="r script"># Run weighted outcome regression model
res_wolca_svyglm &lt;- wolca_svyglm(res = res_wolca_adjust, y_all = y_all, 
                                 V_data = V_data, glm_form = glm_form, 
                                 ci_level = 0.95, save_res = FALSE)</code>
      </sec>
    </sec>
    <sec id="option-2-use-swolca-to-perform-supervised-clustering">
      <title>Option 2: Use SWOLCA to perform supervised
      clustering</title>
      <sec id="clustering-analysis-and-outcome-association">
        <title>Clustering analysis and outcome association</title>
        <p>As an alternative to the two-step approach in Option 1, a
        one-step “supervised” approach allows information about the
        binary outcome to directly inform the creation of the clusters.
        We use the <monospace>swolca()</monospace> function to obtain
        dietary pattern clusters while simultaneously relating them to
        the hypertension outcome.</p>
        <p>In this example, we specify the categorical variables for
        clustering (<monospace>x_mat</monospace>), the outcome and
        regression variables (<monospace>y_all</monospace>,
        <monospace>V_data</monospace>, <monospace>glm_form</monospace>),
        and the survey design variables
        (<monospace>sampling_wt</monospace>,
        <monospace>cluster_id</monospace>,
        <monospace>stratum_id</monospace>). We run the sampler for
        <monospace>n_runs = 300</monospace> iterations, discarding
        initial iterations as burn-in
        (<monospace>burn = 150</monospace>), thinning to every third
        iteration (<monospace>thin = 3</monospace>), and printing out a
        progress update every 20 iterations
        (<monospace>update = 20</monospace>). Typically, at least 20000
        iterations should be used for <monospace>swolca()</monospace>,
        corresponding to a runtime of around 3 hours.</p>
        <p>We run both the adaptive and fixed sampler
        (<monospace>run_sampler = &quot;both&quot;</monospace>) and set
        a seed (<monospace>adapt_seed = 222</monospace>). Other options
        are <monospace>&quot;adapt&quot;</monospace> for only the
        adaptive sampler, or <monospace>&quot;fixed&quot;</monospace>
        for only the fixed sampler when the number of latent classes is
        known a priori. The maximum number of latent classes is set to
        30 (<monospace>K_max = 30</monospace>). The minimum size of each
        latent class is set to 5% of the population
        (<monospace>class_cutoff = 0.05</monospace>).</p>
        <p>We do not save results for this example
        (<monospace>save_res = FALSE</monospace>). If results are to be
        saved, set <monospace>save_res = TRUE</monospace> and specify
        <monospace>save_path</monospace> by including both the desired
        directory and the beginning of the file name for the results
        (e.g.,
        <monospace>save_path = &quot;~/Documents/run&quot;</monospace>).</p>
        <p>Note: if continuous variables are incorporated into the
        binary probit outcome model, any such variables with standard
        deviation greater than 5 may result in errors in the variance
        adjustment. To avoid these errors, consider standardizing the
        variable to have mean 0 and standard deviation 1 or converting
        the variable into a categorical form.</p>
        <code language="r script"># Run SWOLCA
res_swolca &lt;- swolca(x_mat = x_mat, y_all = y_all, V_data = V_data, 
                     glm_form = glm_form, sampling_wt = sampling_wt, 
                     cluster_id = cluster_id, stratum_id = stratum_id,  
                     run_sampler = &quot;both&quot;, K_max = 30, adapt_seed = 222, 
                     class_cutoff = 0.05, n_runs = 300, burn = 150, 
                     thin = 3, update = 20, save_res = FALSE)</code>
      </sec>
      <sec id="variance-adjustment-1">
        <title>Variance adjustment</title>
        <p>The <monospace>swolca_var_adjust()</monospace> function can
        be used after to apply a post-processing adjustment that allows
        for correct estimation of the variability of the parameter
        estimates. If this adjustment is not applied, the estimated
        variances will be too small.</p>
        <p>For this example, we set a random seed for reproducibility
        (<monospace>adjust_seed = 222</monospace>) and use 100 bootstrap
        replicates (<monospace>num_reps = 100</monospace>) to estimate
        variability in the sampling process. Again, we choose not to
        save results.</p>
        <p>When running the variance adjustment, some warning messages
        may arise to indicate instability in the variance adjustment
        matrix inversions. Possible solutions include running the
        sampler for more iterations or reducing the number of additional
        covariate terms in the outcome regression. If continuous
        covariates are included in the probit regression model, these
        errors may also be due to the variance of the covariate being
        too large. In such cases, it is recommended to reduce the
        variance of the covariate, either by standardizing the variable
        to have mean 0 and standard deviation 1, or by transforming the
        variable into a categorical variable. One could also choose to
        forgo the variance adjustment and simply use the posterior
        distributions produced by <monospace>swolca()</monospace>,
        acknowledging that estimated variances will be slight
        underestimates.</p>
        <code language="r script"># Apply variance adjustment
res_swolca_adjust &lt;- swolca_var_adjust(res = res_swolca, adjust_seed = 222,
                                       num_reps = 100, save_res = FALSE)</code>
      </sec>
    </sec>
  </sec>
  <sec id="visualization">
    <title>4. Visualization</title>
    <p>We demonstrate plotting and summarization functions for SWOLCA
    (option 2) using the <monospace>res_swolca_adjust</monospace>
    results from running <monospace>swolca()</monospace> and
    <monospace>swolca_var_adjust()</monospace>. The same functions can
    also be used for summarizing output for WOLCA (option 1) using the
    results from <monospace>wolca()</monospace>,
    <monospace>wolca_var_adjust()</monospace>, and
    <monospace>wolca_svyglm()</monospace>.</p>
    <sec id="plot-pattern-profiles">
      <title>Plot pattern profiles</title>
      <p>For each latent class (i.e., cluster), there is a pattern
      profile defined by the category with the highest posterior
      probability, also referred to as the modal
      <inline-formula><alternatives>
      <tex-math><![CDATA[\theta]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>,
      for each item. To visualize these pattern profiles, use the
      <monospace>plot_pattern_profiles</monospace> function with output
      from <monospace>swolca()</monospace>,
      <monospace>swolca_var_adjust()</monospace>,
      <monospace>wolca()</monospace>, or
      <monospace>wolca_var_adjust()</monospace>.</p>
      <p>We specify labels for the items
      (<monospace>item_labels</monospace>), categories
      (<monospace>categ_labels</monospace>), and latent classes
      (<monospace>class_labels</monospace>), as well as the axis and
      legend titles (<monospace>item_title</monospace>,
      <monospace>categ_title</monospace>, and
      <monospace>class_title</monospace>).</p>
      <code language="r script"># Categorical item labels
item_title &lt;- &quot;Item&quot;
item_labels &lt;- c(&quot;Citrus/Melon/Berries&quot;, &quot;Other Fruits&quot;, &quot;Fruit Juice&quot;, 
                 &quot;Dark Green Vegs&quot;, &quot;Tomatoes&quot;, &quot;Oth Red/Orange Vegs&quot;,
                 &quot;Potatoes&quot;, &quot;Other Starchy Vegs&quot;, &quot;Other Vegetables&quot;,
                 &quot;Whole Grains&quot;, &quot;Refined Grains&quot;, &quot;Meat&quot;, &quot;Cured Meats&quot;,
                 &quot;Organ Meat&quot;, &quot;Poultry&quot;, &quot;Seafood (High n-3)&quot;, 
                 &quot;Seafood (Low n-3)&quot;, &quot;Eggs&quot;, &quot;Soybean Products&quot;, 
                 &quot;Nuts and Seeds&quot;, &quot;Legumes (Protein)&quot;, &quot;Milk&quot;, &quot;Yogurt&quot;, 
                 &quot;Cheese&quot;, &quot;Oils&quot;, &quot;Solid Fats&quot;, &quot;Added Sugar&quot;,
                 &quot;Alcoholic Drinks&quot;)
# Category level labels
categ_title &lt;- &quot;Consumption Level&quot;
categ_labels &lt;- c(&quot;None&quot;, &quot;Low&quot;, &quot;Med&quot;, &quot;High&quot;)
# Latent class (i.e., cluster) labels
class_title &lt;- &quot;Dietary Pattern&quot;
class_labels &lt;- 1:5

# Get pattern profiles
plot_pattern_profiles(res = res_swolca_adjust, 
                      item_labels = item_labels, item_title = item_title,
                      categ_labels = categ_labels, categ_title = categ_title,
                      class_labels = class_labels, class_title = class_title)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_pattern_profiles.png" />
      <p>For the NHANES example using the
      <monospace>swolca()</monospace> supervised clustering function, we
      can interpret these 5 patterns as diet-hypertension patterns where
      individuals following the same pattern share similar dietary
      intake and hypertension status. If the
      <monospace>wolca()</monospace> unsupervised clustering function
      had been used, these patterns would be interpreted as solely diet
      patterns where individuals following the same pattern share
      similar dietary intake. Since survey design was accounted for,
      these patterns should be representative of the patterns in the
      broader population.</p>
    </sec>
    <sec id="plot-pattern-probabilities">
      <title>Plot pattern probabilities</title>
      <p>To examine to what extent the data support the pattern
      profiles, we can view the specific distribution of posterior
      probabilities across the item categories for each item and each
      class using <monospace>plot_pattern_probs()</monospace>, with
      output from <monospace>swolca()</monospace>,
      <monospace>swolca_var_adjust()</monospace>,
      <monospace>wolca()</monospace>, or
      <monospace>wolca_var_adjust()</monospace>. This allows us to
      examine how much evidence supports the category with the highest
      posterior probability compared to the other categories. If there
      is no evidence supporting one category over the others, then all
      the probabilities will be equal to <inline-formula><alternatives>
      <tex-math><![CDATA[1/R_j]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>,
      where <inline-formula><alternatives>
      <tex-math><![CDATA[R_j]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
      is the number of categories for item
      <inline-formula><alternatives>
      <tex-math><![CDATA[j]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>j</mml:mi></mml:math></alternatives></inline-formula>.
      For example, the distribution for Other Fruits for Class 2 is
      pretty even across the 4 consumption levels, indicating that Class
      2 still has a fair amount of heterogeneity in consumption of Other
      Fruits. If the data strongly support a category, the posterior
      probability for that category will be much closer to 1 (e.g.,
      0.8). For example, the probability that Organ Meat is consumed at
      level “None” is very high for those in classes 4 and 5.</p>
      <code language="r script">plot_pattern_probs(res = res_swolca_adjust, 
                   item_labels = item_labels,
                   categ_labels = categ_labels) + 
  # font size for item labels
  theme(strip.text.x = element_text(size = 7))  </code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_pattern_probs.png" />
    </sec>
    <sec id="obtain-individual-class-assignments-and-class-separation">
      <title>Obtain individual class assignments and class
      separation</title>
      <p>For each individual in the sample, we can obtain their final
      class (i.e., cluster) assignment as well the posterior probability
      of them belonging to each class. The ability to check posterior
      class assignment probability is an advantage of model-based
      clustering and allows us to see the uncertainty associated with
      the clustering analysis. This information can be used to check
      class separation metrics such as entropy
      (<xref alt="Wang, Deng, Bi, Ye, &amp; Yang, 2017" rid="ref-wang2017performance" ref-type="bibr">Wang,
      Deng, Bi, Ye, &amp; Yang, 2017</xref>) or the average latent class
      posterior probability
      (<xref alt="Muthén &amp; Muthén, 2000" rid="ref-muthen2000integrating" ref-type="bibr">Muthén
      &amp; Muthén, 2000</xref>), both recommended to be above 0.8 for
      adequate class separation
      (<xref alt="Weller, Bowen, &amp; Faubert, 2020" rid="ref-weller2020latent" ref-type="bibr">Weller,
      Bowen, &amp; Faubert, 2020</xref>). Note that these metrics are
      <italic>not</italic> generalizable to the broader population and
      are limited to describing individuals included in the dataset.</p>
      <p>In this example, we can see that individual 1 is assigned to
      class 1 and individual 2 is assigned to class 2 with very high
      probabilities (&gt;0.98), and individual 3 is assigned to class 2
      with lower probability (0.793).</p>
      <code language="r script"># Class assignments for first 3 individuals
res_swolca_adjust$estimates_adjust$c_all[1:3]</code>
      <preformat>[1] 1 2 2</preformat>
      <code language="r script"># Posterior class probabilities for first 3 indivs, rounded to 3 decimals
round(res_swolca_adjust$estimates_adjust$pred_class_probs[1:3, ], 3)</code>
      <preformat>      [,1]  [,2]  [,3] [,4] [,5]
[1,] 0.981 0.000 0.019    0    0
[2,] 0.010 0.990 0.000    0    0
[3,] 0.207 0.793 0.001    0    0</preformat>
      <p>A dendrogram displaying the distances between classes can also
      be created to check class separation. The distance is the number
      of MCMC iterations with differing class assignments (after
      discarding burn-in and thinning). The dendrogram displays the
      hierarchical clustering setup, where individuals first are all
      assigned to their own class, and then classes are systematically
      merged together starting from classes that have the smallest
      distance between them. The preliminary number of latent classes
      selected is displayed by the rectangles, with each individual
      assigned to a class. A final merging step between classes that
      have the exact same modal pattern was done to merge any duplicate
      classes. In the below example, we can see that Class 5 is composed
      of two smaller groups that were merged together.</p>
      <code language="r script"># Get dendrogram
dend &lt;- res_swolca_adjust$post_MCMC_out$dendrogram
# Get preliminary number of latent classes
K_med &lt;- res_swolca_adjust$post_MCMC_out$K_med
# Remove labels for individuals to declutter the plot
dend$labels &lt;- &quot;&quot;
# Plot dendrogram
plot(as.dendrogram(dend), ylab = &quot;Distance&quot;)
# Rectangles around the latent classes
rect.hclust(dend, k = K_med, border = 2:(2 + K_med - 1))</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="dendrogram.png" />
    </sec>
    <sec id="plot-distribution-of-classes">
      <title>Plot distribution of classes</title>
      <p>To examine how common the classes are in the broader
      population, the <monospace>plot_class_dist()</monospace> function
      displays boxplots for the estimated proportion of the population
      belonging to each class (i.e., latent class membership
      probabilities, <inline-formula><alternatives>
      <tex-math><![CDATA[\pi]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>)
      across the iterations of the MCMC sampler. In the below example,
      there is quite a lot of variability in the estimates for classes 1
      and 3.</p>
      <code language="r script"># Median estimated population class proportions
round(res_swolca_adjust$estimates_adjust$pi_med, 3)</code>
      <preformat>[1] 0.196 0.252 0.110 0.185 0.257</preformat>
      <code language="r script"># Plot distribution of classes
plot_class_dist(res = res_swolca_adjust)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_class_dist.png" />
    </sec>
    <sec id="reorder-classes">
      <title>Reorder classes</title>
      <p>If desired, we can also change the order of the classes using
      the <monospace>reorder_classes()</monospace> function, applied to
      output from <monospace>swolca()</monospace>,
      <monospace>swolca_var_adjust()</monospace>,
      <monospace>wolca()</monospace>, or
      <monospace>wolca_var_adjust()</monospace>. For example, we may
      want to order the class by most to least common in the population
      so that the baseline class for the regression model is the most
      common class. One may also want to swap classes so that more
      visually similar pattern profiles are displayed together.</p>
      <p>To switch the order so the classes are ordered from most to
      least common, we specify
      <monospace>new_order = c(5, 2, 1, 4, 3)</monospace>. This will
      change the order so that all subsequent plotting functions will
      follow the new order, with the previously fifth class now
      displayed first. Individual class assignments will also follow the
      new order. That is, individuals who were previously assigned to
      class 5 will now be assigned to class 1, individuals who were
      previously class 1 will now be class 3, and individuals who were
      class 3 will now be class 5.</p>
      <code language="r script"># Reorder latent classes
res_swolca_adjust &lt;- reorder_classes(res = res_swolca_adjust, 
                                      new_order = c(5, 2, 1, 4, 3))
# Class assignments for first 3 individuals
res_swolca_adjust$estimates_adjust$c_all[1:3]</code>
      <preformat>[1] 3 2 2</preformat>
      <code language="r script"># Pattern profiles after reordering
plot_pattern_profiles(res = res_swolca_adjust, 
                      item_labels = item_labels, item_title = item_title,
                      categ_labels = categ_labels, categ_title = categ_title,
                      class_labels = class_labels, class_title = class_title)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="reorder_classes.png" />
    </sec>
    <sec id="display-distribution-of-additional-variables-across-classes">
      <title>Display distribution of additional variables across
      classes</title>
      <p>We can create a table to examine the distribution of additional
      variables across the derived classes by using the
      <monospace>vars_across_class()</monospace> function. For these
      distributions, the data are by default weighted, using the R
      <monospace>survey</monospace> package, so that the proportions are
      representative of the distribution of the variables across classes
      in the <italic>population</italic>. If desired, users can see the
      proportions in the <italic>sample</italic> by specifying
      <monospace>population = FALSE</monospace>.</p>
      <p>First, we define <monospace>c_all</monospace>, the
      <inline-formula><alternatives>
      <tex-math><![CDATA[n\times 1]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      factor vector of latent class assignments obtained from the
      <monospace>swolca()</monospace>, <monospace>wolca()</monospace>,
      <monospace>swolca_var_adjust()</monospace> or
      <monospace>wolca_var_adjust()</monospace> functions. Factor levels
      should be labeled with the names that are to appear in the output
      table.</p>
      <code language="r script"># Convert class assignment variable from model output to a factor
c_all &lt;- factor(res_swolca_adjust$estimates_adjust$c_all, 
                levels = 1:5, labels = paste0(&quot;C&quot;, 1:5))</code>
      <p>Next, we create dataframe <monospace>cov_df</monospace> that
      consists of <inline-formula><alternatives>
      <tex-math><![CDATA[n]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>n</mml:mi></mml:math></alternatives></inline-formula>
      rows containing sociodemographic variables age, race and
      ethnicity, physical activity, and smoking status. Factors should
      be labeled with the names and levels that are to appear in the
      output table.</p>
      <code language="r script"># Create dataframe containing covariates to view distribution across 
# classes, editing the labels for the variable names and levels 
cov_df &lt;- data_nhanes %&gt;%
  select(RIDAGEYR, age_cat, racethnic, smoker, physactive) %&gt;%
  rename(Age = RIDAGEYR) %&gt;%
  mutate(Age_Group = factor(age_cat, levels = c(1, 2, 3), 
                            labels = c(&quot;[20, 40)&quot;, &quot;[40, 60)&quot;, &quot;&gt;=60&quot;)),
         Race_Ethnicity = factor(racethnic, c(1, 2, 3, 4, 5),
                                 labels = c(&quot;NH White&quot;, &quot;NH Black&quot;, 
                                            &quot;NH Asian&quot;,&quot;Hispanic/Latino&quot;, 
                                            &quot;Other/Mixed&quot;)),
         Current_Smoker = factor(smoker, levels = c(0, 1), 
                                 labels = c(&quot;No&quot;, &quot;Yes&quot;)),
         Physical_Activity = factor(physactive, 
                                    levels = c(&quot;Inactive&quot;, &quot;Active&quot;)),
         .keep = &quot;unused&quot;)</code>
      <p>Finally, we create a table of the distribution of age, race and
      ethnicity, physical activity, and smoking status in the population
      across five derived dietary patterns. We include the survey design
      variables (<monospace>sampling_wt</monospace>,
      <monospace>cluster_id</monospace>,
      <monospace>stratum_id</monospace>), which are accounted for. We
      want factor variables to have percentages reported as column
      totals (<monospace>col_props = TRUE</monospace>), displaying the
      population percentage in each category for a given class. If
      <monospace>FALSE</monospace>, row totals are used instead and
      display the population percentage in each class for a given
      category. We also specify that we want the output to be rounded to
      the first decimal (<monospace>digits = 1</monospace>).</p>
      <p>The first row of the table is the proportion of the classes in
      the population. This is calculated using estimates of
      <inline-formula><alternatives>
      <tex-math><![CDATA[\pi]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
      from <monospace>swolca_var_adjust()</monospace> to obtain the
      estimated percentage of individuals falling into each class in the
      population, accounting for survey design. The second row is the
      distribution of the classes in the sample.</p>
      <code language="r script"># Obtain table displaying distribution of variables across classes
output_df &lt;- vars_across_class(c_all = c_all, cov_df = cov_df, 
                              sampling_wt = sampling_wt, 
                              stratum_id = stratum_id, 
                              cluster_id = cluster_id, digits = 1, 
                              col_props = TRUE, res = res_swolca_adjust)
View(output_df)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="vars_across_class.png" />
    </sec>
    <sec id="summarize-and-plot-the-exposure-outcome-relationship">
      <title>Summarize and plot the exposure-outcome
      relationship</title>
      <p>To examine how the latent classes relate to the binary outcome
      of interest, we can display a summary of the parameter estimates
      by using <monospace>get_regr_coefs()</monospace>. For the one-step
      method (Option 2) that uses the output from
      <monospace>swolca()</monospace> or
      <monospace>swolca_var_adjust()</monospace>, this will convert the
      probit regression coefficients from factor reference coding to the
      more commonly used reference cell coding. One advantage of factor
      reference coding is it allows the reference class to be determined
      post-hoc, so any class can be chosen as the reference level for
      which to display regression coefficients without having to re-run
      the model. Simply run <monospace>reorder_classes()</monospace>
      with the desired reference level as the first class in
      <monospace>new_order</monospace>, and then run
      <monospace>get_regr_coefs()</monospace> as shown below.</p>
      <p>For the two-step method (Option 1) that uses the output from
      <monospace>wolca_svyglm()</monospace>, the results will already be
      in reference cell coding. For this approach, changes to the
      reference class should be done by re-running the regression model
      with the desired reference level refactoring.</p>
      <p>In this example, we display a summary of the probit regression
      coefficients using class 1 as the reference. We also display the
      95% credible intervals (<monospace>ci_level = 0.95</monospace>)
      and round the table values to two decimal points
      (<monospace>digits = 2</monospace>). To save space, we only
      display the first 10 regression coefficients in the output.</p>
      <p>The output shows the posterior median estimates, the lower and
      upper bounds of the credible intervals, and the posterior
      probability of the estimate being greater than 0. A posterior
      probability greater than 0.975 shows strong evidence for the
      estimate being positive, and a posterior probability less than
      0.025 shows strong evidence for the estimate being negative. If
      using the two-step (Option 1) method with
      <monospace>wolca_svyglm()</monospace> output, a p-value will be
      shown in the last column instead.</p>
      <code language="r script"># Get table of regression coefficients
regr_coefs &lt;- get_regr_coefs(res = res_swolca_adjust, ci_level = 0.95, 
                             digits = 2)
regr_coefs[1:10, ]</code>
      <preformat>     Covariate Estimate    LB    UB P(xi &gt; 0)
1  (Intercept)    -1.22 -1.94 -0.77     &lt;0.01
2       c_all2    -0.08 -1.01  0.71      0.44
3       c_all3     0.52 -0.78  1.90      0.76
4       c_all4     0.14 -1.15  1.73      0.62
5       c_all5    -0.19 -5.52  1.23      0.38
6     age_cat2     1.11  0.21  1.85      0.98
7     age_cat3     2.07  1.29  3.80      1.00
8   racethnic2     0.31 -0.48  0.85      0.86
9   racethnic3     0.05 -1.28  1.15      0.52
10  racethnic4    -0.15 -0.66  0.57      0.26</preformat>
      <p>To visualize the regression coefficients in the form of a
      boxplot, use the <monospace>plot_regr_coefs()</monospace>
      function. We rename the covariate labels to more interpretable
      names using the <monospace>cov_labels</monospace> argument. We can
      also modify other aspects of the plot, such as moving the legend
      position, by using typical arguments from the
      <monospace>ggplot2</monospace> package.</p>
      <code language="r script"># Rename covariate labels
K &lt;- res_swolca_adjust$estimates$K_red
class_dummies &lt;- paste0(&quot;C&quot;, 2:K)
age_dummies &lt;- paste0(&quot;Age&quot;, c(&quot;40_60&quot;, &quot;60&quot;))
race_dummies &lt;- paste0(&quot;RaceEth&quot;, c(&quot;NH_Black&quot;, &quot;NH_Asian&quot;, &quot;Hisp&quot;, &quot;Other&quot;))
cov_labels &lt;- c(&quot;Intercept&quot;, class_dummies, age_dummies, race_dummies,
                &quot;SmokerYes&quot;, &quot;PhysActive&quot;,
                paste0(class_dummies, &quot;:&quot;, rep(age_dummies, each = (K - 1))),
                paste0(class_dummies, &quot;:&quot;, rep(race_dummies, each = (K - 1))),
                paste0(class_dummies, &quot;:&quot;, rep(&quot;SmokerYes&quot;, each = (K - 1))),
                paste0(class_dummies, &quot;:&quot;, rep(&quot;PhysActive&quot;, each = (K - 1))))

# Get plot of regression coefficient estimates and error bars
regr_plot &lt;- plot_regr_coefs(regr_coefs = regr_coefs, 
                             res = res_swolca_adjust, 
                             cov_labels = cov_labels)
# Display plot with legend above
regr_plot + ggplot2::theme(legend.position = &quot;top&quot;)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_regr_coefs.png" />
      <p>Alternatively, for categorical covariates, rather than plotting
      the regression coefficients, we can evaluate the probit regression
      model at all levels of the covariate and then plot the conditional
      probability of the outcome using the
      <monospace>plot_outcome_probs()</monospace> function. This
      displays the probability of the outcome for the different classes,
      evaluated at all levels of a categorical covariate, with all other
      covariates evaluated at their reference level. In this example, we
      plot the probability of hypertension for the five dietary patterns
      across levels of age, with error bars for the 95% credible
      intervals.</p>
      <code language="r script"># Cluster labels
class_labels &lt;- paste0(&quot;C&quot;, 1:5) 
# Age covariate labels
age_cat_categs &lt;- c(&quot;[20,40)&quot;, &quot;[40,60)&quot;, &quot;&gt;=60&quot;) 
# Plot conditional outcome probabilities
plot_outcome_probs(res = res_swolca_adjust, cov_name = &quot;age_cat&quot;,
                   cov_labels = age_cat_categs, class_labels = class_labels, 
                   x_title = &quot;Age Group&quot;)</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_outcome_probs.png" />
      <p>We can also display the probability of outcome plots for two
      categorical covariates at the same time, assessing for any
      interactions. We can add lines connecting the points between
      levels of “Age” using the <monospace>add_lines = TRUE</monospace>
      parameter, and remove the error bars by setting
      <monospace>ci_level = NULL</monospace>.</p>
      <code language="r script"># Race and ethnicity covariate labels
racethnic_categs &lt;- c(&quot;NH White&quot;, &quot;NH Black&quot;, &quot;NH Asian&quot;, &quot;Hispanic/Latino&quot;, 
                      &quot;Other/Mixed&quot;)
# Plot two categorical covariate outcome probabilites simultaneously
p &lt;- plot_outcome_probs(res = res_swolca_adjust, 
                        cov_name = c(&quot;age_cat&quot;, &quot;racethnic&quot;),
                        cov_labels = list(age_cat_categs, racethnic_categs), 
                        class_labels = class_labels, x_title = &quot;Age Group&quot;, 
                        ci_level = NULL, add_lines = TRUE)
print(p + ggplot2::theme(axis.text.x = ggplot2::element_text(size = 9)))</code>
      <graphic mimetype="image" mime-subtype="png" xlink:href="plot_outcome_probs_two.png" />
    </sec>
  </sec>
  <sec id="diagnostics">
    <title>5. Performance diagnostics</title>
    <p>Total model runtime and the deviance information criteria (DIC)
    goodness-of-fit measure for model selection are available within the
    package using the following functions. Smaller values of DIC
    indicate better fit. See function documentation for more
    information.</p>
    <code language="r script"># Runtime
res_swolca_adjust$runtime</code>
    <preformat>Time difference of 8.722689 mins</preformat>
    <code language="r script"># Deviance information criteria for model goodness-of-fit
get_dic(res_swolca_adjust)</code>
    <preformat>[1] 124746.9</preformat>
    <p>A list of the raw posterior point and interval estimates for all
    parameters can be obtained. We set a credible interval level of 95%
    and round the estimates to two digits. The possible parameters
    consist of:</p>
    <list list-type="bullet">
      <list-item>
        <p><inline-formula><alternatives>
        <tex-math><![CDATA[\pi_1,\ldots, \pi_K]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
        latent class membership probabilities for each of the
        <inline-formula><alternatives>
        <tex-math><![CDATA[K]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>
        underlying classes. <inline-formula><alternatives>
        <tex-math><![CDATA[\pi]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
        parameters are returned in a vector of length
        <inline-formula><alternatives>
        <tex-math><![CDATA[K]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>.</p>
      </list-item>
      <list-item>
        <p><inline-formula><alternatives>
        <tex-math><![CDATA[\theta_{jk1}, \ldots, \theta_{jkR_j}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
        exposure level probabilities ranging from 1 to
        <inline-formula><alternatives>
        <tex-math><![CDATA[R_j]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        where <inline-formula><alternatives>
        <tex-math><![CDATA[R_j]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
        is the number of exposure levels for item
        <inline-formula><alternatives>
        <tex-math><![CDATA[j]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>j</mml:mi></mml:math></alternatives></inline-formula>
        out of a total of <inline-formula><alternatives>
        <tex-math><![CDATA[J]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>J</mml:mi></mml:math></alternatives></inline-formula>
        items, and <inline-formula><alternatives>
        <tex-math><![CDATA[k=1,\ldots, K]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.
        <inline-formula><alternatives>
        <tex-math><![CDATA[\theta]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>
        parameters are returned in a <inline-formula><alternatives>
        <tex-math><![CDATA[JxKxR]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>J</mml:mi><mml:mi>x</mml:mi><mml:mi>K</mml:mi><mml:mi>x</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>-dimensional
        array.</p>
      </list-item>
      <list-item>
        <p><inline-formula><alternatives>
        <tex-math><![CDATA[\xi_{k1}, \ldots, \xi_{kQ}]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
        coefficients in the binary outcome probit regression with
        <inline-formula><alternatives>
        <tex-math><![CDATA[Q]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Q</mml:mi></mml:math></alternatives></inline-formula>
        covariates. <inline-formula><alternatives>
        <tex-math><![CDATA[\xi]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ξ</mml:mi></mml:math></alternatives></inline-formula>
        parameters are returned in a <inline-formula><alternatives>
        <tex-math><![CDATA[KxQ]]></tex-math>
        <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>K</mml:mi><mml:mi>x</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>-dimensional
        matrix.</p>
      </list-item>
    </list>
    <p>Thus, a total of <inline-formula><alternatives>
    <tex-math><![CDATA[K + (J*K*R) + (K*Q) = 610]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>J</mml:mi><mml:mo>*</mml:mo><mml:mi>K</mml:mi><mml:mo>*</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>K</mml:mi><mml:mo>*</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mn>610</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    estimates are available for this SWOLCA example, listed in order of
    <inline-formula><alternatives>
    <tex-math><![CDATA[\pi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>,
    then <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>,
    then <inline-formula><alternatives>
    <tex-math><![CDATA[\xi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ξ</mml:mi></mml:math></alternatives></inline-formula>.
    To conserve space, we only display the first three estimates for
    <inline-formula><alternatives>
    <tex-math><![CDATA[\pi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>,
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\xi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ξ</mml:mi></mml:math></alternatives></inline-formula>
    here. <inline-formula><alternatives>
    <tex-math><![CDATA[\pi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
    estimates are labeled with “pi_k”, <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>
    estimates are labeled with “theta_j_k_r”, and
    <inline-formula><alternatives>
    <tex-math><![CDATA[\xi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ξ</mml:mi></mml:math></alternatives></inline-formula>
    estimates are labeled with “xi_k_q”. <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>
    ranges from 1 to <inline-formula><alternatives>
    <tex-math><![CDATA[K]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[j]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>j</mml:mi></mml:math></alternatives></inline-formula>
    from 1 to <inline-formula><alternatives>
    <tex-math><![CDATA[J]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>J</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[r]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>r</mml:mi></mml:math></alternatives></inline-formula>
    from 1 to <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>,
    and <inline-formula><alternatives>
    <tex-math><![CDATA[q]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>q</mml:mi></mml:math></alternatives></inline-formula>
    from 1 to <inline-formula><alternatives>
    <tex-math><![CDATA[Q]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Q</mml:mi></mml:math></alternatives></inline-formula>.</p>
    <code language="r script"># Extract summary of parameter estimates
estimates_df &lt;- summarize_res(res = res_swolca_adjust, ci_level = 0.95, 
                              digits = 2)
# First few pi estimates
estimates_df[1:3, ]</code>
    <preformat>  Parameter Estimate Lower Bound Upper Bound
1      pi_1     0.26        0.02        0.32
2      pi_2     0.25        0.03        0.31
3      pi_3     0.20        0.03        0.73</preformat>
    <code language="r script"># First few theta estimates
estimates_df[6:9, ]</code>
    <preformat>    Parameter Estimate Lower Bound Upper Bound
6 theta_1_1_1     0.64        0.52        0.81
7 theta_2_1_1     0.44        0.27        0.66
8 theta_3_1_1     0.44        0.37        0.50
9 theta_4_1_1     0.58        0.41        0.74</preformat>
    <code language="r script"># First few xi estimates
estimates_df[566:569, ]</code>
    <preformat>    Parameter Estimate Lower Bound Upper Bound
566    xi_1_1    -1.22       -1.94       -0.77
567    xi_2_1    -1.27       -2.89       -0.26
568    xi_3_1    -0.76       -1.79        0.25
569    xi_4_1    -1.09       -1.99        0.07</preformat>
    <p>We can also extract the MCMC iteration values for all parameters
    that were obtained through the MCMC sampler. For SWOLCA, this will
    be <inline-formula><alternatives>
    <tex-math><![CDATA[\pi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>,
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\xi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>ξ</mml:mi></mml:math></alternatives></inline-formula>.
    For WOLCA, this will be only <inline-formula><alternatives>
    <tex-math><![CDATA[\pi]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\theta]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>θ</mml:mi></mml:math></alternatives></inline-formula>.</p>
    <code language="r script"># Extract parameter MCMC iteration values
param_mcmc &lt;- get_param_mcmc(res_swolca_adjust)
# Display first 10 iterations of pi
param_mcmc$pi_mcmc[1:10, ]</code>
    <preformat>         pi_1      pi_2       pi_3      pi_4       pi_5
1  0.21404681 0.2711999 0.07060048 0.1909269 0.25322591
2  0.22903296 0.2661842 0.28179132 0.1814540 0.04153747
3  0.25255569 0.2535889 0.31593950 0.1495266 0.02838934
4  0.21749612 0.2915196 0.27117051 0.1896920 0.03012178
5  0.29684094 0.3192869 0.15172239 0.1643078 0.06784196
6  0.21846102 0.1808988 0.43656612 0.1439221 0.02015193
7  0.01116411 0.1098699 0.41500674 0.2052747 0.25868460
8  0.16876390 0.3169399 0.11467908 0.3135302 0.08608692
9  0.25304563 0.2567038 0.27085077 0.1733324 0.04606740
10 0.25843459 0.2335444 0.18879545 0.2410795 0.07814612</preformat>
    <p>Bayesian model diagnostics such as traceplots and autocorrelation
    plots can be created for all estimates to examine whether the MCMC
    sampler has adequately converged. For example, we display code to
    create traceplots and autocorrelation plots for the five class
    membership probability parameters, <inline-formula><alternatives>
    <tex-math><![CDATA[\pi_1,\ldots, \pi_5]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <code language="r script"># Specify selection of pi_1 to pi_5
param_names &lt;- colnames(param_mcmc$pi_mcmc)
# Create traceplots
create_traceplot(param_mcmc = param_mcmc, param_names = param_names)</code>
    <graphic mimetype="image" mime-subtype="png" xlink:href="create_traceplot.png" />
    <code language="r script"># Create ACF plots
create_acfplot(param_mcmc = param_mcmc, param_names = param_names)</code>
    <graphic mimetype="image" mime-subtype="png" xlink:href="create_acfplot.png" />
  </sec>
</sec>
<sec id="acknowledgement">
  <title>Acknowledgement</title>
  <p>This work was supported in part by the National Institute of
  Allergy and Infectious Diseases (NIAID: T32 AI007358), the National
  Heart, Lung, and Blood Institute (NHLBI: R25 HL105400), and the
  Harvard Data Science Initiative <inline-formula><alternatives>
  <tex-math><![CDATA[\text{Bias}^2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mtext mathvariant="normal">Bias</mml:mtext><mml:mn>2</mml:mn></mml:msup></mml:math></alternatives></inline-formula>
  Program. The authors declare no conflicts of interest.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-stephenson2020empirically">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stephenson</surname><given-names>Briana JK</given-names></name>
        <name><surname>Sotres-Alvarez</surname><given-names>Daniela</given-names></name>
        <name><surname>Siega-Riz</surname><given-names>Anna-Maria</given-names></name>
        <name><surname>Mossavar-Rahmani</surname><given-names>Yasmin</given-names></name>
        <name><surname>Daviglus</surname><given-names>Martha L</given-names></name>
        <name><surname>Van Horn</surname><given-names>Linda</given-names></name>
        <name><surname>Herring</surname><given-names>Amy H</given-names></name>
        <name><surname>Cai</surname><given-names>Jianwen</given-names></name>
      </person-group>
      <article-title>Empirically derived dietary patterns using robust profile clustering in the hispanic community health study/study of latinos</article-title>
      <source>The Journal of Nutrition</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>150</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1093/jn/nxaa208</pub-id>
      <fpage>2825</fpage>
      <lpage>2834</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lanza2016latent">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lanza</surname><given-names>Stephanie T</given-names></name>
        <name><surname>Cooper</surname><given-names>Brittany R</given-names></name>
      </person-group>
      <article-title>Latent class analysis for developmental research</article-title>
      <source>Child Development Perspectives</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>10</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1111/cdep.12163</pub-id>
      <fpage>59</fpage>
      <lpage>64</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nchs2023homepage">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>National Center for Health Statistics</string-name>
      </person-group>
      <article-title>National health and nutrition examination survey home page</article-title>
      <publisher-name>Centers for Disease Control; Prevention, National Center for Health Statistics, Atlanta, GA</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.cdc.gov/nchs/nhanes.htm</uri>
    </element-citation>
  </ref>
  <ref id="ref-wu2024derivation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wu</surname><given-names>Stephanie M</given-names></name>
        <name><surname>Williams</surname><given-names>Matthew R</given-names></name>
        <name><surname>Savitsky</surname><given-names>Terrance D</given-names></name>
        <name><surname>Stephenson</surname><given-names>Briana JK</given-names></name>
      </person-group>
      <article-title>Derivation of outcome-dependent dietary patterns for low-income women obtained from survey data using a supervised weighted overfitted latent class analysis</article-title>
      <source>Biometrics</source>
      <publisher-name>Oxford University Press</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <volume>80</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1093/biomtc/ujae122</pub-id>
      <fpage>ujae122</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-stephenson2023identifying">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stephenson</surname><given-names>Briana JK</given-names></name>
        <name><surname>Wu</surname><given-names>Stephanie M</given-names></name>
        <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
      </person-group>
      <article-title>Identifying dietary consumption patterns from survey data: a Bayesian nonparametric latent class model</article-title>
      <source>Journal of the Royal Statistical Society Series A: Statistics in Society</source>
      <year iso-8601-date="2023-12">2023</year><month>12</month>
      <issn>0964-1998</issn>
      <uri>https://doi.org/10.1093/jrsssa/qnad135</uri>
      <pub-id pub-id-type="doi">10.1093/jrsssa/qnad135</pub-id>
      <fpage>qnad135</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-lumley2004analysis">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lumley</surname><given-names>Thomas</given-names></name>
      </person-group>
      <article-title>Analysis of complex survey samples</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2004">2004</year>
      <volume>9</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v009.i08</pub-id>
      <fpage>1</fpage>
      <lpage>19</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2017performance">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Meng-Cheng</given-names></name>
        <name><surname>Deng</surname><given-names>Qiaowen</given-names></name>
        <name><surname>Bi</surname><given-names>Xiangyang</given-names></name>
        <name><surname>Ye</surname><given-names>Haosheng</given-names></name>
        <name><surname>Yang</surname><given-names>Wendeng</given-names></name>
      </person-group>
      <article-title>Performance of the entropy as an index of classification accuracy in latent profile analysis: A monte carlo simulation study.</article-title>
      <source>Acta Psychologica Sinica</source>
      <publisher-name>Science Press</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.3724/SP.J.1041.2017.01473</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-muthen2000integrating">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Muthén</surname><given-names>Bengt</given-names></name>
        <name><surname>Muthén</surname><given-names>Linda K</given-names></name>
      </person-group>
      <article-title>Integrating person-centered and variable-centered analyses: Growth mixture modeling with latent trajectory classes</article-title>
      <source>Alcoholism: Clinical and experimental research</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2000">2000</year>
      <volume>24</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1111/j.1530-0277.2000.tb02070.x</pub-id>
      <fpage>882</fpage>
      <lpage>891</lpage>
    </element-citation>
  </ref>
  <ref id="ref-weller2020latent">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weller</surname><given-names>Bridget E</given-names></name>
        <name><surname>Bowen</surname><given-names>Natasha K</given-names></name>
        <name><surname>Faubert</surname><given-names>Sarah J</given-names></name>
      </person-group>
      <article-title>Latent class analysis: A guide to best practice</article-title>
      <source>Journal of Black Psychology</source>
      <publisher-name>Sage Publications Sage CA: Los Angeles, CA</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>46</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1177/0095798420930932</pub-id>
      <fpage>287</fpage>
      <lpage>311</lpage>
    </element-citation>
  </ref>
  <ref id="ref-nylund2019prediction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nylund-Gibson</surname><given-names>Karen</given-names></name>
        <name><surname>Grimm</surname><given-names>Ryan P</given-names></name>
        <name><surname>Masyn</surname><given-names>Katherine E</given-names></name>
      </person-group>
      <article-title>Prediction from latent classes: A demonstration of different approaches to include distal outcomes in mixture models</article-title>
      <source>Structural equation modeling: A multidisciplinary Journal</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>26</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1080/10705511.2019.1590146</pub-id>
      <fpage>967</fpage>
      <lpage>985</lpage>
    </element-citation>
  </ref>
  <ref id="ref-linzer2011polca">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Linzer</surname><given-names>Drew A</given-names></name>
        <name><surname>Lewis</surname><given-names>Jeffrey B</given-names></name>
      </person-group>
      <article-title>poLCA: An r package for polytomous variable latent class analysis</article-title>
      <source>Journal of statistical software</source>
      <year iso-8601-date="2011">2011</year>
      <volume>42</volume>
      <pub-id pub-id-type="doi">10.18637/jss.v042.i10</pub-id>
      <fpage>1</fpage>
      <lpage>29</lpage>
    </element-citation>
  </ref>
  <ref id="ref-beath2017randomlca">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Beath</surname><given-names>Ken J</given-names></name>
      </person-group>
      <article-title>randomLCA: An r package for latent class with random effects analysis</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2017">2017</year>
      <volume>81</volume>
      <pub-id pub-id-type="doi">10.18637/jss.v081.i13</pub-id>
      <fpage>1</fpage>
      <lpage>25</lpage>
    </element-citation>
  </ref>
  <ref id="ref-scrucca2023model">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Scrucca</surname><given-names>Luca</given-names></name>
        <name><surname>Fraley</surname><given-names>Chris</given-names></name>
        <name><surname>Murphy</surname><given-names>T Brendan</given-names></name>
        <name><surname>Raftery</surname><given-names>Adrian E</given-names></name>
      </person-group>
      <source>Model-based clustering, classification, and density estimation using mclust in r</source>
      <publisher-name>Chapman; Hall/CRC</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1201/9781003277965</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-rosenberg2019tidylpa">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rosenberg</surname><given-names>Joshua M</given-names></name>
        <name><surname>Beymer</surname><given-names>Patrick N</given-names></name>
        <name><surname>Anderson</surname><given-names>Daniel J</given-names></name>
        <name><surname>Van Lissa</surname><given-names>CJ</given-names></name>
        <name><surname>Schmidt</surname><given-names>Jennifer A</given-names></name>
      </person-group>
      <article-title>tidyLPA: An r package to easily carry out latent profile analysis (LPA) using open-source or commercial software</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2019">2019</year>
      <volume>3</volume>
      <issue>30</issue>
      <pub-id pub-id-type="doi">10.21105/joss.00978</pub-id>
      <fpage>978</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-white2014bayeslca">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>White</surname><given-names>Arthur</given-names></name>
        <name><surname>Murphy</surname><given-names>Thomas Brendan</given-names></name>
      </person-group>
      <article-title>BayesLCA: An r package for bayesian latent class analysis</article-title>
      <publisher-name>Foundation for Open Access Statistics</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <pub-id pub-id-type="doi">10.18637/jss.v061.i13</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-papastamoulis2017bayesbinmix">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Papastamoulis</surname><given-names>Panagiotis</given-names></name>
        <name><surname>Rattray</surname><given-names>Magnus</given-names></name>
      </person-group>
      <article-title>BayesBinMix: An r package for model based clustering of multivariate binary data.</article-title>
      <source>R J.</source>
      <year iso-8601-date="2017">2017</year>
      <volume>9</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.32614/RJ-2017-022</pub-id>
      <fpage>403</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-liverani2015premium">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Liverani</surname><given-names>Silvia</given-names></name>
        <name><surname>Hastie</surname><given-names>David I</given-names></name>
        <name><surname>Azizi</surname><given-names>Lamiae</given-names></name>
        <name><surname>Papathomas</surname><given-names>Michail</given-names></name>
        <name><surname>Richardson</surname><given-names>Sylvia</given-names></name>
      </person-group>
      <article-title>PReMiuM: An r package for profile regression mixture models using dirichlet processes</article-title>
      <source>Journal of statistical software</source>
      <publisher-name>Europe PMC Funders</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>64</volume>
      <issue>7</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v064.i07</pub-id>
      <fpage>1</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
