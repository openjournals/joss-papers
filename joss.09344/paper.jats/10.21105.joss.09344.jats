<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">9344</article-id>
<article-id pub-id-type="doi">10.21105/joss.09344</article-id>
<title-group>
<article-title>RegularizedOptimization.jl: A Julia framework for
regularized and nonsmooth optimization</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6609-7330</contrib-id>
<name>
<surname>Diouane</surname>
<given-names>Youssef</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-3158-7912</contrib-id>
<name>
<surname>Gollier</surname>
<given-names>Maxence</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0005-3631-2799</contrib-id>
<name>
<surname>Habiboullah</surname>
<given-names>Mohamed Laghdaf</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-2"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8017-7687</contrib-id>
<name>
<surname>Orban</surname>
<given-names>Dominique</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>GERAD and Department of Mathematics and Industrial
Engineering, Polytechnique Montréal, QC, Canada</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
<corresp id="cor-2">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-09-01">
<day>1</day>
<month>9</month>
<year>2025</year>
</pub-date>
<volume>11</volume>
<issue>118</issue>
<fpage>9344</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>nonsmooth optimization</kwd>
<kwd>nonconvex optimization</kwd>
<kwd>regularization methods</kwd>
<kwd>trust-region methods</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl">RegularizedOptimization.jl</ext-link>
  is a Julia package that implements families of quadratic
  regularization and trust-region methods for solving the nonsmooth
  optimization problem
  <named-content id="eqU003Anlp" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
      \underset{x \in \mathbb{R}^n}{\text{minimize}} \quad f(x) + h(x) \quad \text{subject to} \quad c(x) = 0,]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:munder><mml:mtext mathvariant="normal">minimize</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:munder><mml:mspace width="1.0em"></mml:mspace><mml:mi>f</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mspace width="1.0em"></mml:mspace><mml:mtext mathvariant="normal">subject to</mml:mtext><mml:mspace width="1.0em"></mml:mspace><mml:mi>c</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></named-content>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[f: \mathbb{R}^n \to \mathbb{R}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mi>ℝ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[c: \mathbb{R}^n \to \mathbb{R}^m]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>c</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
  are continuously differentiable, and <inline-formula><alternatives>
  <tex-math><![CDATA[h: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>h</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mi>ℝ</mml:mi><mml:mo>∪</mml:mo><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mi>+</mml:mi><mml:mi>∞</mml:mi><mml:mo stretchy="false" form="postfix">}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
  is lower semi-continuous. The nonsmooth objective
  <inline-formula><alternatives>
  <tex-math><![CDATA[h]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>
  can be a <italic>regularizer</italic>, such as a sparsity-inducing
  penalty, model simple constraints, such as
  <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  belonging to a simple convex set, or be a combination of both. All
  <inline-formula><alternatives>
  <tex-math><![CDATA[f]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[h]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[c]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>c</mml:mi></mml:math></alternatives></inline-formula>
  can be nonconvex. RegularizedOptimization.jl provides a modular and
  extensible framework for solving
  <xref alt="1" rid="eqU003Anlp">1</xref>, and developing novel solvers.
  Currently, the following solvers are implemented:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Trust-region solvers TR and TRDH</bold>
      (<xref alt="Aravkin et al., 2022" rid="ref-aravkin-baraldi-orban-2022" ref-type="bibr">Aravkin
      et al., 2022</xref>;
      <xref alt="Leconte &amp; Orban, 2025" rid="ref-leconte-orban-2023" ref-type="bibr">Leconte
      &amp; Orban, 2025</xref>)</p>
    </list-item>
    <list-item>
      <p><bold>Quadratic regularization solvers R2, R2DH and R2N</bold>
      (<xref alt="Aravkin et al., 2022" rid="ref-aravkin-baraldi-orban-2022" ref-type="bibr">Aravkin
      et al., 2022</xref>;
      <xref alt="Diouane, Habiboullah, et al., 2024" rid="ref-diouane-habiboullah-orban-2024" ref-type="bibr">Diouane,
      Habiboullah, et al., 2024</xref>)</p>
    </list-item>
    <list-item>
      <p><bold>Levenberg-Marquardt solvers LM and LMTR</bold>
      (<xref alt="Aravkin et al., 2024" rid="ref-aravkin-baraldi-orban-2024" ref-type="bibr">Aravkin
      et al., 2024</xref>) used when <inline-formula><alternatives>
      <tex-math><![CDATA[f]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
      is a least-squares residual.</p>
    </list-item>
    <list-item>
      <p><bold>Augmented Lagrangian solver AL</bold>
      (<xref alt="De Marchi et al., 2023" rid="ref-demarchi-jia-kanzow-mehlitz-2023" ref-type="bibr">De
      Marchi et al., 2023</xref>).</p>
    </list-item>
  </list>
  <p>All solvers rely on first derivatives of
  <inline-formula><alternatives>
  <tex-math><![CDATA[f]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[c]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>c</mml:mi></mml:math></alternatives></inline-formula>,
  and optionally on their second derivatives in the form of
  Hessian-vector products. If second derivatives are not available,
  quasi-Newton approximations can be used. In addition, the proximal
  mapping of the nonsmooth part <inline-formula><alternatives>
  <tex-math><![CDATA[h]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>,
  or adequate models thereof, must be evaluated. At each iteration, a
  step is computed by solving a subproblem of the form
  <xref alt="1" rid="eqU003Anlp">1</xref> inexactly, in which
  <inline-formula><alternatives>
  <tex-math><![CDATA[f]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[h]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>,
  and <inline-formula><alternatives>
  <tex-math><![CDATA[c]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>c</mml:mi></mml:math></alternatives></inline-formula>
  are replaced with appropriate models around the current iterate. The
  solvers R2, R2DH and TRDH are particularly well suited to solve the
  subproblems, though they are general enough to solve
  <xref alt="1" rid="eqU003Anlp">1</xref>. All solvers are
  allocation-free, so re-solves incur no additional allocations. To
  illustrate our claim of extensibility, a first version of the AL
  solver was implemented by an external contributor. Furthermore, a
  nonsmooth penalty approach, described in
  (<xref alt="Diouane, Gollier, et al., 2024" rid="ref-diouane-gollier-orban-2024" ref-type="bibr">Diouane,
  Gollier, et al., 2024</xref>), is currently being developed, that
  relies on the library to efficiently solve the subproblems.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <sec id="model-based-framework-for-nonsmooth-methods">
    <title>Model-based framework for nonsmooth methods</title>
    <p>In Julia, <xref alt="1" rid="eqU003Anlp">1</xref> can be solved
    using
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaFirstOrder/ProximalAlgorithms.jl">ProximalAlgorithms.jl</ext-link>,
    which implements splitting schemes and line-search–based methods
    (<xref alt="Stella et al., 2017" rid="ref-stella-themelis-sopasakis-patrinos-2017" ref-type="bibr">Stella
    et al., 2017</xref>;
    <xref alt="Themelis et al., 2018" rid="ref-themelis-stella-patrinos-2017" ref-type="bibr">Themelis
    et al., 2018</xref>). Among others, the <bold>PANOC</bold>
    (<xref alt="Stella et al., 2017" rid="ref-stella-themelis-sopasakis-patrinos-2017" ref-type="bibr">Stella
    et al., 2017</xref>) solver takes a step along a direction
    <inline-formula><alternatives>
    <tex-math><![CDATA[d]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>d</mml:mi></mml:math></alternatives></inline-formula>,
    which depends on the L-BFGS quasi-Newton approximation of
    <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>,
    followed by proximal steps on <inline-formula><alternatives>
    <tex-math><![CDATA[h]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>.</p>
    <p>By contrast,
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl">RegularizedOptimization.jl</ext-link>
    focuses on model-based trust-region and quadratic regularization
    methods, which typically require fewer evaluations of
    <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
    and its gradient than first-order line search methods, at the
    expense of more evaluations of proximal operators
    (<xref alt="Aravkin et al., 2022" rid="ref-aravkin-baraldi-orban-2022" ref-type="bibr">Aravkin
    et al., 2022</xref>). However, each proximal computation is
    inexpensive for numerous commonly used choices of
    <inline-formula><alternatives>
    <tex-math><![CDATA[h]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>,
    such as separable penalties and bound constraints, so that the
    overall approach is efficient for large-scale problems.</p>
    <p>RegularizedOptimization.jl provides an API to formulate
    optimization problems and apply different solvers. It integrates
    seamlessly with the
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers">JuliaSmoothOptimizers</ext-link>
    (<xref alt="Migot et al., 2021" rid="ref-jso" ref-type="bibr">Migot
    et al., 2021</xref>) ecosystem.</p>
    <p>The smooth objective <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
    can be defined via
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl">NLPModels.jl</ext-link>
    (<xref alt="Orban et al., 2020" rid="ref-orban-siqueira-nlpmodels-2020" ref-type="bibr">Orban
    et al., 2020</xref>), which provides a standardized Julia API for
    representing nonlinear programming (NLP) problems. The nonsmooth
    term <inline-formula><alternatives>
    <tex-math><![CDATA[h]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>
    can be modeled using
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/ProximalOperators.jl">ProximalOperators.jl</ext-link>.</p>
    <p>Given <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[h]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>h</mml:mi></mml:math></alternatives></inline-formula>,
    the companion package
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/RegularizedProblems.jl">RegularizedProblems.jl</ext-link>
    provides a way to pair them into a <italic>Regularized Nonlinear
    Programming Model</italic></p>
    <code language="julia">reg_nlp = RegularizedNLPModel(f, h)</code>
    <p>They can also be paired into a <italic>Regularized Nonlinear
    Least-Squares Model</italic>, used by the <bold>LM</bold> and
    <bold>LMTR</bold> solvers, if <inline-formula><alternatives>
    <tex-math><![CDATA[f(x) = \tfrac{1}{2} \|F(x)\|^2]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:msup><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
    for some residual <inline-formula><alternatives>
    <tex-math><![CDATA[F: \mathbb{R}^n \to \mathbb{R}^m]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>F</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <code language="julia">reg_nls = RegularizedNLSModel(F, h)</code>
    <p>RegularizedProblems.jl also provides a set of instances commonly
    used in data science and in nonsmooth optimization, where several
    choices of <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
    can be paired with various regularizers. This design makes for a
    convenient source of problem instances for benchmarking the solvers
    in
    <ext-link ext-link-type="uri" xlink:href="https://www.github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl">RegularizedOptimization.jl</ext-link>.</p>
  </sec>
  <sec id="support-for-both-exact-and-approximate-hessian">
    <title>Support for both exact and approximate Hessian</title>
    <p>In contrast to
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaFirstOrder/ProximalAlgorithms.jl">ProximalAlgorithms.jl</ext-link>,
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl">RegularizedOptimization.jl</ext-link>
    methods such as <bold>R2N</bold> and <bold>TR</bold> support exact
    Hessians as well as several Hessian approximations of
    <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>.
    Hessian–vector products <inline-formula><alternatives>
    <tex-math><![CDATA[v \mapsto Hv]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>v</mml:mi><mml:mo>↦</mml:mo><mml:mi>H</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    can be obtained via automatic differentiation through
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl">ADNLPModels.jl</ext-link>
    or implemented manually. Limited-memory and diagonal quasi-Newton
    approximations can be selected from
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</ext-link>.
    This design allows solvers to exploit second-order information
    without explicitly forming dense or sparse Hessians, which is often
    expensive in time and memory, particularly at large scale.</p>
  </sec>
</sec>
<sec id="example">
  <title>Example</title>
  <p>We illustrate the capabilities of
  <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/RegularizedOptimization.jl">RegularizedOptimization.jl</ext-link>
  on a Support Vector Machine (SVM) model with a
  <inline-formula><alternatives>
  <tex-math><![CDATA[\ell_{1/2}^{1/2}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mi>ℓ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
  penalty for image classification
  (<xref alt="Aravkin et al., 2024" rid="ref-aravkin-baraldi-orban-2024" ref-type="bibr">Aravkin
  et al., 2024</xref>).</p>
  <p>Below is a condensed example showing how to define the problem and
  perform a solve followed by a re-solve:</p>
  <code language="julia">using LinearAlgebra, Random, ProximalOperators
using NLPModels, RegularizedProblems, RegularizedOptimization
using MLDatasets

Random.seed!(1234)
model, nls_model, _ = RegularizedProblems.svm_train_model()  # Build SVM model
f = LSR1Model(model)                                         # L-SR1 Hessian approximation
λ = 1.0                                                      # Regularization parameter
h = RootNormLhalf(λ)                                         # Nonsmooth term
reg_nlp = RegularizedNLPModel(f, h)                          # Regularized problem
solver = R2NSolver(reg_nlp)                                  # Choose solver
stats  = RegularizedExecutionStats(reg_nlp)
solve!(solver, reg_nlp, stats; atol=1e-4, rtol=1e-4, verbose=1, sub_kwargs=(max_iter=200,))
solve!(solver, reg_nlp, stats; atol=1e-5, rtol=1e-5, verbose=1, sub_kwargs=(max_iter=200,))</code>
  <sec id="numerical-results">
    <title>Numerical results</title>
    <p>We compare <bold>TR</bold>, <bold>R2N</bold>, <bold>LM</bold> and
    <bold>LMTR</bold> from our library on the SVM problem. Experiments
    were performed on macOS (arm64) on an Apple M2 (8-core) machine,
    using Julia 1.11.7.</p>
    <p>The table reports the convergence status of each solver, the
    number of evaluations of <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>,
    the number of evaluations of <inline-formula><alternatives>
    <tex-math><![CDATA[\nabla f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>∇</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
    the number of proximal operator evaluations, the elapsed time, and
    the final objective value. For TR and R2N, we use limited-memory SR1
    Hessian approximations. The subproblem solver is
    <bold>R2</bold>.</p>
    <table-wrap>
      <table>
        <thead>
          <tr>
            <th align="left">Method</th>
            <th align="left">Status</th>
            <th align="right"><inline-formula><alternatives>
            <tex-math><![CDATA[t]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>(<inline-formula><alternatives>
            <tex-math><![CDATA[s]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>)</th>
            <th align="right"><inline-formula><alternatives>
            <tex-math><![CDATA[\#f]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>#</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></th>
            <th align="right"><inline-formula><alternatives>
            <tex-math><![CDATA[\#\nabla f]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>#</mml:mi><mml:mi>∇</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></th>
            <th align="right"><inline-formula><alternatives>
            <tex-math><![CDATA[\#prox]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>#</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></th>
            <th align="right">Objective</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">TR</td>
            <td align="left">first_order</td>
            <td align="right">3.9349</td>
            <td align="right">347</td>
            <td align="right">291</td>
            <td align="right">4037</td>
            <td align="right">179.837</td>
          </tr>
          <tr>
            <td align="left">R2N</td>
            <td align="left">first_order</td>
            <td align="right">1.9511</td>
            <td align="right">185</td>
            <td align="right">101</td>
            <td align="right">27932</td>
            <td align="right">192.493</td>
          </tr>
          <tr>
            <td align="left">LM</td>
            <td align="left">first_order</td>
            <td align="right">19.7826</td>
            <td align="right">6</td>
            <td align="right">2876</td>
            <td align="right">1001</td>
            <td align="right">201.186</td>
          </tr>
          <tr>
            <td align="left">LMTR</td>
            <td align="left">first_order</td>
            <td align="right">12.4967</td>
            <td align="right">11</td>
            <td align="right">1614</td>
            <td align="right">432</td>
            <td align="right">188.274</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>For the <bold>LM</bold> and <bold>LMTR</bold> solvers,
    <inline-formula><alternatives>
    <tex-math><![CDATA[\#\nabla f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>#</mml:mi><mml:mi>∇</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    counts the number of Jacobian–vector and adjoint-Jacobian–vector
    products.</p>
    <p>All methods successfully reduced the optimality measure below the
    specified tolerance of <inline-formula><alternatives>
    <tex-math><![CDATA[10^{-4}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mi>−</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>,
    and thus converged to an approximate first-order stationary point.
    Note that the final objective values differ due to the nonconvexity
    of the problem.</p>
    <p><bold>R2N</bold> is the fastest in terms of time and number of
    gradient evaluations. However, it requires more proximal
    evaluations, but these are inexpensive. <bold>LMTR</bold> and
    <bold>LM</bold> require the fewest function evaluations, but incur
    many Jacobian–vector products, and are the slowest in terms of
    time.</p>
    <p>Ongoing research aims to reduce the number of proximal
    evaluations, for instance by allowing inexact proximal computations
    (<xref alt="Allaire et al., 2025" rid="ref-allaire-le-digabel-orban-2025" ref-type="bibr">Allaire
    et al., 2025</xref>).</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors would like to thank A. De Marchi for the Augmented
  Lagrangian solver. M. L. Habiboullah is supported by an excellence
  FRQNT grant. Y. Diouane, M. Gollier and D. Orban are partially
  supported by an NSERC Discovery Grant.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-aravkin-baraldi-orban-2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Aravkin</surname><given-names>A. Y.</given-names></name>
        <name><surname>Baraldi</surname><given-names>R.</given-names></name>
        <name><surname>Orban</surname><given-names>D.</given-names></name>
      </person-group>
      <article-title>A proximal quasi-Newton trust-region method for nonsmooth regularized optimization</article-title>
      <source>SIAM J. Optim.</source>
      <year iso-8601-date="2022">2022</year>
      <volume>32</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/21M1409536</pub-id>
      <fpage>900</fpage>
      <lpage>929</lpage>
    </element-citation>
  </ref>
  <ref id="ref-aravkin-baraldi-orban-2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Aravkin</surname><given-names>A. Y.</given-names></name>
        <name><surname>Baraldi</surname><given-names>R.</given-names></name>
        <name><surname>Orban</surname><given-names>D.</given-names></name>
      </person-group>
      <article-title>A Levenberg–Marquardt method for nonsmooth regularized least squares</article-title>
      <source>SIAM J. Sci. Comput.</source>
      <year iso-8601-date="2024">2024</year>
      <volume>46</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1137/22M1538971</pub-id>
      <fpage>A2557</fpage>
      <lpage>A2581</lpage>
    </element-citation>
  </ref>
  <ref id="ref-leconte-orban-2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Leconte</surname><given-names>G.</given-names></name>
        <name><surname>Orban</surname><given-names>D.</given-names></name>
      </person-group>
      <article-title>The indefinite proximal gradient method</article-title>
      <source>Comput. Optim. Appl.</source>
      <year iso-8601-date="2025">2025</year>
      <volume>91</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1007/s10589-024-00604-5</pub-id>
      <fpage>861</fpage>
      <lpage>903</lpage>
    </element-citation>
  </ref>
  <ref id="ref-diouane-habiboullah-orban-2024">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Diouane</surname><given-names>Youssef</given-names></name>
        <name><surname>Habiboullah</surname><given-names>Mohamed Laghdaf</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>A proximal modified quasi-Newton method for nonsmooth regularized optimization</article-title>
      <publisher-name>GERAD</publisher-name>
      <publisher-loc>Montréal, Canada</publisher-loc>
      <year iso-8601-date="2024">2024</year>
      <uri>https://www.gerad.ca/fr/papers/G-2024-64</uri>
    </element-citation>
  </ref>
  <ref id="ref-diouane-gollier-orban-2024">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Diouane</surname><given-names>Youssef</given-names></name>
        <name><surname>Gollier</surname><given-names>Maxence</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>A nonsmooth exact penalty method for equality-constrained optimization: Complexity and implementation</article-title>
      <publisher-name>GERAD</publisher-name>
      <publisher-loc>Montréal, Canada</publisher-loc>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.13140/RG.2.2.16095.47527</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-orban-siqueira-nlpmodels-2020">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Orban</surname><given-names>D.</given-names></name>
        <name><surname>Siqueira</surname><given-names>A. S.</given-names></name>
        <string-name>contributors</string-name>
      </person-group>
      <article-title>NLPModels.jl: Data structures for optimization models</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/JuliaSmoothOptimizers/NLPModels.jl</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.2558627</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-jso">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Migot</surname><given-names>T.</given-names></name>
        <name><surname>Orban</surname><given-names>D.</given-names></name>
        <name><surname>Siqueira</surname><given-names>A. S.</given-names></name>
      </person-group>
      <article-title>The JuliaSmoothOptimizers ecosystem for linear and nonlinear optimization</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://juliasmoothoptimizers.github.io/</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.2655082</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-stella-themelis-sopasakis-patrinos-2017">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Stella</surname><given-names>L.</given-names></name>
        <name><surname>Themelis</surname><given-names>A.</given-names></name>
        <name><surname>Sopasakis</surname><given-names>P.</given-names></name>
        <name><surname>Patrinos</surname><given-names>P.</given-names></name>
      </person-group>
      <article-title>A simple and efficient algorithm for nonlinear model predictive control</article-title>
      <source>2017 IEEE 56th annual conference on decision and control (CDC)</source>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.1109/CDC.2017.8263933</pub-id>
      <fpage>1939</fpage>
      <lpage>1944</lpage>
    </element-citation>
  </ref>
  <ref id="ref-demarchi-jia-kanzow-mehlitz-2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>De Marchi</surname><given-names>Alberto</given-names></name>
        <name><surname>Jia</surname><given-names>Xiaoxi</given-names></name>
        <name><surname>Kanzow</surname><given-names>Christian</given-names></name>
        <name><surname>Mehlitz</surname><given-names>Patrick</given-names></name>
      </person-group>
      <article-title>Constrained composite optimization and augmented Lagrangian methods</article-title>
      <source>Math. Program.</source>
      <year iso-8601-date="2023-09">2023</year><month>09</month>
      <volume>201</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1007/s10107-022-01922-4</pub-id>
      <fpage>863</fpage>
      <lpage>896</lpage>
    </element-citation>
  </ref>
  <ref id="ref-themelis-stella-patrinos-2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Themelis</surname><given-names>Andreas</given-names></name>
        <name><surname>Stella</surname><given-names>Lorenzo</given-names></name>
        <name><surname>Patrinos</surname><given-names>Panagiotis</given-names></name>
      </person-group>
      <article-title>Forward-backward envelope for the sum of two nonconvex functions: Further properties and nonmonotone line search algorithms</article-title>
      <source>SIAM J. Optim.</source>
      <year iso-8601-date="2018">2018</year>
      <volume>28</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1137/16M1080240</pub-id>
      <fpage>2274</fpage>
      <lpage>2303</lpage>
    </element-citation>
  </ref>
  <ref id="ref-allaire-le-digabel-orban-2025">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Allaire</surname><given-names>Nathan</given-names></name>
        <name><surname>Digabel</surname><given-names>Sébastien Le</given-names></name>
        <name><surname>Orban</surname><given-names>Dominique</given-names></name>
      </person-group>
      <article-title>An inexact modified quasi-newton method for nonsmooth regularized optimization</article-title>
      <publisher-name>GERAD</publisher-name>
      <publisher-loc>Montréal, Canada</publisher-loc>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.13140/RG.2.2.32728.97288</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
