<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5187</article-id>
<article-id pub-id-type="doi">10.21105/joss.05187</article-id>
<title-group>
<article-title>Krylov.jl: A Julia basket of hand-picked Krylov
methods</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3403-5450</contrib-id>
<name>
<surname>Montoison</surname>
<given-names>Alexis</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8017-7687</contrib-id>
<name>
<surname>Orban</surname>
<given-names>Dominique</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>GERAD and Department of Mathematics and Industrial
Engineering, Polytechnique Montréal, QC, Canada.</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-08-06">
<day>6</day>
<month>8</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>89</issue>
<fpage>5187</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Julia</kwd>
<kwd>linear algebra</kwd>
<kwd>Krylov methods</kwd>
<kwd>Krylov processes</kwd>
<kwd>sparse linear systems</kwd>
<kwd>GPU computing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaSmoothOptimizers/Krylov.jl">Krylov.jl</ext-link>
  is a Julia
  (<xref alt="Bezanson et al., 2017" rid="ref-bezanson-edelman-karpinski-shah-2017" ref-type="bibr">Bezanson
  et al., 2017</xref>) package that implements a collection of Krylov
  processes and methods for solving a variety of linear problems:</p>
  <table-wrap>
    <table>
      <colgroup>
        <col width="19%" />
        <col width="35%" />
        <col width="45%" />
      </colgroup>
      <thead>
        <tr>
          <th align="center">Square systems</th>
          <th align="center">Linear least-squares problems</th>
          <th align="center">Linear least-norm problems</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[Ax = b]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[\min \|b - Ax\|]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>min</mml:mo><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">∥</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[\min \|x\|~~\text{subject to}~~Ax = b]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>min</mml:mo><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mspace width="0.222em"></mml:mspace><mml:mspace width="0.222em"></mml:mspace><mml:mtext mathvariant="normal">subject to</mml:mtext><mml:mspace width="0.222em"></mml:mspace><mml:mspace width="0.222em"></mml:mspace><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap>
    <table>
      <colgroup>
        <col width="13%" />
        <col width="39%" />
        <col width="48%" />
      </colgroup>
      <thead>
        <tr>
          <th align="center">Adjoint systems</th>
          <th align="center">Saddle-point and Hermitian quasi-definite
          systems</th>
          <th align="center">Generalized saddle-point and non-Hermitian
          partitioned systems</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[\begin{matrix} Ax = b \\ A^{H\!} y = c \end{matrix}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></inline-formula></td>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[\begin{bmatrix} M & \!\phantom{-}A \\ A^{  H\!} & \!-N \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} b \\ c \end{bmatrix}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>M</mml:mi></mml:mtd><mml:mtd columnalign="center" style="text-align: center"><mml:mspace width="-0.167em"></mml:mspace><mml:mphantom><mml:mo>−</mml:mo></mml:mphantom><mml:mi>A</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup></mml:mtd><mml:mtd columnalign="center" style="text-align: center"><mml:mspace width="-0.167em"></mml:mspace><mml:mo>−</mml:mo><mml:mi>N</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>x</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>y</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>b</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>c</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
          <td align="center"><inline-formula><alternatives>
          <tex-math><![CDATA[\begin{bmatrix} M & A \\ B & N \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} b \\ c \end{bmatrix}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>M</mml:mi></mml:mtd><mml:mtd columnalign="center" style="text-align: center"><mml:mi>A</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>B</mml:mi></mml:mtd><mml:mtd columnalign="center" style="text-align: center"><mml:mi>N</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>x</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>y</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>b</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center" style="text-align: center"><mml:mi>c</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p><inline-formula><alternatives>
  <tex-math><![CDATA[A^{H\!}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>
  denotes the conjugate transpose of <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>.
  It coincides with <inline-formula><alternatives>
  <tex-math><![CDATA[A^{T\!}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>,
  the transpose of <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>,
  if <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>
  is real. Krylov methods are iterative methods based on Krylov
  (<xref alt="1931" rid="ref-krylov-1931" ref-type="bibr">1931</xref>)
  subspaces. They are an alternative to direct methods such as Gaussian
  elimination or QR decomposition when storage requirements or
  computational costs become prohibitive, which is often the case for
  large and sparse linear problems. Contrary to direct methods, which
  require storing <inline-formula><alternatives>
  <tex-math><![CDATA[A]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>
  explicitly, Krylov methods support linear operators to model
  operator-vector products <inline-formula><alternatives>
  <tex-math><![CDATA[u \leftarrow Av]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>u</mml:mi><mml:mo>←</mml:mo><mml:mi>A</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
  and in some instances <inline-formula><alternatives>
  <tex-math><![CDATA[u \leftarrow A^{H\!}w]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>u</mml:mi><mml:mo>←</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  because Krylov processes only require those operations to build Krylov
  subspaces. The same goes with preconditioners, i.e., transformations
  that modify a linear system into an equivalent form with favorable
  spectral properties that may yield faster convergence in
  finite-precision arithmetic. We refer interested readers to Ipsen
  &amp; Meyer
  (<xref alt="1998" rid="ref-ipsen-meyer-1998" ref-type="bibr">1998</xref>)
  for an introduction to Krylov methods along with Greenbaum
  (<xref alt="1997" rid="ref-greenbaum-1997" ref-type="bibr">1997</xref>)
  and Saad
  (<xref alt="2003" rid="ref-saad-2003" ref-type="bibr">2003</xref>) for
  more details.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <sec id="largest-collection-of-krylov-processes-and-methods">
    <title>Largest collection of Krylov processes and methods</title>
    <p>Krylov.jl aims to provide a user-friendly and unified interface
    for the largest collection of Krylov processes and methods, all
    programming languages taken together, with six and thirty-five
    implementations, respectively:</p>
    <list list-type="bullet">
      <list-item>
        <p><bold>Krylov processes</bold>: <sc>Arnoldi</sc>,
        <sc>Golub-Kahan</sc>, <sc>Hermitian Lanczos</sc>,
        <sc>Montoison-Orban</sc>, <sc>Non-Hermitian Lanczos</sc>,
        <sc>Saunders-Simon-Yip</sc></p>
      </list-item>
      <list-item>
        <p><bold>Krylov methods</bold>: <sc>Bicgstab</sc>,
        <sc>Bilq</sc>, <sc>Bilqr</sc>, <sc>Car</sc>, <sc>Cg</sc>,
        <sc>Cg-lanczos</sc>, <sc>Cg-lanczos-shift</sc>, <sc>Cgls</sc>,
        <sc>Cgne</sc>, <sc>Cgs</sc>, <sc>Cr</sc>, <sc>Craig</sc>,
        <sc>Craigmr</sc>, <sc>Crls</sc>, <sc>Crmr</sc>, <sc>Diom</sc>,
        <sc>Dqgmres</sc>, <sc>Fgmres</sc>, <sc>Fom</sc>, <sc>Gmres</sc>,
        <sc>Gpmr</sc>, <sc>Lnlq</sc>, <sc>Lslq</sc>, <sc>Lsmr</sc>,
        <sc>Lsqr</sc>, <sc>Minares</sc>, <sc>Minres</sc>,
        <sc>Minres-qlp</sc>, <sc>Qmr</sc>, <sc>Symmlq</sc>,
        <sc>Tricg</sc>, <sc>Trilqr</sc>, <sc>Trimr</sc>,
        <sc>Usymlq</sc>, <sc>Usymqr</sc></p>
      </list-item>
    </list>
    <p>Hence Krylov.jl is a suitable toolbox for easily comparing
    existing methods with each other as well as new ones. The number of
    distinct Krylov methods is twenty-two for PETSc
    (<xref alt="Balay et al., 2023" rid="ref-petsc" ref-type="bibr">Balay
    et al., 2023</xref>), eleven for MATLAB
    (<xref alt="2022" rid="ref-MATLAB" ref-type="bibr">2022</xref>) and
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaInv/KrylovMethods.jl">KrylovMethods.jl</ext-link>,
    nine for
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaLinearAlgebra/IterativeSolvers.jl">IterativeSolvers.jl</ext-link>
    and three for
    <ext-link ext-link-type="uri" xlink:href="https://github.com/Jutho/KrylovKit.jl">KrylovKit.jl</ext-link>.
    However Krylov.jl doesn’t have implementations of recycling Krylov
    methods nor block Krylov methods, unlike some alternatives, except
    for special cases, including <sc>Tricg</sc>, <sc>Trimr</sc>, and
    <sc>Gpmr</sc>. Note that we only consider the number of Krylov
    methods that generate different iterates without preconditioning.
    Variants with preconditioning are not counted except flexible ones
    such as <sc>Fgmres</sc>.</p>
    <p>Some processes and methods are not available elsewhere and are
    the product of our own research. References for each process and
    method are available in the extensive
    <ext-link ext-link-type="uri" xlink:href="https://juliasmoothoptimizers.github.io/Krylov.jl/stable/">documentation</ext-link>.
    Beyond the number of methods, Krylov.jl is the only package that
    offers all of the features that we describe below.</p>
  </sec>
  <sec id="support-for-any-floating-point-system-supported-by-julia">
    <title>Support for any floating-point system supported by
    Julia</title>
    <p>Krylov.jl works with real and complex data in any floating-point
    system supported by Julia, which means that Krylov.jl handles any
    precision <monospace>T</monospace> and
    <monospace>Complex{T}</monospace> where
    <monospace>T &lt;: AbstractFloat</monospace>. Although most personal
    computers offer IEEE 754 single and double precision computations,
    new architectures implement native computations in other
    floating-point systems. In addition, software libraries such as the
    GNU MPFR, shipped with Julia, let users experiment with computations
    in variable, extended precision at the software level with the
    <monospace>BigFloat</monospace> data type. Working in high precision
    has obvious benefits in terms of accuracy.</p>
  </sec>
  <sec id="support-for-nvidia-amd-and-intel-gpus">
    <title>Support for NVIDIA, AMD and Intel GPUs</title>
    <p>Krylov methods are well suited for GPU computations because they
    only require operator-vector products
    (<inline-formula><alternatives>
    <tex-math><![CDATA[u \leftarrow Av]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>u</mml:mi><mml:mo>←</mml:mo><mml:mi>A</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[u \leftarrow A^{H\!}w]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>u</mml:mi><mml:mo>←</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="-0.167em"></mml:mspace></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>)
    and vector operations (<inline-formula><alternatives>
    <tex-math><![CDATA[\|v\|]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false" form="postfix">∥</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[u^H v]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mi>H</mml:mi></mml:msup><mml:mi>v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[v \leftarrow \alpha u + \beta v]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>v</mml:mi><mml:mo>←</mml:mo><mml:mi>α</mml:mi><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>),
    which are highly parallelizable. The implementations in Krylov.jl
    are generic so as to take advantage of the multiple dispatch and
    broadcast features of Julia. Those allow the implementations to be
    specialized automatically by the compiler for both CPU and GPU.
    Thus, Krylov.jl works with GPU backends that build on
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaGPU/GPUArrays.jl">GPUArrays.jl</ext-link>,
    including
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</ext-link>,
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaGPU/AMDGPU.jl">AMDGPU.jl</ext-link>,
    and
    <ext-link ext-link-type="uri" xlink:href="https://github.com/JuliaGPU/oneAPI.jl">oneAPI.jl</ext-link>,
    the Julia interfaces to NVIDIA, AMD, and Intel GPUs. </p>
  </sec>
  <sec id="support-for-linear-operators">
    <title>Support for linear operators</title>
    <p>The input arguments of all Krylov.jl solvers that model
    <inline-formula><alternatives>
    <tex-math><![CDATA[A]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[B]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>B</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[N]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>N</mml:mi></mml:math></alternatives></inline-formula>
    and preconditioners can be any object that represents a linear
    operator. Krylov methods combined with linear operators allow to
    reduce computation time and memory requirements considerably by
    avoiding building and storing matrices. In nonlinear optimization,
    finding a critical point of a continuous function frequently
    involves linear systems where <inline-formula><alternatives>
    <tex-math><![CDATA[A]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>A</mml:mi></mml:math></alternatives></inline-formula>
    is a Hessian or a Jacobian. Materializing such operators as matrices
    is expensive in terms of operations and memory consumption and is
    unreasonable for high-dimensional problems. However, it is often
    possible to implement efficient Hessian-vector and Jacobian-vector
    products, for example with the help of automatic differentiation
    tools.</p>
  </sec>
  <sec id="in-place-methods">
    <title>In-place methods</title>
    <p>All solvers in Krylov.jl have an in-place variant that allows to
    solve multiple linear systems with the same dimensions, precision
    and architecture. Optimization methods such as the Newton and
    Gauss-Newton methods can take advantage of this functionality by
    allocating workspace for the solve only once. The in-place variants
    only require a Julia structure that contains all the storage needed
    by a Krylov method as additional argument. In-place methods limit
    memory allocations and deallocations, which are particularly
    expensive on GPUs.</p>
  </sec>
  <sec id="performance-optimizations-and-storage-requirements">
    <title>Performance optimizations and storage requirements</title>
    <p>Operator-vector products and vector operations are the most
    expensive operations in Krylov.jl. The vectors in Krylov.jl are
    always dense. One may then expect that taking advantage of an
    optimized BLAS library when one is available on CPU and when the
    problem data is stored in a supported representation should improve
    performance. Thus, we dispatch vector-vector operations to BLAS1
    routines, and operator-vector operations to BLAS2 routines when the
    operator is a dense matrix. By default, Julia ships with OpenBLAS
    and provides multithreaded routines. Since Julia 1.6, users can also
    switch dynamically to other BLAS backends, such as the Intel MKL,
    BLIS or Apple Accelerate, thanks to the BLAS demuxing library
    <monospace>libblastrampoline</monospace>, if an optimized BLAS is
    available.</p>
    <p>A “Storage Requirements” section is available in the
    documentation to provide the theoretical number of bytes required by
    each method. Our implementations are storage-optimal in the sense
    that they are guaranteed to match the theoretical storage amount.
    The match is verified in the unit tests by way of functions that
    return the number of bytes allocated by our implementations.</p>
  </sec>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>Our first example is a simple implementation of the Gauss-Newton
  method without linesearch for nonlinear least squares. It illustrates
  several of the facilities of Krylov.jl: solver preallocation and
  reuse, genericity with respect to data types, and linear operators.
  Another example based on a simplistic Newton method without linesearch
  for convex optimization is also available in the documentation, and
  illustrates the same concepts in the sections “In-place methods” and
  “Factorization-free operators”.</p>
  <code language="julia">using LinearAlgebra    # Linear algebra library of Julia
using SparseArrays     # Sparse library of Julia
using Test             # Test library of Julia
using Krylov           # Krylov methods and processes
using LinearOperators  # Linear operators
using ForwardDiff      # Automatic differentiation
using Quadmath         # Quadruple precision
using MKL              # Intel BLAS

&quot;The Gauss-Newton method for Nonlinear Least Squares&quot;
function gauss_newton(F, JF, x₀::AbstractVector{T}; itmax = 200, tol = √eps(T)) where T
    n = length(x₀)
    x = copy(x₀)
    Fx = F(x)
    m = length(Fx)
    iter = 0
    S = typeof(x)                 # precision and architecture
    solver = LsmrSolver(m, n, S)  # structure that contains the workspace of LSMR
    solved = tired = false
    while !(solved || tired)
        Jx = JF(x)              # Compute J(xₖ)
        lsmr!(solver, Jx, -Fx)  # Minimize ‖J(xₖ)Δx + F(xₖ)‖
        x .+= solver.x          # Update xₖ₊₁ = xₖ + Δx
        Fx_old = Fx             # F(xₖ)
        Fx = F(x)               # F(xₖ₊₁)
        iter += 1
        solved = norm(Fx - Fx_old) / norm(Fx) ≤ tol
        tired = iter ≥ itmax
    end
    return x
end

T = Float128  # IEEE quadruple precision
x_exact = T[8, 0.25]
x₀ = ones(T, 2)
t = T[1, 2, 3, 4, 5, 6, 7, 8]
y = [trunc(x_exact[1] * exp(x_exact[2] * t[i]), digits=3) for i=1:8]
F(x) = [x[1] * exp(x[2] * t[i]) - y[i] for i=1:8]              # F(x)
J(y, x, v) = ForwardDiff.derivative!(y, h -&gt; F(x + h * v), 0)  # y ← JF(x)v
Jᵀ(y, x, w) = ForwardDiff.gradient!(y, x -&gt; dot(F(x), w), x)   # y ← JFᵀ(x)w
symmetric = hermitian = false
JF(x) = LinearOperator(T, 8, 2, symmetric, hermitian, (y, v) -&gt; J(y, x, v),   # non-transpose
                                                      (y, w) -&gt; Jᵀ(y, x, w),  # transpose
                                                      (y, w) -&gt; Jᵀ(y, x, w))  # conjugate transpose
x = gauss_newton(F, JF, x₀)

# Check the solution returned by the Gauss-Newton method
@test norm(x - x_exact) ≤ 1e-4</code>
  <p>Our second example concerns the solution of a complex Hermitian
  linear system from the SuiteSparse Matrix Collection
  (<xref alt="Davis &amp; Hu, 2011" rid="ref-davis-hu-2011" ref-type="bibr">Davis
  &amp; Hu, 2011</xref>) with an incomplete Cholesky factorization
  preconditioner on GPU. The preconditioner is implemented as an
  in-place linear operator that performs the forward and backward sweeps
  with the Cholesky factor of the incomplete decomposition. Because the
  system matrix is Hermitian and positive definite, we use the conjugate
  gradient method. However, other methods for Hermitian systems could be
  used, including <sc>Symmlq</sc>, <sc>Cr</sc>, and <sc>Minres</sc>.</p>
  <code language="julia">using LinearAlgebra                # Linear algebra library of Julia
using SparseArrays                 # Sparse library of Julia
using Test                         # Test library of Julia
using Krylov                       # Krylov methods and processes
using LinearOperators              # Linear operators
using MatrixMarket                 # Reader of matrices stored in the Matrix Market format
using SuiteSparseMatrixCollection  # Interface to the SuiteSparse Matrix Collection
using CUDA                         # Interface to NVIDIA GPUs
using CUDA.CUSPARSE                # NVIDIA CUSPARSE library

if CUDA.functional()
  ssmc = ssmc_db(verbose=false)
  matrices = ssmc_matrices(ssmc, &quot;Sinclair&quot;, &quot;3Dspectralwave2&quot;)
  paths = fetch_ssmc(matrices, format=&quot;MM&quot;)
  path_A = joinpath(paths[1], &quot;3Dspectralwave2.mtx&quot;)

  # A is an Hermitian and positive definite matrix of size 292008 x 292008
  A_cpu = MatrixMarket.mmread(path_A) + 50I
  m, n = size(A_cpu)
  x_exact = ones(ComplexF64, m)
  b_cpu = A_cpu * x_exact

  # Transfer the linear system from the CPU to the GPU
  A_gpu = CuSparseMatrixCSR(A_cpu)
  b_gpu = CuVector(b_cpu)

  # Incomplete Cholesky factorization LLᴴ ≈ A with zero fill-in
  P = ic02(A_gpu)

  # Additional vector required for solving triangular systems
  z = CUDA.zeros(ComplexF64, n)

  # Solve Py = x
  function ldiv_ic0!(P, x, y, z)
    L = LowerTriangular(P)
    Lᴴ = adjoint(L)
    ldiv!(z, L, x)   # Forward substitution with L
    ldiv!(y, Lᴴ, z)  # Backward substitution with Lᴴ
    return y
  end

  # Linear operator that approximates the preconditioner P⁻¹ in floating-point arithmetic
  T = ComplexF64
  symmetric = false
  hermitian = true
  P⁻¹ = LinearOperator(T, m, n, symmetric, hermitian, (y, x) -&gt; ldiv_ic0!(P, x, y, z))

  # Solve an Hermitian positive definite system with an incomplete Cholesky factorization preconditioner
  x_gpu, stats = cg(A_gpu, b_gpu, M=P⁻¹)

  # Check the solution returned by the conjugate gradient method
  x_cpu = Vector{ComplexF64}(x_gpu)
  @test norm(x_cpu - x_exact) ≤ 1e-5
end</code>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Alexis Montoison is supported by an FRQNT grant and an excellence
  scholarship of the IVADO institute, and Dominique Orban is partially
  supported by an NSERC Discovery Grant.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-davis-hu-2011">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Davis</surname><given-names>T.</given-names></name>
        <name><surname>Hu</surname><given-names>Y.</given-names></name>
      </person-group>
      <article-title>The University of Florida sparse matrix collection</article-title>
      <source>ACM Transactions on Mathematical Software</source>
      <publisher-name>ACM</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>38</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1145/2049662.2049663</pub-id>
      <fpage>1</fpage>
      <lpage>25</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bezanson-edelman-karpinski-shah-2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
      </person-group>
      <article-title>Julia: A fresh approach to numerical computing</article-title>
      <source>SIAM Review</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2017">2017</year>
      <volume>59</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
  <ref id="ref-krylov-1931">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Krylov</surname><given-names>Aleksey Nikolaevich</given-names></name>
      </person-group>
      <article-title>On the numerical solution of the equation by which, in technical matters, frequencies of small oscillations of material systems are determined</article-title>
      <source>Izvestija AN SSSR (News of Academy of Sciences of the USSR), Otdel. mat. i estest. nauk</source>
      <year iso-8601-date="1931">1931</year>
      <volume>7</volume>
      <issue>4</issue>
      <fpage>491</fpage>
      <lpage>539</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ipsen-meyer-1998">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ipsen</surname><given-names>Ilse CF</given-names></name>
        <name><surname>Meyer</surname><given-names>Carl D</given-names></name>
      </person-group>
      <article-title>The idea behind Krylov methods</article-title>
      <source>The American mathematical monthly</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="1998">1998</year>
      <volume>105</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1080/00029890.1998.12004985</pub-id>
      <fpage>889</fpage>
      <lpage>899</lpage>
    </element-citation>
  </ref>
  <ref id="ref-saad-2003">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Saad</surname><given-names>Yousef</given-names></name>
      </person-group>
      <source>Iterative methods for sparse linear systems</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2003">2003</year>
      <pub-id pub-id-type="doi">10.1137/1.9780898718003</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-greenbaum-1997">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Greenbaum</surname><given-names>Anne</given-names></name>
      </person-group>
      <source>Iterative methods for solving linear systems</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="1997">1997</year>
      <pub-id pub-id-type="doi">10.1137/1.9781611970937</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-petsc">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Balay</surname><given-names>Satish</given-names></name>
        <name><surname>Abhyankar</surname><given-names>Shrirang</given-names></name>
        <name><surname>Adams</surname><given-names>Mark F.</given-names></name>
        <name><surname>Benson</surname><given-names>Steven</given-names></name>
        <name><surname>Brown</surname><given-names>Jed</given-names></name>
        <name><surname>Brune</surname><given-names>Peter</given-names></name>
        <name><surname>Buschelman</surname><given-names>Kris</given-names></name>
        <name><surname>Constantinescu</surname><given-names>Emil</given-names></name>
        <name><surname>Dalcin</surname><given-names>Lisandro</given-names></name>
        <name><surname>Dener</surname><given-names>Alp</given-names></name>
        <name><surname>Eijkhout</surname><given-names>Victor</given-names></name>
        <name><surname>Faibussowitsch</surname><given-names>Jacob</given-names></name>
        <name><surname>Gropp</surname><given-names>William D.</given-names></name>
        <name><surname>Hapla</surname><given-names>Václav</given-names></name>
        <name><surname>Isaac</surname><given-names>Tobin</given-names></name>
        <name><surname>Jolivet</surname><given-names>Pierre</given-names></name>
        <name><surname>Karpeev</surname><given-names>Dmitry</given-names></name>
        <name><surname>Kaushik</surname><given-names>Dinesh</given-names></name>
        <name><surname>Knepley</surname><given-names>Matthew G.</given-names></name>
        <name><surname>Kong</surname><given-names>Fande</given-names></name>
        <name><surname>Kruger</surname><given-names>Scott</given-names></name>
        <name><surname>May</surname><given-names>Dave A.</given-names></name>
        <name><surname>McInnes</surname><given-names>Lois Curfman</given-names></name>
        <name><surname>Mills</surname><given-names>Richard Tran</given-names></name>
        <name><surname>Mitchell</surname><given-names>Lawrence</given-names></name>
        <name><surname>Munson</surname><given-names>Todd</given-names></name>
        <name><surname>Roman</surname><given-names>Jose E.</given-names></name>
        <name><surname>Rupp</surname><given-names>Karl</given-names></name>
        <name><surname>Sanan</surname><given-names>Patrick</given-names></name>
        <name><surname>Sarich</surname><given-names>Jason</given-names></name>
        <name><surname>Smith</surname><given-names>Barry F.</given-names></name>
        <name><surname>Zampini</surname><given-names>Stefano</given-names></name>
        <name><surname>Zhang</surname><given-names>Hong</given-names></name>
        <name><surname>Zhang</surname><given-names>Hong</given-names></name>
        <name><surname>Zhang</surname><given-names>Junchao</given-names></name>
      </person-group>
      <article-title>PETSc/TAO users manual</article-title>
      <publisher-name>Argonne National Laboratory</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.2172/1968587</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-MATLAB">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>MATLAB</surname></name>
      </person-group>
      <source>Version 9.13.0 (R2022b)</source>
      <publisher-name>The MathWorks Inc.</publisher-name>
      <publisher-loc>Natick, Massachusetts</publisher-loc>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
