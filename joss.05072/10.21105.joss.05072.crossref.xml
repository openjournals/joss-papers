<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20230315T001033-883b66e5c68055c2504d7391b5d1fe93a54ee924</doi_batch_id>
    <timestamp>20230315001033</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>03</month>
          <year>2023</year>
        </publication_date>
        <journal_volume>
          <volume>8</volume>
        </journal_volume>
        <issue>83</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>Universal Numbers Library: Multi-format Variable
Precision Arithmetic Library</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>E. Theodore L.</given_name>
            <surname>Omtzigt</surname>
            <ORCID>https://orcid.org/0000-0003-0194-951X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>James</given_name>
            <surname>Quinlan</surname>
            <ORCID>https://orcid.org/0000-0002-2628-1651</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>03</month>
          <day>15</day>
          <year>2023</year>
        </publication_date>
        <pages>
          <first_page>5072</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.05072</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.7735084</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/5072</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.05072</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.05072</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.05072.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="carmichael:2019">
            <article_title>Deep positron: A deep neural network using
the posit number system</article_title>
            <author>Carmichael</author>
            <journal_title>2019 design, automation &amp; test in europe
conference &amp; exhibition (DATE)</journal_title>
            <doi>10.23919/date.2019.8715262</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Carmichael, Z., Langroudi, H. F.,
Khazanov, C., Lillie, J., Gustafson, J. L., &amp; Kudithipudi, D.
(2019). Deep positron: A deep neural network using the posit number
system. 2019 Design, Automation &amp; Test in Europe Conference &amp;
Exhibition (DATE), 1421–1426.
https://doi.org/10.23919/date.2019.8715262</unstructured_citation>
          </citation>
          <citation key="carson:2018">
            <article_title>Accelerating the solution of linear systems
by iterative refinement in three precisions</article_title>
            <author>Carson</author>
            <journal_title>SIAM Journal on Scientific
Computing</journal_title>
            <issue>2</issue>
            <volume>40</volume>
            <doi>10.1137/17m1140819</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Carson, E., &amp; Higham, N. J.
(2018). Accelerating the solution of linear systems by iterative
refinement in three precisions. SIAM Journal on Scientific Computing,
40(2), A817–A847.
https://doi.org/10.1137/17m1140819</unstructured_citation>
          </citation>
          <citation key="choquette2021nvidia">
            <article_title>NVIDIA A100 tensor core GPU: Performance and
innovation</article_title>
            <author>Choquette</author>
            <journal_title>IEEE Micro</journal_title>
            <issue>2</issue>
            <volume>41</volume>
            <doi>10.1109/mm.2021.3061394</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Choquette, J., Gandhi, W., Giroux,
O., Stam, N., &amp; Krashinsky, R. (2021). NVIDIA A100 tensor core GPU:
Performance and innovation. IEEE Micro, 41(2), 29–35.
https://doi.org/10.1109/mm.2021.3061394</unstructured_citation>
          </citation>
          <citation key="cococcioni2022small">
            <article_title>Small reals representations for deep learning
at the edge: A comparison</article_title>
            <author>Cococcioni</author>
            <journal_title>Proc. Of the 2022 conference on next
generation arithmetic (CoNGA’22)</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>Cococcioni, M., Rossi, F., Emanuele,
R., &amp; Saponara, S. (2022). Small reals representations for deep
learning at the edge: A comparison. Proc. Of the 2022 Conference on Next
Generation Arithmetic (CoNGA’22).</unstructured_citation>
          </citation>
          <citation key="desrentes:2022posit8">
            <article_title>A Posit8 decompression operator for deep
neural network inference</article_title>
            <author>Desrentes</author>
            <journal_title>Next generation arithmetic: Third
international conference, CoNGA 2022, singapore, march 1–3, 2022,
revised selected papers</journal_title>
            <volume>13253</volume>
            <doi>10.1007/978-3-031-09779-9_2</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Desrentes, O., Resmerita, D., &amp;
Dinechin, B. D. de. (2022). A Posit8 decompression operator for deep
neural network inference. Next Generation Arithmetic: Third
International Conference, CoNGA 2022, Singapore, March 1–3, 2022,
Revised Selected Papers, 13253, 14.
https://doi.org/10.1007/978-3-031-09779-9_2</unstructured_citation>
          </citation>
          <citation key="haidar:2018a">
            <article_title>Harnessing GPU tensor cores for fast FP16
arithmetic to speed up mixed-precision iterative refinement
solvers</article_title>
            <author>Haidar</author>
            <journal_title>SC18: International conference for high
performance computing, networking, storage and analysis</journal_title>
            <doi>10.1109/sc.2018.00050</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Haidar, A., Tomov, S., Dongarra, J.,
&amp; Higham, N. J. (2018). Harnessing GPU tensor cores for fast FP16
arithmetic to speed up mixed-precision iterative refinement solvers.
SC18: International Conference for High Performance Computing,
Networking, Storage and Analysis, 603–613.
https://doi.org/10.1109/sc.2018.00050</unstructured_citation>
          </citation>
          <citation key="haidar:2017">
            <article_title>Investigating half precision arithmetic to
accelerate dense linear system solvers</article_title>
            <author>Haidar</author>
            <journal_title>Proceedings of the 8th workshop on latest
advances in scalable algorithms for large-scale systems</journal_title>
            <doi>10.1145/3148226.3148237</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Haidar, A., Wu, P., Tomov, S., &amp;
Dongarra, J. (2017). Investigating half precision arithmetic to
accelerate dense linear system solvers. Proceedings of the 8th Workshop
on Latest Advances in Scalable Algorithms for Large-Scale Systems, 1–8.
https://doi.org/10.1145/3148226.3148237</unstructured_citation>
          </citation>
          <citation key="haidar:2018b">
            <article_title>The design of fast and energy-efficient
linear solvers: On the potential of half-precision arithmetic and
iterative refinement techniques</article_title>
            <author>Haidar</author>
            <journal_title>International conference on computational
science</journal_title>
            <doi>10.1007/978-3-319-93698-7_45</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Haidar, A., Abdelfattah, A., Zounon,
M., Wu, P., Pranesh, S., Tomov, S., &amp; Dongarra, J. (2018). The
design of fast and energy-efficient linear solvers: On the potential of
half-precision arithmetic and iterative refinement techniques.
International Conference on Computational Science, 586–600.
https://doi.org/10.1007/978-3-319-93698-7_45</unstructured_citation>
          </citation>
          <citation key="higham:2019">
            <article_title>Squeezing a matrix into half precision, with
an application to solving linear systems</article_title>
            <author>Higham</author>
            <journal_title>SIAM Journal on Scientific
Computing</journal_title>
            <issue>4</issue>
            <volume>41</volume>
            <doi>10.1137/18m1229511</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Higham, N. J., Pranesh, S., &amp;
Zounon, M. (2019). Squeezing a matrix into half precision, with an
application to solving linear systems. SIAM Journal on Scientific
Computing, 41(4), A2536–A2551.
https://doi.org/10.1137/18m1229511</unstructured_citation>
          </citation>
          <citation key="intel:2018">
            <article_title>BFLOAT16 - Hardware Numerics
Definition</article_title>
            <author>Intel Corporation</author>
            <cYear>2018</cYear>
            <unstructured_citation>Intel Corporation. (2018). BFLOAT16 -
Hardware Numerics Definition.
https://tinyurl.com/y8ybct4</unstructured_citation>
          </citation>
          <citation key="kharya:2020">
            <article_title>TensorFloat-32 in the A100 GPU accelerates AI
training HPC up to 20x</article_title>
            <author>Kharya</author>
            <journal_title>NVIDIA Corporation, Tech. Rep</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Kharya, P. (2020). TensorFloat-32 in
the A100 GPU accelerates AI training HPC up to 20x. NVIDIA Corporation,
Tech. Rep.
https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/</unstructured_citation>
          </citation>
          <citation key="omtzigt:2022">
            <article_title>Universal: Reliable, reproducible, and
energy-efficient numerics</article_title>
            <author>Omtzigt</author>
            <journal_title>Conference on next generation
arithmetic</journal_title>
            <doi>10.1007/978-3-031-09779-9_7</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Omtzigt, E. T. L., &amp; Quinlan, J.
(2022). Universal: Reliable, reproducible, and energy-efficient
numerics. Conference on Next Generation Arithmetic, 100–116.
https://doi.org/10.1007/978-3-031-09779-9_7</unstructured_citation>
          </citation>
          <citation key="omtzigt:2020">
            <article_title>Universal Numbers Library: Design and
implementation of a high-performance reproducible number systems
library</article_title>
            <author>Omtzigt</author>
            <journal_title>arXiv:2012.11011</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Omtzigt, E. T. L., Gottschling, P.,
Seligman, M., &amp; Zorn, W. (2020). Universal Numbers Library: Design
and implementation of a high-performance reproducible number systems
library. arXiv:2012.11011.</unstructured_citation>
          </citation>
          <citation key="wang2019bfloat16">
            <article_title>BFloat16: The secret to high performance on
cloud TPUs</article_title>
            <author>Wang</author>
            <journal_title>Google Cloud Blog</journal_title>
            <volume>4</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Wang, S., &amp; Kanwar, P. (2019).
BFloat16: The secret to high performance on cloud TPUs. Google Cloud
Blog, 4.</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
