<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5072</article-id>
<article-id pub-id-type="doi">10.21105/joss.05072</article-id>
<title-group>
<article-title>Universal Numbers Library: Multi-format Variable
Precision Arithmetic Library</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0194-951X</contrib-id>
<name>
<surname>Omtzigt</surname>
<given-names>E. Theodore L.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2628-1651</contrib-id>
<name>
<surname>Quinlan</surname>
<given-names>James</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Stillwater Supercomputing, Inc, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>School of Mathematical and Physical Sciences, University of
New England, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2022-12-15">
<day>15</day>
<month>12</month>
<year>2022</year>
</pub-date>
<volume>8</volume>
<issue>83</issue>
<fpage>5072</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>C++</kwd>
<kwd>numerical analysis</kwd>
<kwd>deep learning</kwd>
<kwd>machine learning</kwd>
<kwd>floating-point representations</kwd>
<kwd>mixed-precision</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><italic>Universal Numbers Library</italic>, or simply
  <italic>Universal</italic>, is a comprehensive, self-contained C++
  header-only template library that provides implementations of various
  number representations and standard arithmetic operations on arbitrary
  configurations of integer and real numbers
  (<xref alt="Omtzigt et al., 2020" rid="ref-omtzigtU003A2020" ref-type="bibr">Omtzigt
  et al., 2020</xref>). With its extensive collection of number systems,
  including integers, decimals, fixed-points, rationals, linear floats,
  tapered floats, logarithmic, SORNs, interval, level-index, and
  adaptive-precision binary and decimal integers and floats, Universal
  offers a robust verification suite for each system.</p>
  <p>Using a posit number as an example, the basic pattern to use a
  custom <italic>Universal</italic> type is:</p>
  <code language="c++">#include &lt;universal/number/posit/posit.hpp&gt;

template&lt;typename Real&gt;
Real MyKernel(const Real&amp; a, const Real&amp; b) {
    return a * b;  // replace this with your kernel computation
}

constexpr double pi = 3.14159265358979323846;

int main() {
    using Real = sw::universal::posit&lt;32,2&gt;;  

    Real a = sqrt(2);
    Real b = pi;
    std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; MyKernel(a, b) &lt;&lt; std::endl;
}</code>
  <p><italic>Universal</italic> delivers software and hardware co-design
  capabilities to develop low and mixed-precision algorithms for
  reducing energy consumption in signal processing, Industry 4.0,
  machine learning, robotics, and high-performance computing
  applications
  (<xref alt="Omtzigt &amp; Quinlan, 2022" rid="ref-omtzigtU003A2022" ref-type="bibr">Omtzigt
  &amp; Quinlan, 2022</xref>). The package includes command-line tools
  for visualizing and interrogating numeric encodings, an interface for
  setting and querying bits, and educational examples showcasing
  performance gain and numerical accuracy with the different number
  systems. Finally, Docker containers are available to experiment with
  the library without cloning the repo and building the source code.</p>
  <preformat>$ docker pull stillwater/universal
$ docker run -it --rm stillwater/universal bash</preformat>
  <p><italic>Universal</italic> was originally established in 2017 as a
  reference implementation of the evolving unum Type III (posit and
  valid) standard for bit-level arithmetic. However, as the demand for
  supporting a diverse range of number systems grew,
  <italic>Universal</italic> evolved into a complete platform for
  numerical analysis and computational mathematics, capable of solving
  problems such as large factorials using adaptive-precision integers
  and serving as Oracles using adaptive-precision floats. Many projects
  have leveraged <italic>Universal</italic>, including the Matrix
  Template Library (MTL4), Geometry + Simulation Modules (G+SMO), Bembel
  (a fast IGA BEM solver), and the Odeint ODE solver.</p>
  <p>The default build configuration will produce the command line
  tools, a playground, and educational and application examples. It is
  also possible to construct the full regression suite across all the
  number systems. For instance, the shortened output for the commands
  <monospace>single</monospace> and
  <monospace>single 1.23456789</monospace> are below.</p>
  <code language="bash">$ single
min exponent                                           -125
max exponent                                            128
radix                                                     2
radix digits                                             24
min                                             1.17549e-38
max                                             3.40282e+38
lowest                                         -3.40282e+38
epsilon (1+1ULP-1)                              1.19209e-07
round_error                                             0.5
denorm_min                                       1.4013e-45
infinity                                                inf
quiet_NAN                                               nan
signaling_NAN                                           nan
...


$ single 1.23456789
scientific   : 1.2345679
triple form  : (+,0,0b00111100000011001010010)
binary form  : 0b0.0111'1111.001'1110'0000'0110'0101'0010
color coded  : 0b0.0111'1111.001'1110'0000'0110'0101'0010
  </code>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The demand for high-performance computing (HPC), machine learning,
  and deep learning has grown significantly in recent years (e.g.,
  <xref alt="Carmichael et al., 2019" rid="ref-carmichaelU003A2019" ref-type="bibr">Carmichael
  et al., 2019</xref>;
  <xref alt="Cococcioni et al., 2022" rid="ref-cococcioni2022small" ref-type="bibr">Cococcioni
  et al., 2022</xref>;
  <xref alt="Desrentes et al., 2022" rid="ref-desrentesU003A2022posit8" ref-type="bibr">Desrentes
  et al., 2022</xref>), leading to increased environmental impact and
  financial cost due to their high energy consumption for storage and
  processing
  (<xref alt="Haidar, Abdelfattah, et al., 2018" rid="ref-haidarU003A2018b" ref-type="bibr">Haidar,
  Abdelfattah, et al., 2018</xref>). To address these challenges,
  researchers are exploring ways to reduce energy consumption through
  redesigning algorithms and minimizing data movement and processing.
  The use of multi-precision arithmetic in hardware is also becoming
  more prevalent
  (<xref alt="Haidar, Tomov, et al., 2018" rid="ref-haidarU003A2018a" ref-type="bibr">Haidar,
  Tomov, et al., 2018</xref>). NVIDIA has added support for
  low-precision formats in its GPUs to perform tensor operations
  (<xref alt="Choquette et al., 2021" rid="ref-choquette2021nvidia" ref-type="bibr">Choquette
  et al., 2021</xref>), including a 19-bit format with an 8-bit exponent
  and 10-bit mantissa (see also
  (<xref alt="Intel Corporation, 2018" rid="ref-intelU003A2018" ref-type="bibr">Intel
  Corporation, 2018</xref>;
  <xref alt="Kharya, 2020" rid="ref-kharyaU003A2020" ref-type="bibr">Kharya,
  2020</xref>). Additionally, Google has developed the “Brain Floating
  Point Format,” known as “bfloat16,” which enables the training and
  operation of deep neural networks using Tensor Processing Units (TPUs)
  at higher performance and lower cost
  (<xref alt="Wang &amp; Kanwar, 2019" rid="ref-wang2019bfloat16" ref-type="bibr">Wang
  &amp; Kanwar, 2019</xref>). This trend towards low-precision numerics
  is driving the redesign of many standard algorithms, particularly in
  the field of energy-efficient linear solvers, which is a rapidly
  growing area of research
  (<xref alt="Carson &amp; Higham, 2018" rid="ref-carsonU003A2018" ref-type="bibr">Carson
  &amp; Higham, 2018</xref>;
  <xref alt="Haidar et al., 2017" rid="ref-haidarU003A2017" ref-type="bibr">Haidar
  et al., 2017</xref>;
  <xref alt="Haidar, Tomov, et al., 2018" rid="ref-haidarU003A2018a" ref-type="bibr">Haidar,
  Tomov, et al., 2018</xref>;
  <xref alt="Haidar, Abdelfattah, et al., 2018" rid="ref-haidarU003A2018b" ref-type="bibr">Haidar,
  Abdelfattah, et al., 2018</xref>;
  <xref alt="Higham et al., 2019" rid="ref-highamU003A2019" ref-type="bibr">Higham
  et al., 2019</xref>).</p>
  <p>While the primary motivation for low-precision arithmetic is its
  high performance and energy efficiency, mixed-precision algorithm
  designs aim to identify and exploit opportunities to rightsize the
  number system used for critical computational paths representing the
  execution bottleneck. Furthermore, when these algorithms are
  incorporated into embedded devices and custom hardware engines, we
  approach optimal performance and power efficiency. Therefore,
  investigations into computational mathematics and measuring
  mixed-precision algorithms’ accuracy, efficiency, robustness, and
  stability are needed.</p>
  <p>Custom number systems that optimize the entire system’s performance
  are crucial components to imbue embedded systems with more autonomy.
  Likewise, energy efficiency is an essential differentiator for
  embedded intelligence applications. By observing distinct arithmetic
  requirements of the control and data flow, many performance and power
  efficiency gains can be achieved when developing unique compute
  solutions. It is essential to consider the precision requirements and
  the necessary dynamic range of arithmetic operations when optimizing
  these compute engines.</p>
  <sec id="verification-suite">
    <title>Verification Suite</title>
    <p>Each number system contained within <italic>Universal</italic> is
    supported by a comprehensive verification environment testing
    library class API consistency, logic and arithmetic operators, the
    standard math library, arithmetic exceptions, and language features
    such as compile-time constexpr. The verification suite is run as
    part of the <monospace>make test</monospace> command in the build
    directory.</p>
    <p>Due to the size of the library, the build system for
    <italic>Universal</italic> allows for fine-grain control to subset
    the test environment for productive development and verification.
    There are twelve core build category flags defined:</p>
    <list list-type="bullet">
      <list-item>
        <p>BUILD_APPLICATIONS</p>
      </list-item>
      <list-item>
        <p>BUILD_BENCHMARKS</p>
      </list-item>
      <list-item>
        <p>BUILD_CI</p>
      </list-item>
      <list-item>
        <p>BUILD_CMD_LINE_TOOLS</p>
      </list-item>
      <list-item>
        <p>BUILD_C_API</p>
      </list-item>
      <list-item>
        <p>BUILD_DEMONSTRATION</p>
      </list-item>
      <list-item>
        <p>BUILD_EDUCATION</p>
      </list-item>
      <list-item>
        <p>BUILD_LINEAR_ALGEBRA</p>
      </list-item>
      <list-item>
        <p>BUILD_MIXEDPRECISION_SDK</p>
      </list-item>
      <list-item>
        <p>BUILD_NUMBERS</p>
      </list-item>
      <list-item>
        <p>BUILD_NUMERICS</p>
      </list-item>
      <list-item>
        <p>BUILD_PLAYGROUND</p>
      </list-item>
    </list>
    <p>The flags, when set during cmake configuration, i.e.,
    <monospace>cmake -DBUILD_CI=ON ..</monospace>, enable build targets
    specialized to the category. For example, the
    <monospace>BUILD_CI</monospace> flag turns on the continuous
    integration regression test suites for all number systems, and the
    <monospace>BUILD_APPLICATIONS</monospace> flag will build all the
    example applications that provide demonstrations of mixed-precision,
    high-accuracy, reproducible and/or interval arithmetic.</p>
    <p>Each build category contains individual targets that further
    refine the build targets. For example,
    <monospace>cmake -DBUILD_NUMBER_POSIT=ON -DBUILD_DEMONSTRATION=OFF ..</monospace>
    will build just the fixed-size, arbitrary configuration posit number
    system regression environment.</p>
    <p>It is also possible to run specific test suite components, for
    example, to validate algorithmic changes to more complex arithmetic
    functions, such as square root, exponent, logarithm, and
    trigonometric functions. Here is an example, assuming that the
    logarithmic number system has been configured during the cmake build
    generation:</p>
    <preformat>$ make lns_trigonometry</preformat>
    <p>The repository’s README file has all the details about the build
    and regression environment and how to streamline its operation.</p>
  </sec>
</sec>
<sec id="availability-and-documentation">
  <title>Availability and Documentation</title>
  <p><italic>Universal Number Library</italic> is available under the
  <ext-link ext-link-type="uri" xlink:href="https://choosealicense.com/licenses/mit/">MIT
  License</ext-link>. The package may be cloned or forked from the
  <ext-link ext-link-type="uri" xlink:href="https://github.com/stillwater-sc/universal.git">GitHub
  repository</ext-link>. Documentation is provided via
  <monospace>docs</monospace>, including a tutorial introducing primary
  functionality and detailed reference and communication networks. The
  library employs extensive unit testing.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We want to acknowledge all code contributions, bug reports, and
  feedback from numerous other developers and users.</p>
  <p>Matthias Möller, Peter Gottschling, Caleb James DeLisle, Mark
  Seligman, rainmaker6, Jake Todd, Bill Zorn, Andrew Liu, Allan Leal,
  Flo Edelmann, ShinYee, Will Wray, lvandam, David Summers, Gus Smith,
  Scott Pakin, Silvan Kuttimalai, Simon Barton</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-carmichaelU003A2019">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Carmichael</surname><given-names>Zachariah</given-names></name>
        <name><surname>Langroudi</surname><given-names>Hamed F</given-names></name>
        <name><surname>Khazanov</surname><given-names>Char</given-names></name>
        <name><surname>Lillie</surname><given-names>Jeffrey</given-names></name>
        <name><surname>Gustafson</surname><given-names>John L</given-names></name>
        <name><surname>Kudithipudi</surname><given-names>Dhireesha</given-names></name>
      </person-group>
      <article-title>Deep positron: A deep neural network using the posit number system</article-title>
      <source>2019 design, automation &amp; test in europe conference &amp; exhibition (DATE)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.23919/date.2019.8715262</pub-id>
      <fpage>1421</fpage>
      <lpage>1426</lpage>
    </element-citation>
  </ref>
  <ref id="ref-carsonU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Carson</surname><given-names>Erin</given-names></name>
        <name><surname>Higham</surname><given-names>Nicholas J</given-names></name>
      </person-group>
      <article-title>Accelerating the solution of linear systems by iterative refinement in three precisions</article-title>
      <source>SIAM Journal on Scientific Computing</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>40</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1137/17m1140819</pub-id>
      <fpage>A817</fpage>
      <lpage>A847</lpage>
    </element-citation>
  </ref>
  <ref id="ref-choquette2021nvidia">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Choquette</surname><given-names>Jack</given-names></name>
        <name><surname>Gandhi</surname><given-names>Wishwesh</given-names></name>
        <name><surname>Giroux</surname><given-names>Olivier</given-names></name>
        <name><surname>Stam</surname><given-names>Nick</given-names></name>
        <name><surname>Krashinsky</surname><given-names>Ronny</given-names></name>
      </person-group>
      <article-title>NVIDIA A100 tensor core GPU: Performance and innovation</article-title>
      <source>IEEE Micro</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>41</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1109/mm.2021.3061394</pub-id>
      <fpage>29</fpage>
      <lpage>35</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cococcioni2022small">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cococcioni</surname><given-names>Marco</given-names></name>
        <name><surname>Rossi</surname><given-names>Federico</given-names></name>
        <name><surname>Emanuele</surname><given-names>Ruffaldi</given-names></name>
        <name><surname>Saponara</surname><given-names>Sergio</given-names></name>
      </person-group>
      <article-title>Small reals representations for deep learning at the edge: A comparison</article-title>
      <source>Proc. Of the 2022 conference on next generation arithmetic (CoNGA’22)</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-desrentesU003A2022posit8">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Desrentes</surname><given-names>Orégane</given-names></name>
        <name><surname>Resmerita</surname><given-names>Diana</given-names></name>
        <name><surname>Dinechin</surname><given-names>Benoˆıt Dupont de</given-names></name>
      </person-group>
      <article-title>A Posit8 decompression operator for deep neural network inference</article-title>
      <source>Next generation arithmetic: Third international conference, CoNGA 2022, singapore, march 1–3, 2022, revised selected papers</source>
      <publisher-name>Springer Nature</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>13253</volume>
      <pub-id pub-id-type="doi">10.1007/978-3-031-09779-9_2</pub-id>
      <fpage>14</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-haidarU003A2018a">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Haidar</surname><given-names>Azzam</given-names></name>
        <name><surname>Tomov</surname><given-names>Stanimire</given-names></name>
        <name><surname>Dongarra</surname><given-names>Jack</given-names></name>
        <name><surname>Higham</surname><given-names>Nicholas J</given-names></name>
      </person-group>
      <article-title>Harnessing GPU tensor cores for fast FP16 arithmetic to speed up mixed-precision iterative refinement solvers</article-title>
      <source>SC18: International conference for high performance computing, networking, storage and analysis</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1109/sc.2018.00050</pub-id>
      <fpage>603</fpage>
      <lpage>613</lpage>
    </element-citation>
  </ref>
  <ref id="ref-haidarU003A2017">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Haidar</surname><given-names>Azzam</given-names></name>
        <name><surname>Wu</surname><given-names>Panruo</given-names></name>
        <name><surname>Tomov</surname><given-names>Stanimire</given-names></name>
        <name><surname>Dongarra</surname><given-names>Jack</given-names></name>
      </person-group>
      <article-title>Investigating half precision arithmetic to accelerate dense linear system solvers</article-title>
      <source>Proceedings of the 8th workshop on latest advances in scalable algorithms for large-scale systems</source>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.1145/3148226.3148237</pub-id>
      <fpage>1</fpage>
      <lpage>8</lpage>
    </element-citation>
  </ref>
  <ref id="ref-haidarU003A2018b">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Haidar</surname><given-names>Azzam</given-names></name>
        <name><surname>Abdelfattah</surname><given-names>Ahmad</given-names></name>
        <name><surname>Zounon</surname><given-names>Mawussi</given-names></name>
        <name><surname>Wu</surname><given-names>Panruo</given-names></name>
        <name><surname>Pranesh</surname><given-names>Srikara</given-names></name>
        <name><surname>Tomov</surname><given-names>Stanimire</given-names></name>
        <name><surname>Dongarra</surname><given-names>Jack</given-names></name>
      </person-group>
      <article-title>The design of fast and energy-efficient linear solvers: On the potential of half-precision arithmetic and iterative refinement techniques</article-title>
      <source>International conference on computational science</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1007/978-3-319-93698-7_45</pub-id>
      <fpage>586</fpage>
      <lpage>600</lpage>
    </element-citation>
  </ref>
  <ref id="ref-highamU003A2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Higham</surname><given-names>Nicholas J</given-names></name>
        <name><surname>Pranesh</surname><given-names>Srikara</given-names></name>
        <name><surname>Zounon</surname><given-names>Mawussi</given-names></name>
      </person-group>
      <article-title>Squeezing a matrix into half precision, with an application to solving linear systems</article-title>
      <source>SIAM Journal on Scientific Computing</source>
      <publisher-name>SIAM</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>41</volume>
      <issue>4</issue>
      <pub-id pub-id-type="doi">10.1137/18m1229511</pub-id>
      <fpage>A2536</fpage>
      <lpage>A2551</lpage>
    </element-citation>
  </ref>
  <ref id="ref-intelU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <string-name>Intel Corporation</string-name>
      </person-group>
      <article-title>BFLOAT16 - Hardware Numerics Definition</article-title>
      <source></source>
      <publisher-name>Intel</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume></volume>
      <issue></issue>
      <uri>https://tinyurl.com/y8ybct4</uri>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-kharyaU003A2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kharya</surname><given-names>P</given-names></name>
      </person-group>
      <article-title>TensorFloat-32 in the A100 GPU accelerates AI training HPC up to 20x</article-title>
      <source>NVIDIA Corporation, Tech. Rep</source>
      <year iso-8601-date="2020">2020</year>
      <uri>https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/</uri>
    </element-citation>
  </ref>
  <ref id="ref-omtzigtU003A2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Omtzigt</surname><given-names>E. Theodore L.</given-names></name>
        <name><surname>Quinlan</surname><given-names>James</given-names></name>
      </person-group>
      <article-title>Universal: Reliable, reproducible, and energy-efficient numerics</article-title>
      <source>Conference on next generation arithmetic</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1007/978-3-031-09779-9_7</pub-id>
      <fpage>100</fpage>
      <lpage>116</lpage>
    </element-citation>
  </ref>
  <ref id="ref-omtzigtU003A2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Omtzigt</surname><given-names>E. Theodore L.</given-names></name>
        <name><surname>Gottschling</surname><given-names>Peter</given-names></name>
        <name><surname>Seligman</surname><given-names>Mark</given-names></name>
        <name><surname>Zorn</surname><given-names>William</given-names></name>
      </person-group>
      <article-title>Universal Numbers Library: Design and implementation of a high-performance reproducible number systems library</article-title>
      <source>arXiv:2012.11011</source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-wang2019bfloat16">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Shibo</given-names></name>
        <name><surname>Kanwar</surname><given-names>Pankaj</given-names></name>
      </person-group>
      <article-title>BFloat16: The secret to high performance on cloud TPUs</article-title>
      <source>Google Cloud Blog</source>
      <year iso-8601-date="2019">2019</year>
      <volume>4</volume>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
