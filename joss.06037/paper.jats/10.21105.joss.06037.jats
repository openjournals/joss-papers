<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6037</article-id>
<article-id pub-id-type="doi">10.21105/joss.06037</article-id>
<title-group>
<article-title>Multivariate Covariance Generalized Linear Models in
Python: The mcglm library</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0001-3747-0669</contrib-id>
<name>
<surname>Maia</surname>
<given-names>Jean Carlos Faoot</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0349-7054</contrib-id>
<name>
<surname>Bonat</surname>
<given-names>Wagner Hugo</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Paraná Federal University, Brazil</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-08-09">
<day>9</day>
<month>8</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>98</issue>
<fpage>6037</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>statistical models</kwd>
<kwd>multivariate statistical analysis</kwd>
<kwd>longitudinal data analysis</kwd>
<kwd>MCGLM</kwd>
<kwd>GLM</kwd>
<kwd>statsmodels</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="abstract">
  <title>Abstract</title>
  <p>The <monospace>mcglm</monospace> library, a newly introduced Python
  tool, facilitates statistical analyses using Multivariate Covariance
  Generalized Linear Models (McGLM). This contemporary family of models
  universalizes the traditional Generalized Linear Models (GLM),
  empowering them to handle multivariate and non-independent response
  variables. Due to its flexibility and explicit specification, McGLM
  supports a lot of statistical analyses across different kinds of data
  and distinct traits; in this article, we promote
  <monospace>mcglm</monospace>.</p>
  <p>The <monospace>mcglm</monospace> library provides a comprehensive
  platform for data analysis using the McGLM framework. Built upon the
  established standards of the <monospace>statsmodels</monospace>
  library, it provides a comprehensive summary report for fitting
  assessment, including elementary parameters such as regression and
  dispersion coefficients, confidence intervals, hypothesis testing
  results, residual analysis, goodness-of-fit measurements, and
  correlation coefficients between outcomes. In addition, the library
  provides a rich set of link and variance functions and tools to define
  inner-response dependency matrices through the matrix linear
  predictor. The base code is extendable and reliable, reflecting sound
  object-oriented programming practices and thorough unit testing.</p>
  <p>The library is hosted on PyPI and can be installed with some Python
  library manager, such as <monospace>pip</monospace>.</p>
</sec>
<sec id="introduction">
  <title>Introduction</title>
  <p>Dated at the beginning of the 19th century and controversial about
  the actual authorship, the least squares method established an
  optimization algorithm
  (<xref alt="Stigler, 1981" rid="ref-10.1214U002F1176345451" ref-type="bibr">Stigler,
  1981</xref>). According to the Gauss-Markov theorem
  (<xref alt="Hallin, 2014" rid="ref-Gauss-Marc" ref-type="bibr">Hallin,
  2014</xref>), the resulting estimates are optimal and unbiased under
  linear conditions. This optimization method forms the basis of linear
  regression, one of the earliest statistical models
  (<xref alt="Galton, 1886" rid="ref-galtonU003A1886" ref-type="bibr">Galton,
  1886</xref>;
  <xref alt="Narula &amp; Wellington., 1982" rid="ref-linearregressionU003A1982" ref-type="bibr">Narula
  &amp; Wellington., 1982</xref>). Linear regression associates a
  response variable to a group of covariates by employing a linear
  operation on regression coefficients
  (<xref alt="Seal, 1967" rid="ref-gaussU003A2022" ref-type="bibr">Seal,
  1967</xref>). Three main assumptions for linear regression are
  linearity, independent realizations of the response variable, and a
  Gaussian homoscedastic error with a zero mean. While standing the test
  of time, linear regression has motivated numerous statistical
  proposals seeking to generalize its foundational assumptions.</p>
  <p>Over time, many statistical proposals have aimed to extend the
  linear regression. Nelder &amp; Wedderburn
  (<xref alt="1972" rid="ref-glmU003A1972" ref-type="bibr">1972</xref>)
  proposed the Generalized Linear Model (GLM), which relieves the
  Gaussian assumption accommodating exponential family models
  (<xref alt="Müller, 2004" rid="ref-GLMU003A2004" ref-type="bibr">Müller,
  2004</xref>). Similarly, the Generalized Additive Model (GAM)
  (<xref alt="Hastie &amp; Tibshirani, 1986" rid="ref-GAMU003A1986" ref-type="bibr">Hastie
  &amp; Tibshirani, 1986</xref>) eases the linear assumption by using
  covariates smooth functions. The Generalized Estimating Equations
  (GEE)
  (<xref alt="Liang &amp; Zeger, 1986" rid="ref-ZegerU003A1988" ref-type="bibr">Liang
  &amp; Zeger, 1986</xref>) apply the quasi-likelihood estimating
  functions to deal with dependent data. Additional consolidated
  frameworks for dependent data include Copulas
  (<xref alt="Krupskii &amp; Joe, 2013" rid="ref-KrupskiiU003A2013" ref-type="bibr">Krupskii
  &amp; Joe, 2013</xref>;
  <xref alt="Masarotto &amp; Varin, 2012" rid="ref-MasarottoU003A2012" ref-type="bibr">Masarotto
  &amp; Varin, 2012</xref>), and Mixed Models
  (<xref alt="Verbeke et al., 2014" rid="ref-VerbekeU003A2014" ref-type="bibr">Verbeke
  et al., 2014</xref>), among others. One prevalent aspect of the cited
  frameworks is that they cannot deal with multiple response
  variables.</p>
  <p>The Multivariate Covariance Generalized Linear Model (McGLM)
  (<xref alt="Wagner H. Bonat &amp; Jørgensen, 2016" rid="ref-BonatU003A2016" ref-type="bibr">Wagner
  H. Bonat &amp; Jørgensen, 2016</xref>) extends the GLM by allowing the
  multivariate analysis of non-independent responses, including
  longitudinal and spatial data. The model is defined through
  second-moment assumptions, utilizing five essential components: the
  linear predictor via design matrix, link function, variance function,
  covariance link function, and the matrix linear predictor. As a
  comprehensive statistical model, McGLM facilitates analysis by
  assessing regression and dispersion coefficients, hypothesis tests,
  goodness-of-fit measurements, and correlation coefficients between
  response variables. To the best of our knowledge, the library
  <monospace>mcglm</monospace> is the first holistic framework to
  support statistical analysis in Python with the aid of McGLM.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The McGLM framework is available for R users through the
  open-source package <monospace>mcglm</monospace>
  (<xref alt="W. H. Bonat, 2016" rid="ref-BonatU003A2016b" ref-type="bibr">W.
  H. Bonat, 2016</xref>); nevertheless, the language Python did not have
  a standard library until the library <monospace>mcglm</monospace>. The
  foremost library for statistical analysis in Python is the
  <monospace>statsmodels</monospace>
  (<xref alt="Seabold &amp; Perktold, 2010" rid="ref-SeaboldU003A2010" ref-type="bibr">Seabold
  &amp; Perktold, 2010</xref>). It implements classical statistical
  models, such as GLM, GAM, GEE, and Copulas. Many other libraries stand
  out for probabilistic programming in Python
  (<xref alt="Meent et al., 2018" rid="ref-probabilisticpU003A2018" ref-type="bibr">Meent
  et al., 2018</xref>), such as: <monospace>PyMC</monospace>
  (<xref alt="Salvatier et al., 2016" rid="ref-pymc3U003A2016" ref-type="bibr">Salvatier
  et al., 2016</xref>), <monospace>Pyro</monospace>
  (<xref alt="Bingham et al., 2018" rid="ref-pyroU003A2018" ref-type="bibr">Bingham
  et al., 2018</xref>), and <monospace>PyStan</monospace>
  (<xref alt="Carpenter et al., 2017" rid="ref-stanU003A2017" ref-type="bibr">Carpenter
  et al., 2017</xref>). Those libraries distinguish from
  <monospace>statsmodels</monospace> on their Bayesian paradigm of
  specifying models. The library <monospace>mcglm</monospace> specifies
  the McGLM in a frequentist fashion.</p>
  <p>The library <monospace>mcglm</monospace> provides an easy interface
  for fitting McGLM on the standards of the
  <monospace>statsmodels</monospace>
  (<xref alt="Seabold &amp; Perktold, 2010" rid="ref-SeaboldU003A2010" ref-type="bibr">Seabold
  &amp; Perktold, 2010</xref>) library. It provides a comprehensive
  framework for statistical analysis supported by McGLM, with tools to
  lead its model specification, fitting, and appropriate report to
  assess estimates.</p>
</sec>
<sec id="model-components">
  <title>Model Components</title>
  <p>McGLM is specified by five components: linear predictors, link
  functions, variance functions, matrix linear predictors, and
  covariance link functions. In this section, we discuss the usual
  choice for each of these components.</p>
  <p>McGLM offers the flexibility to specify typical linear predictors,
  including the usual formula notation popular in many statistical
  software. In alignment with the GLM framework, the link function
  encompasses usual choices like logit and probit for binary and
  binomial data, log for count data, and identity for continuous
  accurate data. The variance function is fundamental to the McGLM, as
  it is related to the marginal distribution of the response variable.
  Noteworthy among common choices is the power of the variance function,
  which is specialized for handling continuous data and defines the
  Tweedie family of distributions, as elucidated by Jørgensen
  (<xref alt="1987" rid="ref-bentU003A1987" ref-type="bibr">1987</xref>)
  and Jørgensen
  (<xref alt="1997" rid="ref-bentU003A1997" ref-type="bibr">1997</xref>).
  This family includes exceptional cases such as Gaussian (p = 0), Gamma
  (p = 2), and Inverse Gaussian (p = 3). The variance function extended
  binomial is a common choice for analyzing bounded data. For fitting
  count data, the dispersion function presented by Jørgensen &amp;
  Kokonendji
  (<xref alt="2015" rid="ref-kokonendjiU003A2015" ref-type="bibr">2015</xref>),
  called Poisson-Tweedie, is flexible enough to capture notable models,
  such as Hermite (p = 0), Neyman Type A (p = 1), Negative Binomial (p =
  2) and Poisson inverse Gaussian (p = 3). The following table
  summarizes the mentioned variance functions:</p>
  <table-wrap>
    <caption>
      <p>Table with variance functions implemented</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Function name</th>
          <th align="left">Formula</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left"><monospace>Tweedie/Power</monospace></td>
          <td align="left"><inline-formula><alternatives>
          <tex-math><![CDATA[\mathrm{V}(.;p) = \mu^{p}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>.</mml:mi><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></td>
        </tr>
        <tr>
          <td align="left"><monospace>Binomial</monospace></td>
          <td align="left"><inline-formula><alternatives>
          <tex-math><![CDATA[\mathrm{V}(.;p) = \mu^{p} (1 - \mu)^{p}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>.</mml:mi><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>p</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></td>
        </tr>
        <tr>
          <td align="left"><monospace>Poisson-Tweedie</monospace></td>
          <td align="left"><inline-formula><alternatives>
          <tex-math><![CDATA[\mathrm{V}(.;p) = \mu + \mu^{p}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>.</mml:mi><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>The user specifies the dependency through the Z matrices in the
  matrix linear predictor to describe the covariance structure. Many of
  the classical statistical models are replicable by setting tailored Z
  matrices. To cite a few, mixed models, moving averages, and compound
  symmetry. For more details, see Wagner H. Bonat &amp; Jørgensen
  (<xref alt="2016" rid="ref-BonatU003A2016" ref-type="bibr">2016</xref>)
  and W. Bonat
  (<xref alt="2018" rid="ref-BonatU003A2018" ref-type="bibr">2018</xref>).
  Finally, W. Bonat
  (<xref alt="2018" rid="ref-BonatU003A2018" ref-type="bibr">2018</xref>)
  proposed three covariance link functions: identity, inverse, and
  exponential-matrix.</p>
</sec>
<sec id="the-python-library-mcglm">
  <title>The Python library mcglm</title>
  <fig>
    <caption><p>UML for the library
    <styled-content id="figU003Aumlcode"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="classes.png" />
  </fig>
  <p>The library <monospace>mcglm</monospace> provides the first Python
  tool for statistical analysis with the aid of McGLM. Heavily
  influenced by its twin R version
  (<xref alt="W. Bonat, 2018" rid="ref-BonatU003A2018" ref-type="bibr">W.
  Bonat, 2018</xref>), the library has ninety-one percent of
  unit-testing coverage. URLs of source-code and PyPI, the official
  repository for Python libraries, are
  <ext-link ext-link-type="uri" xlink:href="https://github.com/jeancmaia/mcglm">https://github.com/jeancmaia/mcglm</ext-link>
  and
  <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/mcglm">https://pypi.org/project/mcglm</ext-link>.
  The library mcglm can easily be installed using the library
  <monospace>pip</monospace>.</p>
  <p>The <monospace>mcglm</monospace> library is based on popular
  libraries of scientific Python programming:
  <monospace>NumPy</monospace>
  (<xref alt="Harris, 2020" rid="ref-harris2020array" ref-type="bibr">Harris,
  2020</xref>) and <monospace>SciPy</monospace>
  (<xref alt="Virtanen, 2020" rid="ref-2020SciPy-NMeth" ref-type="bibr">Virtanen,
  2020</xref>). We inherit <monospace>statsmodels</monospace>’s
  interface and deliver a code library akin to their standards API.
  Object-oriented programming is another cornerstone for the library
  <monospace>mcglm</monospace>; the SOLID principles
  (<xref alt="Rana &amp; Khonica, 2021" rid="ref-solidU003A2021" ref-type="bibr">Rana
  &amp; Khonica, 2021</xref>) helped to create a readable and extensible
  code base. The UML diagram
  <xref alt="[fig:umlcode]" rid="figU003Aumlcode">[fig:umlcode]</xref>
  presents the <monospace>mcglm</monospace> library architecture.</p>
  <p>The implementation <monospace>mcglm</monospace> lies in six
  classes: <monospace>MCGLM</monospace>,
  <monospace>MCGLMMean</monospace>,
  <monospace>MCGLMVariance</monospace>,
  <monospace>MCGLMCAttributes</monospace>,
  <monospace>MCGLMParameters</monospace> and
  <monospace>MCGLMResults</monospace>. Each class has its scope and
  responsibilities. For in-depth details, access our documentation at
  <ext-link ext-link-type="uri" xlink:href="https://mcglm.readthedocs.io">https://mcglm.readthedocs.io</ext-link>.</p>
  <p>We adopted the <monospace>statsmodels</monospace> standards of
  attribute names; the endog argument is a vector, or a matrix, with the
  realizations of the response variable; the exog statement defines the
  covariates through design matrices. For multiple outcomes, endog and
  exog must be specified via Python lists. The z argument establishes
  dependency arrays through <monospace>numpy</monospace> array
  structures.</p>
  <p>Arguments link and variance set the link and variance functions,
  respectively. For the former, the available options are Identity,
  Logit, Power, Log, Probit, Cauchy, Cloglog, Log-log, NegativeBinomial,
  and Inverse Power - all canonical options for GLM. Suitable options
  for the variance are Constant, Tweedie, BinomialP, BinomialPQ,
  Geometric-Tweedie, and Poisson-Tweedie. The default values for the
  link and variance functions are identity and constant, suitable picks
  for Gaussian models. For multiple outcomes, link and variance must be
  specified via Python lists.</p>
  <p>The offset argument is suitable for either continuous or count
  outcomes. In addition, parameter ntrial is the canonical number of
  trials for binomial data. Finally, parameter power_fixed activates
  searching for the power parameter for Tweedie models. For multiple
  outcomes, parameters must be specified via Python lists.</p>
  <p>An instantiated object can fit a model with the fit() method, which
  returns an object of the <monospace>MCGLMResults</monospace> class.
  This object can trigger two methods: summary(), a comprehensive report
  of estimates on the <monospace>statsmodels</monospace> fashion, and
  anova(), to an ANOVA test for categorical covariates. Some other
  attributes may be helpful, such as mu, which returns a vector with
  expected values; pearson_residuals for the Pearson normalized
  residuals; aic, bic, and loglikelihood for model comparison.</p>
  <p>Moreover, library <monospace>mcglm</monospace> provides methods to
  assist in specifying the matrix linear predictor through dependence
  matrices Z. There are three available methods: mc_id(), which crafts a
  matrix for independent realizations of outcome; mc_mixed(), which
  builds matrices for mixed models, and mc_ma() that build matrices for
  moving average fitting, popular models in time series analysis. The
  package <monospace>mcglm</monospace> of R language implements similar
  methods to aid in the matrix linear predictor specification. For
  in-depth details about those matrices, see Wagner H. Bonat &amp;
  Jørgensen
  (<xref alt="2016" rid="ref-BonatU003A2016" ref-type="bibr">2016</xref>).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-pymc3U003A2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Salvatier</surname><given-names>John</given-names></name>
        <name><surname>Wiecki</surname><given-names>Thomas</given-names></name>
        <name><surname>Fonnesbeck</surname><given-names>Christopher</given-names></name>
      </person-group>
      <article-title>Probabilistic programming in Python using PyMC3</article-title>
      <year iso-8601-date="2016-01">2016</year><month>01</month>
      <pub-id pub-id-type="doi">10.7287/PEERJ.PREPRINTS.1686V1</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-probabilisticpU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Meent</surname><given-names>Jan-Willem</given-names></name>
        <name><surname>Paige</surname><given-names>Brooks</given-names></name>
        <name><surname>Yang</surname><given-names>Hongseok</given-names></name>
        <name><surname>Wood</surname><given-names>Frank</given-names></name>
      </person-group>
      <article-title>An introduction to probabilistic programming</article-title>
      <year iso-8601-date="2018-09">2018</year><month>09</month>
      <pub-id pub-id-type="doi">10.48550/arXiv.1809.10756</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-pyroU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bingham</surname><given-names>Eli</given-names></name>
        <name><surname>Chen</surname><given-names>Jonathan</given-names></name>
        <name><surname>Jankowiak</surname><given-names>Martin</given-names></name>
        <name><surname>Obermeyer</surname><given-names>Fritz</given-names></name>
        <name><surname>Pradhan</surname><given-names>Neeraj</given-names></name>
        <name><surname>Karaletsos</surname><given-names>Theofanis</given-names></name>
        <name><surname>Singh</surname><given-names>Rohit</given-names></name>
        <name><surname>Szerlip</surname><given-names>Paul</given-names></name>
        <name><surname>Horsfall</surname><given-names>Paul</given-names></name>
        <name><surname>Goodman</surname><given-names>Noah</given-names></name>
      </person-group>
      <article-title>Pyro: Deep universal probabilistic programming</article-title>
      <year iso-8601-date="2018-10">2018</year><month>10</month>
      <pub-id pub-id-type="doi">10.48550/arXiv.1810.09538</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-stanU003A2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Carpenter</surname><given-names>Bob</given-names></name>
        <name><surname>Gelman</surname><given-names>Andrew</given-names></name>
        <name><surname>Hoffman</surname><given-names>Matthew</given-names></name>
        <name><surname>Lee</surname><given-names>Daniel</given-names></name>
        <name><surname>Goodrich</surname><given-names>Ben</given-names></name>
        <name><surname>Betancourt</surname><given-names>Michael</given-names></name>
        <name><surname>Brubaker</surname><given-names>Marcus</given-names></name>
        <name><surname>Guo</surname><given-names>Jiqiang</given-names></name>
        <name><surname>Li</surname><given-names>Peter</given-names></name>
        <name><surname>Riddell</surname><given-names>Allen</given-names></name>
      </person-group>
      <article-title>Stan : A probabilistic programming language</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <volume>76</volume>
      <pub-id pub-id-type="doi">10.18637/jss.v076.i01</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-kokonendjiU003A2015">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jørgensen</surname><given-names>B.</given-names></name>
        <name><surname>Kokonendji</surname><given-names>C. C.</given-names></name>
      </person-group>
      <article-title>Discrete dispersion models and their Tweedie asymptotics.</article-title>
      <source>AStA Advances in Statistical Analysis, 100(1)</source>
      <year iso-8601-date="2015">2015</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1409.7482</pub-id>
      <fpage>43</fpage>
      <lpage>78</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bentU003A1987">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jørgensen</surname><given-names>B.</given-names></name>
      </person-group>
      <article-title>Exponential dispersion models.</article-title>
      <source>Journal of the Royal Statistical Society</source>
      <year iso-8601-date="1987">1987</year>
      <pub-id pub-id-type="doi">10.1111/j.2517-6161.1987.tb01685.x</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bentU003A1997">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jørgensen</surname><given-names>B.</given-names></name>
      </person-group>
      <article-title>The theory of dispersion models.</article-title>
      <source>CRC Press</source>
      <year iso-8601-date="1997">1997</year>
      <pub-id pub-id-type="doi">10.1002/1097-0258(20000730)19:14&lt;1952::AID-SIM474&gt;3.0.CO;2-K</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-glmU003A1972">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Nelder</surname><given-names>J. A.</given-names></name>
        <name><surname>Wedderburn</surname><given-names>R. W. M.</given-names></name>
      </person-group>
      <article-title>Generalized Linear Models.</article-title>
      <year iso-8601-date="1972">1972</year>
      <isbn>978-0-8176-4810-7</isbn>
      <pub-id pub-id-type="doi">10.2307/2344614</pub-id>
      <fpage>370</fpage>
      <lpage>384</lpage>
    </element-citation>
  </ref>
  <ref id="ref-GLMU003A2004">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Müller</surname><given-names>Marlene</given-names></name>
      </person-group>
      <article-title>Generalized Linear Models</article-title>
      <year iso-8601-date="2004-02">2004</year><month>02</month>
      <isbn>978-3-540-66207-5</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-642-21551-3_24</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-GAMU003A1986">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hastie</surname><given-names>T.</given-names></name>
        <name><surname>Tibshirani</surname><given-names>R.</given-names></name>
      </person-group>
      <article-title>Generalized Additive Models (with discussion)</article-title>
      <source>Statistical Science 1</source>
      <year iso-8601-date="1986">1986</year>
      <pub-id pub-id-type="doi">10.1214/ss/1177013604</pub-id>
      <fpage>297</fpage>
      <lpage>318</lpage>
    </element-citation>
  </ref>
  <ref id="ref-10.1214U002F1176345451">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stigler</surname><given-names>Stephen M.</given-names></name>
      </person-group>
      <article-title>Gauss and the invention of Least Squares</article-title>
      <source>The Annals of Statistics</source>
      <publisher-name>Institute of Mathematical Statistics</publisher-name>
      <year iso-8601-date="1981">1981</year>
      <volume>9</volume>
      <issue>3</issue>
      <uri>https://doi.org/10.1214/aos/1176345451</uri>
      <pub-id pub-id-type="doi">10.1214/aos/1176345451</pub-id>
      <fpage>465 </fpage>
      <lpage> 474</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Gauss-Marc">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Hallin</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Gauss-Markov theorem in Statistics</article-title>
      <year iso-8601-date="2014-09">2014</year><month>09</month>
      <isbn>9781118445112</isbn>
      <pub-id pub-id-type="doi">10.1002/9781118445112.stat07536</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-galtonU003A1886">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Galton</surname><given-names>F</given-names></name>
      </person-group>
      <article-title>Regression towards mediocrity in hereditary stature.</article-title>
      <source>Journal of the Anthropological Institute of Great Britain and Ireland</source>
      <year iso-8601-date="1886">1886</year>
      <pub-id pub-id-type="doi">10.2307/2841583</pub-id>
      <fpage>246</fpage>
      <lpage>263</lpage>
    </element-citation>
  </ref>
  <ref id="ref-gaussU003A2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Seal</surname><given-names>Hilary L.</given-names></name>
      </person-group>
      <article-title>Studies in the history of probability and statistics. XV: The historical development of the Gauss linear model</article-title>
      <source>Biometrika</source>
      <publisher-name>[Oxford University Press, Biometrika Trust]</publisher-name>
      <year iso-8601-date="1967">1967</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2022-12-22">2022</year><month>12</month><day>22</day></date-in-citation>
      <volume>54</volume>
      <issue>1/2</issue>
      <uri>http://www.jstor.org/stable/2333849</uri>
      <pub-id pub-id-type="doi">10.2307/2333849</pub-id>
      <fpage>1</fpage>
      <lpage>24</lpage>
    </element-citation>
  </ref>
  <ref id="ref-linearregressionU003A1982">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Narula</surname><suffix>Subhash C.</suffix></name>
        <name><surname>Wellington.</surname><given-names>John F.</given-names></name>
      </person-group>
      <article-title>The minimum sum of absolute errors regression: A state of the art survey.</article-title>
      <source>Internationale de Statistique</source>
      <publisher-name>JSTOR</publisher-name>
      <year iso-8601-date="1982">1982</year>
      <volume>585</volume>
      <issue>3</issue>
      <uri>https://doi.org/10.2307/1402501</uri>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>317</fpage>
      <lpage>26</lpage>
    </element-citation>
  </ref>
  <ref id="ref-harris2020array">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Harris</surname><given-names>Harris et al.</given-names></name>
      </person-group>
      <article-title>Array programming with NumPy</article-title>
      <source>Nature</source>
      <publisher-name>Springer Science; Business Media LLC</publisher-name>
      <year iso-8601-date="2020-09">2020</year><month>09</month>
      <volume>585</volume>
      <issue>7825</issue>
      <uri>https://doi.org/10.1038/s41586-020-2649-2</uri>
      <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      <fpage>357</fpage>
      <lpage>362</lpage>
    </element-citation>
  </ref>
  <ref id="ref-2020SciPy-NMeth">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Virtanen</surname><given-names>Pauli et al.</given-names></name>
      </person-group>
      <article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>
      <source>Nature Methods</source>
      <year iso-8601-date="2020">2020</year>
      <volume>17</volume>
      <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>
      <fpage>261</fpage>
      <lpage>272</lpage>
    </element-citation>
  </ref>
  <ref id="ref-BonatU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bonat</surname><given-names>Wagner</given-names></name>
      </person-group>
      <article-title>Multiple response variables regression models in R : The mcglm package</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2018-04">2018</year><month>04</month>
      <volume>84</volume>
      <pub-id pub-id-type="doi">10.18637/jss.v084.i04</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-SeaboldU003A2010">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Seabold</surname><given-names>Skipper</given-names></name>
        <name><surname>Perktold</surname><given-names>Josef</given-names></name>
      </person-group>
      <article-title>Statsmodels: Econometric and statistical modeling with Python</article-title>
      <source>Proceedings of the 9th Python in Science Conference</source>
      <year iso-8601-date="2010-01">2010</year><month>01</month>
      <volume>2010</volume>
      <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-011</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-solidU003A2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rana</surname><given-names>Muhammad Ehsan</given-names></name>
        <name><surname>Khonica</surname><given-names>Eddy</given-names></name>
      </person-group>
      <article-title>Impact of design principles and patterns on software flexibility: An experimental evaluation using flexible point (FXP)</article-title>
      <source>Journal of Computer Science</source>
      <publisher-name>Science Publications</publisher-name>
      <year iso-8601-date="2021-07">2021</year><month>07</month>
      <volume>17</volume>
      <issue>7</issue>
      <uri>https://thescipub.com/abstract/jcssp.2021.624.638</uri>
      <pub-id pub-id-type="doi">10.3844/jcssp.2021.624.638</pub-id>
      <fpage>624</fpage>
      <lpage>638</lpage>
    </element-citation>
  </ref>
  <ref id="ref-VerbekeU003A2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Verbeke</surname><given-names>G.</given-names></name>
        <name><surname>Fieuws</surname><given-names>S.</given-names></name>
        <name><surname>Molenberghs</surname><given-names>G.</given-names></name>
        <name><surname>Davidian</surname><given-names>M.</given-names></name>
      </person-group>
      <article-title>The analysis of Multivariate Longitudinal data: A review</article-title>
      <source>Statistical Methods in Medical Research</source>
      <year iso-8601-date="2014">2014</year>
      <volume>23</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1177/0962280212445834</pub-id>
      <fpage>42</fpage>
      <lpage>59</lpage>
    </element-citation>
  </ref>
  <ref id="ref-MasarottoU003A2012">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Masarotto</surname><given-names>G.</given-names></name>
        <name><surname>Varin</surname><given-names>C.</given-names></name>
      </person-group>
      <article-title>Gaussian Copula marginal regression</article-title>
      <source>Electronic Journal of Statistics</source>
      <year iso-8601-date="2012">2012</year>
      <volume>6</volume>
      <pub-id pub-id-type="doi">10.1214/12-EJS721</pub-id>
      <fpage>1517</fpage>
      <lpage>1549</lpage>
    </element-citation>
  </ref>
  <ref id="ref-KrupskiiU003A2013">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Krupskii</surname><given-names>P.</given-names></name>
        <name><surname>Joe</surname><given-names>H.</given-names></name>
      </person-group>
      <article-title>Factor Copula Models for multivariate data</article-title>
      <source>Journal of Multivariate Analysis</source>
      <year iso-8601-date="2013">2013</year>
      <volume>120</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1016/j.jmva.2013.05.001</pub-id>
      <fpage>85</fpage>
      <lpage>101</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ZegerU003A1988">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Liang</surname><given-names>Kung-Yee</given-names></name>
        <name><surname>Zeger</surname><given-names>S. L.</given-names></name>
      </person-group>
      <article-title>Longitudinal data analysis using Generalized Linear Models</article-title>
      <source>Biometrika</source>
      <year iso-8601-date="1986">1986</year>
      <volume>73</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1093/biomet/73.1.13</pub-id>
      <fpage>13</fpage>
      <lpage>22</lpage>
    </element-citation>
  </ref>
  <ref id="ref-BonatU003A2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bonat</surname><given-names>Wagner H.</given-names></name>
        <name><surname>Jørgensen</surname><given-names>Bent</given-names></name>
      </person-group>
      <article-title>Multivariate Covariance Generalized Linear Models</article-title>
      <source>Journal of the Royal Statistical Society C</source>
      <year iso-8601-date="2016">2016</year>
      <volume>65</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1111/rssc.12145</pub-id>
      <fpage>649</fpage>
      <lpage>675</lpage>
    </element-citation>
  </ref>
  <ref id="ref-BonatU003A2016b">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bonat</surname><given-names>W. H.</given-names></name>
      </person-group>
      <article-title>Modeling Mixed outcomes in Additive Genetic Models</article-title>
      <source>ArXiv</source>
      <year iso-8601-date="2016">2016</year>
      <volume></volume>
      <issue></issue>
      <pub-id pub-id-type="doi">10.1515/ijb-2017-0001</pub-id>
      <fpage></fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
