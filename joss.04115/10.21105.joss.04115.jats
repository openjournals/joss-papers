<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">4115</article-id>
<article-id pub-id-type="doi">10.21105/joss.04115</article-id>
<title-group>
<article-title>Cabana: A Performance Portable Library for Particle-Based
Simulations</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0103-888X</contrib-id>
<name>
<surname>Slattery</surname>
<given-names>Stuart</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-4250-9476</contrib-id>
<name>
<surname>Reeve</surname>
<given-names>Samuel Temple</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Junghans</surname>
<given-names>Christoph</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lebrun-Grandié</surname>
<given-names>Damien</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bird</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Guangye</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fogerty</surname>
<given-names>Shane</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Qiu</surname>
<given-names>Yuxing</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schulz</surname>
<given-names>Stephan</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Scheinberg</surname>
<given-names>Aaron</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Isner</surname>
<given-names>Austin</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chong</surname>
<given-names>Kwitae</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moore</surname>
<given-names>Stan</given-names>
</name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Germann</surname>
<given-names>Timothy</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Belak</surname>
<given-names>James</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mniszewski</surname>
<given-names>Susan</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Oak Ridge National Laboratory, Oak Ridge, TN,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Los Alamos National Laboratory, Los Alamos, NM,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of California, Los Angeles, Los Angeles, CA,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Jülich Supercomputing Centre, Jülich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Jubilee Development, Cambridge, MA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Sandia National Laboratories, Albuquerque, NM,
USA</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Lawrence Livermore National Laboratory, Livermore, CA,
USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-12-15">
<day>15</day>
<month>12</month>
<year>2021</year>
</pub-date>
<volume>7</volume>
<issue>72</issue>
<fpage>4115</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>C++</kwd>
<kwd>Kokkos</kwd>
<kwd>particles</kwd>
<kwd>molecular dynamics</kwd>
<kwd>N-body cosmology</kwd>
<kwd>particle-in-cell</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Particle-based simulations are ubiquitous throughout many fields of
  computational science and engineering, spanning the atomistic level
  with molecular dynamics (MD), to mesoscale particle-in-cell (PIC)
  simulations for solid mechanics, device-scale modeling with PIC
  methods for plasma physics, and massive N-body cosmology simulations
  of galaxy structures, with many other methods in between
  (<xref alt="Hockney &amp; Eastwood, 1989" rid="ref-hockney" ref-type="bibr">Hockney
  &amp; Eastwood, 1989</xref>). While these methods use particles to
  represent significantly different entities with completely different
  physical models, many low-level details are shared including
  performant algorithms for short- and/or long-range particle
  interactions, multi-node particle communication patterns, and other
  data management tasks such as particle sorting and neighbor list
  construction.</p>
  <p><monospace>Cabana</monospace> is a performance portable library for
  particle-based simulations, developed as part of the Co-Design Center
  for Particle Applications (CoPA) within the Exascale Computing Project
  (ECP)
  (<xref alt="Alexander et al., 2020" rid="ref-ecpU003A2020" ref-type="bibr">Alexander
  et al., 2020</xref>). The CoPA project and its full development scope,
  including ECP partner applications, algorithm development, and similar
  software libraries for quantum MD, is described in
  (<xref alt="Mniszewski et al., 2021" rid="ref-copaU003A2021" ref-type="bibr">Mniszewski
  et al., 2021</xref>). <monospace>Cabana</monospace> uses the
  <monospace>Kokkos</monospace> library for on-node parallelism
  (<xref alt="Edwards et al., 2014" rid="ref-kokkosU003A2014" ref-type="bibr">Edwards
  et al., 2014</xref>;
  <xref alt="Trott et al., 2022" rid="ref-kokkosU003A2022" ref-type="bibr">Trott
  et al., 2022</xref>), enabling simulation on multi-core CPU and GPU
  architectures, and <monospace>MPI</monospace> for GPU-aware,
  multi-node communication. <monospace>Cabana</monospace> provides
  particle simulation capabilities on almost all current
  <monospace>Kokkos</monospace> backends, including serial execution,
  <monospace>OpenMP</monospace> (including
  <monospace>OpenMP-Target</monospace> for GPUs),
  <monospace>CUDA</monospace> (NVIDIA GPUs), <monospace>HIP</monospace>
  (AMD GPUs), and <monospace>SYCL</monospace> (Intel GPUs), providing a
  clear path for the coming generation of accelerator-based exascale
  hardware. <monospace>Cabana</monospace> builds on
  <monospace>Kokkos</monospace> by providing new particle data
  structures and particle algorithms resulting in a similar execution
  policy-based, node-level programming model that is intended to be used
  in addition to the core <monospace>Kokkos</monospace> library within
  an application. <monospace>Cabana</monospace> is designed as an
  application and physics agnostic, but particle-specific toolkit which
  can either be used to generate a new application, or to be used as
  needed in existing applications at various levels of invasiveness
  including through interfaces that wrap user memory in existing data
  structures.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>For the most part, particle simulation codes targeting high
  performance computing have been developed specific to a given
  application area. Examples include <monospace>HACC</monospace> for
  cosmology
  (<xref alt="Habib et al., 2016" rid="ref-haccU003A2016" ref-type="bibr">Habib
  et al., 2016</xref>), <monospace>LAMMPS</monospace> for atomic systems
  (<xref alt="Plimpton, 1995" rid="ref-lammpsU003A1995" ref-type="bibr">Plimpton,
  1995</xref>), and <monospace>XGC</monospace> for plasma physics
  (<xref alt="Ku et al., 2018" rid="ref-xgcU003A2018" ref-type="bibr">Ku
  et al., 2018</xref>) (all ECP partner applications for the CoPA
  project). In contrast, other areas of computational science have
  successfully developed motif-based libraries,
  e.g. <monospace>AMReX</monospace> for block structured adaptive mesh
  based simulations
  (<xref alt="Zhang et al., 2019" rid="ref-amrexU003A2019" ref-type="bibr">Zhang
  et al., 2019</xref>), with many applications sharing the development
  effort for common needs. Co-designing software for a simulation
  “motif” such as particles is increasingly important as hardware for
  scientific simulations continues to evolve, becoming more
  heterogeneous, requiring more effort to extract performance, and
  otherwise likely requiring separate versions of a single application
  (or kernel) for each vendor-specific API to utilize the multitude of
  available accelerators. We note that there are some well designed and
  broad featured general particle simulation libraries:
  <monospace>AutoPas</monospace> automatically chooses underlying
  particle algorithms and parallel options using performance tuning
  (<xref alt="Gratl et al., 2021" rid="ref-autopas" ref-type="bibr">Gratl
  et al., 2021</xref>) and <monospace>OpenFPM</monospace> includes both
  particle and particle-grid capabilities
  (<xref alt="Incardona et al., 2019" rid="ref-openfpm" ref-type="bibr">Incardona
  et al., 2019</xref>). However, the former does not currently support
  GPUs and the latter currently supports only
  <monospace>CUDA</monospace> (and does so internally, rather than
  through a separate library such as <monospace>Kokkos</monospace>). To
  address this need, our objective is to provide scalable software
  services applicable to high-performance scientific codes across
  numerous application domains through general particle algorithms and
  data structures that are performant on a variety of distributed memory
  and accelerated architectures in a single implementation.</p>
  <sec id="particle-capability">
    <title>Particle capability</title>
    <p><monospace>Cabana</monospace> provides particle data structures
    to optimize performance across hardware through an
    array-of-structs-of-arrays (AoSoA) concept. This directly extends
    the <monospace>Kokkos::View</monospace> (portable multidimensional
    arrays) with an additional dimension that creates small,
    statically-sized groups of particles. Intermediate between
    struct-of-arrays (SoA) and array-of-structs (AoS), the size of these
    groups may be changed depending on the compute hardware in use which
    makes the data layout configurable to achieve the performance of SoA
    in SIMD-like settings where coalescing is achievable and the memory
    locality of AoS when random access memory patterns dominate. This
    tunable layout was designed to enable optimal performance across
    multiple kernels and across different hardware for a given
    application.</p>
    <p>The main algorithmic functionality of the library includes
    particle neighbor list generation and traversal, particle
    redistribution and halo communication for domain decomposition, and
    particle sorting. Particle sorting currently builds directly on
    <monospace>Kokkos</monospace> binning and sorting capabilities.
    Similarly, parallel iteration within <monospace>Cabana</monospace>
    algorithms directly uses <monospace>Kokkos</monospace> options for
    threaded parallelism. As with the AoSoA,
    <monospace>Cabana</monospace> extends the
    <monospace>Kokkos::parallel_for</monospace> (portable parallel
    execution) with SIMD-parallel capabilities for threading over the
    <monospace>AoSoA</monospace> data structures, as well as
    neighbor-parallel iteration over both central particles and their
    neighbors (potentially with many-body interactions and multiple
    levels of neighbors) with user-configurable options for serial or
    threaded execution as needed for application performance. Particle
    communication for multi-node simulation uses GPU-aware
    <monospace>MPI</monospace>, with capabilities for migrating
    particles from one unique owning rank to another, as well as to
    gather and scatter particle information from owning ranks to
    neighboring ranks.</p>
    <p>Existing packages are also leveraged for accelerating complex
    operations. For example, an interface to
    <monospace>ArborX</monospace>, a library for performance portable
    geometric search also built on <monospace>Kokkos</monospace>, has
    been included for neighbor list creation which is more scalable for
    non-uniform particle distributions than other options in
    <monospace>Cabana</monospace>
    (<xref alt="Lebrun-Grandié et al., 2020" rid="ref-arborxU003A2020" ref-type="bibr">Lebrun-Grandié
    et al., 2020</xref>).</p>
  </sec>
  <sec id="particle-grid-capability">
    <title>Particle-grid capability</title>
    <p>In addition to particle-specific algorithms, almost all
    particle-based codes use grids in some way. To support these
    applications <monospace>Cabana</monospace> also provides algorithms
    and data structures for many particle-grid motifs within the
    <monospace>Cajita</monospace> subpackage. Distributed, logically
    rectilinear grid data structures and high order, multidimensional
    spline kernels and spatial gradients are available, together with
    the requisite parallel communication to interpolate data between
    particles and grids. While this is most relevant to PIC methods and
    long-range MD algorithms, grid structures are useful even in
    simulations which are generally “mesh-free” (e.g. short-range MD),
    for accelerating neighbor list generation and multi-node spatial
    decomposition. In addition, support for sparse grids is in progress
    to enable only allocating and iterating over the grid where
    particles exist.</p>
    <p>As with the core particle package, <monospace>Cajita</monospace>
    includes interfaces to separate libraries for complex particle-grid
    related motifs. This includes distributed, performance portable fast
    Fourier transforms (e.g. for long-range MD and N-body simulations)
    through the <monospace>heFFTe</monospace> library
    (<xref alt="Ayala et al., 2019" rid="ref-heffteU003A2019" ref-type="bibr">Ayala
    et al., 2019</xref>)), preconditioners and linear solvers for
    structured grids through the <monospace>HYPRE</monospace> library
    (<xref alt="Falgout &amp; Yang, 2002" rid="ref-hypreU003A2002" ref-type="bibr">Falgout
    &amp; Yang, 2002</xref>), as well as redistribution of the grid
    across MPI ranks for non-uniform particle distributions through the
    <monospace>ALL</monospace> load-balancing library
    (<xref alt="Halver et al., n.d." rid="ref-all" ref-type="bibr">Halver
    et al., n.d.</xref>).</p>
  </sec>
  <sec id="exascale-design-patterns">
    <title>Exascale design patterns</title>
    <p><monospace>Cabana</monospace> has been designed for performance
    across both multi and many-core systems (CPU and GPU). Often, a
    focus on GPU performance also results in relatively good CPU
    performance (while the reverse is often not true). However, one
    notable exception is the relative efficiency of threaded atomic
    operations (hardware support for avoiding data race conditions) on
    each type of device. <monospace>Kokkos</monospace> provides support
    for this discrepancy through the
    <monospace>Kokkos::ScatterView</monospace>, where by default the GPU
    uses atomic memory and the CPU uses data duplication, which is being
    increasingly relied upon throughout <monospace>Cabana</monospace>.
    <monospace>Cabana</monospace> also primarily encourages a
    GPU-resident strategy: data is created and computed on the device
    without intermittent copies to the host to whatever degree possible.
    This is in contrast to a GPU-offload approach, although this
    strategy is still possible through the library.</p>
    <sec id="data-structures-across-physics-kernels">
      <title>Data structures across physics kernels</title>
      <p>The AoSoA data structure enables not only flexibility for ideal
      layouts for different architectures, but also for complex physics
      applications with multiple kernels that are each optimized for a
      different data layout. This is common, for example, in molecular
      dynamics where the particle update (integration) kernel has
      regular memory access across all particles which can be
      effectively coalesced and therefore an SoA would be the optimal
      choice. Elsewhere in the time integration loop, the particle
      interaction kernel is based on random memory accesses across
      neighbors of each particle such that an AoS would be preferred for
      performance. Rather than pay the performance penalty of choosing
      one data layout (SoA or AoS) which is suboptimal for at least one
      kernel or transposing data to the optimal layout for each kernel,
      the AoSoA enables performance near the ideal for both kernels.
      Further discussion of the AoSoA is provided in
      (<xref alt="Mniszewski et al., 2021" rid="ref-copaU003A2021" ref-type="bibr">Mniszewski
      et al., 2021</xref>).</p>
    </sec>
    <sec id="separating-memory-and-execution">
      <title>Separating memory and execution</title>
      <p>In creating <monospace>Cabana</monospace>, optimal design
      patterns have emerged to build application functionality. The
      first such pattern is the separation of memory and execution
      spaces, which are general <monospace>Kokkos</monospace> concepts
      for where data resides and where parallel execution takes place:
      host (CPU) or device (GPU). The <monospace>Kokkos</monospace>
      <monospace>Device</monospace> combines both in one object, leading
      to one design strategy in the following code:</p>
      <preformat>template&lt;Device&gt;
struct Foo
{
    View&lt;typename Device::memory_space&gt; _device_data;

    void bar()
    {
        parallel_for&lt;typename Device::execution_space&gt;( _device_data );
    }
};</preformat>
      <p>The class is created such that the same memory and execution
      space must always be used to store and operate on the data. In
      contrast, <monospace>Cabana</monospace> has moved to the following
      design:</p>
      <preformat>template&lt;MemorySpace&gt;
struct Foo
{
    View&lt;MemorySpace&gt; _device_data;

    template&lt;class ExecutionSpace&gt;
    void bar( const ExecutionSpace&amp; exec_space )
    {
        static_assert( is_accessible_from&lt;MemorySpace,
                                          ExecutionSpace&gt;{}, &quot;&quot; );

        parallel_for( exec_space, _device_data );
    }
};</preformat>
      <p>Here, the class data is stored in a specific memory space and,
      separately for each parallel execution, the user can choose any
      execution space that is compatible with that memory space. This
      greatly increases the flexibility of the class for using different
      parallel threading backends on a given device, e.g. both
      <monospace>OpenMP-Target</monospace> and vendor-specific backends.
      This also extends to easier adoption of newer execution options,
      such as <monospace>CUDA</monospace> streams, which can enable
      coarse-grained asynchronous tasking in applications. In addition,
      this makes the class amenable to both separate host or device
      computation as well as an offload model where a new overload that
      first copies the data to the class memory space is all that is
      required. In user code, multiple instances of this class may be
      used with different memory and execution spaces possible for each
      instance.</p>
    </sec>
    <sec id="enabling-kernel-fusion">
      <title>Enabling kernel fusion</title>
      <p>A more specific design pattern that enables not only
      flexibility, but also significant performance improvements in some
      cases, is support for kernel fusion. As an example, below is a
      straightforward implementation for a simulation that needs
      particle-grid interpolation for multiple physical entities using
      <monospace>Cajita</monospace>:</p>
      <preformat>// Create halo exchange pattern for an individual array.
auto halo = Cajita::createHalo( field, ... );

// Interpolate scalar gradient to the grid with kernel and MPI scatter.
auto val_1 = Cajita::createScalarGradientP2G( ... );
Cajita::p2g( val_1, ..., halo, ...);

// Interpolate tensor divergence to the grid with kernel and MPI scatter.
auto val_2 = Cajita::createTensorDivergenceP2G( ... );
Cajita::p2g( val_2, ..., halo, ... );</preformat>
      <p>Often, the time to launch each kernel and communicate the data
      (in a distributed and accelerated computing setting) is
      significant compared to the time for the execution of the parallel
      kernel itself which introduces significant latency costs. In the
      above case, each function call requires a separate parallel kernel
      and scatter communication kernel. The following reimplementation
      can, in some cases, improve performance considerably:</p>
      <preformat>// Create fused halo exchange pattern.
auto fused_halo = Cajita::createHalo( ..., *field_1, *field_2 );

// Fused local interpolation of both properties.
Kokkos::parallel_for( exec_space, num_point, points,
    KOKKOS_LAMBDA( const Particle&amp; p ){
        Cajita::SplineData&lt;float,3,Cajita::Node&gt; sd;
        Cajita::evaluateSpline( p.x );
        Cajita::P2G::gradient( sd, p.scalar_field, field_1 );
        Cajita::P2G::divergence( sd, p.tensor_field, field_2 ); });

// Fused MPI scatter.
fused_halo.scatter( exec_space, Cajita::ScatterReduce::Sum,
                    field_1, field_2 );</preformat>
      <p>There are a number of benefits to this approach. First, the
      number of kernel launches in an accelerated setting and MPI
      communication calls have been reduced by a factor of 2, thus
      reducing latency. Second, identical quantities that would have
      been computed in each interpolation kernel, such as the spline
      interpolation data, can be reused for multiple interpolations to
      reduce total operation counts. Third, our experience shows that
      kernel fusion often allows for temporary variables that are needed
      across multiple kernels no longer need to be allocated in large
      global memory arrays and can instead become in-kernel,
      thread-local temporaries, significantly reducing memory costs.
      Finally, cache performance can be significantly improved due to
      global data reuse combined with the AoSoA data structure such that
      a single particle is accessed multiple times in a single kernel
      rather than a single time in multiple kernels.</p>
    </sec>
  </sec>
  <sec id="tutorial-proxy-applications-and-fortran-support">
    <title>Tutorial, proxy applications, and Fortran support</title>
    <p>An extensive set of documentation, tests, and examples are
    available for <monospace>Cabana</monospace> including unit tests,
    tutorial examples, and performance testing across library
    functionality along with the GitHub wiki and
    <monospace>doxygen</monospace> API documentation. Continuous
    integration is used to ensure software quality, with testing across
    <monospace>Kokkos</monospace> backends and corresponding
    architectures. In addition, a <monospace>Cabana</monospace> Docker
    container is deployed, <monospace>spack</monospace> installation is
    available, and <monospace>Cabana</monospace> is a part of the
    Extreme-scale Scientific Software Stack (E4S)
    (<xref alt="E4S, 2021" rid="ref-e4s" ref-type="bibr">E4S,
    2021</xref>) to enable easy testing and use. For Fortran
    integration, a separate repository exemplifies using
    <monospace>Cabana</monospace> with Fortran applications
    (<xref alt="CoPA, 2021" rid="ref-copa" ref-type="bibr">CoPA,
    2021</xref>). Many proxy applications have also been developed using
    <monospace>Cabana</monospace>: <monospace>CabanaMD</monospace> for
    MD, <monospace>CabanaPIC</monospace> for plasma PIC,
    <monospace>ExaMPM</monospace> for the material point method (MPM),
    and <monospace>HACCabana</monospace> for N-body cosmology
    (<xref alt="CoPA, 2021" rid="ref-copa" ref-type="bibr">CoPA,
    2021</xref>). Proxy apps are relatively simple representations of
    the main physics in production applications and have proven useful
    within the <monospace>Cabana</monospace> development process for
    demonstrating library needs, capability, and performance. The proxy
    apps developed thus far also demonstrate the potential for rapid
    prototyping of particle codes on emerging hardware and interactions
    with hardware vendors.</p>
  </sec>
  <sec id="application-adoption-and-future-work">
    <title>Application adoption and future work</title>
    <p><monospace>Cabana</monospace> is designed for high-performance,
    large-scale particle simulations, with early adoption by the
    <monospace>XGC</monospace> plasma physics code
    (<xref alt="Mniszewski et al., 2021" rid="ref-copaU003A2021" ref-type="bibr">Mniszewski
    et al., 2021</xref>;
    <xref alt="Scheinberg et al., 2019" rid="ref-ScheinbergU003A2019" ref-type="bibr">Scheinberg
    et al., 2019</xref>), as well as the new
    <monospace>PicassoMPM</monospace> code for additive manufacturing
    (<xref alt="Belak et al., 2019" rid="ref-belak2019exaam" ref-type="bibr">Belak
    et al., 2019</xref>), both a part of ECP. One important aspect of
    continuing work is consistent interaction with
    <monospace>Cabana</monospace>-based applications, contributing
    algorithms and data structures back to <monospace>Cabana</monospace>
    where they could be useful in other particle applications.
    Similarly, interaction with the <monospace>Kokkos</monospace> team
    is critical to keep <monospace>Cabana</monospace> up-to-date with
    the latest architecture trends, but also to potentially contribute
    general parallel approaches or data structures from
    <monospace>Cabana</monospace>, where appropriate. Other continuing
    work includes tighter integration of the particle and particle-grid
    motifs, load balancing, additional input/output capabilities, and
    performance optimizations on early exascale systems.</p>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>The authors would like to thank Steve Plimpton for fruitful
  discussion on design and implementation.</p>
  <p>This work was performed as part of the Co-design Center for
  Particle Applications, supported by the Exascale Computing Project
  (17-SC-20-SC), a collaborative effort of the U.S. DOE Office of
  Science and the NNSA.</p>
  <p>This manuscript has been authored by UT-Battelle, LLC under
  Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy
  (DOE). The publisher, by accepting the article for publication,
  acknowledges that the United States Government retains a
  non-exclusive, paid-up, irrevocable, world-wide license to publish or
  reproduce the published form of this manuscript, or allow others to do
  so, for United States Government purposes. The DOE will provide public
  access to these results of federally sponsored research in accordance
  with the DOE Public Access Plan.</p>
  <p>This work was performed at Lawrence Livermore National Laboratory
  under U.S. Government Contract DE-AC52-07NA27344, Oak Ridge National
  Laboratory under U.S. Government Contract DE-AC05-00OR22725, Los
  Alamos National Laboratory, and at Sandia National Laboratories.</p>
  <p>Los Alamos National Laboratory is operated by Triad National
  Security, LLC, for the National Nuclear Security Administration of the
  U.S. Department of Energy (Contract No. 89233218NCA000001).</p>
  <p>Sandia National Laboratories is a multimission laboratory managed
  and operated by National Technology and Engineering Solutions of
  Sandia, LLC., a wholly owned subsidiary of Honeywell International,
  Inc., for the U.S. Department of Energy’s National Nuclear Security
  Administration under contract number DE-NA-0003525.</p>
  <p>This research used resources of the Oak Ridge Leadership Computing
  Facility (OLCF), supported by DOE under contract
  DE-AC05-00OR22725.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-copa">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>CoPA</surname></name>
      </person-group>
      <article-title>Co-design Center for Particle Applications: Libraries and proxy applications</article-title>
      <publisher-name>​GitHub</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>http://github.com/ECP-CoPA</uri>
    </element-citation>
  </ref>
  <ref id="ref-copaU003A2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mniszewski</surname><given-names>Susan M</given-names></name>
        <name><surname>Belak</surname><given-names>James</given-names></name>
        <name><surname>Fattebert</surname><given-names>Jean-Luc</given-names></name>
        <name><surname>Negre</surname><given-names>Christian FA</given-names></name>
        <name><surname>Slattery</surname><given-names>Stuart R</given-names></name>
        <name><surname>Adedoyin</surname><given-names>Adetokunbo A</given-names></name>
        <name><surname>Bird</surname><given-names>Robert F</given-names></name>
        <name><surname>Chang</surname><given-names>Choongseok</given-names></name>
        <name><surname>Chen</surname><given-names>Guangye</given-names></name>
        <name><surname>Ethier</surname><given-names>Stéphane</given-names></name>
        <name><surname>Fogerty</surname><given-names>Shane</given-names></name>
        <name><surname>Habib</surname><given-names>Salman</given-names></name>
        <name><surname>Junghans</surname><given-names>Christoph</given-names></name>
        <name><surname>Lebrun-Grandié</surname><given-names>Damien</given-names></name>
        <name><surname>Mohd-Yusof</surname><given-names>Jamaludin</given-names></name>
        <name><surname>Moore</surname><given-names>Stan G</given-names></name>
        <name><surname>Osei-Kuffuor</surname><given-names>Daniel</given-names></name>
        <name><surname>Plimpton</surname><given-names>Steven J</given-names></name>
        <name><surname>Pope</surname><given-names>Adrian</given-names></name>
        <name><surname>Reeve</surname><given-names>Samuel Temple</given-names></name>
        <name><surname>Ricketson</surname><given-names>Lee</given-names></name>
        <name><surname>Scheinberg</surname><given-names>Aaron</given-names></name>
        <name><surname>Sharma</surname><given-names>Amil Y</given-names></name>
        <name><surname>Wall</surname><given-names>Michael E</given-names></name>
      </person-group>
      <article-title>Enabling particle applications for exascale computing platforms</article-title>
      <source>The International Journal of High Performance Computing Applications</source>
      <year iso-8601-date="2021">2021</year>
      <volume>0</volume>
      <issue>0</issue>
      <pub-id pub-id-type="doi">10.1177/10943420211022829</pub-id>
      <fpage>10943420211022829</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-kokkosU003A2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Edwards</surname><given-names>H. Carter</given-names></name>
        <name><surname>Trott</surname><given-names>Christian R.</given-names></name>
        <name><surname>Sunderland</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>Kokkos: Enabling manycore performance portability through polymorphic memory access patterns</article-title>
      <source>Journal of Parallel and Distributed Computing</source>
      <year iso-8601-date="2014-12">2014</year><month>12</month>
      <volume>74</volume>
      <issue>12</issue>
      <issn>0743-7315</issn>
      <pub-id pub-id-type="doi">10.1016/j.jpdc.2014.07.003</pub-id>
      <fpage>3202</fpage>
      <lpage>3216</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kokkosU003A2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Trott</surname><given-names>Christian R.</given-names></name>
        <name><surname>Lebrun-Grandié</surname><given-names>Damien</given-names></name>
        <name><surname>Arndt</surname><given-names>Daniel</given-names></name>
        <name><surname>Ciesko</surname><given-names>Jan</given-names></name>
        <name><surname>Dang</surname><given-names>Vinh</given-names></name>
        <name><surname>Ellingwood</surname><given-names>Nathan</given-names></name>
        <name><surname>Gayatri</surname><given-names>Rahulkumar</given-names></name>
        <name><surname>Harvey</surname><given-names>Evan</given-names></name>
        <name><surname>Hollman</surname><given-names>Daisy S.</given-names></name>
        <name><surname>Ibanez</surname><given-names>Dan</given-names></name>
        <name><surname>Liber</surname><given-names>Nevin</given-names></name>
        <name><surname>Madsen</surname><given-names>Jonathan</given-names></name>
        <name><surname>Miles</surname><given-names>Jeff</given-names></name>
        <name><surname>Poliakoff</surname><given-names>David</given-names></name>
        <name><surname>Powell</surname><given-names>Amy</given-names></name>
        <name><surname>Rajamanickam</surname><given-names>Sivasankaran</given-names></name>
        <name><surname>Simberg</surname><given-names>Mikael</given-names></name>
        <name><surname>Sunderland</surname><given-names>Dan</given-names></name>
        <name><surname>Turcksin</surname><given-names>Bruno</given-names></name>
        <name><surname>Wilke</surname><given-names>Jeremiah</given-names></name>
      </person-group>
      <article-title>Kokkos 3: Programming Model Extensions for the Exascale Era</article-title>
      <source>IEEE Transactions on Parallel and Distributed Systems</source>
      <year iso-8601-date="2022-04">2022</year><month>04</month>
      <volume>33</volume>
      <issue>4</issue>
      <issn>1558-2183</issn>
      <pub-id pub-id-type="doi">10.1109/TPDS.2021.3097283</pub-id>
      <fpage>805</fpage>
      <lpage>817</lpage>
    </element-citation>
  </ref>
  <ref id="ref-hockney">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Hockney</surname><given-names>R. W.</given-names></name>
        <name><surname>Eastwood</surname><given-names>J. W.</given-names></name>
      </person-group>
      <source>Computer Simulation Using Particles</source>
      <publisher-name>CRC Press</publisher-name>
      <publisher-loc>Bristol England ; Philadelphia</publisher-loc>
      <year iso-8601-date="1989-01">1989</year><month>01</month>
      <edition>1st edition</edition>
      <isbn>978-0-85274-392-8</isbn>
    </element-citation>
  </ref>
  <ref id="ref-amrexU003A2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zhang</surname><given-names>Weiqun</given-names></name>
        <name><surname>Almgren</surname><given-names>Ann</given-names></name>
        <name><surname>Beckner</surname><given-names>Vince</given-names></name>
        <name><surname>Bell</surname><given-names>John</given-names></name>
        <name><surname>Blaschke</surname><given-names>Johannes</given-names></name>
        <name><surname>Chan</surname><given-names>Cy</given-names></name>
        <name><surname>Day</surname><given-names>Marcus</given-names></name>
        <name><surname>Friesen</surname><given-names>Brian</given-names></name>
        <name><surname>Gott</surname><given-names>Kevin</given-names></name>
        <name><surname>Graves</surname><given-names>Daniel</given-names></name>
        <name><surname>Katz</surname><given-names>Max</given-names></name>
        <name><surname>Myers</surname><given-names>Andrew</given-names></name>
        <name><surname>Nguyen</surname><given-names>Tan</given-names></name>
        <name><surname>Nonaka</surname><given-names>Andrew</given-names></name>
        <name><surname>Rosso</surname><given-names>Michele</given-names></name>
        <name><surname>Williams</surname><given-names>Samuel</given-names></name>
        <name><surname>Zingale</surname><given-names>Michael</given-names></name>
      </person-group>
      <article-title>AMReX: A framework for block-structured adaptive mesh refinement</article-title>
      <source>Journal of Open Source Software</source>
      <year iso-8601-date="2019-05">2019</year><month>05</month>
      <volume>4</volume>
      <issue>37</issue>
      <issn>2475-9066</issn>
      <pub-id pub-id-type="doi">10.21105/joss.01370</pub-id>
      <fpage>1370</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ecpU003A2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alexander</surname><given-names>Francis</given-names></name>
        <name><surname>Almgren</surname><given-names>Ann</given-names></name>
        <name><surname>Bell</surname><given-names>John</given-names></name>
        <name><surname>Bhattacharjee</surname><given-names>Amitava</given-names></name>
        <name><surname>Chen</surname><given-names>Jacqueline</given-names></name>
        <name><surname>Colella</surname><given-names>Phil</given-names></name>
        <name><surname>Daniel</surname><given-names>David</given-names></name>
        <name><surname>DeSlippe</surname><given-names>Jack</given-names></name>
        <name><surname>Diachin</surname><given-names>Lori</given-names></name>
        <name><surname>Draeger</surname><given-names>Erik</given-names></name>
        <name><surname>Dubey</surname><given-names>Anshu</given-names></name>
        <name><surname>Dunning</surname><given-names>Thom</given-names></name>
        <name><surname>Evans</surname><given-names>Thomas</given-names></name>
        <name><surname>Foster</surname><given-names>Ian</given-names></name>
        <name><surname>Francois</surname><given-names>Marianne</given-names></name>
        <name><surname>Germann</surname><given-names>Tim</given-names></name>
        <name><surname>Gordon</surname><given-names>Mark</given-names></name>
        <name><surname>Habib</surname><given-names>Salman</given-names></name>
        <name><surname>Halappanavar</surname><given-names>Mahantesh</given-names></name>
        <name><surname>Hamilton</surname><given-names>Steven</given-names></name>
        <name><surname>Hart</surname><given-names>William</given-names></name>
        <name><surname>Huang</surname><given-names>Zhenyu (Henry)</given-names></name>
        <name><surname>Hungerford</surname><given-names>Aimee</given-names></name>
        <name><surname>Kasen</surname><given-names>Daniel</given-names></name>
        <name><surname>Kent</surname><given-names>Paul R. C.</given-names></name>
        <name><surname>Kolev</surname><given-names>Tzanio</given-names></name>
        <name><surname>Kothe</surname><given-names>Douglas B.</given-names></name>
        <name><surname>Kronfeld</surname><given-names>Andreas</given-names></name>
        <name><surname>Luo</surname><given-names>Ye</given-names></name>
        <name><surname>Mackenzie</surname><given-names>Paul</given-names></name>
        <name><surname>McCallen</surname><given-names>David</given-names></name>
        <name><surname>Messer</surname><given-names>Bronson</given-names></name>
        <name><surname>Mniszewski</surname><given-names>Sue</given-names></name>
        <name><surname>Oehmen</surname><given-names>Chris</given-names></name>
        <name><surname>Perazzo</surname><given-names>Amedeo</given-names></name>
        <name><surname>Perez</surname><given-names>Danny</given-names></name>
        <name><surname>Richards</surname><given-names>David</given-names></name>
        <name><surname>Rider</surname><given-names>William J.</given-names></name>
        <name><surname>Rieben</surname><given-names>Rob</given-names></name>
        <name><surname>Roche</surname><given-names>Kenneth</given-names></name>
        <name><surname>Siegel</surname><given-names>Andrew</given-names></name>
        <name><surname>Sprague</surname><given-names>Michael</given-names></name>
        <name><surname>Steefel</surname><given-names>Carl</given-names></name>
        <name><surname>Stevens</surname><given-names>Rick</given-names></name>
        <name><surname>Syamlal</surname><given-names>Madhava</given-names></name>
        <name><surname>Taylor</surname><given-names>Mark</given-names></name>
        <name><surname>Turner</surname><given-names>John</given-names></name>
        <name><surname>Vay</surname><given-names>Jean-Luc</given-names></name>
        <name><surname>Voter</surname><given-names>Artur F.</given-names></name>
        <name><surname>Windus</surname><given-names>Theresa L.</given-names></name>
        <name><surname>Yelick</surname><given-names>Katherine</given-names></name>
      </person-group>
      <article-title>Exascale applications: Skin in the game</article-title>
      <source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>
      <year iso-8601-date="2020-03">2020</year><month>03</month>
      <volume>378</volume>
      <issue>2166</issue>
      <pub-id pub-id-type="doi">10.1098/rsta.2019.0056</pub-id>
      <fpage>20190056</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-arborxU003A2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lebrun-Grandié</surname><given-names>Damien</given-names></name>
        <name><surname>Prokopenko</surname><given-names>Andrey</given-names></name>
        <name><surname>Turcksin</surname><given-names>Bruno</given-names></name>
        <name><surname>Slattery</surname><given-names>Stuart R</given-names></name>
      </person-group>
      <article-title>ArborX: A performance portable geometric search library</article-title>
      <source>ACM Transactions on Mathematical Software (TOMS)</source>
      <publisher-name>ACM New York, NY, USA</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>47</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1145/3412558</pub-id>
      <fpage>1</fpage>
      <lpage>15</lpage>
    </element-citation>
  </ref>
  <ref id="ref-heffteU003A2019">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ayala</surname><given-names>Alan</given-names></name>
        <name><surname>Tomov</surname><given-names>Stanimire</given-names></name>
        <name><surname>Luo</surname><given-names>Xi</given-names></name>
        <name><surname>Shaiek</surname><given-names>Hejer</given-names></name>
        <name><surname>Haidar</surname><given-names>Azzam</given-names></name>
        <name><surname>Bosilca</surname><given-names>George</given-names></name>
        <name><surname>Dongarra</surname><given-names>Jack</given-names></name>
      </person-group>
      <article-title>Impacts of multi-GPU MPI collective communications on large FFT computation</article-title>
      <publisher-loc>Denver, CO</publisher-loc>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.1109/ExaMPI49596.2019.00007</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hypreU003A2002">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Falgout</surname><given-names>Robert D.</given-names></name>
        <name><surname>Yang</surname><given-names>Ulrike Meier</given-names></name>
      </person-group>
      <article-title>Hypre: A Library of High Performance Preconditioners</article-title>
      <source>Computational Science — ICCS 2002</source>
      <person-group person-group-type="editor">
        <name><surname>Sloot</surname><given-names>Peter M. A.</given-names></name>
        <name><surname>Hoekstra</surname><given-names>Alfons G.</given-names></name>
        <name><surname>Tan</surname><given-names>C. J. Kenneth</given-names></name>
        <name><surname>Dongarra</surname><given-names>Jack J.</given-names></name>
      </person-group>
      <publisher-name>Springer</publisher-name>
      <publisher-loc>Berlin, Heidelberg</publisher-loc>
      <year iso-8601-date="2002">2002</year>
      <isbn>978-3-540-47789-1</isbn>
      <pub-id pub-id-type="doi">10.1007/3-540-47789-6_66</pub-id>
      <fpage>632</fpage>
      <lpage>641</lpage>
    </element-citation>
  </ref>
  <ref id="ref-haccU003A2016">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Habib</surname><given-names>Salman</given-names></name>
        <name><surname>Pope</surname><given-names>Adrian</given-names></name>
        <name><surname>Finkel</surname><given-names>Hal</given-names></name>
        <name><surname>Frontiere</surname><given-names>Nicholas</given-names></name>
        <name><surname>Heitmann</surname><given-names>Katrin</given-names></name>
        <name><surname>Daniel</surname><given-names>David</given-names></name>
        <name><surname>Fasel</surname><given-names>Patricia</given-names></name>
        <name><surname>Morozov</surname><given-names>Vitali</given-names></name>
        <name><surname>Zagaris</surname><given-names>George</given-names></name>
        <name><surname>Peterka</surname><given-names>Tom</given-names></name>
        <name><surname>Vishwanath</surname><given-names>Venkatram</given-names></name>
        <name><surname>Lukić</surname><given-names>Zarija</given-names></name>
        <name><surname>Sehrish</surname><given-names>Saba</given-names></name>
        <name><surname>Liao</surname><given-names>Wei-keng</given-names></name>
      </person-group>
      <article-title>HACC: Simulating sky surveys on state-of-the-art supercomputing architectures</article-title>
      <source>New Astron.</source>
      <year iso-8601-date="2016-01">2016</year><month>01</month>
      <volume>42</volume>
      <uri>https://arxiv.org/abs/1410.2805</uri>
      <pub-id pub-id-type="doi">10.1016/j.newast.2015.06.003</pub-id>
      <fpage>49</fpage>
      <lpage>65</lpage>
    </element-citation>
  </ref>
  <ref id="ref-lammpsU003A1995">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Plimpton</surname><given-names>S.</given-names></name>
      </person-group>
      <article-title>Fast parallel algorithms for short-range molecular dynamics</article-title>
      <source>J. Comput. Phys.</source>
      <year iso-8601-date="1995">1995</year>
      <volume>117</volume>
      <issue>1</issue>
      <uri>http://lammps.sandia.gov</uri>
      <pub-id pub-id-type="doi">10.1006/jcph.1995.1039</pub-id>
      <fpage>1 </fpage>
      <lpage> 19</lpage>
    </element-citation>
  </ref>
  <ref id="ref-xgcU003A2018">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ku</surname><given-names>S</given-names></name>
        <name><surname>Chang</surname><given-names>CS</given-names></name>
        <name><surname>Hager</surname><given-names>R</given-names></name>
        <name><surname>Churchill</surname><given-names>RM</given-names></name>
        <name><surname>Tynan</surname><given-names>GR</given-names></name>
        <name><surname>Cziegler</surname><given-names>I</given-names></name>
        <name><surname>Greenwald</surname><given-names>M</given-names></name>
        <name><surname>Hughes</surname><given-names>J</given-names></name>
        <name><surname>Parker</surname><given-names>SE</given-names></name>
        <name><surname>Adams</surname><given-names>MF</given-names></name>
        <name><surname>D’Azevedo</surname><given-names>E</given-names></name>
        <name><surname>Worley</surname><given-names>P</given-names></name>
      </person-group>
      <article-title>A fast low-to-high confinement mode bifurcation dynamics in the boundary-plasma gyrokinetic code XGC1</article-title>
      <source>Physics of Plasmas</source>
      <year iso-8601-date="2018">2018</year>
      <volume>25</volume>
      <pub-id pub-id-type="doi">10.1063/1.5020792</pub-id>
      <fpage>056107</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ScheinbergU003A2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Scheinberg</surname><given-names>A</given-names></name>
        <name><surname>Chen</surname><given-names>G</given-names></name>
        <name><surname>Ethier</surname><given-names>S</given-names></name>
        <name><surname>Slattery</surname><given-names>S</given-names></name>
        <name><surname>Bird</surname><given-names>R</given-names></name>
        <name><surname>Worley</surname><given-names>P</given-names></name>
        <name><surname>Chang</surname><given-names>CS</given-names></name>
      </person-group>
      <article-title>Kokkos and Fortran in the exascale computing project plasma physics code XGC</article-title>
      <source>Proceedings of SC19 Conference</source>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-e4s">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>E4S</surname></name>
      </person-group>
      <article-title>The extreme-scale scientific software stack</article-title>
      <publisher-name>​GitHub</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>https://github.com/E4S-Project</uri>
    </element-citation>
  </ref>
  <ref id="ref-belak2019exaam">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Belak</surname><given-names>James</given-names></name>
        <name><surname>Turner</surname><given-names>John</given-names></name>
        <name><surname>Team</surname><given-names>ExaAM Team</given-names></name>
      </person-group>
      <article-title>Exaam: Additive manufacturing process modeling at the fidelity of the microstructure</article-title>
      <source>APS march meeting abstracts</source>
      <year iso-8601-date="2019">2019</year>
      <volume>2019</volume>
      <fpage>C22</fpage>
      <lpage>010</lpage>
    </element-citation>
  </ref>
  <ref id="ref-all">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Halver</surname><given-names>R.</given-names></name>
        <name><surname>Schulz</surname><given-names>S.</given-names></name>
        <name><surname>Sutmann</surname><given-names>G.</given-names></name>
      </person-group>
      <article-title>ALL - A loadbalancing library, C++ / Fortran library</article-title>
      <publisher-name>https://gitlab.version.fz-juelich.de/SLMS/loadbalancing/-/releases</publisher-name>
      <uri>http://slms.pages.jsc.fz-juelich.de/websites/all-website</uri>
    </element-citation>
  </ref>
  <ref id="ref-autopas">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gratl</surname><given-names>Fabio Alexander</given-names></name>
        <name><surname>Seckler</surname><given-names>Steffen</given-names></name>
        <name><surname>Bungartz</surname><given-names>Hans-Joachim</given-names></name>
        <name><surname>Neumann</surname><given-names>Philipp</given-names></name>
      </person-group>
      <article-title>N ways to simulate short-range particle systems: Automated algorithm selection with the node-level library AutoPas</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2021.108262</pub-id>
      <fpage>108262</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-openfpm">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Incardona</surname><given-names>Pietro</given-names></name>
        <name><surname>Leo</surname><given-names>Antonio</given-names></name>
        <name><surname>Zaluzhnyi</surname><given-names>Yaroslav</given-names></name>
        <name><surname>Ramaswamy</surname><given-names>Rajesh</given-names></name>
        <name><surname>Sbalzarini</surname><given-names>Ivo F</given-names></name>
      </person-group>
      <article-title>OpenFPM: A scalable open framework for particle and particle-mesh codes on parallel computers</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>241</volume>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2019.03.007</pub-id>
      <fpage>155</fpage>
      <lpage>177</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
