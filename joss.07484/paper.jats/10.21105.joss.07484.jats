<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7484</article-id>
<article-id pub-id-type="doi">10.21105/joss.07484</article-id>
<title-group>
<article-title>ExaDEM: a HPC application based on exaNBody targeting
scalable DEM simulations with complex particle shapes</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0002-3808-5401</contrib-id>
<name>
<surname>Prat</surname>
<given-names>Raphaël</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9396-4658</contrib-id>
<name>
<surname>Carrard</surname>
<given-names>Thierry</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0009-5120-1308</contrib-id>
<name>
<surname>Amarsid</surname>
<given-names>Lhassan</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8897-5499</contrib-id>
<name>
<surname>Richefeu</surname>
<given-names>Vincent</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0009-6361-3131</contrib-id>
<name>
<surname>Doncecchi</surname>
<given-names>Carlo-elia</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4416-6091</contrib-id>
<name>
<surname>Lafourcade</surname>
<given-names>Paul</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0001-7274-1305</contrib-id>
<name>
<surname>Latu</surname>
<given-names>Guillaume</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5764-0928</contrib-id>
<name>
<surname>Vanson</surname>
<given-names>Jean-Mathieu</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>CEA, DES, IRESNE, DEC, Cadarache F 13108
St-Paul-Lez-Durance</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>CEA, DAM, DIF, F-91297 Arpajon, France</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Université Paris-Saclay, LMCE, F-91680 Bruyères-le-Châtel,
France</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>3SR, CNRS, University of Grenoble Alpes, Grenoble, 38400,
France</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-08-16">
<day>16</day>
<month>8</month>
<year>2023</year>
</pub-date>
<volume>10</volume>
<issue>106</issue>
<fpage>7484</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>DEM</kwd>
<kwd>HPC</kwd>
<kwd>N-Body</kwd>
<kwd>MPI</kwd>
<kwd>OpenMP</kwd>
<kwd>GPU</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>ExaDEM</monospace> is a Discrete Element Method
  (<monospace>DEM</monospace>) code developed using the
  <monospace>exaNBody</monospace> framework
  (<xref alt="Carrard et al., 2023" rid="ref-carrard2023exanbody" ref-type="bibr">Carrard
  et al., 2023</xref>) at the French atomic commission
  (<monospace>CEA</monospace>). This software provides
  <monospace>DEM</monospace> modeling capabilities to enable the
  modeling of mechanical interactions occuring at contact between
  spheres and polyhedra particles while offering performance
  optimizations on modern <monospace>HPC</monospace> platforms. A
  notable aspect of <monospace>ExaDEM</monospace> stands in its hybrid
  parallelization approach, combining the use of
  <monospace>MPI</monospace> and Threads (OpenMP). Additionally,
  <monospace>ExaDEM</monospace> offers portability to clusters of
  <monospace>GPU</monospace>s, using the <monospace>CUDA</monospace>
  programming model and <monospace>MPI</monospace> for
  <monospace>DEM</monospace> simulations with spherical particles.
  Developed in <monospace>C++17</monospace>,
  <monospace>ExaDEM</monospace> is designed to offer
  <monospace>HPC</monospace> capabilities to the scientific
  community.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>A comprehesive description of the behavior of granular media
  remains a significant challenge for the scientific community.
  <monospace>DEM</monospace> simulations enhance our knowledge by
  examining phenomena that are otherwise unreachable or too costly to
  study through experiments. To accurately reproduce these phenomena
  originated at particle scale, we must simulate a representative number
  of particles, ranging from thousands to billions. While a single
  processor can easily handle simulations involving thousands of
  particles, simulating millions requires <monospace>HPC</monospace>
  resources. These simulations are constrained either by memory
  footprint or excessively long execution time. The
  <monospace>DEM</monospace> method is inherently parallel, with various
  techniques avaiable, such as spatial domain decomposition
  (<xref alt="Plimpton, 1995" rid="ref-plimpton1995fast" ref-type="bibr">Plimpton,
  1995</xref>), thread parallelization over cells and vectorization. In
  this paper, we introduce the code <monospace>ExaDEM</monospace>,
  designed for large-scale <monospace>DEM</monospace> simulation on
  <monospace>HPC</monospace> platforms. This code leverages numerous
  features of the <monospace>exaNBody</monospace> framework, including
  data structure management, <monospace>MPI</monospace>+X
  parallelization and add-on modules (optimized
  <monospace>IO</monospace>, Paraview export).</p>
</sec>
<sec id="dem-background">
  <title>DEM Background</title>
  <p>The <monospace>DEM</monospace> method, employed to study granular
  media, falls within the scope of so-called N-body methods. It involves
  numerically replicating the kinetics and interactions of a collection
  of rigid particles over time. Time is divided into discrete steps,
  where at each step n, Newton’s equation <bold>f</bold>=m<bold>a</bold>
  is solved to determine the translation and rotation acceleration for
  each particle. Subsequently, the corresponding velocity and moment are
  computed, leading to the calculation of the new position at step n+1.
  The force <bold>f</bold> is evaluated from particle interactions,
  including contact interactions (normal and tangential force) and
  external forces such as gravity. A commonly employed numerical scheme
  is the Velocity Verlet, while the Hooke law is often used to model
  contact interactions. The versatility of the
  <monospace>DEM</monospace> method allows for simulating rigid bodies
  with various shapes, ranging from spherical to polyhedral particles.
  Note that in <monospace>ExaDEM</monospace>, complex particle shapes
  are handled using a sphero-polyhedral approach, facilitating
  simplified contact detection and representing intricate shapes
  (<xref alt="Alonso-Marroquín, 2008" rid="ref-alonso_marroquin_2008" ref-type="bibr">Alonso-Marroquín,
  2008</xref>). For clarity, the term “polyhedron” is used to refer to a
  sphero-polyhedral particle.</p>
  <p>Efficient neighbor particle detection is a critical aspect of
  <monospace>DEM</monospace> simulation codes. Typically, this is
  achieved by combining the linked cells method
  (<xref alt="Ciccotti et al., 1987" rid="ref-ciccotti1987simulation" ref-type="bibr">Ciccotti
  et al., 1987</xref>) and Verlet lists
  (<xref alt="Verlet, 1967" rid="ref-verlet1967computer" ref-type="bibr">Verlet,
  1967</xref>), which optimize neighbor searches using a cartesian grid
  of cells (with a complexity of N, N is the number of particles) while
  limiting the refresh rate of neighbor lists.</p>
  <p>Several <monospace>DEM</monospace> software packages have emerged
  in recent years, offering <monospace>HPC</monospace> capabilities.
  Examples include <monospace>LIGGGHTS</monospace>
  (<xref alt="Kloss et al., 2012" rid="ref-kloss2012models" ref-type="bibr">Kloss
  et al., 2012</xref>), which is based on <monospace>LAMMPS</monospace>
  (<xref alt="Thompson et al., 2022" rid="ref-thompson2022lammps" ref-type="bibr">Thompson
  et al., 2022</xref>) data structures for Molecular Dynamics
  simulations with spherical particles (<monospace>MPI</monospace>), and
  <monospace>Blaze-DEM</monospace>
  (<xref alt="Govender et al., 2018" rid="ref-govender2018study" ref-type="bibr">Govender
  et al., 2018</xref>) which employs spheres and polyhedra on
  <monospace>GPU</monospace> via <monospace>CUDA</monospace>.
  <monospace>ExaDEM</monospace> aims to establish itself as a software
  solution that combines <monospace>MPI</monospace> parallelization,
  <monospace>OpenMP</monospace> thread parallelization for both
  polyhedral and spherical particles, and <monospace>CUDA</monospace>
  <monospace>GPU</monospace> parallelization for spherical particles.
  Similar to <monospace>LIGGGHTS</monospace> with
  <monospace>LAMMPS</monospace>, <monospace>ExaDEM</monospace> benefits
  from various <monospace>HPC</monospace> features developed in the
  Molecular Dynamics code <monospace>ExaSTAMP</monospace>
  (<xref alt="Cieren et al., 2014" rid="ref-cieren2014exastamp" ref-type="bibr">Cieren
  et al., 2014</xref>) that have been mutualized in the
  <monospace>exaNBody</monospace> framework such as
  <monospace>AMR</monospace> data structures
  (<xref alt="Prat et al., 2018" rid="ref-prat2018combining" ref-type="bibr">Prat
  et al., 2018</xref>) with load balancing
  (<xref alt="Prat et al., 2020" rid="ref-prat2020amr" ref-type="bibr">Prat
  et al., 2020</xref>), generation of compact particle configurations
  (<xref alt="Josien &amp; Prat, 2024" rid="ref-JOSIEN2024109354" ref-type="bibr">Josien
  &amp; Prat, 2024</xref>), and In-situ analysis
  (<xref alt="Dirand et al., 2018" rid="ref-dirand2018tins" ref-type="bibr">Dirand
  et al., 2018</xref>). <monospace>ExaDEM</monospace> aims to
  incorporate the physics of interest from the
  <monospace>Rockable</monospace>
  (<xref alt="V. Richefeu, 2023" rid="ref-gitrockable" ref-type="bibr">V.
  Richefeu, 2023</xref>;
  <xref alt="Vincent Richefeu &amp; Villard, 2016" rid="ref-richefeu_2016" ref-type="bibr">Vincent
  Richefeu &amp; Villard, 2016</xref>) (open source), originally created
  at CNRS for polyhedra on a <monospace>HPC</monospace> framework. To
  the best of our knowledge, this is a non-exhaustive list of other
  well-known <monospace>DEM</monospace> codes:
  <monospace>EDEM</monospace> (not open source),
  <monospace>Rocky DEM</monospace> (not open source),
  <monospace>MercuryDPM</monospace>
  (<xref alt="Weinhart et al., 2020" rid="ref-weinhart2020fast" ref-type="bibr">Weinhart
  et al., 2020</xref>) (open source), and <monospace>Yade</monospace>
  (<xref alt="Smilauer et al., 2023" rid="ref-smilauer2023yade" ref-type="bibr">Smilauer
  et al., 2023</xref>) (open source).</p>
</sec>
<sec id="implementation-details">
  <title>Implementation Details</title>
  <p><monospace>ExaDEM</monospace> leverages the
  <monospace>exaNBody</monospace> data structures (grid, cells, fields)
  as well as key parallel algorithms (domain decomposition, particles
  migration, numerical schemes) while proposing
  <monospace>DEM</monospace>-specific mechanism.
  <monospace>ExaDEM</monospace> achieves a <monospace>MPI</monospace>
  parallelization where the simulation domain is decomposed into
  subdomains using spatial domain decomposition and the Recursive
  Coordinate Bisection (<monospace>RCB</monospace>) partitioning method
  to evenly distribute the workload among <monospace>MPI</monospace>
  processes. Particle information stored within these cells, and a
  subdomain corresponds to a grid of cells. The use of cells aims to
  apply the state-of-the-art linked cells method to expedite neighbor
  searches with a complexity of O(N), where N represents the number of
  particles. Additionally, the Verlet lists method maintains larger
  neighbor lists over timesteps as long as a particle has a displacement
  shorter than half of the Verlet radius. Regarding the data layout, it
  is decomposed into two levels. The first level consists of cells
  (<monospace>SOA</monospace>), each composed of fields
  (<monospace>Array</monospace>) containing particle data. The second
  level is associated with the grid of cells
  (<monospace>AOSOA</monospace>), corresponding to a subdomain. The
  <monospace>DEM</monospace> grid includes the following fields: type,
  position, velocity, acceleration, radius, angular velocity,
  orientation. The <monospace>AOSAO</monospace> data structure
  facilitates data movement between <monospace>MPI</monospace> processes
  while maintaining good data locality, ensuring that particles in the
  same cell or neighboring cells interact with a good memory hit ratio.
  Moreover, the use of <monospace>SOA</monospace> storage (cell layout)
  enhances the use of <monospace>SIMD</monospace> instructions.</p>
  <p>Regarding the intra-<monospace>MPI</monospace> parallelization, we
  distinguish two main differences based on the type of particle,
  i.e. sphere or polyhedron:</p>
  <list list-type="bullet">
    <list-item>
      <p>For spherical particles, <monospace>OpenMP</monospace>
      parallelization involves iterating over cells. In
      <monospace>GPU</monospace> parallelization, a block of
      <monospace>GPU</monospace> threads is assigned to a cell, with
      each <monospace>GPU</monospace> thread processing a particle.</p>
    </list-item>
    <list-item>
      <p>For polyhedral particles, another parallel level is chosen for
      thread parallelization, the interaction. Unlike spherical
      particles, polyhedra can have multiple contacts of different types
      (vertex-vertex, vertex-edge, vertex-face, edge-edge). Hence, it is
      more effective to consider interactions rather than cells to
      achieved thread-parallelization. However, this strategy introduces
      synchronizations, such as the usage of mutexes. The
      <monospace>GPU</monospace> parallelization of polyhedra is still
      an upcoming development.</p>
    </list-item>
  </list>
  <p>In conclusion, the design of <monospace>ExaDEM</monospace>, guided
  by the <monospace>exaNBody</monospace> framework, facilitates the
  addition or removal of individual operators or features without
  disrupting other functionalities, provided theses operators are
  independents. For instance, removing the
  <monospace>gravity_force</monospace> from the
  <monospace>ExaDEM</monospace> repository is feasible, while ensuring
  the preservation of the <monospace>contact_neighbor</monospace>
  operator (building neighbor lists for every particle), which is
  crucial for running the <monospace>hooke_force</monospace> operator.
  Significant efforts have been made to minimize interactions between
  operators, simplifying the process of adding or removing new
  modules/operators.</p>
</sec>
<sec id="main-features">
  <title>Main Features</title>
  <fig>
    <caption><p>Simulation of 700 thousand octahedra in a rotating drum
    running on 128 MPI processes with 8 OpenMP threads per MPI process
    (processor: AMD EPYC Milan 7763).
    <styled-content id="figU003Arotating-drum"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="./rotating-drum.png" xlink:title="test" />
  </fig>
  <fig>
    <caption><p>Simulation of 20 million spherical particles falling
    into a funnel. This simulation runs on 512 MPI processes with 8
    OpenMP threads per MPI process (processor: AMD EPYC Milan 7763).
    <styled-content id="figU003Afunnel"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="./funnel.png" xlink:title="test" />
  </fig>
  <p><monospace>ExaDEM</monospace> aims to to meet scientific
  expectations, particularly for nuclear fuel simulations involving
  scenarios such as rotating drums (see figure
  <xref alt="[fig:rotating-drum]" rid="figU003Arotating-drum">[fig:rotating-drum]</xref>)
  or compaction processes. To achieve this goal,
  <monospace>ExaDEM</monospace> provides the following key features:</p>
  <list list-type="bullet">
    <list-item>
      <p>Handling of different particle types: spherical and
      polyhedral,</p>
    </list-item>
    <list-item>
      <p>Hybrid parallelisation <monospace>MPI</monospace> + X,</p>
      <list list-type="bullet">
        <list-item>
          <p>X = <monospace>OpenMP</monospace> or
          <monospace>CUDA</monospace> for spherical particles,</p>
        </list-item>
        <list-item>
          <p>X = <monospace>OpenMP</monospace> for polyhedral
          particles,</p>
        </list-item>
        <list-item>
          <p>The Recursive Coordinate Bissection method is used for the
          load balancing,</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p>I/O support for check and restart files (MPI-IO files),</p>
    </list-item>
    <list-item>
      <p>Paraview output files containing fields,</p>
    </list-item>
    <list-item>
      <p>Drivers: rigid wall, rotating drum or mesh of polyhedron
      surface for complex geometries such as funnel (see figure
      <xref alt="[fig:funnel]" rid="figU003Afunnel">[fig:funnel]</xref>),</p>
    </list-item>
    <list-item>
      <p>Time integration scheme: Velocity Verlet,</p>
    </list-item>
    <list-item>
      <p>Contact detection: Linked-cell method and Verlet Lists,</p>
    </list-item>
    <list-item>
      <p>Force fields: contact force (Hooke law), cohesive force, and
      gravity.</p>
    </list-item>
  </list>
  <p>All these functionalities are likely to evolve to accomodate new
  development needs, such as the addition of particle fragmentation. It
  is worth noting that most of these functionalities have been
  rigorously tested over 500 million spheres or 10 million polyhedra
  over ten thousand cores with hybrid <monospace>MPI</monospace> +
  <monospace>OpenMP</monospace> programming on AMD EPYC Milan 7763
  processors.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was performed using HPC resources from CCRT funded by the
  CEA/DEs simulation program. <monospace>ExaDEM</monospace> is part of
  the <monospace>PLEIADES</monospace> platform which has been developped
  in collaboration with the French nuclear industry - mainly CEA, EDF,
  and Framatome - for simulation of fuel elements.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-carrard2023exanbody">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Carrard</surname><given-names>Thierry</given-names></name>
        <name><surname>Prat</surname><given-names>Raphaël</given-names></name>
        <name><surname>Latu</surname><given-names>Guillaume</given-names></name>
        <name><surname>Babilotte</surname><given-names>Killian</given-names></name>
        <name><surname>Lafourcade</surname><given-names>Paul</given-names></name>
        <name><surname>Amarsid</surname><given-names>Lhassan</given-names></name>
        <name><surname>Soulard</surname><given-names>Laurent</given-names></name>
      </person-group>
      <article-title>ExaNBody: A HPC framework for n-body applications</article-title>
      <source>European conference on parallel processing</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.1007/978-3-031-50684-0_27</pub-id>
      <fpage>342</fpage>
      <lpage>354</lpage>
    </element-citation>
  </ref>
  <ref id="ref-JOSIEN2024109354">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Josien</surname><given-names>Marc</given-names></name>
        <name><surname>Prat</surname><given-names>Raphaël</given-names></name>
      </person-group>
      <article-title>Parallel and bias-free RSA algorithm for maximal Poisson-sphere sampling</article-title>
      <source>Computer Physics Communications</source>
      <year iso-8601-date="2024">2024</year>
      <volume>305</volume>
      <issn>0010-4655</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0010465524002777</uri>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2024.109354</pub-id>
      <fpage>109354</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ciccotti1987simulation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ciccotti</surname><given-names>Giovanni</given-names></name>
        <name><surname>Frenkel</surname><given-names>Daan</given-names></name>
        <name><surname>Mc Donald</surname><given-names>Ian R</given-names></name>
      </person-group>
      <article-title>Simulation of liquids and solids</article-title>
      <publisher-name>Elsevier Science Pub. Co. Inc., New York, NY</publisher-name>
      <year iso-8601-date="1987">1987</year>
      <pub-id pub-id-type="doi"></pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gitrockable">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Richefeu</surname><given-names>V.</given-names></name>
      </person-group>
      <article-title>Rockable</article-title>
      <source>GitHub repository</source>
      <publisher-name>https://github.com/richefeu/rockable.git; GitHub</publisher-name>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-thompson2022lammps">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Thompson</surname><given-names>Aidan P</given-names></name>
        <name><surname>Aktulga</surname><given-names>H Metin</given-names></name>
        <name><surname>Berger</surname><given-names>Richard</given-names></name>
        <name><surname>Bolintineanu</surname><given-names>Dan S</given-names></name>
        <name><surname>Brown</surname><given-names>W Michael</given-names></name>
        <name><surname>Crozier</surname><given-names>Paul S</given-names></name>
        <name><surname>In’t Veld</surname><given-names>Pieter J</given-names></name>
        <name><surname>Kohlmeyer</surname><given-names>Axel</given-names></name>
        <name><surname>Moore</surname><given-names>Stan G</given-names></name>
        <name><surname>Nguyen</surname><given-names>Trung Dac</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>LAMMPS-a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>271</volume>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2021.108171</pub-id>
      <fpage>108171</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-plimpton1995fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Plimpton</surname><given-names>Steve</given-names></name>
      </person-group>
      <article-title>Fast parallel algorithms for short-range molecular dynamics</article-title>
      <source>Journal of computational physics</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="1995">1995</year>
      <volume>117</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.2172/10176421</pub-id>
      <fpage>1</fpage>
      <lpage>19</lpage>
    </element-citation>
  </ref>
  <ref id="ref-verlet1967computer">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Verlet</surname><given-names>Loup</given-names></name>
      </person-group>
      <article-title>Computer&quot; experiments&quot; on classical fluids. I. Thermodynamical properties of Lennard-Jones molecules</article-title>
      <source>Physical review</source>
      <publisher-name>APS</publisher-name>
      <year iso-8601-date="1967">1967</year>
      <volume>159</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1103/physrev.159.98</pub-id>
      <fpage>98</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-kloss2012models">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kloss</surname><given-names>Christoph</given-names></name>
        <name><surname>Goniva</surname><given-names>Christoph</given-names></name>
        <name><surname>Hager</surname><given-names>Alice</given-names></name>
        <name><surname>Amberger</surname><given-names>Stefan</given-names></name>
        <name><surname>Pirker</surname><given-names>Stefan</given-names></name>
      </person-group>
      <article-title>Models, algorithms and validation for opensource DEM and CFD–DEM</article-title>
      <source>Progress in Computational Fluid Dynamics, an International Journal</source>
      <publisher-name>Inderscience Publishers</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>12</volume>
      <issue>2-3</issue>
      <pub-id pub-id-type="doi">10.1504/PCFD.2012.047457</pub-id>
      <fpage>140</fpage>
      <lpage>152</lpage>
    </element-citation>
  </ref>
  <ref id="ref-dirand2018tins">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Dirand</surname><given-names>Estelle</given-names></name>
        <name><surname>Colombet</surname><given-names>Laurent</given-names></name>
        <name><surname>Raffin</surname><given-names>Bruno</given-names></name>
      </person-group>
      <article-title>Tins: A task-based dynamic helper core strategy for in situ analytics</article-title>
      <source>Supercomputing frontiers: 4th asian conference, SCFA 2018, singapore, march 26-29, 2018, proceedings 4</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1007/978-3-319-69953-0_10</pub-id>
      <fpage>159</fpage>
      <lpage>178</lpage>
    </element-citation>
  </ref>
  <ref id="ref-govender2018study">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Govender</surname><given-names>Nicolin</given-names></name>
        <name><surname>Wilke</surname><given-names>Daniel N</given-names></name>
        <name><surname>Pizette</surname><given-names>Patrick</given-names></name>
        <name><surname>Abriak</surname><given-names>Nor-Edine</given-names></name>
      </person-group>
      <article-title>A study of shape non-uniformity and poly-dispersity in hopper discharge of spherical and polyhedral particle systems using the Blaze-DEM GPU code</article-title>
      <source>Applied Mathematics and Computation</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>319</volume>
      <pub-id pub-id-type="doi">10.1016/j.amc.2017.03.037</pub-id>
      <fpage>318</fpage>
      <lpage>336</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cieren2014exastamp">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cieren</surname><given-names>Emmanuel</given-names></name>
        <name><surname>Colombet</surname><given-names>Laurent</given-names></name>
        <name><surname>Pitoiset</surname><given-names>Samuel</given-names></name>
        <name><surname>Namyst</surname><given-names>Raymond</given-names></name>
      </person-group>
      <article-title>ExaStamp: A parallel framework for molecular dynamics on heterogeneous clusters</article-title>
      <source>Euro-par 2014: Parallel processing workshops: Euro-par 2014 international workshops, porto, portugal, august 25-26, 2014, revised selected papers, part II 20</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <pub-id pub-id-type="doi">10.1007/978-3-319-14313-2_11</pub-id>
      <fpage>121</fpage>
      <lpage>132</lpage>
    </element-citation>
  </ref>
  <ref id="ref-prat2018combining">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Prat</surname><given-names>Raphaël</given-names></name>
        <name><surname>Colombet</surname><given-names>Laurent</given-names></name>
        <name><surname>Namyst</surname><given-names>Raymond</given-names></name>
      </person-group>
      <article-title>Combining task-based parallelism and adaptive mesh refinement techniques in molecular dynamics simulations</article-title>
      <source>Proceedings of the 47th international conference on parallel processing</source>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1145/3225058.3225085</pub-id>
      <fpage>1</fpage>
      <lpage>10</lpage>
    </element-citation>
  </ref>
  <ref id="ref-prat2020amr">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Prat</surname><given-names>Raphaël</given-names></name>
        <name><surname>Carrard</surname><given-names>Thierry</given-names></name>
        <name><surname>Soulard</surname><given-names>Laurent</given-names></name>
        <name><surname>Durand</surname><given-names>Olivier</given-names></name>
        <name><surname>Namyst</surname><given-names>Raymond</given-names></name>
        <name><surname>Colombet</surname><given-names>Laurent</given-names></name>
      </person-group>
      <article-title>AMR-based molecular dynamics for non-uniform, highly dynamic particle simulations</article-title>
      <source>Computer Physics Communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>253</volume>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2020.107177</pub-id>
      <fpage>107177</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-weinhart2020fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weinhart</surname><given-names>Thomas</given-names></name>
        <name><surname>Orefice</surname><given-names>Luca</given-names></name>
        <name><surname>Post</surname><given-names>Mitchel</given-names></name>
        <name><surname>Schrojenstein Lantman</surname><given-names>Marnix P van</given-names></name>
        <name><surname>Denissen</surname><given-names>Irana FC</given-names></name>
        <name><surname>Tunuguntla</surname><given-names>Deepak R</given-names></name>
        <name><surname>Tsang</surname><given-names>JMF</given-names></name>
        <name><surname>Cheng</surname><given-names>Hongyang</given-names></name>
        <name><surname>Shaheen</surname><given-names>Mohamad Yousef</given-names></name>
        <name><surname>Shi</surname><given-names>Hao</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Fast, flexible particle simulations—an introduction to MercuryDPM</article-title>
      <source>Computer physics communications</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>249</volume>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2019.107129</pub-id>
      <fpage>107129</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-smilauer2023yade">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Smilauer</surname><given-names>Vaclav</given-names></name>
        <name><surname>Angelidakis</surname><given-names>Vasileios</given-names></name>
        <name><surname>Catalano</surname><given-names>Emanuele</given-names></name>
        <name><surname>Caulk</surname><given-names>Robert</given-names></name>
        <name><surname>Chareyre</surname><given-names>Bruno</given-names></name>
        <name><surname>Chevremont</surname><given-names>William</given-names></name>
        <name><surname>Dorofeenko</surname><given-names>Sergei</given-names></name>
        <name><surname>Duriez</surname><given-names>Jerome</given-names></name>
        <name><surname>Dyck</surname><given-names>Nolan</given-names></name>
        <name><surname>Elias</surname><given-names>Jan</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Yade documentation</article-title>
      <source>arXiv preprint arXiv:2301.00611</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2301.00611</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-richefeu_2016">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Richefeu</surname><given-names>Vincent</given-names></name>
        <name><surname>Villard</surname><given-names>Pascal</given-names></name>
      </person-group>
      <source>Modeling gravity hazards from rockfalls to landslides</source>
      <person-group person-group-type="editor">
        <name><surname>Richefeu</surname><given-names>Vincent</given-names></name>
        <name><surname>Villard</surname><given-names>Pascal</given-names></name>
      </person-group>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <isbn>978-1-78548-076-8</isbn>
      <pub-id pub-id-type="doi">10.1016/c2015-0-01294-1</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-alonso_marroquin_2008">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alonso-Marroquín</surname><given-names>F.</given-names></name>
      </person-group>
      <article-title>Spheropolygons: A new method to simulate conservative and dissipative interactions between 2D complex-shaped rigid bodies</article-title>
      <source>Europhysics Letters</source>
      <year iso-8601-date="2008-06">2008</year><month>06</month>
      <volume>83</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1209/0295-5075/83/14001</pub-id>
      <fpage>14001</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
