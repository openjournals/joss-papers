<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7887</article-id>
<article-id pub-id-type="doi">10.21105/joss.07887</article-id>
<title-group>
<article-title>fuzzyclara: Efficient Medoid-based Clustering Algorithms
for Large and Fuzzy Data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6783-1421</contrib-id>
<name>
<surname>Weigert</surname>
<given-names>Maximilian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3495-5131</contrib-id>
<name>
<surname>Bauer</surname>
<given-names>Alexander</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0003-3624-5915</contrib-id>
<name>
<surname>Gauss</surname>
<given-names>Jana</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3495-5131</contrib-id>
<name>
<surname>Nalmpatian</surname>
<given-names>Asmik</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Statistical Consulting Unit StaBLab, Department of
Statistics, LMU Munich, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-12-19">
<day>19</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>10</volume>
<issue>110</issue>
<fpage>7887</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>R</kwd>
<kwd>cluster analysis</kwd>
<kwd>high-dimensional data</kwd>
<kwd>fuzzy clustering</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Cluster analysis identifies groupings of observations that share
  similar characteristics. One popular approach are medoid-based methods
  where each cluster center is represented by one
  <italic>typical</italic> observation
  (<xref alt="Kaufman &amp; Rousseeuw, 2005" rid="ref-kaufman_rousseeuw_2005" ref-type="bibr">Kaufman
  &amp; Rousseeuw, 2005</xref>). The R package
  <monospace>fuzzyclara</monospace> makes a wide range of clustering
  algorithms conveniently available. It covers classical <italic>hard
  clustering</italic> methods (where one observation belongs to exactly
  one cluster) and alternative <italic>fuzzy clustering</italic> methods
  (where each observation is shaped by its partial membership to
  different clusters), and further implements the option to combine such
  algorithms with subsampling-based estimation techniques to make the
  estimation on large data feasible. The package additionally provides
  convenience functionalities and visualization techniques to cover the
  whole workflow for real-world clustering applications.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Partitioning clustering algorithms aim to find reasonable groupings
  (<italic>clusters</italic>) of a set of observations based on a
  predefined number of clusters. Medoid-based versions of this strategy
  build clusters based on <italic>medoids</italic>, i.e.Â one observation
  per cluster best representing its typical characteristics. The most
  prominent representative of medoid-based clustering is the
  <italic>partitioning around medoids</italic> (PAM) algorithm
  (<xref alt="Kaufman &amp; Rousseeuw, 2005" rid="ref-kaufman_rousseeuw_2005" ref-type="bibr">Kaufman
  &amp; Rousseeuw, 2005</xref>).</p>
  <p>The PAM algorithm, however, has two drawbacks. First, its
  estimation can become hardly feasible in data situations with
  thousands of observations, scaling quadratically
  (<inline-formula><alternatives>
  <tex-math><![CDATA[O(n^2)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>)
  in terms of runtime and memory usage. Sampling-based algorithms like
  CLARA
  (<xref alt="Kaufman &amp; Rousseeuw, 1986" rid="ref-kaufman_rousseew_1986" ref-type="bibr">Kaufman
  &amp; Rousseeuw, 1986</xref>) or CLARANS
  (<xref alt="Ng &amp; Han, 2002" rid="ref-ng_han_2002" ref-type="bibr">Ng
  &amp; Han, 2002</xref>) allow for a more efficient estimation in such
  situations. Second, PAM is a hard clustering algorithm where each
  observation is assigned to a single cluster. This assumption often
  does not resemble reality when observations share characteristics of
  several <italic>typical</italic> clusters. Such structures are taken
  into account by <italic>fuzzy clustering</italic> methods, which
  compute membership scores for each observation to every cluster.</p>
  <p>The statistical software R already provides a wide range of
  packages implementing clustering algorithms for large or fuzzy data.
  The <monospace>cluster</monospace> package
  (<xref alt="Maechler et al., 2022" rid="ref-R_cluster" ref-type="bibr">Maechler
  et al., 2022</xref>) contains diverse clustering routines developed by
  Kaufman &amp; Rousseeuw
  (<xref alt="2005" rid="ref-kaufman_rousseeuw_2005" ref-type="bibr">2005</xref>)
  including the CLARA algorithm for large data and the FANNY algorithm
  for fuzzy data. The CLARANS algorithm as an extension of CLARA is
  implemented in the package <monospace>qtcat</monospace>
  (<xref alt="Klasen, 2022" rid="ref-R_qtcat" ref-type="bibr">Klasen,
  2022</xref>). The package <monospace>fastkmedoids</monospace>
  (<xref alt="Li, 2021" rid="ref-R_fastkmedoids" ref-type="bibr">Li,
  2021</xref>) provides computationally more efficient versions of the
  CLARA and CLARANS algorithms. A variety of medoid-based fuzzy
  clustering methods are further available in packages
  <monospace>vegclust</monospace>
  (<xref alt="De Caceres et al., 2010" rid="ref-R_vegclust" ref-type="bibr">De
  Caceres et al., 2010</xref>) and <monospace>fclust</monospace>
  (<xref alt="Ferraro et al., 2019" rid="ref-R_fclust" ref-type="bibr">Ferraro
  et al., 2019</xref>).</p>
  <p>All above implementations either allow for the application of fuzzy
  clustering or of subsampling approaches, but not both simultaneously.
  While the <monospace>fuzzyclara</monospace> package includes the
  option to perform hard clustering using the classical PAM algorithm
  and to use all implemented algorithms with any kind of (dis)similarity
  metric, the package also allows for simultaneously analyzing large and
  fuzzy data, by combining the CLARA / CLARANS algorithms with the
  fuzzy-k-medoids algorithm by Krishnapuram et al.
  (<xref alt="1999" rid="ref-krishnapuram_1999" ref-type="bibr">1999</xref>).
  The package further provides routines to cover the whole workflow for
  real-world clustering applications, including the use of user-defined
  distance functions.</p>
</sec>
<sec id="combination-of-fuzzy-and-clara-clustering">
  <title>Combination of fuzzy and CLARA clustering</title>
  <p>We combine the CLARA clustering algorithm of Kaufman &amp;
  Rousseeuw
  (<xref alt="1986" rid="ref-kaufman_rousseew_1986" ref-type="bibr">1986</xref>)
  with the principle of fuzzy clustering. The original CLARA algorithm
  consists of the following steps, given a predefined number of
  <inline-formula><alternatives>
  <tex-math><![CDATA[J]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>J</mml:mi></mml:math></alternatives></inline-formula>
  clusters:</p>
  <list list-type="order">
    <list-item>
      <p>Determination of <inline-formula><alternatives>
      <tex-math><![CDATA[K]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>
      random subsamples of the data
      </p>
    </list-item>
    <list-item>
      <p>For each subsample <inline-formula><alternatives>
      <tex-math><![CDATA[k = 1,..., K]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>:
      </p>
      <list list-type="alpha-lower">
        <list-item>
          <label>(a)</label>
          <p>Application of PAM clustering on the subsample.
          </p>
        </list-item>
        <list-item>
          <label>(b)</label>
          <p>Assignment of each observation in the complete dataset to
          the cluster with the closest medoid.
          </p>
        </list-item>
        <list-item>
          <label>(c)</label>
          <p>Computation of the average distance of each observation to
          its closest clustering medoid as clustering criterion
          <inline-formula><alternatives>
          <tex-math><![CDATA[C_p]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></alternatives></inline-formula>:
          <disp-formula><alternatives>
          <tex-math><![CDATA[C_p = \frac{1}{n} \sum_{i=1}^n d_{ij_{min}p},]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
          where <inline-formula><alternatives>
          <tex-math><![CDATA[d_{ijp}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
          denotes the distance of observation
          <inline-formula><alternatives>
          <tex-math><![CDATA[i]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>
          to its closest medoid (i.e.Â observation
          <inline-formula><alternatives>
          <tex-math><![CDATA[j_{min}]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>)
          based on the clustering solution on subsample
          <inline-formula><alternatives>
          <tex-math><![CDATA[k]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p>Selection of the optimal set of clusters according to the
      minimal clustering criterion.</p>
    </list-item>
  </list>
  <p>We adapt this scheme to allow for fuzziness by applying the
  fuzzy-k-medoids algorithm
  (<xref alt="Krishnapuram et al., 1999" rid="ref-krishnapuram_1999" ref-type="bibr">Krishnapuram
  et al., 1999</xref>) in step 2a. Each observation of the complete
  dataset is then assigned a membership score to all clusters
  <inline-formula><alternatives>
  <tex-math><![CDATA[j]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>j</mml:mi></mml:math></alternatives></inline-formula>:
  <disp-formula><alternatives>
  <tex-math><![CDATA[u_{ijp} = \frac{(\frac{1}{d_{ijp}})^{\frac{1}{m-1}}}{\sum_{j = 1}^J (\frac{1}{d_{ijp}})^{\frac{1}{m-1}}},]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:msup><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>J</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
  where <inline-formula><alternatives>
  <tex-math><![CDATA[m]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>m</mml:mi></mml:math></alternatives></inline-formula>
  controls the degree of fuzziness. The clustering criterion
  <inline-formula><alternatives>
  <tex-math><![CDATA[C_p]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  is accordingly defined as the weighted sum of all distances to the
  medoids of all clusters, with weights according to the membership
  scores: <disp-formula><alternatives>
  <tex-math><![CDATA[C_p = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^K u_{ijp}^m d_{ijp}.]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>
  The optimal cluster solution is the subsample solution which minimizes
  this average weighted distance. Note that this simplifies to the hard
  clustering CLARA algorithm when only allowing membership scores of 0
  and 1. The implementation of a fuzzy version of the more efficient
  CLARANS algorithm (which iteratively evaluates random pairs of medoids
  and non-medoids)
  (<xref alt="Ng &amp; Han, 2002" rid="ref-ng_han_2002" ref-type="bibr">Ng
  &amp; Han, 2002</xref>) follows the same scheme of adaptation.</p>
  <p><monospace>fuzzyclara</monospace> further covers the whole
  clustering workflow, allowing for the interpretation of clustering
  solutions (e.g.Â with principal components plots), the analysis of
  silhouette scores or the determination of the number of clusters. </p>
</sec>
<sec id="application">
  <title>Application</title>
  <p>We demonstrate the functionality by clustering German tourists from
  the included <monospace>travel</monospace> dataset. The data
  originates from an annual cross-sectional study on pleasure travel and
  comprises 11,871 travelers between 2009 to 2018. Included variables
  cover the travel year, the annual number of trips, the overall travel
  expenses and the maximum travel distance.</p>
  <p>Due to the large data size of over 10,000 observations, we apply
  the CLARA algorithm with 20 randomly drawn samples of size 1,000. As
  tourists typically share characteristics of several tourist types, we
  use the fuzzy version with a membership exponent of
  <inline-formula><alternatives>
  <tex-math><![CDATA[m = 1.5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  The elbow criterion (see
  <xref alt="[fig:elbow]" rid="figU003Aelbow">[fig:elbow]</xref>)
  suggests the use of a five cluster solution.</p>
  <fig>
    <caption><p>Elbow plot of clustering solutions with 1 to 10
    clusters, depicting the minimal average weighted
    distance.<styled-content id="figU003Aelbow"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="travel_elbow.png" />
  </fig>
  <p><xref alt="[fig:parcoord]" rid="figU003Aparcoord">[fig:parcoord]</xref>
  highlights the characteristics of the different clusters. While
  clusters 1 and 3 show a tendency to trips of shorter length, lower
  distance and lower costs, the tourists of cluster 4 tend to travel
  most frequently and spend the most money for travelling. Less salient
  differences exist between clusters 2 and 5.</p>
  <fig>
    <caption><p>Parallel coordinate plot showing 500 randomly sampled
    observations, with cluster medoids in bold black lines. The linesâ
    transparency encode the respective observationâs membership score,
    with less transparency encoding a lower degree of fuzziness and thus
    a clearer membership.
    <styled-content id="figU003Aparcoord"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="travel_clustered.png" />
  </fig>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>This work has been partially funded by the German Research
  Foundation (DFG) under Grant No.Â KU 1359/4-1 and by the German Federal
  Ministry of Education and Research (BMBF) under Grant
  No.Â 01IS18036A.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-kaufman_rousseew_1986">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kaufman</surname><given-names>Leonard</given-names></name>
        <name><surname>Rousseeuw</surname><given-names>Peter J</given-names></name>
      </person-group>
      <article-title>Clustering large data sets</article-title>
      <source>Pattern recognition in practice</source>
      <publisher-name>North Holland</publisher-name>
      <year iso-8601-date="1986">1986</year>
      <fpage>425</fpage>
      <lpage>437</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kaufman_rousseeuw_2005">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Kaufman</surname><given-names>Leonard</given-names></name>
        <name><surname>Rousseeuw</surname><given-names>Peter J</given-names></name>
      </person-group>
      <source>Finding groups in data: An introduction to cluster analysis</source>
      <publisher-name>John Wiley &amp; Sons</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <pub-id pub-id-type="doi">10.1002/9780470316801</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-krishnapuram_1999">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Krishnapuram</surname><given-names>Raghu</given-names></name>
        <name><surname>Joshi</surname><given-names>Anupam</given-names></name>
        <name><surname>Yi</surname><given-names>Liyu</given-names></name>
      </person-group>
      <article-title>A fuzzy relative of the k-medoids algorithm with application to web document and snippet clustering</article-title>
      <source>FUZZ-IEEEâ99. 1999 IEEE international fuzzy systems. Conference proceedings (cat. No. 99CH36315)</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="1999">1999</year>
      <volume>3</volume>
      <pub-id pub-id-type="doi">10.1109/fuzzy.1999.790086</pub-id>
      <fpage>1281</fpage>
      <lpage>1286</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ng_han_2002">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ng</surname><given-names>Raymond T.</given-names></name>
        <name><surname>Han</surname><given-names>Jiawei</given-names></name>
      </person-group>
      <article-title>CLARANS: A method for clustering objects for spatial data mining</article-title>
      <source>IEEE transactions on knowledge and data engineering</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <volume>14</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1109/tkde.2002.1033770</pub-id>
      <fpage>1003</fpage>
      <lpage>1016</lpage>
    </element-citation>
  </ref>
  <ref id="ref-R_cluster">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Maechler</surname><given-names>Martin</given-names></name>
        <name><surname>Rousseeuw</surname><given-names>Peter</given-names></name>
        <name><surname>Struyf</surname><given-names>Anja</given-names></name>
        <name><surname>Hubert</surname><given-names>Mia</given-names></name>
        <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
      </person-group>
      <source>Cluster: Cluster analysis basics and extensions</source>
      <year iso-8601-date="2022">2022</year>
      <uri>https://CRAN.R-project.org/package=cluster</uri>
    </element-citation>
  </ref>
  <ref id="ref-R_fastkmedoids">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Xun</given-names></name>
      </person-group>
      <source>Fastkmedoids: Faster k-medoids clustering algorithms: FastPAM, FastCLARA, FastCLARANS</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.32614/cran.package.fastkmedoids</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-R_fclust">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ferraro</surname><given-names>M. B.</given-names></name>
        <name><surname>Giordani</surname><given-names>P.</given-names></name>
        <name><surname>Serafini</surname><given-names>A.</given-names></name>
      </person-group>
      <article-title>Fclust: An r package for fuzzy clustering</article-title>
      <source>The R Journal</source>
      <year iso-8601-date="2019">2019</year>
      <volume>11</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.32614/RJ-2019-017</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-R_qtcat">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Klasen</surname><given-names>Jonas</given-names></name>
      </person-group>
      <source>Qtcat: Quantitative trait cluster association test</source>
      <year iso-8601-date="2022">2022</year>
      <uri>http://github.com/QTCAT/qtcat</uri>
    </element-citation>
  </ref>
  <ref id="ref-R_vegclust">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>De Caceres</surname><given-names>Miquel</given-names></name>
        <name><surname>Font</surname><given-names>Xavier</given-names></name>
        <name><surname>Oliva</surname><given-names>Francesc</given-names></name>
      </person-group>
      <source>The management of vegetation classifications with fuzzy clustering</source>
      <year iso-8601-date="2010">2010</year>
      <volume>21</volume>
      <pub-id pub-id-type="doi">10.1111/j.1654-1103.2010.01211.x</pub-id>
      <fpage>1138</fpage>
      <lpage>1151</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
