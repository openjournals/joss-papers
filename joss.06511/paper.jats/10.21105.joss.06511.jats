<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6511</article-id>
<article-id pub-id-type="doi">10.21105/joss.06511</article-id>
<title-group>
<article-title>CCS-Lib: A Python package to elicit latent knowledge from
LLMs</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<name>
<surname>Laurito</surname>
<given-names>Walter</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Belrose</surname>
<given-names>Nora</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mallen</surname>
<given-names>Alex</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kozaronek</surname>
<given-names>Kay</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Roger</surname>
<given-names>Fabien</given-names>
</name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Koh</surname>
<given-names>Christy</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chua</surname>
<given-names>James</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>NG</surname>
<given-names>Jonathan</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wan</surname>
<given-names>Alexander</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lee</surname>
<given-names>Reagan</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>W.</surname>
<given-names>Ben</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>O’Brien</surname>
<given-names>Kyle</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Macijauskas</surname>
<given-names>Augustas</given-names>
</name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kinuthia</surname>
<given-names>Eric Mungai</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>PL</surname>
<given-names>Marius</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sethapun</surname>
<given-names>Waree</given-names>
</name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hänni</surname>
<given-names>Kaarel</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>EleutherAI</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Independent</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>FZI Research Center for Information
Technology</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Redwood Research</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>UC Berkeley</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Microsoft</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>CAML Lab, University of Cambridge</institution>
</institution-wrap>
</aff>
<aff id="aff-8">
<institution-wrap>
<institution>Princeton University</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<volume>10</volume>
<issue>114</issue>
<fpage>6511</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>python</kwd>
<kwd>machine learning</kwd>
<kwd>interpretability</kwd>
<kwd>ai alignment</kwd>
<kwd>honest AI</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>CCS-Lib is a library designed to elicit latent knowledge
  (<ext-link ext-link-type="uri" xlink:href="%60https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/%60">elk</ext-link>
  (<xref alt="Christiano et al., December 2021" rid="ref-christiano2021" ref-type="bibr">Christiano
  et al., December 2021</xref>)) from language models. It includes
  implementations of both the original and an enhanced version of the
  Contrast-Consistent Search (CCS) method and an approach based on
  Contrastive Representation Clustering-Top Principal Component
  (CRC-TPC)
  (<xref alt="Burns et al., 2022" rid="ref-burns2022" ref-type="bibr">Burns
  et al., 2022</xref>), called VINC. Designed for researchers, the
  CCS-Lib offers features like multi-GPU support, integration with
  Hugging Face and the training of supervised probes for
  comparisons.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The widespread adoption of language models in real-world
  applications presents significant challenges, particularly the
  potential generation of unreliable or inaccurate content
  (<xref alt="Evans et al., 2021" rid="ref-evans2021truthful" ref-type="bibr">Evans
  et al., 2021</xref>;
  <xref alt="Hendrycks et al., 2021" rid="ref-hendrycks2021unsolved" ref-type="bibr">Hendrycks
  et al., 2021</xref>;
  <xref alt="Park et al., 2024" rid="ref-park2023ai" ref-type="bibr">Park
  et al., 2024</xref>;
  <xref alt="Weidinger et al., 2021" rid="ref-weidinger2021ethical" ref-type="bibr">Weidinger
  et al., 2021</xref>). A notable concern is that models fine-tuned on
  human preferences may exacerbate existing biases or lead to convincing
  yet misleading outputs
  (<xref alt="Perez et al., 2022" rid="ref-perez2022" ref-type="bibr">Perez
  et al., 2022</xref>).</p>
  <p>Recent studies indicate that it’s possible to extract simulated
  internal beliefs or ‘knowledge’ from language model activations
  (<xref alt="Azaria &amp; Mitchell, 2023" rid="ref-azaria2023internal" ref-type="bibr">Azaria
  &amp; Mitchell, 2023</xref>;
  <xref alt="Bubeck et al., 2023" rid="ref-bubeck2023sparks" ref-type="bibr">Bubeck
  et al., 2023</xref>;
  <xref alt="Gurnee &amp; Tegmark, 2023" rid="ref-gurnee2023language" ref-type="bibr">Gurnee
  &amp; Tegmark, 2023</xref>;
  <xref alt="Li et al., 2022" rid="ref-li2022emergent" ref-type="bibr">Li
  et al., 2022</xref>). While supervised probing techniques can be used
  for this purpose
  (<xref alt="Alain &amp; Bengio, 2016" rid="ref-alain2016understanding" ref-type="bibr">Alain
  &amp; Bengio, 2016</xref>;
  <xref alt="Marks &amp; Tegmark, 2023" rid="ref-marks2023geometry" ref-type="bibr">Marks
  &amp; Tegmark, 2023</xref>), they rely on labels that may be
  compromised by human biases or limitations in human knowledge. In some
  cases, it’s crucial to avoid human labels altogether to allow
  distinguishing between a model’s true knowledge and its representation
  of human beliefs.</p>
  <p>These considerations have led to the development of unsupervised
  probing methods, such as Contrast-Consistent Search (CCS)
  (<xref alt="Burns et al., 2022" rid="ref-burns2022" ref-type="bibr">Burns
  et al., 2022</xref>). These techniques aim to extract knowledge
  embedded in language models without relying on ground truth labels
  (<xref alt="Burns et al., 2022" rid="ref-burns2022" ref-type="bibr">Burns
  et al., 2022</xref>;
  <xref alt="Zou et al., 2023" rid="ref-zou2023representation" ref-type="bibr">Zou
  et al., 2023</xref>). Such approaches offer a promising direction for
  uncovering the latent knowledge within language models while
  mitigating the influence of human biases and limitations.</p>
  <p>Nonetheless, current unsupervised probing methods still face
  challenges
  (<xref alt="Farquhar et al., 2023" rid="ref-farquhar2023" ref-type="bibr">Farquhar
  et al., 2023</xref>;
  <xref alt="Laurito et al., 2024" rid="ref-laurito2024" ref-type="bibr">Laurito
  et al., 2024</xref>;
  <xref alt="Levinstein &amp; Herrmann, 2024" rid="ref-levinstein2024" ref-type="bibr">Levinstein
  &amp; Herrmann, 2024</xref>). These issues underscore the need for
  tools that enable researchers to easily train, investigate, and
  compare probes while analyzing the internal representations of
  language models. In this context, one aim of our CCS-Lib is to provide
  a testbed that allows researchers to experiment with existing
  unsupervised probing methods — and compare them with their supervised
  counterparts — to elicit latent knowledge from within the activations
  of a language model.</p>
  <p>Refer to the <italic>Example Usage</italic> section for a
  demonstration of how to use the library.</p>
</sec>
<sec id="implementation">
  <title>Implementation</title>
  <p>The CCS-Lib is developed to provide both the original and an
  enhanced version of the Contrast-Consistent Search (CCS) method
  described in Burns et al.
  (<xref alt="2022" rid="ref-burns2022" ref-type="bibr">2022</xref>).</p>
  <p>Our enhanced version of CCS uses the Limited-memory BFGS (LBFGS)
  optimizer instead of Adam, which speeds up the training process.
  Furthermore, it uses learnable Platt scaling parameters to avoid the
  problem of sign ambiguity from the original implementation.</p>
  <p>In addition, we have implemented an approach called VINC (Variance,
  Invariance, Negative Covariance). VINC is an enhanced method for
  eliciting latent knowledge from language models. It builds upon the
  Contrastive Representation Clustering—Top Principal Component
  (CRC-TPC)
  (<xref alt="Burns et al., 2022" rid="ref-burns2022" ref-type="bibr">Burns
  et al., 2022</xref>) approach and incorporates additional principles.
  VINC aims to find a direction in activation space that maximizes
  variance while encouraging negative correlation between statement
  pairs and paraphrase invariance. The method uses eigendecomposition to
  optimize a quadratic objective that balances these criteria. VINC can
  be seen as an alternative to CCS, which takes less time to train.
  Additional changes and more recent results on VINC and its successor
  can be found
  <ext-link ext-link-type="uri" xlink:href="https://blog.eleuther.ai/vincs/">here</ext-link>.</p>
  <p>Finally, we provide a method to train supervised probes using
  logistic regression, allowing a comparison with unsupervised
  methods.</p>
  <p>CCS-Lib serves as a tool for researchers to investigate the
  truthfulness of model outputs and explore the underlying beliefs
  embedded within the model. The library offers:</p>
  <list list-type="bullet">
    <list-item>
      <p>A clean implementation of the enhanced and original version of
      CCS</p>
    </list-item>
    <list-item>
      <p>Multi-GPU Support: Efficient extraction, training, and
      evaluation through parallel processing</p>
    </list-item>
    <list-item>
      <p>Integration with Hugging Face: Easy utilization of models and
      datasets from a popular source</p>
    </list-item>
    <list-item>
      <p>VINC, an alternative to CCS</p>
    </list-item>
    <list-item>
      <p>Training supervised probes with logistic regression for
      comparisons</p>
    </list-item>
  </list>
  <p>For collaboration, discussion, and support, the
  <ext-link ext-link-type="uri" xlink:href="https://discord.com/channels/729741769192767510/1070194752785489991">Eleuther
  AI Discord’s elk channel</ext-link> provides a platform for engaging
  with others interested in the library or related research
  projects.</p>
</sec>
<sec id="example-usage---comparing-unsupervised-and-supervised-probes">
  <title>Example usage - Comparing unsupervised and supervised
  probes</title>
  <p>As mentioned above, one aim of this library is to provide a testbed
  for experimentation with unsupervised probing methods and to compare
  them with their supervised counterparts. We provide a simple example
  of how to use the library to compare the performance of unsupervised
  and supervised probes.</p>
  <p>First install the package with
  <monospace>pip install -e .</monospace> in the root directory. This
  should install all the necessary dependencies.</p>
  <p>To fit reporters for the Hugging Face model
  <monospace>model</monospace> and dataset
  <monospace>dataset</monospace>, run:</p>
  <code language="bash">ccs elicit microsoft/deberta-v2-xxlarge-mnli imdb</code>
  <p>This will automatically download the model and dataset, run the
  model and extract the relevant representations if they aren’t cached
  on disk, fit reporters on them, and save the reporter checkpoints to
  the <monospace>ccs-reporters</monospace> folder in your home
  directory. It will also evaluate the reporter classification
  performance on a held out test set and save it to a CSV file in the
  same folder. By default the VINC reporter is used.</p>
  <p>In addition, as an upper-bound is provided by training a supervised
  reporter using logistic regression (LR) models.</p>
  <p>Once the run is complete, the following files are generated for
  analysis:</p>
  <list list-type="bullet">
    <list-item>
      <p><monospace>results/reporters/</monospace>: Folder containing
      the trained reporters (CCS or VINC probes) for each layer</p>
    </list-item>
    <list-item>
      <p><monospace>results/cfg.yaml</monospace>: Configuration used for
      the run</p>
    </list-item>
    <list-item>
      <p><monospace>results/eval.csv</monospace>: Evaluation results for
      the reporters</p>
    </list-item>
    <list-item>
      <p><monospace>results/train_eval.csv</monospace>: Evaluation
      results for the reporter on the training set</p>
    </list-item>
    <list-item>
      <p><monospace>results/lr_eval.csv</monospace>: Evaluation results
      for the logistic regression models</p>
    </list-item>
    <list-item>
      <p><monospace>results/sweeps/</monospace>: Folder containing the
      sweeps for the run</p>
    </list-item>
    <list-item>
      <p><monospace>results/plots/</monospace>: Folder containing the
      plots for the run</p>
    </list-item>
    <list-item>
      <p><monospace>results/fingerprints.yaml</monospace>: Metadata
      files that store unique identifiers (fingerprints) for different
      dataset splits</p>
    </list-item>
  </list>
  <p>Now, if you want to run a sweep to compare the performance of
  different models and datasets, you can use the following command:</p>
  <code language="bash">ccs sweep --models gpt2-{medium,large,xl} --datasets imdb amazon_polarity --add_pooled</code>
  <p>Additional details are available in the library’s
  <ext-link ext-link-type="uri" xlink:href="https://github.com/EleutherAI/ccs/blob/main/README.md">README</ext-link>.</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the field</title>
  <p>Most available code is often tailored to demonstrate a paper’s
  specific methods and results rather than being user-friendly for
  researchers
  (<xref alt="Burns et al., 2022" rid="ref-burns2022" ref-type="bibr">Burns
  et al., 2022</xref>;
  <xref alt="Farquhar et al., 2023" rid="ref-farquhar2023" ref-type="bibr">Farquhar
  et al., 2023</xref>;
  <xref alt="Marks &amp; Tegmark, 2023" rid="ref-marks2023geometry" ref-type="bibr">Marks
  &amp; Tegmark, 2023</xref>). In contrast, our work is explicitly
  engineered to simplify the testing, comparison, and enhancement of
  unsupervised methods. The key features of the library are described in
  Section <italic>Implementation</italic>.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We would like to thank
  <ext-link ext-link-type="uri" xlink:href="https://www.eleuther.ai/">EleutherAI</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://www.serimats.org/">SERI
  MATS</ext-link>, and
  <ext-link ext-link-type="uri" xlink:href="https://funds.effectivealtruism.org/funds/far-future">Long-Term
  Future Fund (LTFF)</ext-link> for supporting our work.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-burns2022">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Burns</surname><given-names>Collin</given-names></name>
        <name><surname>Ye</surname><given-names>Haotian</given-names></name>
        <name><surname>Klein</surname><given-names>Dan</given-names></name>
        <name><surname>Steinhardt</surname><given-names>Jacob</given-names></name>
      </person-group>
      <article-title>Discovering latent knowledge in language models without supervision</article-title>
      <source>arXiv preprint arXiv:2212.03827</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2212.03827</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-christiano2021">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Christiano</surname><given-names>Paul</given-names></name>
        <name><surname>Cotra</surname><given-names>Ajeya</given-names></name>
        <name><surname>Xu</surname><given-names>Mark</given-names></name>
      </person-group>
      <article-title>Eliciting latent knowledge (ELK)</article-title>
      <publisher-name>https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/</publisher-name>
    </element-citation>
  </ref>
  <ref id="ref-perez2022">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Perez</surname><given-names>Ethan</given-names></name>
        <name><surname>Huang</surname><given-names>Saffron</given-names></name>
        <name><surname>Song</surname><given-names>Francis</given-names></name>
        <name><surname>Cai</surname><given-names>Trevor</given-names></name>
        <name><surname>Ring</surname><given-names>Roman</given-names></name>
        <name><surname>Aslanides</surname><given-names>John</given-names></name>
        <name><surname>Glaese</surname><given-names>Amelia</given-names></name>
        <name><surname>McAleese</surname><given-names>Nat</given-names></name>
        <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
      </person-group>
      <article-title>Red teaming language models with language models</article-title>
      <source>Proceedings of the 2022 conference on empirical methods in natural language processing</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.18653/v1/2022.emnlp-main.225</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-weidinger2021ethical">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weidinger</surname><given-names>Laura</given-names></name>
        <name><surname>Mellor</surname><given-names>John</given-names></name>
        <name><surname>Rauh</surname><given-names>Moritz</given-names></name>
        <name><surname>Griffin</surname><given-names>Conor</given-names></name>
        <name><surname>Uesato</surname><given-names>Jonathan</given-names></name>
        <name><surname>Huang</surname><given-names>Po-Sen</given-names></name>
        <name><surname>Cheng</surname><given-names>Michael</given-names></name>
        <name><surname>Glaese</surname><given-names>Matthew</given-names></name>
        <name><surname>Balle</surname><given-names>Borja</given-names></name>
        <name><surname>Kasirzadeh</surname><given-names>Atoosa</given-names></name>
        <name><surname>Kenton</surname><given-names>Zachary</given-names></name>
      </person-group>
      <article-title>Ethical and social risks of harm from language models</article-title>
      <source>arXiv preprint arXiv:2112.04359</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2112.04359</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hendrycks2021unsolved">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hendrycks</surname><given-names>Dan</given-names></name>
        <name><surname>Carlini</surname><given-names>Nicholas</given-names></name>
        <name><surname>Schulman</surname><given-names>John</given-names></name>
        <name><surname>Steinhardt</surname><given-names>Jacob</given-names></name>
      </person-group>
      <article-title>Unsolved problems in ML safety</article-title>
      <source>arXiv preprint arXiv:2109.13916</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2109.13916</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-park2023ai">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Park</surname><given-names>Peter S.</given-names></name>
        <name><surname>Goldstein</surname><given-names>Simon</given-names></name>
        <name><surname>O’Gara</surname><given-names>Aidan</given-names></name>
        <name><surname>Chen</surname><given-names>Michael</given-names></name>
        <name><surname>Hendrycks</surname><given-names>Dan</given-names></name>
      </person-group>
      <article-title>AI deception: A survey of examples, risks, and potential solutions</article-title>
      <source>Patterns</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1016/j.patter.2024.100988</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-evans2021truthful">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Evans</surname><given-names>Owain</given-names></name>
        <name><surname>Cotton-Barratt</surname><given-names>Owen</given-names></name>
        <name><surname>Finnveden</surname><given-names>Lars</given-names></name>
        <name><surname>Bales</surname><given-names>Adam</given-names></name>
        <name><surname>Balwit</surname><given-names>Amanda</given-names></name>
        <name><surname>Wills</surname><given-names>Peter</given-names></name>
        <name><surname>Righetti</surname><given-names>Luca</given-names></name>
        <name><surname>Saunders</surname><given-names>William</given-names></name>
      </person-group>
      <article-title>Truthful AI: Developing and governing AI that does not lie</article-title>
      <source>arXiv preprint arXiv:2110.06674</source>
      <year iso-8601-date="2021">2021</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2110.06674</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-li2022emergent">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Kenneth</given-names></name>
        <name><surname>Hopkins</surname><given-names>Aspen K.</given-names></name>
        <name><surname>Bau</surname><given-names>David</given-names></name>
        <name><surname>Viégas</surname><given-names>Fernanda</given-names></name>
        <name><surname>Pfister</surname><given-names>Hanspeter</given-names></name>
        <name><surname>Wattenberg</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Emergent world representations: Exploring a sequence model trained on a synthetic task</article-title>
      <source>arXiv preprint arXiv:2210.13382</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2210.13382</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-gurnee2023language">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gurnee</surname><given-names>Wes</given-names></name>
        <name><surname>Tegmark</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>Language models represent space and time</article-title>
      <source>arXiv preprint arXiv:2310.02207</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.02207</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-azaria2023internal">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Azaria</surname><given-names>Amos</given-names></name>
        <name><surname>Mitchell</surname><given-names>Tom</given-names></name>
      </person-group>
      <article-title>The internal state of an LLM knows when it’s lying</article-title>
      <source>Findings of the association for computational linguistics: EMNLP 2023</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.18653/v1/2023.findings-emnlp.68</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bubeck2023sparks">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bubeck</surname><given-names>Sébastien</given-names></name>
        <name><surname>Chandrasekaran</surname><given-names>Varun</given-names></name>
        <name><surname>Eldan</surname><given-names>Ronen</given-names></name>
        <name><surname>Gehrke</surname><given-names>Johannes</given-names></name>
        <name><surname>Horvitz</surname><given-names>Eric</given-names></name>
        <name><surname>Kamar</surname><given-names>Ece</given-names></name>
        <name><surname>Lee</surname><given-names>Peter</given-names></name>
        <name><surname>Lee</surname><given-names>Yin Tat</given-names></name>
        <name><surname>Li</surname><given-names>Yuanzhi</given-names></name>
        <name><surname>Lundberg</surname><given-names>Scott</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Sparks of artificial general intelligence: Early experiments with GPT-4</article-title>
      <source>arXiv preprint arXiv:2303.12712</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2303.12712</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-alain2016understanding">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Alain</surname><given-names>Guillaume</given-names></name>
        <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>
      </person-group>
      <article-title>Understanding intermediate layers using linear classifier probes</article-title>
      <source>arXiv preprint arXiv:1610.01644</source>
      <year iso-8601-date="2016">2016</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1610.01644</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-marks2023geometry">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Marks</surname><given-names>Samuel</given-names></name>
        <name><surname>Tegmark</surname><given-names>Max</given-names></name>
      </person-group>
      <article-title>The geometry of truth: Emergent linear structure in large language model representations of true/false datasets</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2310.06824</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.06824</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-zou2023representation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zou</surname><given-names>Andy</given-names></name>
        <name><surname>Phan</surname><given-names>Long</given-names></name>
        <name><surname>Chen</surname><given-names>Sarah</given-names></name>
        <name><surname>Campbell</surname><given-names>James</given-names></name>
        <name><surname>Guo</surname><given-names>Phillip</given-names></name>
        <name><surname>Ren</surname><given-names>Richard</given-names></name>
        <name><surname>Pan</surname><given-names>Alexander</given-names></name>
        <name><surname>Yin</surname><given-names>Xuwang</given-names></name>
        <name><surname>Mazeika</surname><given-names>Mantas</given-names></name>
        <name><surname>Dombrowski</surname><given-names>Ann-Kathrin</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Representation engineering: A top-down approach to AI transparency</article-title>
      <source>arXiv preprint arXiv:2310.01405</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2310.01405</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-farquhar2023">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Farquhar</surname><given-names>Sebastian</given-names></name>
        <name><surname>Varma</surname><given-names>Vikrant</given-names></name>
        <name><surname>Kenton</surname><given-names>Zachary</given-names></name>
        <name><surname>Gasteiger</surname><given-names>Johannes</given-names></name>
        <name><surname>Mikulik</surname><given-names>Vladimir</given-names></name>
        <name><surname>Shah</surname><given-names>Rohin</given-names></name>
      </person-group>
      <article-title>Challenges with unsupervised LLM knowledge discovery</article-title>
      <source>arXiv preprint arXiv:2312.10029</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2312.10029</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-levinstein2024">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Levinstein</surname><given-names>Benjamin A.</given-names></name>
        <name><surname>Herrmann</surname><given-names>Daniel A.</given-names></name>
      </person-group>
      <article-title>Still no lie detector for language models: Probing empirical and conceptual roadblocks</article-title>
      <source>Philosophical Studies</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.1007/s11098-023-02094-3</pub-id>
      <fpage>1</fpage>
      <lpage>27</lpage>
    </element-citation>
  </ref>
  <ref id="ref-laurito2024">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Laurito</surname><given-names>Walter</given-names></name>
        <name><surname>Maiya</surname><given-names>Sharan</given-names></name>
        <name><surname>Dhimoïla</surname><given-names>Grégoire</given-names></name>
        <name><surname>Hänni</surname><given-names>Kaarel</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Cluster-norm for unsupervised probing of knowledge</article-title>
      <source>Proceedings of the 2024 conference on empirical methods in natural language processing</source>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.18653/v1/2024.emnlp-main.780</pub-id>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
