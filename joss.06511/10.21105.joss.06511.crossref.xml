<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20251021131918-39e06cc2bd77657128f7a87902306c18eeafaf0c</doi_batch_id>
    <timestamp>20251021131918</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>10</month>
          <year>2025</year>
        </publication_date>
        <journal_volume>
          <volume>10</volume>
        </journal_volume>
        <issue>114</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>CCS-Lib: A Python package to elicit latent knowledge from LLMs</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Walter</given_name>
            <surname>Laurito</surname>
            <affiliations>
              <institution><institution_name>FZI Research Center for Information Technology</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Nora</given_name>
            <surname>Belrose</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Alex</given_name>
            <surname>Mallen</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
              <institution><institution_name>Redwood Research</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Kay</given_name>
            <surname>Kozaronek</surname>
            <affiliations>
              <institution><institution_name>Independent</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Fabien</given_name>
            <surname>Roger</surname>
            <affiliations>
              <institution><institution_name>Redwood Research</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Christy</given_name>
            <surname>Koh</surname>
            <affiliations>
              <institution><institution_name>UC Berkeley</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>James</given_name>
            <surname>Chua</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jonathan</given_name>
            <surname>NG</surname>
            <affiliations>
              <institution><institution_name>Independent</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Alexander</given_name>
            <surname>Wan</surname>
            <affiliations>
              <institution><institution_name>UC Berkeley</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Reagan</given_name>
            <surname>Lee</surname>
            <affiliations>
              <institution><institution_name>UC Berkeley</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Ben</given_name>
            <surname>W.</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Kyle</given_name>
            <surname>O’Brien</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
              <institution><institution_name>Microsoft</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Augustas</given_name>
            <surname>Macijauskas</surname>
            <affiliations>
              <institution><institution_name>CAML Lab, University of Cambridge</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Eric Mungai</given_name>
            <surname>Kinuthia</surname>
            <affiliations>
              <institution><institution_name>EleutherAI</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Marius</given_name>
            <surname>PL</surname>
            <affiliations>
              <institution><institution_name>Independent</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Waree</given_name>
            <surname>Sethapun</surname>
            <affiliations>
              <institution><institution_name>Princeton University</institution_name></institution>
            </affiliations>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Kaarel</given_name>
            <surname>Hänni</surname>
            <affiliations>
              <institution><institution_name>Independent</institution_name></institution>
            </affiliations>
          </person_name>
        </contributors>
        <publication_date>
          <month>10</month>
          <day>21</day>
          <year>2025</year>
        </publication_date>
        <pages>
          <first_page>6511</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06511</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.17344146</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6511</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06511</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06511</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06511.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="burns2022">
            <article_title>Discovering latent knowledge in language models without supervision</article_title>
            <author>Burns</author>
            <journal_title>arXiv preprint arXiv:2212.03827</journal_title>
            <doi>10.48550/arXiv.2212.03827</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Burns, C., Ye, H., Klein, D., &amp; Steinhardt, J. (2022). Discovering latent knowledge in language models without supervision. arXiv Preprint arXiv:2212.03827. https://doi.org/10.48550/arXiv.2212.03827</unstructured_citation>
          </citation>
          <citation key="christiano2021">
            <article_title>Eliciting latent knowledge (ELK)</article_title>
            <author>Christiano</author>
            <unstructured_citation>Christiano, P., Cotra, A., &amp; Xu, M. (December 2021). Eliciting latent knowledge (ELK). https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/.</unstructured_citation>
          </citation>
          <citation key="perez2022">
            <article_title>Red teaming language models with language models</article_title>
            <author>Perez</author>
            <journal_title>Proceedings of the 2022 conference on empirical methods in natural language processing</journal_title>
            <doi>10.18653/v1/2022.emnlp-main.225</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Perez, E., Huang, S., Song, F., Cai, T., Ring, R., Aslanides, J., Glaese, A., McAleese, N., &amp; Irving, G. (2022). Red teaming language models with language models. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. https://doi.org/10.18653/v1/2022.emnlp-main.225</unstructured_citation>
          </citation>
          <citation key="weidinger2021ethical">
            <article_title>Ethical and social risks of harm from language models</article_title>
            <author>Weidinger</author>
            <journal_title>arXiv preprint arXiv:2112.04359</journal_title>
            <doi>10.48550/arXiv.2112.04359</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Weidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P.-S., Cheng, M., Glaese, M., Balle, B., Kasirzadeh, A., &amp; Kenton, Z. (2021). Ethical and social risks of harm from language models. arXiv Preprint arXiv:2112.04359. https://doi.org/10.48550/arXiv.2112.04359</unstructured_citation>
          </citation>
          <citation key="hendrycks2021unsolved">
            <article_title>Unsolved problems in ML safety</article_title>
            <author>Hendrycks</author>
            <journal_title>arXiv preprint arXiv:2109.13916</journal_title>
            <doi>10.48550/arXiv.2109.13916</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Hendrycks, D., Carlini, N., Schulman, J., &amp; Steinhardt, J. (2021). Unsolved problems in ML safety. arXiv Preprint arXiv:2109.13916. https://doi.org/10.48550/arXiv.2109.13916</unstructured_citation>
          </citation>
          <citation key="park2023ai">
            <article_title>AI deception: A survey of examples, risks, and potential solutions</article_title>
            <author>Park</author>
            <journal_title>Patterns</journal_title>
            <doi>10.1016/j.patter.2024.100988</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Park, P. S., Goldstein, S., O’Gara, A., Chen, M., &amp; Hendrycks, D. (2024). AI deception: A survey of examples, risks, and potential solutions. Patterns. https://doi.org/10.1016/j.patter.2024.100988</unstructured_citation>
          </citation>
          <citation key="evans2021truthful">
            <article_title>Truthful AI: Developing and governing AI that does not lie</article_title>
            <author>Evans</author>
            <journal_title>arXiv preprint arXiv:2110.06674</journal_title>
            <doi>10.48550/arXiv.2110.06674</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Evans, O., Cotton-Barratt, O., Finnveden, L., Bales, A., Balwit, A., Wills, P., Righetti, L., &amp; Saunders, W. (2021). Truthful AI: Developing and governing AI that does not lie. arXiv Preprint arXiv:2110.06674. https://doi.org/10.48550/arXiv.2110.06674</unstructured_citation>
          </citation>
          <citation key="li2022emergent">
            <article_title>Emergent world representations: Exploring a sequence model trained on a synthetic task</article_title>
            <author>Li</author>
            <journal_title>arXiv preprint arXiv:2210.13382</journal_title>
            <doi>10.48550/arXiv.2210.13382</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Li, K., Hopkins, A. K., Bau, D., Viégas, F., Pfister, H., &amp; Wattenberg, M. (2022). Emergent world representations: Exploring a sequence model trained on a synthetic task. arXiv Preprint arXiv:2210.13382. https://doi.org/10.48550/arXiv.2210.13382</unstructured_citation>
          </citation>
          <citation key="gurnee2023language">
            <article_title>Language models represent space and time</article_title>
            <author>Gurnee</author>
            <journal_title>arXiv preprint arXiv:2310.02207</journal_title>
            <doi>10.48550/arXiv.2310.02207</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Gurnee, W., &amp; Tegmark, M. (2023). Language models represent space and time. arXiv Preprint arXiv:2310.02207. https://doi.org/10.48550/arXiv.2310.02207</unstructured_citation>
          </citation>
          <citation key="azaria2023internal">
            <article_title>The internal state of an LLM knows when it’s lying</article_title>
            <author>Azaria</author>
            <journal_title>Findings of the association for computational linguistics: EMNLP 2023</journal_title>
            <doi>10.18653/v1/2023.findings-emnlp.68</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Azaria, A., &amp; Mitchell, T. (2023). The internal state of an LLM knows when it’s lying. Findings of the Association for Computational Linguistics: EMNLP 2023. https://doi.org/10.18653/v1/2023.findings-emnlp.68</unstructured_citation>
          </citation>
          <citation key="bubeck2023sparks">
            <article_title>Sparks of artificial general intelligence: Early experiments with GPT-4</article_title>
            <author>Bubeck</author>
            <journal_title>arXiv preprint arXiv:2303.12712</journal_title>
            <doi>10.48550/arXiv.2303.12712</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., &amp; others. (2023). Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv Preprint arXiv:2303.12712. https://doi.org/10.48550/arXiv.2303.12712</unstructured_citation>
          </citation>
          <citation key="alain2016understanding">
            <article_title>Understanding intermediate layers using linear classifier probes</article_title>
            <author>Alain</author>
            <journal_title>arXiv preprint arXiv:1610.01644</journal_title>
            <doi>10.48550/arXiv.1610.01644</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Alain, G., &amp; Bengio, Y. (2016). Understanding intermediate layers using linear classifier probes. arXiv Preprint arXiv:1610.01644. https://doi.org/10.48550/arXiv.1610.01644</unstructured_citation>
          </citation>
          <citation key="marks2023geometry">
            <article_title>The geometry of truth: Emergent linear structure in large language model representations of true/false datasets</article_title>
            <author>Marks</author>
            <doi>10.48550/arXiv.2310.06824</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Marks, S., &amp; Tegmark, M. (2023). The geometry of truth: Emergent linear structure in large language model representations of true/false datasets. https://doi.org/10.48550/arXiv.2310.06824</unstructured_citation>
          </citation>
          <citation key="zou2023representation">
            <article_title>Representation engineering: A top-down approach to AI transparency</article_title>
            <author>Zou</author>
            <journal_title>arXiv preprint arXiv:2310.01405</journal_title>
            <doi>10.48550/arXiv.2310.01405</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Zou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren, R., Pan, A., Yin, X., Mazeika, M., Dombrowski, A.-K., &amp; others. (2023). Representation engineering: A top-down approach to AI transparency. arXiv Preprint arXiv:2310.01405. https://doi.org/10.48550/arXiv.2310.01405</unstructured_citation>
          </citation>
          <citation key="farquhar2023">
            <article_title>Challenges with unsupervised LLM knowledge discovery</article_title>
            <author>Farquhar</author>
            <journal_title>arXiv preprint arXiv:2312.10029</journal_title>
            <doi>10.48550/arXiv.2312.10029</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Farquhar, S., Varma, V., Kenton, Z., Gasteiger, J., Mikulik, V., &amp; Shah, R. (2023). Challenges with unsupervised LLM knowledge discovery. arXiv Preprint arXiv:2312.10029. https://doi.org/10.48550/arXiv.2312.10029</unstructured_citation>
          </citation>
          <citation key="levinstein2024">
            <article_title>Still no lie detector for language models: Probing empirical and conceptual roadblocks</article_title>
            <author>Levinstein</author>
            <journal_title>Philosophical Studies</journal_title>
            <doi>10.1007/s11098-023-02094-3</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Levinstein, B. A., &amp; Herrmann, D. A. (2024). Still no lie detector for language models: Probing empirical and conceptual roadblocks. Philosophical Studies, 1–27. https://doi.org/10.1007/s11098-023-02094-3</unstructured_citation>
          </citation>
          <citation key="laurito2024">
            <article_title>Cluster-norm for unsupervised probing of knowledge</article_title>
            <author>Laurito</author>
            <journal_title>Proceedings of the 2024 conference on empirical methods in natural language processing</journal_title>
            <doi>10.18653/v1/2024.emnlp-main.780</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Laurito, W., Maiya, S., Dhimoïla, G., Hänni, K., &amp; others. (2024). Cluster-norm for unsupervised probing of knowledge. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. https://doi.org/10.18653/v1/2024.emnlp-main.780</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
