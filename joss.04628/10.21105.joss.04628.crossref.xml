<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20221102T164751-e37671077a7dc0181346a752b2d16cfdbd1ec519</doi_batch_id>
    <timestamp>20221102164751</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org/</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>11</month>
          <year>2022</year>
        </publication_date>
        <journal_volume>
          <volume>7</volume>
        </journal_volume>
        <issue>79</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>DBMS-Benchmarker: Benchmark and Evaluate DBMS in
Python</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Patrick K.</given_name>
            <surname>Erdelt</surname>
            <ORCID>https://orcid.org/0000-0002-3359-2386</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Jascha</given_name>
            <surname>Jestel</surname>
          </person_name>
        </contributors>
        <publication_date>
          <month>11</month>
          <day>02</day>
          <year>2022</year>
        </publication_date>
        <pages>
          <first_page>4628</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.04628</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.7213676</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/4628</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.04628</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.04628</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.04628.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="10.1007/978-3-030-84924-5_6">
            <article_title>A framework for supporting repetition and
evaluation in the process of cloud-based DBMS performance
benchmarking</article_title>
            <author>Erdelt</author>
            <journal_title>Performance evaluation and
benchmarking</journal_title>
            <doi>10.1007/978-3-030-84924-5_6</doi>
            <isbn>978-3-030-84924-5</isbn>
            <cYear>2021</cYear>
            <unstructured_citation>Erdelt, P. K. (2021). A framework for
supporting repetition and evaluation in the process of cloud-based DBMS
performance benchmarking. In R. Nambiar &amp; M. Poess (Eds.),
Performance evaluation and benchmarking (pp. 75–92). Springer
International Publishing.
https://doi.org/10.1007/978-3-030-84924-5_6</unstructured_citation>
          </citation>
          <citation key="10.1007/978-3-030-94437-7_6">
            <article_title>Orchestrating DBMS benchmarking in the cloud
with kubernetes</article_title>
            <author>Erdelt</author>
            <journal_title>Performance evaluation and
benchmarking</journal_title>
            <doi>10.1007/978-3-030-94437-7_6</doi>
            <isbn>978-3-030-94437-7</isbn>
            <cYear>2022</cYear>
            <unstructured_citation>Erdelt, P. K. (2022). Orchestrating
DBMS benchmarking in the cloud with kubernetes. In R. Nambiar &amp; M.
Poess (Eds.), Performance evaluation and benchmarking (pp. 81–97).
Springer International Publishing.
https://doi.org/10.1007/978-3-030-94437-7_6</unstructured_citation>
          </citation>
          <citation key="10.1007/978-3-319-67162-8_12">
            <article_title>Is distributed database evaluation
cloud-ready?</article_title>
            <author>Seybold</author>
            <journal_title>New trends in databases and information
systems</journal_title>
            <doi>10.1007/978-3-319-67162-8_12</doi>
            <isbn>978-3-319-67162-8</isbn>
            <cYear>2017</cYear>
            <unstructured_citation>Seybold, D., &amp; Domaschka, J.
(2017). Is distributed database evaluation cloud-ready? New Trends in
Databases and Information Systems, 100–108.
https://doi.org/10.1007/978-3-319-67162-8_12</unstructured_citation>
          </citation>
          <citation key="10.1007/978-3-030-12079-5_4">
            <article_title>A versatile framework for painless
benchmarking of database management systems</article_title>
            <author>Brent</author>
            <journal_title>Databases theory and
applications</journal_title>
            <doi>10.1007/978-3-030-12079-5_4</doi>
            <isbn>978-3-030-12079-5</isbn>
            <cYear>2019</cYear>
            <unstructured_citation>Brent, L., &amp; Fekete, A. (2019). A
versatile framework for painless benchmarking of database management
systems. In L. Chang, J. Gan, &amp; X. Cao (Eds.), Databases theory and
applications (pp. 45–56). Springer International Publishing.
https://doi.org/10.1007/978-3-030-12079-5_4</unstructured_citation>
          </citation>
          <citation key="Raasveldt2018FBC32099503209955">
            <article_title>Fair benchmarking considered difficult:
Common pitfalls in database performance testing</article_title>
            <author>Raasveldt</author>
            <journal_title>Proceedings of the workshop on testing
database systems</journal_title>
            <doi>10.1145/3209950.3209955</doi>
            <isbn>978-1-4503-5826-2</isbn>
            <cYear>2018</cYear>
            <unstructured_citation>Raasveldt, M., Holanda, P., Gubner,
T., &amp; Mühleisen, H. (2018). Fair benchmarking considered difficult:
Common pitfalls in database performance testing. Proceedings of the
Workshop on Testing Database Systems, 2:1–2:6.
https://doi.org/10.1145/3209950.3209955</unstructured_citation>
          </citation>
          <citation key="DBLPconfsigmodKerstenKZ18">
            <article_title>Finding the pitfalls in query
performance</article_title>
            <author>Kersten</author>
            <journal_title>Proceedings of the 7th International Workshop
on Testing Database Systems, DBTest@SIGMOD 2018,</journal_title>
            <doi>10.1145/3209950.3209951</doi>
            <cYear>2018</cYear>
            <unstructured_citation>Kersten, M. L., Koutsourakis, P.,
&amp; Zhang, Y. (2018). Finding the pitfalls in query performance. In A.
Böhm &amp; T. Rabl (Eds.), Proceedings of the 7th International Workshop
on Testing Database Systems, DBTest@SIGMOD 2018, (pp. 3:1–3:6). ACM.
https://doi.org/10.1145/3209950.3209951</unstructured_citation>
          </citation>
          <citation key="reback2020pandas">
            <volume_title>Pandas-dev/pandas: pandas</volume_title>
            <author>The pandas development team</author>
            <doi>10.5281/zenodo.3509134</doi>
            <cYear>2020</cYear>
            <unstructured_citation>The pandas development team. (2020).
Pandas-dev/pandas: pandas (latest) [Computer software]. Zenodo.
https://doi.org/10.5281/zenodo.3509134</unstructured_citation>
          </citation>
          <citation key="mckinney-proc-scipy-2010">
            <article_title>Data Structures for Statistical Computing in
Python</article_title>
            <author>McKinney</author>
            <journal_title>Proceedings of the 9th Python in Science
Conference</journal_title>
            <doi>10.25080/Majora-92bf1922-00a</doi>
            <cYear>2010</cYear>
            <unstructured_citation>McKinney, W. (2010). Data Structures
for Statistical Computing in Python. In Stéfan van der Walt &amp; Jarrod
Millman (Eds.), Proceedings of the 9th Python in Science Conference (pp.
56–61).
https://doi.org/10.25080/Majora-92bf1922-00a</unstructured_citation>
          </citation>
          <citation key="208870">
            <article_title>Prometheus: A next-generation monitoring
system (talk)</article_title>
            <author>Rabenstein</author>
            <cYear>2015</cYear>
            <unstructured_citation>Rabenstein, B., &amp; Volz, J.
(2015). Prometheus: A next-generation monitoring system (talk). USENIX
Association.</unstructured_citation>
          </citation>
          <citation key="Kluyver2016jupyter">
            <article_title>Jupyter notebooks – a publishing format for
reproducible computational workflows</article_title>
            <author>Kluyver</author>
            <doi>10.3233/978-1-61499-649-1-87</doi>
            <cYear>2016</cYear>
            <unstructured_citation>Kluyver, T., Ragan-Kelley, B., Pérez,
F., Granger, B., Bussonnier, M., Frederic, J., Kelley, K., Hamrick, J.,
Grout, J., Corlay, S., Ivanov, P., Avila, D., Abdalla, S., &amp;
Willing, C. (2016). Jupyter notebooks – a publishing format for
reproducible computational workflows (F. Loizides &amp; B. Schmidt,
Eds.; pp. 87–90). IOS Press.
https://doi.org/10.3233/978-1-61499-649-1-87</unstructured_citation>
          </citation>
          <citation key="Hunter:2007">
            <article_title>Matplotlib: A 2D graphics
environment</article_title>
            <author>Hunter</author>
            <journal_title>Computing in Science &amp;
Engineering</journal_title>
            <issue>3</issue>
            <volume>9</volume>
            <doi>10.1109/MCSE.2007.55</doi>
            <cYear>2007</cYear>
            <unstructured_citation>Hunter, J. D. (2007). Matplotlib: A
2D graphics environment. Computing in Science &amp; Engineering, 9(3),
90–95. https://doi.org/10.1109/MCSE.2007.55</unstructured_citation>
          </citation>
          <citation key="2020SciPy-NMeth">
            <article_title>SciPy 1.0: Fundamental Algorithms for
Scientific Computing in Python</article_title>
            <author>Virtanen</author>
            <journal_title>Nature Methods</journal_title>
            <volume>17</volume>
            <doi>10.1038/s41592-019-0686-2</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Virtanen, P., Gommers, R., Oliphant,
T. E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson,
P., Weckesser, W., Bright, J., van der Walt, S. J., Brett, M., Wilson,
J., Millman, K. J., Mayorov, N., Nelson, A. R. J., Jones, E., Kern, R.,
Larson, E., … SciPy 1.0 Contributors. (2020). SciPy 1.0: Fundamental
Algorithms for Scientific Computing in Python. Nature Methods, 17,
261–272.
https://doi.org/10.1038/s41592-019-0686-2</unstructured_citation>
          </citation>
          <citation key="KounevLK20">
            <volume_title>Systems benchmarking - for scientists and
engineers</volume_title>
            <author>Kounev</author>
            <doi>10.1007/978-3-030-41705-5</doi>
            <isbn>978-3-030-41704-8</isbn>
            <cYear>2020</cYear>
            <unstructured_citation>Kounev, S., Lange, K.-D., &amp;
Kistowski, J. von. (2020). Systems benchmarking - for scientists and
engineers. Springer.
https://doi.org/10.1007/978-3-030-41705-5</unstructured_citation>
          </citation>
          <citation key="series/utcs/IgualS17">
            <volume_title>Introduction to data science - a Python
approach to concepts, techniques and applications</volume_title>
            <author>Igual</author>
            <doi>10.1007/978-3-319-50017-1</doi>
            <isbn>978-3-319-50017-1</isbn>
            <cYear>2017</cYear>
            <unstructured_citation>Igual, L., &amp; Seguí, S. (2017).
Introduction to data science - a Python approach to concepts, techniques
and applications (pp. 1–215). Springer.
https://doi.org/10.1007/978-3-319-50017-1</unstructured_citation>
          </citation>
          <citation key="Waskom2021">
            <article_title>Seaborn: Statistical data
visualization</article_title>
            <author>Waskom</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>60</issue>
            <volume>6</volume>
            <doi>10.21105/joss.03021</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Waskom, M. L. (2021). Seaborn:
Statistical data visualization. Journal of Open Source Software, 6(60),
3021. https://doi.org/10.21105/joss.03021</unstructured_citation>
          </citation>
          <citation key="TIOBE">
            <article_title>TIOBE Index - TIOBE</article_title>
            <author>TIOBE</author>
            <journal_title>TIOBE</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>TIOBE. (2022). TIOBE Index - TIOBE.
In TIOBE. https://www.tiobe.com/tiobe-index</unstructured_citation>
          </citation>
          <citation key="PYPL">
            <article_title>PYPL PopularitY of Programming Language
index</article_title>
            <author>PYPL</author>
            <cYear>2022</cYear>
            <unstructured_citation>PYPL. (2022). PYPL PopularitY of
Programming Language index.
https://pypl.github.io/PYPL.html</unstructured_citation>
          </citation>
          <citation key="10114533389063338912">
            <article_title>A statistics-based performance testing
methodology for cloud applications</article_title>
            <author>He</author>
            <journal_title>Proceedings of the 2019 27th ACM joint
meeting on european software engineering conference and symposium on the
foundations of software engineering</journal_title>
            <doi>10.1145/3338906.3338912</doi>
            <isbn>9781450355728</isbn>
            <cYear>2019</cYear>
            <unstructured_citation>He, S., Manns, G., Saunders, J.,
Wang, W., Pollock, L., &amp; Soffa, M. L. (2019). A statistics-based
performance testing methodology for cloud applications. Proceedings of
the 2019 27th ACM Joint Meeting on European Software Engineering
Conference and Symposium on the Foundations of Software Engineering,
188–199. https://doi.org/10.1145/3338906.3338912</unstructured_citation>
          </citation>
          <citation key="DBDBIO">
            <article_title>Database of Databases</article_title>
            <author>Carnegie Mellon Database Group</author>
            <journal_title>Database of Databases</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>Carnegie Mellon Database Group.
(2022). Database of Databases. In Database of Databases.
https://dbdb.io</unstructured_citation>
          </citation>
          <citation key="DBEngines">
            <article_title>DB-Engines Ranking</article_title>
            <author>solid IT GmbH</author>
            <journal_title>DB-Engines</journal_title>
            <cYear>2022</cYear>
            <unstructured_citation>solid IT GmbH. (2022). DB-Engines
Ranking. In DB-Engines.
https://db-engines.com/en/ranking</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
