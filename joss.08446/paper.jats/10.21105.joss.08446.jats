<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8446</article-id>
<article-id pub-id-type="doi">10.21105/joss.08446</article-id>
<title-group>
<article-title>TMLE.jl: Targeted Minimum Loss-Based Estimation in
Julia</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3708-3706</contrib-id>
<name>
<surname>Labayle</surname>
<given-names>Olivier</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0202-7816</contrib-id>
<name>
<surname>Ponting</surname>
<given-names>Chris P.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>van der Laan</surname>
<given-names>Mark J.</given-names>
</name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5203-2205</contrib-id>
<name>
<surname>Khamseh</surname>
<given-names>Ava</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7998-4262</contrib-id>
<name>
<surname>Beentjes</surname>
<given-names>Sjoerd Viktor</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-4"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Institute for Regeneration and Repair, University of
Edinburgh, Edinburgh EH16 4UU, United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>MRC Human Genetics Unit, Institute of Genetics and Cancer,
University of Edinburgh, Edinburgh EH4 2XU, United
Kingdom.</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>School of Informatics, University of Edinburgh, Edinburgh
EH8 9AB, United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>School of Mathematics and Maxwell Institute for
Mathematical Sciences, University of Edinburgh, Edinburgh EH9 3FD,
United Kingdom</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Division of Biostatistics, University of California,
Berkeley, CA, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-05-28">
<day>28</day>
<month>5</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>112</issue>
<fpage>8446</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>julia</kwd>
<kwd>statistics</kwd>
<kwd>semiparametric statistics</kwd>
<kwd>machine learning</kwd>
<kwd>causal inference</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>TMLE.jl is a Julia
  (<xref alt="Bezanson et al., 2017" rid="ref-julia" ref-type="bibr">Bezanson
  et al., 2017</xref>) package implementing targeted minimum loss-based
  estimation (TMLE), a general framework for causal effect estimation
  that unites modern machine learning with the theoretical guarantees of
  semiparametric statistics. TMLE yields doubly robust and
  semiparametrically efficient estimators, meaning it remains consistent
  if either the outcome model or the treatment assignment model is
  correctly specified, and it achieves the smallest possible asymptotic
  variance under standard regularity conditions. The package integrates
  with the broader Julia machine learning ecosystem and can be used in
  both observational and experimental settings. It is particularly
  well-suited for high-dimensional problems where robust inference is
  essential.</p>
</sec>
<sec id="background">
  <title>Background</title>
  <p>Causal inference is essential for understanding the effects of
  interventions in real-world settings, such as determining whether a
  treatment improves health outcomes or whether a genetic variant
  contributes to disease risk. Traditional approaches often begin by
  positing a specific parametric model, such as a linear-Gaussian or
  logistic regression model, and then estimating its parameters using
  efficient likelihood-based methods. This strategy has two main
  drawbacks. First, the quantity being estimated is often dictated by
  the parametric form of the model rather than the scientific question
  of interest (e.g., additive effects under a linear model, odds ratios
  under a logistic model). Second, when the model is misspecified,
  particularly in high-dimensional settings with complex interactions,
  parametric estimators can be severely biased.</p>
  <p>Over the past two decades, new approaches have emerged that combine
  causal inference, machine learning (ML), and semiparametric theory to
  address these limitations. These methods begin with the explicit
  definition of a target parameter, often a causal estimand such as the
  average treatment effect, derived from a causal model. They then
  replace restrictive parametric models with flexible ML algorithms
  (e.g., gradient boosting, neural networks) to estimate nuisance
  components such as the outcome regression and treatment mechanism
  (called nuisance functions). However, since most ML methods are
  optimised for prediction rather than unbiased estimation, ML-based
  estimates are still biased when plugged directly into the parameter
  formula. To remove this bias, modern approaches use a debiasing step
  based on a key mathematical object, the efficient influence function
  (EIF). The result is an estimator that is asymptotically unbiased,
  efficient, and valid under much weaker assumptions than traditional
  parametric models.</p>
  <p>Several estimators share this debiasing principle. The one-step
  estimator (OSE)
  (<xref alt="Kennedy, 2024" rid="ref-kennedy2024semiparametric" ref-type="bibr">Kennedy,
  2024</xref>;
  <xref alt="Pfanzagl &amp; Wefelmeyer, 1985" rid="ref-pfanzagl1985contributions" ref-type="bibr">Pfanzagl
  &amp; Wefelmeyer, 1985</xref>) is a general methodology which proceeds
  by estimating and removing the bias resulting from machine-learning
  fitting via the EIF. The widely used augmented inverse probability of
  treatment weighting
  (<xref alt="Glynn &amp; Quinn, 2010" rid="ref-glynn2010introduction" ref-type="bibr">Glynn
  &amp; Quinn, 2010</xref>), is a special case of the OSE for the
  average treatment effect. The double machine learning (DML) framework
  (<xref alt="Chernozhukov et al., 2018" rid="ref-chernozhukov2018double" ref-type="bibr">Chernozhukov
  et al., 2018</xref>) extends the OSE by introducing cross-fitting,
  which allows the use of highly flexible ML algorithms without
  restrictive empirical process conditions (e.g., Donsker assumptions).
  A limitation of both OSE and DML is that they perform debiasing in the
  parameter space, which can lead to estimates outside the natural range
  of the target causal estimand (e.g., probabilities below 0 or above
  1). In contrast, the targeted maximum likelihood estimator (TMLE)
  (<xref alt="Van der Laan et al., 2011" rid="ref-van2011targeted" ref-type="bibr">Van
  der Laan et al., 2011</xref>;
  <xref alt="Van der Laan &amp; Rose, 2018" rid="ref-van2018targeted" ref-type="bibr">Van
  der Laan &amp; Rose, 2018</xref>) performs the debiasing step in
  function space by iteratively updating the initial ML fit so that the
  resulting estimate both removes bias and respects the parameter’s
  natural bounds. While more involved to implement, TMLE retains all the
  theoretical guarantees of OSE/DML while ensuring parameter
  validity.</p>
  <p>TMLE.jl is a Julia package that implements both TMLE and the OSE,
  with or without cross-fitting, for the estimation of causal parameters
  in observational and experimental studies. It enables researchers to
  estimate average treatment effects and other causal parameters while
  leveraging modern ML algorithms. TMLE.jl is applicable across a broad
  range of disciplines—including epidemiology, biostatistics,
  econometrics, and genomics—where valid causal effect estimation from
  high-dimensional or observational data is essential.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The main entry point to the DML methodology, in both Python and R,
  is the DoubleML package
  (<xref alt="Bach et al., 2022" rid="ref-DoubleML2022Python" ref-type="bibr">Bach
  et al., 2022</xref>;
  <xref alt="Bach, Kurz, et al., 2024" rid="ref-doubleml2024R" ref-type="bibr">Bach,
  Kurz, et al., 2024</xref>;
  <xref alt="Bach, Chernozhukov, et al., 2024" rid="ref-DoubleML" ref-type="bibr">Bach,
  Chernozhukov, et al., 2024</xref>). Further Python packages focused on
  the estimation of the conditional average treatment effect include
  EconML
  (<xref alt="Keith Battocchi, 2019" rid="ref-econml" ref-type="bibr">Keith
  Battocchi, 2019</xref>) and CausalML
  (<xref alt="Chen et al., 2020" rid="ref-chen2020causalml" ref-type="bibr">Chen
  et al., 2020</xref>).</p>
  <p>Despite its theoretical and practical advantages, targeted maximum
  likelihood estimation (TMLE) remains largely implemented in R, with
  limited support in other languages. The original tmle package
  (<xref alt="Gruber &amp; van der Laan, 2012" rid="ref-tmleR" ref-type="bibr">Gruber
  &amp; van der Laan, 2012</xref>) provides a single estimator for
  various causal parameters and relies on the SuperLearner package for
  flexible nuisance estimation. The more recent tmle3 package
  (<xref alt="Coyle, 2021" rid="ref-coyle2021tmle3-rpkg" ref-type="bibr">Coyle,
  2021</xref>) offers a unified, object-oriented interface that
  explicitly represents the key mathematical components of TMLE. It
  supports a broad range of parameters, integrates cross-validated TMLE
  (CV-TMLE), the TMLE analogue of cross-fitting in DML, and is part of
  the broader tlverse ecosystem. Specialised extensions in this
  ecosystem target particular estimands, such as the mean outcome under
  the optimal treatment rule (tmle3mopttx)
  (<xref alt="Malenica et al., 2022" rid="ref-malenica2022tmle3mopttx" ref-type="bibr">Malenica
  et al., 2022</xref>) and stochastic intervention parameters
  (tmle3shift)
  (<xref alt="Hejazi et al., 2021" rid="ref-hejazi2021tmle3shift-rpkg" ref-type="bibr">Hejazi
  et al., 2021</xref>). Longitudinal TMLE for time-varying exposures is
  supported by the separate ltmle package
  (<xref alt="Lendle et al., 2017" rid="ref-lendle2017ltmle" ref-type="bibr">Lendle
  et al., 2017</xref>). To improve the robustness of estimators, for
  instance in the presence of practical violations or model instability,
  the collaborative targeted maximum likelihood estimation (C-TMLE)
  framework has been proposed, with several implementations available
  via the ctmle package
  (<xref alt="Ju et al., 2017" rid="ref-ctmle" ref-type="bibr">Ju et
  al., 2017</xref>).</p>
  <p>For practitioners and developers who prefer a performant,
  composable, and type-safe environment such as Julia, no native TMLE
  implementation previously existed. As causal inference methods gain
  traction in computational biology, health sciences, economics, and
  other data-intensive disciplines, the absence of robust,
  well-integrated TMLE tooling in modern scientific programming
  languages has become increasingly limiting. TMLE.jl addresses this gap
  by providing the first native Julia implementation of TMLE. It
  supports the estimation of a variety of causal estimands, including
  the counterfactual mean, average treatment effect, and average
  interaction effects of arbitrary order. Any differentiable
  transformation of these estimands (e.g., risk ratio, odds ratio) can
  be obtained via automatic differentiation. Both TMLE and one-step
  estimators (OSE) are available in canonical and cross-fitting variants
  through a unified interface, and selected C-TMLE instantiations
  (greedy and scalable) are also implemented. The package accommodates
  more than binary treatments, allowing for any number of categorical
  treatments, an important feature for studying combinatorial
  intervention effects.</p>
  <p>TMLE.jl is fully integrated into the broader Julia ecosystem.
  Machine learning models, including ensemble learners, can be specified
  via the MLJ toolbox
  (<xref alt="Blaom et al., 2020" rid="ref-blaom2020mlj" ref-type="bibr">Blaom
  et al., 2020</xref>); datasets are represented as DataFrames
  (<xref alt="Bouchet-Valat &amp; Kamiński, 2023" rid="ref-bouchet2023dataframes" ref-type="bibr">Bouchet-Valat
  &amp; Kamiński, 2023</xref>); and automatic differentiation is
  supported through any backend via DifferentiationInterface.jl
  (<xref alt="Dalle &amp; Hill, 2024" rid="ref-dalleDifferentiationInterface2025" ref-type="bibr">Dalle
  &amp; Hill, 2024</xref>). Simulation datasets from CausalTables.jl
  (<xref alt="Balkus &amp; Hejazi, 2025" rid="ref-Balkus2025" ref-type="bibr">Balkus
  &amp; Hejazi, 2025</xref>) are also directly supported.</p>
  <p>In doing so, TMLE.jl fills an important niche for causal inference
  in Julia, expanding the reach of TMLE beyond R and contributing to a
  growing ecosystem of open-source tools for rigorous, scalable, and
  reproducible statistical modelling.</p>
</sec>
<sec id="applications-to-population-genetics">
  <title>Applications to Population Genetics</title>
  <p>While TMLE.jl is applicable to a broad range of scientific
  problems, it was developed with population genetics in mind, which
  informed several aspects of its design. Its performance has been
  benchmarked in large-scale population genetics simulations and applied
  to UK Biobank data
  (<xref alt="Labayle et al., 2025" rid="ref-labayle2025semi" ref-type="bibr">Labayle
  et al., 2025</xref>). In such settings, the number of estimands can
  reach millions, posing a challenge for semiparametric estimators that
  rely on computationally intensive machine learning procedures. To
  address this, TMLE.jl implements automatic caching of intermediate
  results, enabling substantial computational savings. For example, when
  estimating the effect of a single treatment variable across multiple
  traits, the same propensity score can be reused across all analyses
  without recomputation. This mechanism has already been applied to the
  discovery of genetic variants affecting human traits via differential
  binding (submitted), and is currently being used in studies of genetic
  variants associated with myalgic encephalomyelitis.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Olivier Labayle was supported by the United Kingdom Research and
  Innovation (grant EP/S02431X/1), UKRI Centre for Doctoral Training in
  Biomedical AI at the University of Edinburgh, School of Informatics.
  Mark van der Laan is supported by NIH grant R01AI074345. Chris P.
  Ponting was funded by the MRC (MC_UU_00007/15). Ava Khamseh was
  supported by the XDF Programme from the University of Edinburgh and
  Medical Research Council (MC_UU_00009/2), and by a Langmuir Talent
  Development Fellowship from the Institute of Genetics and Cancer, and
  a philanthropic donation from Hugh and Josseline Langmuir.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-van2018targeted">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Van der Laan</surname><given-names>Mark J</given-names></name>
        <name><surname>Rose</surname><given-names>Sherri</given-names></name>
      </person-group>
      <source>Targeted learning in data science</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1007/978-3-319-65304-4</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-van2011targeted">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Van der Laan</surname><given-names>Mark J</given-names></name>
        <name><surname>Rose</surname><given-names>Sherri</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <source>Targeted learning: Causal inference for observational and experimental data</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>4</volume>
      <pub-id pub-id-type="doi">10.1007/978-1-4419-9782-1</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-dalleDifferentiationInterface2025">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Dalle</surname><given-names>Guillaume</given-names></name>
        <name><surname>Hill</surname><given-names>Adrian</given-names></name>
      </person-group>
      <article-title>DifferentiationInterface.jl</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <uri>10.5281/zenodo.11092033</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.11092033</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Balkus2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Balkus</surname><given-names>Salvador V.</given-names></name>
        <name><surname>Hejazi</surname><given-names>Nima S.</given-names></name>
      </person-group>
      <article-title>CausalTables.jl: Simulating and storing data for statistical causal inference in Julia</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2025">2025</year>
      <volume>10</volume>
      <issue>106</issue>
      <uri>10.21105/joss.07580</uri>
      <pub-id pub-id-type="doi">10.21105/joss.07580</pub-id>
      <fpage>7580</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-lendle2017ltmle">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lendle</surname><given-names>Samuel D.</given-names></name>
        <name><surname>Schwab</surname><given-names>Joshua</given-names></name>
        <name><surname>Petersen</surname><given-names>Maya L.</given-names></name>
        <name><surname>van der Laan</surname><given-names>Mark J.</given-names></name>
      </person-group>
      <article-title>ltmle: An R package implementing targeted minimum loss-based estimation for longitudinal data</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2017">2017</year>
      <volume>81</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v081.i01</pub-id>
      <fpage>1</fpage>
      <lpage>21</lpage>
    </element-citation>
  </ref>
  <ref id="ref-labayle2025semi">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Labayle</surname><given-names>Olivier</given-names></name>
        <name><surname>Roskams-Hieter</surname><given-names>Breeshey</given-names></name>
        <name><surname>Slaughter</surname><given-names>Joshua</given-names></name>
        <name><surname>Tetley-Campbell</surname><given-names>Kelsey</given-names></name>
        <name><surname>Laan</surname><given-names>Mark J van der</given-names></name>
        <name><surname>Ponting</surname><given-names>Chris P</given-names></name>
        <name><surname>Beentjes</surname><given-names>Sjoerd Viktor</given-names></name>
        <name><surname>Khamseh</surname><given-names>Ava</given-names></name>
      </person-group>
      <article-title>Semi-parametric efficient estimation of small genetic effects in large-scale population cohorts</article-title>
      <source>arXiv preprint arXiv:2505.14675</source>
      <year iso-8601-date="2025">2025</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2505.14675</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-tmleR">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Gruber</surname><given-names>Susan</given-names></name>
        <name><surname>van der Laan</surname><given-names>Mark J.</given-names></name>
      </person-group>
      <article-title>tmle: An R package for targeted maximum likelihood estimation</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2012">2012</year>
      <volume>51</volume>
      <issue>13</issue>
      <uri>https://www.jstatsoft.org/v51/i13/</uri>
      <pub-id pub-id-type="doi">10.18637/jss.v051.i13</pub-id>
      <fpage>1</fpage>
      <lpage>35</lpage>
    </element-citation>
  </ref>
  <ref id="ref-coyle2021tmle3-rpkg">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Coyle</surname><given-names>Jeremy R</given-names></name>
      </person-group>
      <article-title>tmle3: The extensible TMLE framework</article-title>
      <publisher-name>https://github.com/tlverse/tmle3</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>10.5281/zenodo.4603358</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.4603358</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-blaom2020mlj">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blaom</surname><given-names>Anthony D</given-names></name>
        <name><surname>Kiraly</surname><given-names>Franz</given-names></name>
        <name><surname>Lienart</surname><given-names>Thibaut</given-names></name>
        <name><surname>Simillides</surname><given-names>Yiannis</given-names></name>
        <name><surname>Arenas</surname><given-names>Diego</given-names></name>
        <name><surname>Vollmer</surname><given-names>Sebastian J</given-names></name>
      </person-group>
      <article-title>MLJ: A Julia package for composable machine learning</article-title>
      <source>arXiv preprint arXiv:2007.12285</source>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.21105/joss.02704</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-bouchet2023dataframes">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bouchet-Valat</surname><given-names>Milan</given-names></name>
        <name><surname>Kamiński</surname><given-names>Bogumił</given-names></name>
      </person-group>
      <article-title>Dataframes.jl: Flexible and fast tabular data in Julia</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2023">2023</year>
      <volume>107</volume>
      <pub-id pub-id-type="doi">10.18637/jss.v107.i04</pub-id>
      <fpage>1</fpage>
      <lpage>32</lpage>
    </element-citation>
  </ref>
  <ref id="ref-kennedy2024semiparametric">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Kennedy</surname><given-names>Edward H</given-names></name>
      </person-group>
      <article-title>Semiparametric doubly robust targeted double machine learning: A review</article-title>
      <source>Handbook of statistical methods for precision medicine</source>
      <publisher-name>Chapman; Hall/CRC</publisher-name>
      <year iso-8601-date="2024">2024</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2203.06469</pub-id>
      <fpage>207</fpage>
      <lpage>236</lpage>
    </element-citation>
  </ref>
  <ref id="ref-pfanzagl1985contributions">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pfanzagl</surname><given-names>Johann</given-names></name>
        <name><surname>Wefelmeyer</surname><given-names>Wolfgang</given-names></name>
      </person-group>
      <article-title>Contributions to a general asymptotic statistical theory</article-title>
      <source>Statistics &amp; Risk Modeling</source>
      <publisher-name>OLDENBOURG WISSENSCHAFTSVERLAG</publisher-name>
      <year iso-8601-date="1985">1985</year>
      <volume>3</volume>
      <issue>3-4</issue>
      <pub-id pub-id-type="doi">10.1007/978-1-4612-5769-1</pub-id>
      <fpage>379</fpage>
      <lpage>388</lpage>
    </element-citation>
  </ref>
  <ref id="ref-glynn2010introduction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Glynn</surname><given-names>Adam N</given-names></name>
        <name><surname>Quinn</surname><given-names>Kevin M</given-names></name>
      </person-group>
      <article-title>An introduction to the augmented inverse propensity weighted estimator</article-title>
      <source>Political analysis</source>
      <publisher-name>Cambridge University Press</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>18</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1093/pan/mpp036</pub-id>
      <fpage>36</fpage>
      <lpage>56</lpage>
    </element-citation>
  </ref>
  <ref id="ref-chernozhukov2018double">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Chernozhukov</surname><given-names>Victor</given-names></name>
        <name><surname>Chetverikov</surname><given-names>Denis</given-names></name>
        <name><surname>Demirer</surname><given-names>Mert</given-names></name>
        <name><surname>Duflo</surname><given-names>Esther</given-names></name>
        <name><surname>Hansen</surname><given-names>Christian</given-names></name>
        <name><surname>Newey</surname><given-names>Whitney</given-names></name>
        <name><surname>Robins</surname><given-names>James</given-names></name>
      </person-group>
      <article-title>Double/debiased machine learning for treatment and structural parameters</article-title>
      <publisher-name>Oxford University Press Oxford, UK</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <pub-id pub-id-type="doi">10.1111/ectj.12097</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-malenica2022tmle3mopttx">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Malenica</surname><given-names>Ivana</given-names></name>
        <name><surname>Coyle</surname><given-names>Jeremy</given-names></name>
        <name><surname>van der Laan</surname><given-names>Mark J</given-names></name>
      </person-group>
      <article-title>tmle3mopttx: Targeted learning and variable importance with optimal individualized categorical treatment</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://github.com/tlverse/tmle3mopttx</uri>
      <pub-id pub-id-type="doi"></pub-id>
    </element-citation>
  </ref>
  <ref id="ref-hejazi2021tmle3shift-rpkg">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Hejazi</surname><given-names>Nima S</given-names></name>
        <name><surname>Coyle</surname><given-names>Jeremy R</given-names></name>
        <name><surname>van der Laan</surname><given-names>Mark J</given-names></name>
      </person-group>
      <article-title>tmle3shift: Targeted Learning of the causal effects of stochastic interventions</article-title>
      <publisher-name>https://github.com/tlverse/tmle3shift</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <uri>10.5281/zenodo.4603372</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.4603372</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ctmle">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Ju</surname><given-names>Cheng</given-names></name>
        <name><surname>Gruber</surname><given-names>Susan</given-names></name>
        <name><surname>Laan</surname><given-names>Mark van der</given-names></name>
      </person-group>
      <source>Ctmle: Collaborative targeted maximum likelihood estimation</source>
      <year iso-8601-date="2017">2017</year>
      <uri>https://CRAN.R-project.org/package=ctmle</uri>
      <pub-id pub-id-type="doi">10.32614/cran.package.ctmle</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-DoubleML">
    <element-citation publication-type="software">
      <person-group person-group-type="author">
        <name><surname>Bach</surname><given-names>Philipp</given-names></name>
        <name><surname>Chernozhukov</surname><given-names>Victor</given-names></name>
        <name><surname>Klaassen</surname><given-names>Sven</given-names></name>
        <name><surname>Kurz</surname><given-names>Malte S.</given-names></name>
        <name><surname>Spindler</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>DoubleML – Double machine learning in Python</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://github.com/DoubleML/doubleml-for-py</uri>
    </element-citation>
  </ref>
  <ref id="ref-DoubleML2022Python">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bach</surname><given-names>Philipp</given-names></name>
        <name><surname>Chernozhukov</surname><given-names>Victor</given-names></name>
        <name><surname>Kurz</surname><given-names>Malte S.</given-names></name>
        <name><surname>Spindler</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>DoubleML – An object-oriented implementation of double machine learning in Python</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2022">2022</year>
      <volume>23</volume>
      <issue>53</issue>
      <uri>http://jmlr.org/papers/v23/21-0862.html</uri>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-doubleml2024R">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bach</surname><given-names>Philipp</given-names></name>
        <name><surname>Kurz</surname><given-names>Malte S.</given-names></name>
        <name><surname>Chernozhukov</surname><given-names>Victor</given-names></name>
        <name><surname>Spindler</surname><given-names>Martin</given-names></name>
        <name><surname>Klaassen</surname><given-names>Sven</given-names></name>
      </person-group>
      <article-title>DoubleML: An object-oriented implementation of double machine learning in R</article-title>
      <source>Journal of Statistical Software</source>
      <year iso-8601-date="2024">2024</year>
      <volume>108</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.18637/jss.v108.i03</pub-id>
      <fpage>1</fpage>
      <lpage>56</lpage>
    </element-citation>
  </ref>
  <ref id="ref-econml">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Keith Battocchi</surname><given-names>Maggie Hei</given-names><suffix>Eleanor Dillon</suffix></name>
      </person-group>
      <article-title>EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation</article-title>
      <publisher-name>https://github.com/py-why/EconML</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-chen2020causalml">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Chen</surname><given-names>Huigang</given-names></name>
        <name><surname>Harinen</surname><given-names>Totte</given-names></name>
        <name><surname>Lee</surname><given-names>Jeong-Yoon</given-names></name>
        <name><surname>Yung</surname><given-names>Mike</given-names></name>
        <name><surname>Zhao</surname><given-names>Zhenyu</given-names></name>
      </person-group>
      <article-title>CausalML: Python package for causal machine learning</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://arxiv.org/abs/2002.11631</uri>
    </element-citation>
  </ref>
  <ref id="ref-julia">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
        <name><surname>Edelman</surname><given-names>Alan</given-names></name>
        <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
        <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
      </person-group>
      <article-title>Julia: A fresh approach to numerical computing</article-title>
      <source>SIAM Review</source>
      <publisher-name>Society for Industrial &amp; Applied Mathematics (SIAM)</publisher-name>
      <year iso-8601-date="2017-01">2017</year><month>01</month>
      <volume>59</volume>
      <issue>1</issue>
      <uri>10.1137%2F141000671</uri>
      <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      <fpage>65</fpage>
      <lpage>98</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
