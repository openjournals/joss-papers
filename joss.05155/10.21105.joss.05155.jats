<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5155</article-id>
<article-id pub-id-type="doi">10.21105/joss.05155</article-id>
<title-group>
<article-title>pysr3: A Python Package for Sparse Relaxed Regularized
Regression</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8173-6236</contrib-id>
<name>
<surname>Sholokhov</surname>
<given-names>Aleksei</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3313-215X</contrib-id>
<name>
<surname>Zheng</surname>
<given-names>Peng</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1875-1801</contrib-id>
<name>
<surname>Aravkin</surname>
<given-names>Aleksandr</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Applied Mathematics, University of
Washington</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Health Metrics Sciences, University of
Washington</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>8</volume>
<issue>84</issue>
<fpage>5155</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>feature selection</kwd>
<kwd>linear models</kwd>
<kwd>mixed-effect models</kwd>
<kwd>regularization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Datasets increasingly contain more and more potential covariates
  that may be related to different research questions. The presence of
  irrelevant or weakly relevant features can be counterproductive to
  modeling, as over-parametrized models may lead to unstable estimates,
  invalid inference, and low prediction accuracy. Reliable feature
  selection is a requirement for a wide range of regression
  settings.</p>
  <p>Feature selection methods are a hot research topic
  (<xref alt="Buscemi &amp; Plaia, 2020" rid="ref-Buscemi2019Survey" ref-type="bibr">Buscemi
  &amp; Plaia,
  2020</xref>),(<xref alt="Miao &amp; Niu, 2016" rid="ref-miao2016survey" ref-type="bibr">Miao
  &amp; Niu,
  2016</xref>),(<xref alt="Li et al., 2020" rid="ref-li2020survey" ref-type="bibr">Li
  et al., 2020</xref>), with a plethora of numerical approaches and
  corresponding implementations. However, most of the current
  state-of-the-art tools custom-tailor their implementation to their
  mathematical approach (e.g.Â use an optimization scheme that works only
  for a particular regularizer). In practice, it forces practitioners to
  re-implement their workflow for each method that they want to use or
  try, even when the difference between methods is minor. The absence of
  universal open source implementations effectively blocks practitioners
  from comparing all available methods, with the effect of slowing
  uptake of research results in the field.</p>
  <p>We fill this gap by implementing recently developed universal
  solvers
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>),
  (<xref alt="Sholokhov et al., 2022" rid="ref-sholokhov2022relaxation" ref-type="bibr">Sholokhov
  et al., 2022</xref>) that (1) work with most popular regularized
  regression techniques, and (2) improve selection accuracy of any
  regularized regression approach using new relaxation reformulations.
  To date, the library supports linear models (classic regression) and
  linear mixed effects models. Because of full compatibility with
  <monospace>sklearn</monospace>, all <monospace>pysr3</monospace>
  models can be used in pipeline with classic modelling blocks such as
  data pre-processors, randomized grid search, cross-validation, and
  quality metrics.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Reliable automated feature selection requires easy-to-use
  libraries, so that practitioners can test and compare multiple
  regularization approaches using their data, choose the most effective
  method, and apply the analysis at scale. These libraries should be
  flexible and modular enough to accommodate future developments, such
  as newly proposed regularizers, without forcing the practitioner to
  implement new solvers for each approach. At the same time, the
  libraries must be efficient and robust enough to handle common
  challenges such as ill-conditioned problems that arise in datasets
  with correlated predictors. The PySR3 library is designed to easily
  include new loss functions, constraints, information criteria, and
  regularization strategies. All PySR3 models fully adhere the standards
  and interface requirements of <monospace>sklearn</monospace>
  (<xref alt="Buitinck et al., 2013" rid="ref-sklearn_api" ref-type="bibr">Buitinck
  et al., 2013</xref>), providing a familiar interface to users.</p>
  <p>Currently, PySR3 models can be used to automatically select
  features in both linear regression models and linear mixed effects
  (LME) models, which extend linear regression to clustered data
  settings. LME models commonly arise in longitudinal data analysis and
  meta-analysis. Feature selection for linear mixed-effects models is
  harder than for linear regression models due to non-linearity of LMEs
  and within-group correlations. To the best of our knowledge, there are
  no standalone Python packages for mixed-effect feature selection,
  while the alternatives implemented in R, such as lmmlasso
  (<xref alt="Schelldorfer et al., 2011" rid="ref-schelldorfer2011estimation" ref-type="bibr">Schelldorfer
  et al., 2011</xref>) and glmmlasso
  (<xref alt="Schelldorfer et al., 2014" rid="ref-schelldorfer2014glmmlasso" ref-type="bibr">Schelldorfer
  et al., 2014</xref>), take more time to converge and yield worse
  selection accuracy, as discussed in
  (<xref alt="Sholokhov et al., 2022" rid="ref-sholokhov2022relaxation" ref-type="bibr">Sholokhov
  et al., 2022</xref>).</p>
</sec>
<sec id="core-idea-and-structure-of-pysr3">
  <title>Core idea and structure of <monospace>pysr3</monospace></title>
  <p>The baseline optimization method of PySR3 is proximal gradient
  descent (PGD). PGD exploits the fact that most feature selection
  methods minimize the sum of a smooth loss that captures the negative
  log likelihood of the data and a non-smooth sparsity promoting
  regularizer. PGD works well as long as the regularizer has an
  implementable proximal operator. Many widely-used regularizers have
  proximal operators that are well known and either have efficient
  numerical routines or closed form solutions
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>). Examples include the zero-norm (L0), least
  absolute shrinkage and selection operator (LASSO), adaptive LASSO
  (A-LASSO), and smoothly clipped absolute deviation (SCAD)
  regularizers.</p>
  <p>Each regularizer included in PySR3 can also be used in its relaxed
  SR3 form
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>). SR3 preconditions the likelihood, improving the
  performance of feature selection methods. PGD on the SR3-transformed
  problem takes fewer iterations to converge, and the features selected
  are more accurate and have lower false positive rates across simulated
  examples for both linear regression
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>) and LME
  (<xref alt="Sholokhov et al., 2022" rid="ref-sholokhov2022relaxation" ref-type="bibr">Sholokhov
  et al., 2022</xref>) models, as illustrated on
  <xref alt="[fig:lme_summary]" rid="figU003Alme_summary">[fig:lme_summary]</xref>
  (adapted from Figure 1 from
  (<xref alt="Sholokhov et al., 2022" rid="ref-sholokhov2022relaxation" ref-type="bibr">Sholokhov
  et al., 2022</xref>)).</p>
  <fig>
    <caption><p>SR3 relaxation makes a problem more well-conditioned
    which accelerates the
    optimization.<styled-content id="figU003Alme_summary"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/images/summary_improved.png" />
  </fig>
  <p>More information about the structure of the library can be found in
  <ext-link ext-link-type="uri" xlink:href="https://aksholokhov.github.io/pysr3/">documentation</ext-link>,
  while the mathematical contributions are extensively discussed in
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>) for linear regression and in
  (<xref alt="Sholokhov et al., 2022" rid="ref-sholokhov2022relaxation" ref-type="bibr">Sholokhov
  et al.,
  2022</xref>),(<xref alt="Aravkin et al., 2022" rid="ref-aravkin2022relaxationb" ref-type="bibr">Aravkin
  et al., 2022</xref>) for linear mixed effects models.</p>
</sec>
<sec id="ongoing-research-and-dissemination">
  <title>Ongoing Research and Dissemination</title>
  <p>The manuscripts âA Relaxation Approach to Feature Selection for
  Linear Mixed Effects Modelsâ and âAnalysis of Relaxation Methods for
  Feature Selection in Mixed Effects Modelsâ are undergoing simultaneous
  peer-review. Since its introduction in
  (<xref alt="Zheng et al., 2018" rid="ref-zheng2018unified" ref-type="bibr">Zheng
  et al., 2018</xref>), SR3 has been cited 92 times, and used in model
  discovery
  (<xref alt="Mendible et al., 2020" rid="ref-Mendible2020" ref-type="bibr">Mendible
  et al., 2020</xref>), optimal dose management
  (<xref alt="Levin et al., 2019" rid="ref-levin2019proof" ref-type="bibr">Levin
  et al., 2019</xref>) and inverse problems
  (<xref alt="Baraldi et al., 2019" rid="ref-baraldi2019basis" ref-type="bibr">Baraldi
  et al., 2019</xref>). The LME extensions of PySR3 was developed for
  variable selection in meta-analysis, which is a fundamental problem in
  risk factor analysis for the Global Burden of Disease study
  (<xref alt="Murray et al., 2020" rid="ref-murray2020global" ref-type="bibr">Murray
  et al., 2020</xref>).</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Buscemi2019Survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Buscemi</surname><given-names>Simona</given-names></name>
        <name><surname>Plaia</surname><given-names>Antonella</given-names></name>
      </person-group>
      <article-title>Model selection in linear mixed-effect models</article-title>
      <source>AStA Advances in Statistical Analysis</source>
      <publisher-name>Springer Berlin Heidelberg</publisher-name>
      <year iso-8601-date="2020-12">2020</year><month>12</month>
      <volume>104</volume>
      <issue>4</issue>
      <issn>1863-8171</issn>
      <uri>https://doi.org/10.1007/s10182-019-00359-z http://link.springer.com/10.1007/s10182-019-00359-z</uri>
      <pub-id pub-id-type="doi">10.1007/s10182-019-00359-z</pub-id>
      <fpage>529</fpage>
      <lpage>575</lpage>
    </element-citation>
  </ref>
  <ref id="ref-zheng2018unified">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Zheng</surname><given-names>Peng</given-names></name>
        <name><surname>Askham</surname><given-names>Travis</given-names></name>
        <name><surname>Brunton</surname><given-names>Steven L</given-names></name>
        <name><surname>Kutz</surname><given-names>J Nathan</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr Y</given-names></name>
      </person-group>
      <article-title>A unified framework for sparse relaxed regularized regression: SR3</article-title>
      <source>IEEE Access</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>7</volume>
      <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2886528</pub-id>
      <fpage>1404</fpage>
      <lpage>1423</lpage>
    </element-citation>
  </ref>
  <ref id="ref-sholokhov2022relaxation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Sholokhov</surname><given-names>Aleksei</given-names></name>
        <name><surname>Burke</surname><given-names>James V</given-names></name>
        <name><surname>Santomauro</surname><given-names>Damian F</given-names></name>
        <name><surname>Zheng</surname><given-names>Peng</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr</given-names></name>
      </person-group>
      <article-title>A relaxation approach to feature selection for linear mixed effects models</article-title>
      <source>arXiv preprint arXiv:2205.06925</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2205.06925</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-aravkin2022relaxationb">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Aravkin</surname><given-names>Aleksandr</given-names></name>
        <name><surname>Burke</surname><given-names>James</given-names></name>
        <name><surname>Sholokhov</surname><given-names>Aleksei</given-names></name>
        <name><surname>Zheng</surname><given-names>Peng</given-names></name>
      </person-group>
      <article-title>Analysis of relaxation methods for feature selection in mixed effects models</article-title>
      <source>arXiv preprint arXiv:2209.10575</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2209.10575</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-baraldi2019basis">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Baraldi</surname><given-names>Robert</given-names></name>
        <name><surname>Kumar</surname><given-names>Rajiv</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr</given-names></name>
      </person-group>
      <article-title>Basis pursuit denoise with nonsmooth constraints</article-title>
      <source>IEEE Transactions on Signal Processing</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>67</volume>
      <issue>22</issue>
      <pub-id pub-id-type="doi">10.1109/tsp.2019.2946029</pub-id>
      <fpage>5811</fpage>
      <lpage>5823</lpage>
    </element-citation>
  </ref>
  <ref id="ref-murray2020global">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Murray</surname><given-names>Christopher JL</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr Y</given-names></name>
        <name><surname>Zheng</surname><given-names>Peng</given-names></name>
        <name><surname>Abbafati</surname><given-names>Cristiana</given-names></name>
        <name><surname>Abbas</surname><given-names>Kaja M</given-names></name>
        <name><surname>Abbasi-Kangevari</surname><given-names>Mohsen</given-names></name>
        <name><surname>Abd-Allah</surname><given-names>Foad</given-names></name>
        <name><surname>Abdelalim</surname><given-names>Ahmed</given-names></name>
        <name><surname>Abdollahi</surname><given-names>Mohammad</given-names></name>
        <name><surname>Abdollahpour</surname><given-names>Ibrahim</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Global burden of 87 risk factors in 204 countries and territories, 1990â2019: A systematic analysis for the global burden of disease study 2019</article-title>
      <source>The Lancet</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>396</volume>
      <issue>10258</issue>
      <pub-id pub-id-type="doi">10.1016/S0140-6736(20)30752-2</pub-id>
      <fpage>1223</fpage>
      <lpage>1249</lpage>
    </element-citation>
  </ref>
  <ref id="ref-schelldorfer2014glmmlasso">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schelldorfer</surname><given-names>JÃ¼rg</given-names></name>
        <name><surname>Meier</surname><given-names>Lukas</given-names></name>
        <name><surname>BÃ¼hlmann</surname><given-names>Peter</given-names></name>
      </person-group>
      <article-title>Glmmlasso: An algorithm for high-dimensional generalized linear mixed models using L1-penalization</article-title>
      <source>Journal of Computational and Graphical Statistics</source>
      <publisher-name>Taylor &amp; Francis</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>23</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1080/10618600.2013.773239</pub-id>
      <fpage>460</fpage>
      <lpage>477</lpage>
    </element-citation>
  </ref>
  <ref id="ref-li2020survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Li</surname><given-names>Xiaoping</given-names></name>
        <name><surname>Wang</surname><given-names>Yadi</given-names></name>
        <name><surname>Ruiz</surname><given-names>RubÃ©n</given-names></name>
      </person-group>
      <article-title>A survey on sparse learning models for feature selection</article-title>
      <source>IEEE transactions on cybernetics</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <pub-id pub-id-type="doi">10.1109/TCYB.2020.2982445</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-miao2016survey">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Miao</surname><given-names>Jianyu</given-names></name>
        <name><surname>Niu</surname><given-names>Lingfeng</given-names></name>
      </person-group>
      <article-title>A survey on feature selection</article-title>
      <source>Procedia Computer Science</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2016">2016</year>
      <volume>91</volume>
      <pub-id pub-id-type="doi">10.1016/j.procs.2016.07.111</pub-id>
      <fpage>919</fpage>
      <lpage>926</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Mendible2020">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Mendible</surname><given-names>Ariana</given-names></name>
        <name><surname>Brunton</surname><given-names>Steven L.</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr Y.</given-names></name>
        <name><surname>Lowrie</surname><given-names>Wes</given-names></name>
        <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
      </person-group>
      <article-title>Dimensionality reduction and reduced-order modeling for traveling wave physics</article-title>
      <source>Theoretical and Computational Fluid Dynamics</source>
      <year iso-8601-date="2020">2020</year>
      <volume>34</volume>
      <issue>4</issue>
      <uri>https://arxiv.org/abs/1911.00565</uri>
      <pub-id pub-id-type="doi">10.1007/s00162-020-00529-9</pub-id>
      <fpage>385</fpage>
      <lpage>400</lpage>
    </element-citation>
  </ref>
  <ref id="ref-levin2019proof">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Levin</surname><given-names>Roman</given-names></name>
        <name><surname>Aravkin</surname><given-names>Aleksandr Y</given-names></name>
        <name><surname>Kim</surname><given-names>Minsun</given-names></name>
      </person-group>
      <article-title>A proof of principle: Multi-modality radiotherapy optimization</article-title>
      <source>arXiv preprint arXiv:1911.05182</source>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1911.05182</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-sklearn_api">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Buitinck</surname><given-names>Lars</given-names></name>
        <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
        <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
        <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
        <name><surname>Mueller</surname><given-names>Andreas</given-names></name>
        <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
        <name><surname>Niculae</surname><given-names>Vlad</given-names></name>
        <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
        <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
        <name><surname>Grobler</surname><given-names>Jaques</given-names></name>
        <name><surname>Layton</surname><given-names>Robert</given-names></name>
        <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
        <name><surname>Joly</surname><given-names>Arnaud</given-names></name>
        <name><surname>Holt</surname><given-names>Brian</given-names></name>
        <name><surname>Varoquaux</surname><given-names>GaÃ«l</given-names></name>
      </person-group>
      <article-title>API design for machine learning software: Experiences from the scikit-learn project</article-title>
      <source>ECML PKDD workshop: Languages for data mining and machine learning</source>
      <year iso-8601-date="2013">2013</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1309.0238</pub-id>
      <fpage>108</fpage>
      <lpage>122</lpage>
    </element-citation>
  </ref>
  <ref id="ref-schelldorfer2011estimation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Schelldorfer</surname><given-names>JÃ¼rg</given-names></name>
        <name><surname>BÃ¼hlmann</surname><given-names>Peter</given-names></name>
        <name><surname>DE GEER</surname><given-names>SARA VAN</given-names></name>
      </person-group>
      <article-title>Estimation for high-dimensional linear mixed-effects models using l1-penalization</article-title>
      <source>Scandinavian Journal of Statistics</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2011">2011</year>
      <volume>38</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1111/j.1467-9469.2011.00740.x</pub-id>
      <fpage>197</fpage>
      <lpage>214</lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
