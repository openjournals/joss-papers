<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">6120</article-id>
<article-id pub-id-type="doi">10.21105/joss.06120</article-id>
<title-group>
<article-title>DICaugment: A Python Package for 3D Medical Imaging
Augmentation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-2573-180X</contrib-id>
<name>
<surname>McIntosh</surname>
<given-names>J.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cao</surname>
<given-names>Qian</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sahiner</surname>
<given-names>Berkman</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Petrick</surname>
<given-names>Nicholas</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Farhangi</surname>
<given-names>M. Mehdi</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Division of Imaging, Diagnostics, and Software Reliability,
CDRH, U.S. Food and Drug Administration, Silver Spring, MD 20993,
USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-08-08">
<day>8</day>
<month>8</month>
<year>2023</year>
</pub-date>
<volume>9</volume>
<issue>95</issue>
<fpage>6120</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Augmentation</kwd>
<kwd>Deep Learning</kwd>
<kwd>Medical</kwd>
<kwd></kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>DICaugment is a Python package based on the popular image
  augmentation library Albumentations
  (<xref alt="Buslaev et al., 2020" rid="ref-info11020125" ref-type="bibr">Buslaev
  et al., 2020</xref>), with specific enhancements for working with
  volumetric medical images, such as Computed Tomography (CT) scans.
  This package provides a collection of over 40 powerful augmentation
  techniques that can be seamlessly integrated into a machine-learning
  pipeline to augment volumetric medical images. The package was
  designed to incorporate the image acquisition metadata available in
  DICOM headers, allowing users to create transformations that are
  consistent with those acquisition parameters for specific CT systems
  and reconstruction kernels. DICaugment extends the success of the
  Albumentations library for two-dimensional (2D) image augmentation to
  the realm of three-dimensional (3D) images, offering a comprehensive
  set of transformations and augmentations, ranging from pixel-level
  intensity transformations to spatial transformations, all designed and
  optimized for 3D data.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The recent advancements in machine learning have significantly
  improved the performance of deep learning models across various
  domains and applications. However, the success of these models still
  largely relies on a significant amount of labeled and annotated
  training data. This is a particular limitation in medical imaging
  applications where imaging data annotation and the establishment of a
  reliable reference standard is expensive, time-consuming, and
  typically requires clinician expertise. DICaugment supports the
  efficient use of available labeled and annotated data by providing
  augmentations that are consistent with preexisting imaging data
  annotations available in the form of masks, bounding boxes, and
  keypoints.</p>
  <p>Considering the distinct geometric and operational factors inherent
  to 3D images, several toolkits have been developed to perform
  transformations in the 3D space domain; SimpleITK
  (<xref alt="Yaniv et al., 2017" rid="ref-Yaniv2017" ref-type="bibr">Yaniv
  et al., 2017</xref>) provides a collection of spatial transformations,
  including linear and deformable geometric transformations, as well as
  intensity-based transformations such as linear, non-linear, and
  histogram-based intensity adjustments. In addition to supporting
  various medical imaging tasks, augmentation methods in packages such
  as TorchIO
  (<xref alt="Pérez-García et al., 2021" rid="ref-Pérez-García2021" ref-type="bibr">Pérez-García
  et al., 2021</xref>) and MONAI
  (<xref alt="Cardoso et al., 2022" rid="ref-cardoso2022monai" ref-type="bibr">Cardoso
  et al., 2022</xref>) were designed to seamlessly integrate into
  popular deep learning frameworks such as PyTorch, providing a
  convenient interface for integration within deep learning pipelines.
  Packages such as Volumentations
  (<xref alt="Solovyev et al., 2022" rid="ref-solovyev20223d" ref-type="bibr">Solovyev
  et al., 2022</xref>) were uniquely developed for the purpose of
  augmenting 3D volumetric images, offering specialized transformations
  for enriching 3D imaging datasets during the training of deep neural
  networks.</p>
  <p>DICaugment offers a variety of transformations including geometric
  and intensity transformations, spatial distortions, and physics-based
  augmentations designed to enhance the diversity of 3D image data. A
  subset of these transformations includes blurring techniques, such as
  median blur and Gaussian blur, that must utilize local spatial
  operations such as convolution to achieve the desired output. Notably,
  DICaugment offers a unique capability by allowing users to choose
  between a 2D by-slice operation or a full 3D operation when applying
  different blurring augmentations in a pipeline. This flexibility
  caters to a variety of use cases and ensures that the blurring effects
  can be consistent across an entire 3D volume.</p>
  <p>Additionally, DICaugment enables users to construct custom
  augmentation pipelines with control over each individual
  transformation. Mimicking the Albumentations
  (<xref alt="Buslaev et al., 2020" rid="ref-info11020125" ref-type="bibr">Buslaev
  et al., 2020</xref>) package, DICaugment utilizes the concept of
  augmentation probabilities. This feature allows users to assign a
  probability of occurrence to each transformation within a pipeline,
  enabling selective and stochastic augmentation of a dataset. By
  specifying different probabilities for various transformations, users
  can create diverse and balanced augmented datasets that reflect
  real-world variability. This level of control ensures that specific
  augmentations, whether it be intensity adjustments or geometric
  transformations, are applied with user-defined frequencies, therefore
  tailoring the augmentation process to the characteristics and use case
  of the dataset.</p>
  <p>Compared to other augmentation packages, DICaugment offers a unique
  advantage through the addition of physics-based augmentations that
  leverage metadata from DICOM files in CT imaging. During the
  reconstruction process of CT images, different manufacturers employ
  different reconstruction kernels, leading to distinct noise textures
  in the resulting images often characterized by the Noise Power
  Spectrum (NPS)
  (<xref alt="Solomon et al., 2012" rid="ref-Solomon2012-lj" ref-type="bibr">Solomon
  et al., 2012</xref>). DICaugment utilizes the NPS profiles from the
  specific reconstruction kernel to generate noisy images that are
  consistent with the imaging acquisition and reconstruction parameters
  (<xref alt="Tward &amp; Siewerdsen, 2008" rid="ref-Tward2008-gz" ref-type="bibr">Tward
  &amp; Siewerdsen, 2008</xref>) from the system and acquisition
  parameters used to acquire the original CT dataset. To illustrate, we
  computed the NPS obtained from the noise insertion transformations
  offered by DICaugment and compared it against simple white Gaussian
  noise, which is a common noise insertion method for data augmentation
  (e.g., MONAI
  (<xref alt="Cardoso et al., 2022" rid="ref-cardoso2022monai" ref-type="bibr">Cardoso
  et al., 2022</xref>) and Volumentations
  (<xref alt="Solovyev et al., 2022" rid="ref-solovyev20223d" ref-type="bibr">Solovyev
  et al., 2022</xref>)).</p>
  <p>For this experiment, we utilized a water phantom
  (<xref alt="Phantom Testing: CT, n.d." rid="ref-Phantom_testing" ref-type="bibr"><italic>Phantom
  Testing: CT</italic>, n.d.</xref>) scanned by a Siemens Somatom
  Definition Flash CT scanner with an exposure of 240 mAs, 120 kVp, and
  reconstructed with a B30f reconstruction kernel at 0.48 mm in-plane
  pixel spacing. The 2D NPS was estimated using the method proposed by
  Solomon et al.
  (<xref alt="Solomon et al., 2012" rid="ref-Solomon2012-lj" ref-type="bibr">Solomon
  et al., 2012</xref>); from the water phantom, we extracted a uniform
  volumetric region of 128 <inline-formula><alternatives>
  <tex-math><![CDATA[\times]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>×</mml:mo></mml:math></alternatives></inline-formula>
  128 <inline-formula><alternatives>
  <tex-math><![CDATA[\times]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>×</mml:mo></mml:math></alternatives></inline-formula>
  70 dimensions and computed the 2D NPS of each slice by using:</p>
  <p><named-content id="eqU003A2dnps" content-type="equation"><disp-formula><alternatives>
  <tex-math><![CDATA[
  NPS(u,v) = \frac{d_xd_y}{N_xN_y}.\mid F[I(x,y)-P(x,y)]\mid^2]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>.</mml:mi><mml:mo>∣</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:msup><mml:mo>∣</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></disp-formula></named-content></p>
  <p>In <xref alt="Equation 1" rid="eqU003A2dnps">Equation 1</xref>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[u]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>u</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[v]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>v</mml:mi></mml:math></alternatives></inline-formula>
  represent spatial frequency (mm<inline-formula><alternatives>
  <tex-math><![CDATA[^{-1}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi></mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>)
  in the <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>
  directions, respectively, <inline-formula><alternatives>
  <tex-math><![CDATA[d_x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[d_y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  are pixel size in millimeter space, <inline-formula><alternatives>
  <tex-math><![CDATA[N_x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>N</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[N_y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>N</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
  are the number of pixels in the <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[y]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>y</mml:mi></mml:math></alternatives></inline-formula>
  directions within the selected ROI (i.e. 128
  <inline-formula><alternatives>
  <tex-math><![CDATA[\times]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>×</mml:mo></mml:math></alternatives></inline-formula>
  128 px), <inline-formula><alternatives>
  <tex-math><![CDATA[F]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>F</mml:mi></mml:math></alternatives></inline-formula>
  denotes the 2D Fourier transform, <inline-formula><alternatives>
  <tex-math><![CDATA[I(x,y)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is the pixel density of the uniform region in Hounsfield Unit at
  position <inline-formula><alternatives>
  <tex-math><![CDATA[(x,y)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives>
  <tex-math><![CDATA[P]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>P</mml:mi></mml:math></alternatives></inline-formula>
  is the second order polynomial fit of <inline-formula><alternatives>
  <tex-math><![CDATA[I]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>I</mml:mi></mml:math></alternatives></inline-formula>.
  Each estimated 2D NPS within the volumetric ROI is normalized by its
  integral across all frequencies and converted into a one-dimensional
  radial representation, <inline-formula><alternatives>
  <tex-math><![CDATA[r = \sqrt{u^2+v^2}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>.
  The final normalized NPS (nNPS) was obtained by averaging the radial
  NPS curves across 70 slices within the volumetric image.</p>
  <fig>
    <caption><p>(a) Water phantom scanned by a Siemens Somatom
    Definition Flash CT scanner with imaging parameters set at 240 mAs,
    120 kVP, and reconstructed with a B30f reconstruction kernel at 0.48
    mm in-plane pixel spacing. The noise magnitude is computed as 9.46
    Hounsfield units (HU). (b) Increasing the noise magnitude by adding
    white Gaussian noise, resulting in a noisy image with a magnitude of
    16.01 HU. (c) Increasing the noise magnitude using DICaugment,
    resulting in a noise image with a magnitude of 16.08 HU. Figures
    (d), (e), and (f) illustrate the benefits of DICaugment in offering
    augmentations consistent with the imaging parameters, demonstrated
    in terms of the Noise Power Spectrum (NPS) of the augmented image
    (i.e., inserting Gaussian noise produces a high-frequency tail in
    the NPS that is inconsistent with that of the Siemens scanner while
    our noise insertion method yields a shape in the NPS that is
    consistent with that of the Siemens
    scanner).<styled-content id="figU003Aexample"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/fig_1.png" />
  </fig>
  <p>Figure 1(a) illustrates a slice of the noise region extracted from
  the uniform water phantom along with the corresponding estimation of
  the normalized Noise Power Spectrum (nNPS). Figure 1(b) illustrates
  the outcome of noise insertion using white Gaussian noise, a common
  approach for noise insertion
  (<xref alt="Cardoso et al., 2022" rid="ref-cardoso2022monai" ref-type="bibr">Cardoso
  et al., 2022</xref>), demonstrating the lack of correlation between
  adjacent pixels. Figure 1(c) shows the outcome of noise insertion by
  DICaugment. Despite the increased magnitude of the noise, the
  correlation among adjacent pixels remained essentially unchanged, as
  evident in the normalized Noise Power Spectrum (nNPS) shown in Figure
  1(f). This shows that a decreased CT exposure can be simulated through
  our augmentation process for specific CT imaging systems and
  kernels.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>J. McIntosh was supported by an appointment to the Research
  Participation Program at the Center for Devices and Radiological
  Health administered by the Oak Ridge Institute for Science and
  Education through an interagency agreement between the U.S. Department
  of Energy and the U.S. Food and Drug Administration. The mention of
  softwares, commercial products, their sources, or their use in
  connection with material reported herein is not to be construed as
  either an actual or implied endorsement of such products by the
  Department of Health and Human Services.</p>
  <p>We would also like to express our gratitude to the developers of
  Albumentations for their excellent work on the original library. The
  pipeline, design, and API - originally introduced in the
  Albumentations library - served as the foundation for DICaugment.</p>
</sec>
<sec id="author-contributions">
  <title>Author Contributions</title>
  <p>J. McIntosh authored the package, developed the pipeline and its
  functions, wrote the documentation, and drafted the article. Qian Cao
  assisted in noise insertion augmentation and contributed to the
  drafting of the article. Berkman Sahiner and Nicholas Petrick assisted
  in designing the validation study, noise simulation, and contributed
  to the drafting of the article. M. Mehdi Farhangi supervised the
  project, implemented the noise insertion augmentation, conducted the
  validation study, and contributed to the article drafting.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-info11020125">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Buslaev</surname><given-names>Alexander</given-names></name>
        <name><surname>Iglovikov</surname><given-names>Vladimir I.</given-names></name>
        <name><surname>Khvedchenya</surname><given-names>Eugene</given-names></name>
        <name><surname>Parinov</surname><given-names>Alex</given-names></name>
        <name><surname>Druzhinin</surname><given-names>Mikhail</given-names></name>
        <name><surname>Kalinin</surname><given-names>Alexandr A.</given-names></name>
      </person-group>
      <article-title>Albumentations: Fast and flexible image augmentations</article-title>
      <source>Information</source>
      <year iso-8601-date="2020">2020</year>
      <volume>11</volume>
      <issue>2</issue>
      <issn>2078-2489</issn>
      <uri>https://www.mdpi.com/2078-2489/11/2/125</uri>
      <pub-id pub-id-type="doi">10.3390/info11020125</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Phantom_testing">
    <element-citation>
      <article-title>Phantom Testing: CT</article-title>
      <publisher-name>https://accreditationsupport.acr.org/support/solutions/articles/11000056197-phantom-testing-ct-revised-11-9-2022-</publisher-name>
    </element-citation>
  </ref>
  <ref id="ref-solovyev20223d">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solovyev</surname><given-names>Roman</given-names></name>
        <name><surname>Kalinin</surname><given-names>Alexandr A</given-names></name>
        <name><surname>Gabruseva</surname><given-names>Tatiana</given-names></name>
      </person-group>
      <article-title>3D convolutional neural networks for stalled brain capillary detection</article-title>
      <source>Computers in Biology and Medicine</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>141</volume>
      <pub-id pub-id-type="doi">10.1016/j.compbiomed.2021.105089</pub-id>
      <fpage>105089</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-cardoso2022monai">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cardoso</surname><given-names>M Jorge</given-names></name>
        <name><surname>Li</surname><given-names>Wenqi</given-names></name>
        <name><surname>Brown</surname><given-names>Richard</given-names></name>
        <name><surname>Ma</surname><given-names>Nic</given-names></name>
        <name><surname>Kerfoot</surname><given-names>Eric</given-names></name>
        <name><surname>Wang</surname><given-names>Yiheng</given-names></name>
        <name><surname>Murrey</surname><given-names>Benjamin</given-names></name>
        <name><surname>Myronenko</surname><given-names>Andriy</given-names></name>
        <name><surname>Zhao</surname><given-names>Can</given-names></name>
        <name><surname>Yang</surname><given-names>Dong</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Monai: An open-source framework for deep learning in healthcare</article-title>
      <source>arXiv preprint arXiv:2211.02701</source>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-Solomon2012-lj">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Solomon</surname><given-names>Justin B</given-names></name>
        <name><surname>Christianson</surname><given-names>Olav</given-names></name>
        <name><surname>Samei</surname><given-names>Ehsan</given-names></name>
      </person-group>
      <article-title>Quantitative comparison of noise texture across CT scanners from different manufacturers</article-title>
      <source>Med. Phys.</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2012-10">2012</year><month>10</month>
      <volume>39</volume>
      <issue>10</issue>
      <pub-id pub-id-type="doi">10.1118/1.4752209</pub-id>
      <fpage>6048</fpage>
      <lpage>6055</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Tward2008-gz">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tward</surname><given-names>Daniel J</given-names></name>
        <name><surname>Siewerdsen</surname><given-names>Jeffrey H</given-names></name>
      </person-group>
      <article-title>Cascaded systems analysis of the 3D noise transfer characteristics of flat-panel cone-beam CT</article-title>
      <source>Med. Phys.</source>
      <publisher-name>Wiley</publisher-name>
      <year iso-8601-date="2008-12">2008</year><month>12</month>
      <volume>35</volume>
      <issue>12</issue>
      <fpage>5510</fpage>
      <lpage>5529</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Yaniv2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yaniv</surname><given-names>Ziv</given-names></name>
        <name><surname>Lowekamp</surname><given-names>Bradley C.</given-names></name>
        <name><surname>Johnson</surname><given-names>Hans J.</given-names></name>
        <name><surname>Beare</surname><given-names>Richard</given-names></name>
      </person-group>
      <article-title>SIMPLEITK image-analysis notebooks: A collaborative environment for education and reproducible research</article-title>
      <source>Journal of Digital Imaging</source>
      <year iso-8601-date="2017">2017</year>
      <volume>31</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.1007/s10278-017-0037-8</pub-id>
      <fpage>290</fpage>
      <lpage>303</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Pérez-García2021">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pérez-García</surname><given-names>Fernando</given-names></name>
        <name><surname>Sparks</surname><given-names>Rachel</given-names></name>
        <name><surname>Ourselin</surname><given-names>Sébastien</given-names></name>
      </person-group>
      <article-title>Torchio: A python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning</article-title>
      <source>Computer Methods and Programs in Biomedicine</source>
      <year iso-8601-date="2021">2021</year>
      <volume>208</volume>
      <pub-id pub-id-type="doi">10.1016/j.cmpb.2021.106236</pub-id>
      <fpage>106236</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
