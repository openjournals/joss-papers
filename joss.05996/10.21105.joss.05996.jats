<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5996</article-id>
<article-id pub-id-type="doi">10.21105/joss.05996</article-id>
<title-group>
<article-title>Machine Learning Validation via Rational Dataset Sampling
with <monospace>astartes</monospace></article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0657-9426</contrib-id>
<name>
<surname>Burns</surname>
<given-names>Jackson W.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9484-9253</contrib-id>
<name>
<surname>Spiekermann</surname>
<given-names>Kevin A.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6598-3939</contrib-id>
<name>
<surname>Bhattacharjee</surname>
<given-names>Himaghna</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6795-8403</contrib-id>
<name>
<surname>Vlachos</surname>
<given-names>Dionisios G.</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2603-9694</contrib-id>
<name>
<surname>Green</surname>
<given-names>William H.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Center for Computational Science and Engineering,
Massachusetts Institute of Technology</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Chemical Engineering, Massachusetts Institute
of Technology, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Chemical and Biomolecular Engineering,
University of Delaware, United States</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-04-03">
<day>3</day>
<month>4</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>91</issue>
<fpage>5996</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>machine learning</kwd>
<kwd>sampling</kwd>
<kwd>interpolation</kwd>
<kwd>extrapolation</kwd>
<kwd>data splits</kwd>
<kwd>cheminformatics</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Machine Learning (ML) has become an increasingly popular tool to
  accelerate traditional workflows. Critical to the use of ML is the
  process of splitting datasets into training, validation, and testing
  subsets that are used to develop and evaluate models. Common practice
  in the literature is to assign these subsets randomly. Although this
  approach is fast and efficient, it only measures a model’s capacity to
  interpolate. Testing errors from random splits may be overly
  optimistic if given new data that is dissimilar to the scope of the
  training set; thus, there is a growing need to easily measure
  performance for extrapolation tasks. To address this issue, we report
  <monospace>astartes</monospace>, an open-source Python package that
  implements many similarity- and distance-based algorithms to partition
  data into more challenging splits. Separate from
  <monospace>astartes</monospace>, users can then use these splits to
  better assess out-of-sample performance with any ML model of choice.
  This publication focuses on use-cases within cheminformatics. However,
  <monospace>astartes</monospace> operates on arbitrary vector inputs,
  so its principals and workflow are generalizable to other ML domains
  as well. <monospace>astartes</monospace> is available via the Python
  package managers <monospace>pip</monospace> and
  <monospace>conda</monospace> and is publicly hosted on GitHub
  (<ext-link ext-link-type="uri" xlink:href="https://github.com/JacksonBurns/astartes">github.com/JacksonBurns/astartes</ext-link>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Machine learning has sparked an explosion of progress in chemical
  kinetics
  (<xref alt="Komp et al., 2022" rid="ref-komp2022progress" ref-type="bibr">Komp
  et al., 2022</xref>;
  <xref alt="Spiekermann et al., 2022a" rid="ref-spiekermann2022fast" ref-type="bibr">Spiekermann
  et al., 2022a</xref>), drug discovery
  (<xref alt="Bannigan et al., 2021" rid="ref-bannigan2021machine" ref-type="bibr">Bannigan
  et al., 2021</xref>;
  <xref alt="X. Yang et al., 2019" rid="ref-yang2019concepts" ref-type="bibr">X.
  Yang et al., 2019</xref>), materials science
  (<xref alt="Wei et al., 2019" rid="ref-wei2019machine" ref-type="bibr">Wei
  et al., 2019</xref>), and energy storage
  (<xref alt="Jha et al., 2023" rid="ref-jha2023learning" ref-type="bibr">Jha
  et al., 2023</xref>) as researchers use data-driven methods to
  accelerate steps in traditional workflows within some acceptable error
  tolerance. To facilitate adoption of these models, researchers must
  critically think about several topics, such as comparing model
  performance to relevant baselines, operating on user-friendly inputs,
  and reporting performance on both interpolative and extrapolative
  tasks Spiekermann, Stuyver, et al.
  (<xref alt="2023" rid="ref-spiekermann2023comment" ref-type="bibr">2023</xref>).
  <monospace>astartes</monospace> aims to make it straightforward for
  machine learning scientists and researchers to focus on two important
  points: rigorous hyperparameter optimization and accurate performance
  evaluation.</p>
  <p>First, <monospace>astartes</monospace>’ key function
  <monospace>train_val_test_split</monospace> returns splits for
  training, validation, and testing sets using an
  <monospace>sklearn</monospace>-like interface. These splits can then
  separately be used with any chosen ML model. This partitioning is
  crucial since best practices in data science dictate that, in order to
  minimize the risk of hyperparameter overfitting, one must only
  optimize hyperparameters with a validation set and use a held-out test
  set to accurately measure performance on unseen data
  (<xref alt="Géron, 2019" rid="ref-geron2019hands" ref-type="bibr">Géron,
  2019</xref>;
  <xref alt="Huyen, 2022" rid="ref-huyen2022designing" ref-type="bibr">Huyen,
  2022</xref>;
  <xref alt="Lakshmanan et al., 2020" rid="ref-lakshmanan2020machine" ref-type="bibr">Lakshmanan
  et al., 2020</xref>;
  <xref alt="Ramsundar et al., 2019" rid="ref-ramsundar2019deep" ref-type="bibr">Ramsundar
  et al., 2019</xref>;
  <xref alt="Wang et al., 2020" rid="ref-wang2020machine" ref-type="bibr">Wang
  et al., 2020</xref>). Unfortunately, many published papers only
  mention training and testing sets but do not mention validation sets,
  implying that they optimize the hyperparameters to the test set, which
  would be blatant data leakage that leads to overly optimistic results.
  For researchers interested in quickly obtaining preliminary results
  without using a validation set to optimize hyperparameters,
  <monospace>astartes</monospace> also implements an
  <monospace>sklearn</monospace>-compatible
  <monospace>train_test_split</monospace> function.</p>
  <p>Second, it is crucial to evaluate model performance in both
  interpolation and extrapolation settings so future users are informed
  of any potential limitations. Although random splits are frequently
  used in the cheminformatics literature, this simply measures
  interpolation performance. However, given the vastness of chemical
  space
  (<xref alt="Ruddigkeit et al., 2012" rid="ref-ruddigkeit_GDB-17_2012" ref-type="bibr">Ruddigkeit
  et al., 2012</xref>) and its often unsmooth nature (e.g. activity
  cliffs), it seems unlikely that users will want to be restricted to
  exclusively operate in an interpolation regime. Thus, to encourage
  adoption of these models, it is crucial to measure performance on more
  challenging splits as well. The general workflow is: 1. Convert each
  molecule into a vector representation. 2. Cluster the molecules based
  on similarity. 3. Train the model on some clusters and then evaluate
  performance on unseen clusters that should be dissimilar to the
  clusters used for training. Although measuring performance on
  chemically dissimilar compounds/clusters is not a new concept
  (<xref alt="Bilodeau et al., 2023" rid="ref-bilodeau2023machine" ref-type="bibr">Bilodeau
  et al., 2023</xref>;
  <xref alt="Durdy et al., 2022" rid="ref-durdy2022random" ref-type="bibr">Durdy
  et al., 2022</xref>;
  <xref alt="Heinen et al., 2021" rid="ref-heinen2021toward" ref-type="bibr">Heinen
  et al., 2021</xref>;
  <xref alt="Jorner et al., 2021" rid="ref-jorner2021machine" ref-type="bibr">Jorner
  et al., 2021</xref>;
  <xref alt="Meredig et al., 2018" rid="ref-meredig2018can" ref-type="bibr">Meredig
  et al., 2018</xref>;
  <xref alt="Stuyver &amp; Coley, 2022" rid="ref-stuyver2022quantum" ref-type="bibr">Stuyver
  &amp; Coley, 2022</xref>;
  <xref alt="Terrones et al., 2023" rid="ref-terrones2023low" ref-type="bibr">Terrones
  et al., 2023</xref>;
  <xref alt="Tricarico et al., 2022" rid="ref-tricarico2022construction" ref-type="bibr">Tricarico
  et al., 2022</xref>), there are a myriad of choices for the first two
  steps; our software incorporates many popular representations and
  similarity metrics to give users freedom to easily explore which
  combination is suitable for their needs.</p>
</sec>
<sec id="example-use-case-in-cheminformatics">
  <title>Example Use-Case in Cheminformatics</title>
  <p>To demonstrate the difference in performance between interpolation
  and extrapolation, <monospace>astartes</monospace> is used to generate
  interpolative and extrapolative data splits for two relevant
  cheminformatics datasets. The impact of these data splits on model
  performance could be analyzed with any ML model. Here, we train a
  modified version of Chemprop
  (<xref alt="K. Yang et al., 2019" rid="ref-yang2019analyzing" ref-type="bibr">K.
  Yang et al., 2019</xref>)–a deep message passing neural network–to
  predict the regression targets of interest. We use the hyperparameters
  reported by Spiekermann et al.
  (<xref alt="2022a" rid="ref-spiekermann2022fast" ref-type="bibr">2022a</xref>)
  as implemented in the <monospace>barrier_prediction</monospace>
  branch, which is publicly available on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/kspieks/chemprop/tree/barrier_prediction">GitHub</ext-link>
  (<xref alt="Spiekermann, Pattanaik, et al., 2023" rid="ref-spiekermann_forked_chemprop" ref-type="bibr">Spiekermann,
  Pattanaik, et al., 2023</xref>). First is property prediction with QM9
  (<xref alt="Ramakrishnan et al., 2014" rid="ref-ramakrishnan2014quantum" ref-type="bibr">Ramakrishnan
  et al., 2014</xref>), a dataset containing approximately 133,000 small
  organic molecules, each containing 12 relevant chemical properties
  calculated at B3LYP/6-31G(2df,p). We train a multi-task model to
  predict all properties, with the arithmetic mean of all predictions
  tabulated below. Second is a single-task model to predict a reaction’s
  barrier height using the RDB7 dataset
  (<xref alt="Spiekermann et al., 2022b" rid="ref-spiekermann2022high" ref-type="bibr">Spiekermann
  et al., 2022b</xref>,
  <xref alt="2022c" rid="ref-spiekermann_zenodo_database" ref-type="bibr">2022c</xref>).
  This reaction database contains a diverse set of 12,000 organic
  reactions calculated at CCSD(T)-F12 that is relevant to the field of
  chemical kinetics.</p>
  <p>For each dataset, a typical interpolative split is generated using
  random sampling. We also create two extrapolative splits for
  comparison. The first uses the cheminformatics-specific Bemis-Murcko
  scaffold
  (<xref alt="Bemis &amp; Murcko, 1996" rid="ref-bemis1996properties" ref-type="bibr">Bemis
  &amp; Murcko, 1996</xref>) as calculated by RDKit
  (<xref alt="Landrum &amp; others, 2006" rid="ref-landrum2006rdkit" ref-type="bibr">Landrum
  &amp; others, 2006</xref>). The second uses the more general-purpose
  K-means clustering based on the Euclidean distance of Morgan (ECFP4)
  fingerprints using 2048 bit hashing and radius of 2
  (<xref alt="Morgan, 1965" rid="ref-morgan1965generation" ref-type="bibr">Morgan,
  1965</xref>;
  <xref alt="Rogers &amp; Hahn, 2010" rid="ref-rogers2010extended" ref-type="bibr">Rogers
  &amp; Hahn, 2010</xref>). The QM9 dataset and RDB7 datasets were
  organized into 100 and 20 clusters, respectively. For each split, we
  create 5 different folds (by changing the random seed) and report the
  mean <inline-formula><alternatives>
  <tex-math><![CDATA[\pm]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
  one standard deviation of the mean absolute error (MAE) and
  root-mean-squared error (RMSE).</p>
  <sec id="table-1-average-testing-errors-for-predicting-the-12-regression-targets-from-qm9-ramakrishnan2014quantum.">
    <title>Table 1: Average testing errors for predicting the 12
    regression targets from QM9
    (<xref alt="Ramakrishnan et al., 2014" rid="ref-ramakrishnan2014quantum" ref-type="bibr">Ramakrishnan
    et al., 2014</xref>).</title>
    <table-wrap>
      <table>
        <thead>
          <tr>
            <th>Split</th>
            <th>MAE</th>
            <th>RMSE</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Random</td>
            <td>2.02 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.06</td>
            <td>3.63 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.21</td>
          </tr>
          <tr>
            <td>Scaffold</td>
            <td>2.20 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.27</td>
            <td>3.46 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.49</td>
          </tr>
          <tr>
            <td>K-means</td>
            <td>2.48 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.33</td>
            <td>4.47 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.81</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec id="table-2-testing-errors-in-kcalmol-for-predicting-a-reactions-barrier-height-from-rdb7-spiekermann2022high.">
    <title>Table 2: Testing errors in kcal/mol for predicting a
    reaction’s barrier height from RDB7
    (<xref alt="Spiekermann et al., 2022b" rid="ref-spiekermann2022high" ref-type="bibr">Spiekermann
    et al., 2022b</xref>).</title>
    <table-wrap>
      <table>
        <thead>
          <tr>
            <th>Split</th>
            <th>MAE</th>
            <th>RMSE</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Random</td>
            <td>3.87 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.05</td>
            <td>6.81 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.28</td>
          </tr>
          <tr>
            <td>Scaffold</td>
            <td>6.28 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.43</td>
            <td>9.49 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            0.50</td>
          </tr>
          <tr>
            <td>K-means</td>
            <td>5.47 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            1.14</td>
            <td>8.77 <inline-formula><alternatives>
            <tex-math><![CDATA[\pm]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></inline-formula>
            1.85</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Table 1 and Table 2 show the expected trend in which the average
    testing errors are higher for the extrapolation tasks than they are
    for the interpolation task. The results from random splitting are
    informative if the model is primarily used in interpolation
    settings. However, these errors are likely unrealistically low if
    the model is intended to make predictions on new molecules that are
    chemically dissimilar to those in the training set. Performance is
    worse on the extrapolative data splits, which present a more
    challenging task, but these errors should be more representative of
    evaluating a new sample that is out-of-scope. Together, these tables
    demonstrate the utility of <monospace>astartes</monospace> in
    allowing users to better understand the likely performance of their
    model in different settings.</p>
    <p>Several approaches could be taken to further reduce the errors
    presented here. One could pre-train on additional data or fine-tune
    with experimental values. Ensembling is another established method
    to improve model predictions.</p>
  </sec>
</sec>
<sec id="related-software-and-code-availability">
  <title>Related Software and Code Availability</title>
  <p>In the machine learning space, <monospace>astartes</monospace>
  functions as a drop-in replacement for the ubiquitous
  <monospace>train_test_split</monospace> from scikit-learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikit-learn" ref-type="bibr">Pedregosa
  et al., 2011</xref>). Transitioning existing code to use this new
  methodology is as simple as running
  <monospace>pip install astartes</monospace>, modifying an
  <monospace>import</monospace> statement at the top of the file, and
  then specifying an additional keyword parameter.
  <monospace>astartes</monospace> has been especially designed to allow
  for maximum interoperability with other packages, using few
  dependencies, supporting all platforms, and validated support for
  Python 3.7 through 3.11. Specific tutorials on this transition are
  provided in the online documentation for
  <monospace>astartes</monospace>, which is available on
  <ext-link ext-link-type="uri" xlink:href="https://jacksonburns.github.io/astartes/sklearn_to_astartes.html">GitHub</ext-link>.</p>
  <p>Here is an example workflow using
  <monospace>train_test_split</monospace> taken from the
  <monospace>scikit-learn</monospace> documentation
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikit-learn" ref-type="bibr">Pedregosa
  et al., 2011</xref>):</p>
  <code language="python">import numpy as np
from sklearn.model_selection import train_test_split

X, y = np.arange(10).reshape((5, 2)), range(5)

X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.33, random_state=42)</code>
  <p>To switch to using <monospace>astartes</monospace>,
  <monospace>from sklearn.model_selection import train_test_split</monospace>
  becomes <monospace>from astartes import train_test_split</monospace>
  and the call to split the data is nearly identical and simple in the
  extensions that it provides:</p>
  <code language="python">import numpy as np
from astartes import train_test_split

X, y = np.arange(10).reshape((5, 2)), range(5)

X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.33, sampler=&quot;kmeans&quot;, random_state=42) </code>
  <p>With this small change, an extrapolative sampler based on k-means
  clustering will be used.</p>
  <p>Inside cheminformatics, <monospace>astartes</monospace> makes use
  of all molecular featurization options implemented in
  <monospace>AIMSim</monospace>
  (<xref alt="Bhattacharjee et al., 2023" rid="ref-aimsim_cpc" ref-type="bibr">Bhattacharjee
  et al., 2023</xref>), which includes those from virtually all popular
  descriptor generation tools used in the cheminformatics field.</p>
  <p>The codebase itself has a clearly defined contribution guideline
  and thorough, easily accessible documentation.
  <monospace>astartes</monospace> uses GitHub actions for Constant
  Integration testing including unit tests, functional tests, and
  regression tests. To emphasize the reliability and reproducibility of
  <monospace>astartes</monospace>, the data splits used to generate
  Table 1 and Table 2 are included in the regression tests. Test
  coverage currently sits at &gt;99%, and all proposed changes are
  subjected to a coverage check and merged only if they cover all
  existing and new lines added as well as satisfy the regression
  tests.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors thank all users who participated in beta testing and
  release candidate testing throughout the development of
  <monospace>astartes</monospace>. Authors Kevin Spiekermann and William
  Green gratefully acknowledge financial support from BASF under award
  number 88803720. Authors Jackson Burns and William Green gratefully
  acknowledge financial support from the U.S. Department of Energy,
  Office of Science, Office of Advanced Scientific Computing Research,
  Department of Energy Computational Science Graduate Fellowship under
  Award Number DE-SC0023112. Authors Himaghna Bhattacharjee and
  Dionisios Vlachos contribution was primarily supported by the National
  Science Foundation under Grant No. 2134471</p>
</sec>
<sec id="disclaimer">
  <title>Disclaimer</title>
  <p>This report was prepared as an account of work sponsored by an
  agency of the United States Government. Neither the United States
  Government nor any agency thereof, nor any of their employees, makes
  any warranty, express or implied, or assumes any legal liability or
  responsibility for the accuracy, completeness, or usefulness of any
  information, apparatus, product, or process disclosed, or represents
  that its use would not infringe privately owned rights. Reference
  herein to any specific commercial product, process, or service by
  trade name, trademark, manufacturer, or otherwise does not necessarily
  constitute or imply its endorsement, recommendation, or favoring by
  the United States Government or any agency thereof. The views and
  opinions of authors expressed herein do not necessarily state or
  reflect those of the United States Government or any agency
  thereof.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-scikit-learn">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
        <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
        <name><surname>Gramfort</surname><given-names>A.</given-names></name>
        <name><surname>Michel</surname><given-names>V.</given-names></name>
        <name><surname>Thirion</surname><given-names>B.</given-names></name>
        <name><surname>Grisel</surname><given-names>O.</given-names></name>
        <name><surname>Blondel</surname><given-names>M.</given-names></name>
        <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
        <name><surname>Weiss</surname><given-names>R.</given-names></name>
        <name><surname>Dubourg</surname><given-names>V.</given-names></name>
        <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
        <name><surname>Passos</surname><given-names>A.</given-names></name>
        <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
        <name><surname>Brucher</surname><given-names>M.</given-names></name>
        <name><surname>Perrot</surname><given-names>M.</given-names></name>
        <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
      </person-group>
      <article-title>Scikit-learn: Machine learning in Python</article-title>
      <source>Journal of Machine Learning Research</source>
      <year iso-8601-date="2011">2011</year>
      <volume>12</volume>
      <fpage>2825</fpage>
      <lpage>2830</lpage>
    </element-citation>
  </ref>
  <ref id="ref-geron2019hands">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Géron</surname><given-names>Aurélien</given-names></name>
      </person-group>
      <source>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-ramsundar2019deep">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Ramsundar</surname><given-names>Bharath</given-names></name>
        <name><surname>Eastman</surname><given-names>Peter</given-names></name>
        <name><surname>Walters</surname><given-names>Patrick</given-names></name>
        <name><surname>Pande</surname><given-names>Vijay</given-names></name>
      </person-group>
      <source>Deep learning for the life sciences: Applying deep learning to genomics, microscopy, drug discovery, and more</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2019">2019</year>
    </element-citation>
  </ref>
  <ref id="ref-lakshmanan2020machine">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Lakshmanan</surname><given-names>Valliappa</given-names></name>
        <name><surname>Robinson</surname><given-names>Sara</given-names></name>
        <name><surname>Munn</surname><given-names>Michael</given-names></name>
      </person-group>
      <source>Machine learning design patterns: Solutions to common challenges in data preparation, model building, and MLOps</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-huyen2022designing">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Huyen</surname><given-names>Chip</given-names></name>
      </person-group>
      <source>Designing machine learning systems: An iterative process for production-ready applications</source>
      <publisher-name>O’Reilly Media, Inc.</publisher-name>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-wang2020machine">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Anthony Yu-Tung</given-names></name>
        <name><surname>Murdock</surname><given-names>Ryan J.</given-names></name>
        <name><surname>Kauwe</surname><given-names>Steven K.</given-names></name>
        <name><surname>Oliynyk</surname><given-names>Anton O.</given-names></name>
        <name><surname>Gurlo</surname><given-names>Aleksander</given-names></name>
        <name><surname>Brgoch</surname><given-names>Jakoah</given-names></name>
        <name><surname>Persson</surname><given-names>Kristin A.</given-names></name>
        <name><surname>Sparks</surname><given-names>Taylor D.</given-names></name>
      </person-group>
      <article-title>Machine learning for materials scientists: An introductory guide toward best practices</article-title>
      <source>Chemistry of Materials</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>32</volume>
      <issue>12</issue>
      <pub-id pub-id-type="doi">10.1021/acs.chemmater.0c01907.s001</pub-id>
      <fpage>4954</fpage>
      <lpage>4965</lpage>
    </element-citation>
  </ref>
  <ref id="ref-spiekermann2023comment">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spiekermann</surname><given-names>Kevin A.</given-names></name>
        <name><surname>Stuyver</surname><given-names>Thijs</given-names></name>
        <name><surname>Pattanaik</surname><given-names>Lagnajit</given-names></name>
        <name><surname>Green</surname><given-names>William H.</given-names></name>
      </person-group>
      <article-title>Comment on ‘physics-based representations for machine learning properties of chemical reactions’</article-title>
      <source>Machine Learning: Science &amp; Technology</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>4</volume>
      <issue>4</issue>
      <fpage>048001</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-ramakrishnan2014quantum">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ramakrishnan</surname><given-names>Raghunathan</given-names></name>
        <name><surname>Dral</surname><given-names>Pavlo O.</given-names></name>
        <name><surname>Rupp</surname><given-names>Matthias</given-names></name>
        <name><surname>Lilienfeld</surname><given-names>O. Anatole von</given-names></name>
      </person-group>
      <article-title>Quantum Chemistry Structures and Properties of 134 Kilo Molecules</article-title>
      <source>Scientific Data</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2014">2014</year>
      <volume>1</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1038/sdata.2014.22</pub-id>
      <fpage>1</fpage>
      <lpage>7</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ruddigkeit_GDB-17_2012">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Ruddigkeit</surname><given-names>Lars</given-names></name>
        <name><surname>Van Deursen</surname><given-names>Ruud</given-names></name>
        <name><surname>Blum</surname><given-names>Lorenz C.</given-names></name>
        <name><surname>Reymond</surname><given-names>Jean-Louis</given-names></name>
      </person-group>
      <article-title>Enumeration of 166 Billion Organic Small Molecules in the Chemical Universe Database GDB-17</article-title>
      <source>Journal of Chemical Information and Modeling</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2012">2012</year>
      <volume>52</volume>
      <issue>11</issue>
      <pub-id pub-id-type="doi">10.1021/ci300415d</pub-id>
      <fpage>2864</fpage>
      <lpage>2875</lpage>
    </element-citation>
  </ref>
  <ref id="ref-spiekermann2022high">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spiekermann</surname><given-names>Kevin A.</given-names></name>
        <name><surname>Pattanaik</surname><given-names>Lagnajit</given-names></name>
        <name><surname>Green</surname><given-names>William H.</given-names></name>
      </person-group>
      <article-title>High Accuracy Barrier Heights, Enthalpies, and Rate Coefficients for Chemical Reactions</article-title>
      <source>Scientific Data</source>
      <publisher-name>Nature Publishing Group</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>9</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1038/s41597-022-01529-6</pub-id>
      <fpage>1</fpage>
      <lpage>12</lpage>
    </element-citation>
  </ref>
  <ref id="ref-spiekermann_zenodo_database">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Spiekermann</surname><given-names>Kevin A.</given-names></name>
        <name><surname>Pattanaik</surname><given-names>Lagnajit</given-names></name>
        <name><surname>Green</surname><given-names>William H.</given-names></name>
      </person-group>
      <article-title>High accuracy barrier heights, enthalpies, and rate coefficients for chemical reactions</article-title>
      <publisher-name>Zenodo</publisher-name>
      <year iso-8601-date="2022-04">2022</year><month>04</month>
      <uri>https://zenodo.org/record/6618262#.YyXlICHMI0Q</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.6618262</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-spiekermann2022fast">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Spiekermann</surname><given-names>Kevin A.</given-names></name>
        <name><surname>Pattanaik</surname><given-names>Lagnajit</given-names></name>
        <name><surname>Green</surname><given-names>William H.</given-names></name>
      </person-group>
      <article-title>Fast predictions of reaction barrier heights: Toward coupled-cluster accuracy</article-title>
      <source>The Journal of Physical Chemistry A</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>126</volume>
      <issue>25</issue>
      <pub-id pub-id-type="doi">10.1021/acs.jpca.2c02614</pub-id>
      <fpage>3976</fpage>
      <lpage>3986</lpage>
    </element-citation>
  </ref>
  <ref id="ref-spiekermann_forked_chemprop">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Spiekermann</surname><given-names>Kevin A.</given-names></name>
        <name><surname>Pattanaik</surname><given-names>Lagnajit</given-names></name>
        <name><surname>Green</surname><given-names>William H.</given-names></name>
        <name><surname>Yang</surname><given-names>Kevin</given-names></name>
        <name><surname>Swanson</surname><given-names>Kyle</given-names></name>
        <name><surname>Jin</surname><given-names>Wengong</given-names></name>
        <name><surname>Coley</surname><given-names>Connor</given-names></name>
        <name><surname>Eiden</surname><given-names>Philipp</given-names></name>
        <name><surname>Gao</surname><given-names>Hua</given-names></name>
        <name><surname>Guzman-Perez</surname><given-names>Angel</given-names></name>
        <name><surname>Hopper</surname><given-names>Timothy</given-names></name>
        <name><surname>Kelley</surname><given-names>Brian</given-names></name>
        <name><surname>Mathea</surname><given-names>Miriam</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <year iso-8601-date="2023-02">2023</year><month>02</month>
      <uri>https://github.com/kspieks/chemprop/tree/barrier_prediction</uri>
    </element-citation>
  </ref>
  <ref id="ref-yang2019concepts">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yang</surname><given-names>Xin</given-names></name>
        <name><surname>Wang</surname><given-names>Yifei</given-names></name>
        <name><surname>Byrne</surname><given-names>Ryan</given-names></name>
        <name><surname>Schneider</surname><given-names>Gisbert</given-names></name>
        <name><surname>Yang</surname><given-names>Shengyong</given-names></name>
      </person-group>
      <article-title>Concepts of artificial intelligence for computer-assisted drug discovery</article-title>
      <source>Chemical Reviews</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>119</volume>
      <issue>18</issue>
      <fpage>10520</fpage>
      <lpage>10594</lpage>
    </element-citation>
  </ref>
  <ref id="ref-bannigan2021machine">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bannigan</surname><given-names>Pauric</given-names></name>
        <name><surname>Aldeghi</surname><given-names>Matteo</given-names></name>
        <name><surname>Bao</surname><given-names>Zeqing</given-names></name>
        <name><surname>Häse</surname><given-names>Florian</given-names></name>
        <name><surname>Aspuru-Guzik</surname><given-names>Alan</given-names></name>
        <name><surname>Allen</surname><given-names>Christine</given-names></name>
      </person-group>
      <article-title>Machine learning directed drug formulation development</article-title>
      <source>Advanced Drug Delivery Reviews</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>175</volume>
      <fpage>113806</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jha2023learning">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jha</surname><given-names>Swarn</given-names></name>
        <name><surname>Yen</surname><given-names>Matthew</given-names></name>
        <name><surname>Salinas</surname><given-names>Yazmin</given-names></name>
        <name><surname>Palmer</surname><given-names>Evan</given-names></name>
        <name><surname>Villafuerte</surname><given-names>John</given-names></name>
        <name><surname>Liang</surname><given-names>Hong</given-names></name>
      </person-group>
      <article-title>Learning-assisted materials development and device management in batteries and supercapacitors: Performance comparison and challenges</article-title>
      <source>Journal of Materials Chemistry A</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>11</volume>
      <fpage>3904</fpage>
      <lpage>3936</lpage>
    </element-citation>
  </ref>
  <ref id="ref-komp2022progress">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Komp</surname><given-names>Evan</given-names></name>
        <name><surname>Janulaitis</surname><given-names>Nida</given-names></name>
        <name><surname>Valleau</surname><given-names>Stéphanie</given-names></name>
      </person-group>
      <article-title>Progress Towards Machine Learning Reaction Rate Constants</article-title>
      <source>Physical Chemistry Chemical Physics</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>24</volume>
      <pub-id pub-id-type="doi">10.1039/d1cp04422b</pub-id>
      <fpage>2692</fpage>
      <lpage>2705</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wei2019machine">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wei</surname><given-names>Jing</given-names></name>
        <name><surname>Chu</surname><given-names>Xuan</given-names></name>
        <name><surname>Sun</surname><given-names>Xiang-Yu</given-names></name>
        <name><surname>Xu</surname><given-names>Kun</given-names></name>
        <name><surname>Deng</surname><given-names>Hui-Xiong</given-names></name>
        <name><surname>Chen</surname><given-names>Jigen</given-names></name>
        <name><surname>Wei</surname><given-names>Zhongming</given-names></name>
        <name><surname>Lei</surname><given-names>Ming</given-names></name>
      </person-group>
      <article-title>Machine learning in materials science</article-title>
      <source>InfoMat</source>
      <publisher-name>Wiley Online Library</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>1</volume>
      <issue>3</issue>
      <fpage>338</fpage>
      <lpage>358</lpage>
    </element-citation>
  </ref>
  <ref id="ref-meredig2018can">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Meredig</surname><given-names>Bryce</given-names></name>
        <name><surname>Antono</surname><given-names>Erin</given-names></name>
        <name><surname>Church</surname><given-names>Carena</given-names></name>
        <name><surname>Hutchinson</surname><given-names>Maxwell</given-names></name>
        <name><surname>Ling</surname><given-names>Julia</given-names></name>
        <name><surname>Paradiso</surname><given-names>Sean</given-names></name>
        <name><surname>Blaiszik</surname><given-names>Ben</given-names></name>
        <name><surname>Foster</surname><given-names>Ian</given-names></name>
        <name><surname>Gibbons</surname><given-names>Brenna</given-names></name>
        <name><surname>Hattrick-Simpers</surname><given-names>Jason</given-names></name>
        <name><surname>Mehta</surname><given-names>Apurva</given-names></name>
        <name><surname>Ward</surname><given-names>Logan</given-names></name>
      </person-group>
      <article-title>Can machine learning identify the next high-temperature superconductor? Examining extrapolation performance for materials discovery</article-title>
      <source>Molecular Systems Design &amp; Engineering</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>3</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1039/d1cp04422b</pub-id>
      <fpage>819</fpage>
      <lpage>825</lpage>
    </element-citation>
  </ref>
  <ref id="ref-durdy2022random">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Durdy</surname><given-names>Samantha</given-names></name>
        <name><surname>Gaultois</surname><given-names>Michael W.</given-names></name>
        <name><surname>Gusev</surname><given-names>Vladimir V.</given-names></name>
        <name><surname>Bollegala</surname><given-names>Danushka</given-names></name>
        <name><surname>Rosseinsky</surname><given-names>Matthew J.</given-names></name>
      </person-group>
      <article-title>Random projections and kernelised leave one cluster out cross validation: Universal baselines and evaluation tools for supervised machine learning of material properties</article-title>
      <source>Digital Discovery</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>1</volume>
      <pub-id pub-id-type="doi">10.1039/d2dd00039c</pub-id>
      <fpage>763</fpage>
      <lpage>778</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tricarico2022construction">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tricarico</surname><given-names>Giovanni A.</given-names></name>
        <name><surname>Hofmans</surname><given-names>Johan</given-names></name>
        <name><surname>Lenselink</surname><given-names>Eelke B.</given-names></name>
        <name><surname>Ramos</surname><given-names>Miriam López</given-names></name>
        <name><surname>Dréanic</surname><given-names>Marie-Pierre</given-names></name>
        <name><surname>Stouten</surname><given-names>Pieter FW</given-names></name>
      </person-group>
      <article-title>Construction of balanced, chemically dissimilar training, validation and test sets for machine learning on molecular datasets</article-title>
      <source>10.26434/chemrxiv-2022-m8l33</source>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.26434/chemrxiv-2022-m8l33-v2</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-terrones2023low">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Terrones</surname><given-names>Gianmarco G.</given-names></name>
        <name><surname>Duan</surname><given-names>Chenru</given-names></name>
        <name><surname>Nandy</surname><given-names>Aditya</given-names></name>
        <name><surname>Kulik</surname><given-names>Heather J.</given-names></name>
      </person-group>
      <article-title>Low-cost machine learning prediction of excited state properties of iridium-centered phosphors</article-title>
      <source>Chemical Science</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <volume>14</volume>
      <pub-id pub-id-type="doi">10.1039/d2sc06150c</pub-id>
      <fpage>1419</fpage>
      <lpage>1433</lpage>
    </element-citation>
  </ref>
  <ref id="ref-stuyver2022quantum">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Stuyver</surname><given-names>Thijs</given-names></name>
        <name><surname>Coley</surname><given-names>Connor W.</given-names></name>
      </person-group>
      <article-title>Quantum Chemistry-Augmented Neural Networks for Reactivity Prediction: Performance, Generalizability, and Explainability</article-title>
      <source>The Journal of Chemical Physics</source>
      <publisher-name>AIP Publishing LLC</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <volume>156</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1063/5.0079574</pub-id>
      <fpage>084104</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-heinen2021toward">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Heinen</surname><given-names>Stefan</given-names></name>
        <name><surname>Rudorff</surname><given-names>Guido Falk von</given-names></name>
        <name><surname>Lilienfeld</surname><given-names>O. Anatole von</given-names></name>
      </person-group>
      <article-title>Toward the Design of Chemical Reactions: Machine Learning Barriers of Competing Mechanisms in Reactant Space</article-title>
      <source>J. Chem. Phys.</source>
      <publisher-name>AIP Publishing LLC</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>155</volume>
      <issue>6</issue>
      <pub-id pub-id-type="doi">10.1063/5.0059742</pub-id>
      <fpage>064105</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-bilodeau2023machine">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bilodeau</surname><given-names>Camille</given-names></name>
        <name><surname>Kazakov</surname><given-names>Andrei</given-names></name>
        <name><surname>Mukhopadhyay</surname><given-names>Sukrit</given-names></name>
        <name><surname>Emerson</surname><given-names>Jillian</given-names></name>
        <name><surname>Kalantar</surname><given-names>Tom</given-names></name>
        <name><surname>Muzny</surname><given-names>Chris</given-names></name>
        <name><surname>Jensen</surname><given-names>Klavs</given-names></name>
      </person-group>
      <article-title>Machine learning for predicting the viscosity of binary liquid mixtures</article-title>
      <source>Chem. Eng. J.</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.2139/ssrn.4289793</pub-id>
      <fpage>142454</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-jorner2021machine">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jorner</surname><given-names>Kjell</given-names></name>
        <name><surname>Brinck</surname><given-names>Tore</given-names></name>
        <name><surname>Norrby</surname><given-names>Per-Ola</given-names></name>
        <name><surname>Buttar</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>Machine Learning Meets Mechanistic Modelling for Accurate Prediction of Experimental Activation Energies</article-title>
      <source>Chem. Sci.</source>
      <publisher-name>Royal Society of Chemistry</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>12</volume>
      <issue>3</issue>
      <pub-id pub-id-type="doi">10.26434/chemrxiv.12758498</pub-id>
      <fpage>1163</fpage>
      <lpage>1175</lpage>
    </element-citation>
  </ref>
  <ref id="ref-landrum2006rdkit">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Landrum</surname><given-names>Greg</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>RDKit: Open-Source Cheminformatics</article-title>
      <year iso-8601-date="2006">2006</year>
      <uri>https://www.rdkit.org</uri>
    </element-citation>
  </ref>
  <ref id="ref-bemis1996properties">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bemis</surname><given-names>Guy W.</given-names></name>
        <name><surname>Murcko</surname><given-names>Mark A.</given-names></name>
      </person-group>
      <article-title>The Properties of Known Drugs. 1. Molecular Frameworks</article-title>
      <source>Journal of Medicinal Chemistry</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="1996">1996</year>
      <volume>39</volume>
      <issue>15</issue>
      <pub-id pub-id-type="doi">10.1021/jm9602928</pub-id>
      <fpage>2887</fpage>
      <lpage>2893</lpage>
    </element-citation>
  </ref>
  <ref id="ref-morgan1965generation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Morgan</surname><given-names>Harry L.</given-names></name>
      </person-group>
      <article-title>The generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service</article-title>
      <source>Journal of Chemical Documentation</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="1965">1965</year>
      <volume>5</volume>
      <issue>2</issue>
      <pub-id pub-id-type="doi">10.1021/c160017a018</pub-id>
      <fpage>107</fpage>
      <lpage>113</lpage>
    </element-citation>
  </ref>
  <ref id="ref-rogers2010extended">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Rogers</surname><given-names>David</given-names></name>
        <name><surname>Hahn</surname><given-names>Mathew</given-names></name>
      </person-group>
      <article-title>Extended-connectivity fingerprints</article-title>
      <source>Journal of Chemical Information and Modeling</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2010">2010</year>
      <volume>50</volume>
      <issue>5</issue>
      <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
      <fpage>742</fpage>
      <lpage>754</lpage>
    </element-citation>
  </ref>
  <ref id="ref-yang2019analyzing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Yang</surname><given-names>Kevin</given-names></name>
        <name><surname>Swanson</surname><given-names>Kyle</given-names></name>
        <name><surname>Jin</surname><given-names>Wengong</given-names></name>
        <name><surname>Coley</surname><given-names>Connor</given-names></name>
        <name><surname>Eiden</surname><given-names>Philipp</given-names></name>
        <name><surname>Gao</surname><given-names>Hua</given-names></name>
        <name><surname>Guzman-Perez</surname><given-names>Angel</given-names></name>
        <name><surname>Hopper</surname><given-names>Timothy</given-names></name>
        <name><surname>Kelley</surname><given-names>Brian</given-names></name>
        <name><surname>Mathea</surname><given-names>Miriam</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Analyzing Learned Molecular Representations for Property Prediction</article-title>
      <source>Journal of Chemical Information and Modeling</source>
      <publisher-name>ACS Publications</publisher-name>
      <year iso-8601-date="2019">2019</year>
      <volume>59</volume>
      <issue>8</issue>
      <pub-id pub-id-type="doi">10.1021/acs.jcim.9b00237.s001</pub-id>
      <fpage>3370</fpage>
      <lpage>3388</lpage>
    </element-citation>
  </ref>
  <ref id="ref-aimsim_cpc">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bhattacharjee</surname><given-names>Himaghna</given-names></name>
        <name><surname>Burns</surname><given-names>Jackson</given-names></name>
        <name><surname>Vlachos</surname><given-names>Dionisios G.</given-names></name>
      </person-group>
      <article-title>AIMSim: An accessible cheminformatics platform for similarity operations on chemicals datasets</article-title>
      <source>Computer Physics Communications</source>
      <year iso-8601-date="2023">2023</year>
      <volume>283</volume>
      <issn>0010-4655</issn>
      <uri>https://www.sciencedirect.com/science/article/pii/S0010465522002983</uri>
      <pub-id pub-id-type="doi">10.1016/j.cpc.2022.108579</pub-id>
      <fpage>108579</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
