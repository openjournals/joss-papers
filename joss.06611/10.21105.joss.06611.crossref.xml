<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/5.3.1"
           xmlns:ai="http://www.crossref.org/AccessIndicators.xsd"
           xmlns:rel="http://www.crossref.org/relations.xsd"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           version="5.3.1"
           xsi:schemaLocation="http://www.crossref.org/schema/5.3.1 http://www.crossref.org/schemas/crossref5.3.1.xsd">
  <head>
    <doi_batch_id>20240621174942-d2632446a6226ab81fae5176ae14073a4818a1db</doi_batch_id>
    <timestamp>20240621174942</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>https://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>06</month>
          <year>2024</year>
        </publication_date>
        <journal_volume>
          <volume>9</volume>
        </journal_volume>
        <issue>98</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>CBX: Python and Julia Packages for Consensus-Based
Interacting Particle Methods</title>
        </titles>
        <contributors>
          <person_name sequence="first" contributor_role="author">
            <given_name>Rafael</given_name>
            <surname>Bailo</surname>
            <ORCID>https://orcid.org/0000-0001-8018-3799</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Alethea</given_name>
            <surname>Barbaro</surname>
            <ORCID>https://orcid.org/0000-0001-9856-2818</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Susana N.</given_name>
            <surname>Gomes</surname>
            <ORCID>https://orcid.org/0000-0002-8731-367X</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Konstantin</given_name>
            <surname>Riedl</surname>
            <ORCID>https://orcid.org/0000-0002-2206-4334</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Tim</given_name>
            <surname>Roith</surname>
            <ORCID>https://orcid.org/0000-0001-8440-2928</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Claudia</given_name>
            <surname>Totzeck</surname>
            <ORCID>https://orcid.org/0000-0001-6283-7154</ORCID>
          </person_name>
          <person_name sequence="additional"
                       contributor_role="author">
            <given_name>Urbain</given_name>
            <surname>Vaes</surname>
            <ORCID>https://orcid.org/0000-0002-7629-7184</ORCID>
          </person_name>
        </contributors>
        <publication_date>
          <month>06</month>
          <day>21</day>
          <year>2024</year>
        </publication_date>
        <pages>
          <first_page>6611</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.06611</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">10.5281/zenodo.12207224</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/6611</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.06611</doi>
          <resource>https://joss.theoj.org/papers/10.21105/joss.06611</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">https://joss.theoj.org/papers/10.21105/joss.06611.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list>
          <citation key="boltzmann1868studien">
            <article_title>Studien über das Gleichgewicht der lebendigen
Kraft zwischen bewegten materiellen Punkten</article_title>
            <author>Boltzmann</author>
            <journal_title>Wiener Berichte</journal_title>
            <volume>58</volume>
            <cYear>1868</cYear>
            <unstructured_citation>Boltzmann, L. (1868). Studien über
das Gleichgewicht der lebendigen Kraft zwischen bewegten materiellen
Punkten. Wiener Berichte, 58, 517–560.</unstructured_citation>
          </citation>
          <citation key="bayraktar2013wind">
            <article_title>The wind driven optimization technique and
its application in electromagnetics</article_title>
            <author>Bayraktar</author>
            <journal_title>IEEE transactions on antennas and
propagation</journal_title>
            <issue>5</issue>
            <volume>61</volume>
            <doi>10.1109/TAP.2013.2238654</doi>
            <cYear>2013</cYear>
            <unstructured_citation>Bayraktar, Z., Komurcu, M., Bossard,
J. A., &amp; Werner, D. H. (2013). The wind driven optimization
technique and its application in electromagnetics. IEEE Transactions on
Antennas and Propagation, 61(5), 2745–2757.
https://doi.org/10.1109/TAP.2013.2238654</unstructured_citation>
          </citation>
          <citation key="hansen2019pycma">
            <article_title>CMA-ES/pycma on GitHub</article_title>
            <author>Hansen</author>
            <doi>10.5281/zenodo.2559634</doi>
            <cYear>2019</cYear>
            <unstructured_citation>Hansen, N., Akimoto, Y., &amp;
Baudis, P. (2019). CMA-ES/pycma on GitHub. Zenodo,
DOI:10.5281/zenodo.2559634.
https://doi.org/10.5281/zenodo.2559634</unstructured_citation>
          </citation>
          <citation key="hansen1996adapting">
            <article_title>Adapting arbitrary normal mutation
distributions in evolution strategies: The covariance matrix
adaptation</article_title>
            <author>Hansen</author>
            <journal_title>Proceedings of IEEE international conference
on evolutionary computation</journal_title>
            <doi>10.1109/ICEC.1996.542381</doi>
            <cYear>1996</cYear>
            <unstructured_citation>Hansen, N., &amp; Ostermeier, A.
(1996). Adapting arbitrary normal mutation distributions in evolution
strategies: The covariance matrix adaptation. Proceedings of IEEE
International Conference on Evolutionary Computation, 312–317.
https://doi.org/10.1109/ICEC.1996.542381</unstructured_citation>
          </citation>
          <citation key="colutto2009cma">
            <article_title>The CMA-ES on Riemannian manifolds to
reconstruct shapes in 3-d voxel images</article_title>
            <author>Colutto</author>
            <journal_title>IEEE Transactions on Evolutionary
Computation</journal_title>
            <issue>2</issue>
            <volume>14</volume>
            <doi>10.1109/TEVC.2009.2029567</doi>
            <cYear>2009</cYear>
            <unstructured_citation>Colutto, S., Fruhauf, F., Fuchs, M.,
&amp; Scherzer, O. (2009). The CMA-ES on Riemannian manifolds to
reconstruct shapes in 3-d voxel images. IEEE Transactions on
Evolutionary Computation, 14(2), 227–245.
https://doi.org/10.1109/TEVC.2009.2029567</unstructured_citation>
          </citation>
          <citation key="kennedy1995particle">
            <article_title>Particle swarm optimization</article_title>
            <author>Kennedy</author>
            <journal_title>Proceedings of ICNN’95-international
conference on neural networks</journal_title>
            <volume>4</volume>
            <doi>10.1109/ICNN.1995.488968</doi>
            <cYear>1995</cYear>
            <unstructured_citation>Kennedy, J., &amp; Eberhart, R.
(1995). Particle swarm optimization. Proceedings of
ICNN’95-International Conference on Neural Networks, 4, 1942–1948.
https://doi.org/10.1109/ICNN.1995.488968</unstructured_citation>
          </citation>
          <citation key="henderson2003theory">
            <article_title>The theory and practice of simulated
annealing</article_title>
            <author>Henderson</author>
            <journal_title>Handbook of metaheuristics</journal_title>
            <doi>10.1007/0-306-48056-5_10</doi>
            <cYear>2003</cYear>
            <unstructured_citation>Henderson, D., Jacobson, S. H., &amp;
Johnson, A. W. (2003). The theory and practice of simulated annealing.
Handbook of Metaheuristics, 287–319.
https://doi.org/10.1007/0-306-48056-5_10</unstructured_citation>
          </citation>
          <citation key="rastrigin1963convergence">
            <article_title>The convergence of the random search method
in the extremal control of a many parameter system</article_title>
            <author>Rastrigin</author>
            <journal_title>Automaton &amp; Remote
Control</journal_title>
            <volume>24</volume>
            <cYear>1963</cYear>
            <unstructured_citation>Rastrigin, L. (1963). The convergence
of the random search method in the extremal control of a many parameter
system. Automaton &amp; Remote Control, 24,
1337–1342.</unstructured_citation>
          </citation>
          <citation key="friedman1947planning">
            <article_title>Planning experiments seeking
maxima</article_title>
            <author>Friedman</author>
            <journal_title>Techniques of statistical
analysis</journal_title>
            <cYear>1947</cYear>
            <unstructured_citation>Friedman, M., &amp; Savage, L. J.
(1947). Planning experiments seeking maxima. Techniques of Statistical
Analysis, 365–372.</unstructured_citation>
          </citation>
          <citation key="hooke1961direct">
            <article_title>“Direct search” solution of numerical and
statistical problems</article_title>
            <author>Hooke</author>
            <journal_title>Journal of the ACM (JACM)</journal_title>
            <issue>2</issue>
            <volume>8</volume>
            <doi>10.1145/321062.321069</doi>
            <cYear>1961</cYear>
            <unstructured_citation>Hooke, R., &amp; Jeeves, T. A.
(1961). “Direct search” solution of numerical and statistical problems.
Journal of the ACM (JACM), 8(2), 212–229.
https://doi.org/10.1145/321062.321069</unstructured_citation>
          </citation>
          <citation key="fornasier2021consensus">
            <article_title>Consensus-based optimization methods converge
globally</article_title>
            <author>Fornasier</author>
            <doi>10.48550/arXiv.2103.15130</doi>
            <cYear>2021</cYear>
            <unstructured_citation>Fornasier, M., Klock, T., &amp;
Riedl, K. (2021). Consensus-based optimization methods converge
globally.
https://doi.org/10.48550/arXiv.2103.15130</unstructured_citation>
          </citation>
          <citation key="carrillo2022consensus">
            <article_title>Consensus-based sampling</article_title>
            <author>Carrillo</author>
            <journal_title>Studies in Applied
Mathematics</journal_title>
            <issue>3</issue>
            <volume>148</volume>
            <doi>10.1111/sapm.12470</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Carrillo, J. A., Hoffmann, F.,
Stuart, A. M., &amp; Vaes, U. (2022). Consensus-based sampling. Studies
in Applied Mathematics, 148(3), 1069–1140.
https://doi.org/10.1111/sapm.12470</unstructured_citation>
          </citation>
          <citation key="harris2020array">
            <article_title>Array programming with NumPy</article_title>
            <author>Harris</author>
            <journal_title>Nature</journal_title>
            <issue>7825</issue>
            <volume>585</volume>
            <doi>10.1038/s41586-020-2649-2</doi>
            <cYear>2020</cYear>
            <unstructured_citation>Harris, C. R., Millman, K. J., Walt,
S. J. van der, Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E.,
Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S.,
Kerkwijk, M. H. van, Brett, M., Haldane, A., Río, J. F. del, Wiebe, M.,
Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy.
Nature, 585(7825), 357–362.
https://doi.org/10.1038/s41586-020-2649-2</unstructured_citation>
          </citation>
          <citation key="gpyopt2016">
            <article_title>GPyOpt: A Bayesian optimization framework in
Python</article_title>
            <author>The GPyOpt authors</author>
            <cYear>2016</cYear>
            <unstructured_citation>The GPyOpt authors. (2016). GPyOpt: A
Bayesian optimization framework in Python.
http://github.com/SheffieldML/GPyOpt.</unstructured_citation>
          </citation>
          <citation key="balandat2020botorch">
            <article_title>BoTorch: A framework for efficient
Monte-Carlo Bayesian optimization</article_title>
            <author>Balandat</author>
            <journal_title>Advances in neural information processing
systems 33</journal_title>
            <cYear>2020</cYear>
            <unstructured_citation>Balandat, M., Karrer, B., Jiang, D.
R., Daulton, S., Letham, B., Wilson, A. G., &amp; Bakshy, E. (2020).
BoTorch: A framework for efficient Monte-Carlo Bayesian optimization.
Advances in Neural Information Processing Systems 33.
http://arxiv.org/abs/1910.06403</unstructured_citation>
          </citation>
          <citation key="GPflowOpt2017">
            <article_title>GPflowOpt: A Bayesian Optimization Library
using TensorFlow</article_title>
            <author>Knudde</author>
            <doi>10.48550/arXiv.1711.03845</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Knudde, N., van der Herten, J.,
Dhaene, T., &amp; Couckuyt, I. (2017). GPflowOpt: A Bayesian
Optimization Library using TensorFlow.
https://doi.org/10.48550/arXiv.1711.03845</unstructured_citation>
          </citation>
          <citation key="Jiménez2017">
            <article_title>pyGPGO: Bayesian optimization for
Python</article_title>
            <author>Jiménez</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>19</issue>
            <volume>2</volume>
            <doi>10.21105/joss.00431</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Jiménez, J., &amp; Ginebra, J.
(2017). pyGPGO: Bayesian optimization for Python. Journal of Open Source
Software, 2(19), 431.
https://doi.org/10.21105/joss.00431</unstructured_citation>
          </citation>
          <citation key="Bayesian14">
            <article_title>Bayesian Optimization: Open source
constrained global optimization tool for Python</article_title>
            <author>Nogueira</author>
            <unstructured_citation>Nogueira, F. (2014–). Bayesian
Optimization: Open source constrained global optimization tool for
Python.https://github.com/bayesian-optimization/BayesianOptimization</unstructured_citation>
          </citation>
          <citation key="scikitopt">
            <article_title>scikit-opt</article_title>
            <author>Guo</author>
            <cYear>2021</cYear>
            <unstructured_citation>Guo, F. (2021). scikit-opt.
https://github.com/guofei9987/scikit-opt</unstructured_citation>
          </citation>
          <citation key="Kim2023">
            <article_title>BayesO: A Bayesian optimization framework in
Python</article_title>
            <author>Kim</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>90</issue>
            <volume>8</volume>
            <doi>10.21105/joss.05320</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Kim, J., &amp; Choi, S. (2023).
BayesO: A Bayesian optimization framework in Python. Journal of Open
Source Software, 8(90), 5320.
https://doi.org/10.21105/joss.05320</unstructured_citation>
          </citation>
          <citation key="deapJMLR2012">
            <article_title>DEAP: Evolutionary algorithms made
easy</article_title>
            <author>Fortin</author>
            <journal_title>Journal of Machine Learning
Research</journal_title>
            <volume>13</volume>
            <cYear>2012</cYear>
            <unstructured_citation>Fortin, F.-A., De Rainville, F.-M.,
Gardner, M.-A., Parizeau, M., &amp; Gagné, C. (2012). DEAP: Evolutionary
algorithms made easy. Journal of Machine Learning Research, 13,
2171–2175.</unstructured_citation>
          </citation>
          <citation key="pagmo2017">
            <article_title>Esa/pagmo2: Pagmo 2.6</article_title>
            <author>Biscani</author>
            <doi>10.5281/zenodo.1054110</doi>
            <cYear>2017</cYear>
            <unstructured_citation>Biscani, F., Izzo, D., &amp; Märtens,
M. (2017). Esa/pagmo2: Pagmo 2.6.
https://doi.org/10.5281/zenodo.1054110</unstructured_citation>
          </citation>
          <citation key="Igor_CBOinPython">
            <article_title>CBO-in-python</article_title>
            <author>Tukh</author>
            <cYear>2022</cYear>
            <unstructured_citation>Tukh, I., &amp; Riedl, K. (2022).
CBO-in-python (Version 1.0).
https://github.com/Igor-Tukh/cbo-in-python</unstructured_citation>
          </citation>
          <citation key="Roith_polarcbo">
            <article_title>polarcbo</article_title>
            <author>Roith</author>
            <cYear>2023</cYear>
            <unstructured_citation>Roith, T., Bungert, L., &amp; Wacker,
P. (2023). polarcbo (Version 1.0.1).
https://github.com/PdIPS/polarcbo</unstructured_citation>
          </citation>
          <citation key="duan2023pypop7">
            <article_title>PyPop7: A pure-Python library for
population-based black-box optimization</article_title>
            <author>Duan</author>
            <doi>10.48550/arXiv.2212.05652</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Duan, Q., Zhou, G., Shao, C., Wang,
Z., Feng, M., Yang, Y., Zhao, Q., &amp; Shi, Y. (2022). PyPop7: A
pure-Python library for population-based black-box optimization.
https://doi.org/10.48550/arXiv.2212.05652</unstructured_citation>
          </citation>
          <citation key="bungert2022polarized">
            <article_title>Polarized consensus-based dynamics for
optimization and sampling</article_title>
            <author>Bungert</author>
            <journal_title>Math. Program.</journal_title>
            <doi>10.1007/s10107-024-02095-y</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Bungert, L., Roith, T., &amp; Wacker,
P. (2024). Polarized consensus-based dynamics for optimization and
sampling. Math. Program.
https://doi.org/10.1007/s10107-024-02095-y</unstructured_citation>
          </citation>
          <citation key="Bergmann2022">
            <article_title>Manopt.jl: Optimization on manifolds in
Julia</article_title>
            <author>Bergmann</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>70</issue>
            <volume>7</volume>
            <doi>10.21105/joss.03866</doi>
            <cYear>2022</cYear>
            <unstructured_citation>Bergmann, R. (2022). Manopt.jl:
Optimization on manifolds in Julia. Journal of Open Source Software,
7(70), 3866. https://doi.org/10.21105/joss.03866</unstructured_citation>
          </citation>
          <citation key="Bailo_consensus">
            <article_title>Consensus.jl</article_title>
            <author>Bailo</author>
            <doi>10.5281/zenodo.7754236</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Bailo, R. (2023). Consensus.jl
(Version 1.0.0).
https://doi.org/10.5281/zenodo.7754236</unstructured_citation>
          </citation>
          <citation key="Singh2024">
            <article_title>PyBADS: Fast and robust black-box
optimization in Python</article_title>
            <author>Singh</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>94</issue>
            <volume>9</volume>
            <doi>10.21105/joss.05694</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Singh, G. S., &amp; Acerbi, L.
(2024). PyBADS: Fast and robust black-box optimization in Python.
Journal of Open Source Software, 9(94), 5694.
https://doi.org/10.21105/joss.05694</unstructured_citation>
          </citation>
          <citation key="carrillo2018analytical">
            <article_title>An analytical framework for consensus-based
global optimization method</article_title>
            <author>Carrillo</author>
            <journal_title>Mathematical Models and Methods in Applied
Sciences</journal_title>
            <issue>6</issue>
            <volume>28</volume>
            <doi>10.1142/S0218202518500276</doi>
            <issn>0218-2025</issn>
            <cYear>2018</cYear>
            <unstructured_citation>Carrillo, J. A., Choi, Y.-P.,
Totzeck, C., &amp; Tse, O. (2018). An analytical framework for
consensus-based global optimization method. Mathematical Models and
Methods in Applied Sciences, 28(6), 1037–1066.
https://doi.org/10.1142/S0218202518500276</unstructured_citation>
          </citation>
          <citation key="paszke2019pytorch">
            <article_title>Pytorch: An imperative style,
high-performance deep learning library</article_title>
            <author>Paszke</author>
            <journal_title>Advances in neural information processing
systems</journal_title>
            <volume>32</volume>
            <cYear>2019</cYear>
            <unstructured_citation>Paszke, A., Gross, S., Massa, F.,
Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein,
N., Antiga, L., &amp; others. (2019). Pytorch: An imperative style,
high-performance deep learning library. Advances in Neural Information
Processing Systems, 32.</unstructured_citation>
          </citation>
          <citation key="riedl2022leveraging">
            <article_title>Leveraging memory effects and gradient
information in consensus-based optimisation: On global convergence in
mean-field law</article_title>
            <author>Riedl</author>
            <journal_title>European Journal of Applied
Mathematics</journal_title>
            <doi>10.1017/S0956792523000293</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Riedl, K. (2023). Leveraging memory
effects and gradient information in consensus-based optimisation: On
global convergence in mean-field law. European Journal of Applied
Mathematics, 1–32.
https://doi.org/10.1017/S0956792523000293</unstructured_citation>
          </citation>
          <citation key="qiu2022PSOconvergence">
            <article_title>On the global convergence of particle swarm
optimization methods</article_title>
            <author>Huang</author>
            <journal_title>Applied Mathematics &amp;
Optimization</journal_title>
            <issue>2</issue>
            <volume>88</volume>
            <doi>10.1007/s00245-023-09983-3</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Huang, H., Qiu, J., &amp; Riedl, K.
(2023). On the global convergence of particle swarm optimization
methods. Applied Mathematics &amp; Optimization, 88(2), 30.
https://doi.org/10.1007/s00245-023-09983-3</unstructured_citation>
          </citation>
          <citation key="grassi2020particle">
            <article_title>From particle swarm optimization to consensus
based optimization: Stochastic modeling and mean-field
limit</article_title>
            <author>Grassi</author>
            <journal_title>Mathematical Models and Methods in Applied
Sciences</journal_title>
            <issue>8</issue>
            <volume>31</volume>
            <doi>10.1142/S0218202521500342</doi>
            <issn>0218-2025</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Grassi, S., &amp; Pareschi, L.
(2021). From particle swarm optimization to consensus based
optimization: Stochastic modeling and mean-field limit. Mathematical
Models and Methods in Applied Sciences, 31(8), 1625–1657.
https://doi.org/10.1142/S0218202521500342</unstructured_citation>
          </citation>
          <citation key="riedl2023gradient">
            <article_title>Gradient is all you need?</article_title>
            <author>Riedl</author>
            <doi>10.48550/arXiv.2306.09778</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Riedl, K., Klock, T., Geldhauser, C.,
&amp; Fornasier, M. (2023). Gradient is all you need?
https://doi.org/10.48550/arXiv.2306.09778</unstructured_citation>
          </citation>
          <citation key="carrillo2023fedcbo">
            <article_title>FedCBO: Reaching group consensus in clustered
federated learning through consensus-based optimization</article_title>
            <author>Carrillo</author>
            <doi>10.48550/arXiv.2305.02894</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Carrillo, J. A., Garcia Trillos, N.,
Li, S., &amp; Zhu, Y. (2023). FedCBO: Reaching group consensus in
clustered federated learning through consensus-based optimization.
https://doi.org/10.48550/arXiv.2305.02894</unstructured_citation>
          </citation>
          <citation key="borghi2022adaptive">
            <article_title>An adaptive consensus based method for
multi-objective optimization with uniform Pareto front
approximation</article_title>
            <author>Borghi</author>
            <journal_title>Applied Mathematics &amp;
Optimization</journal_title>
            <issue>2</issue>
            <volume>88</volume>
            <doi>10.1007/s00245-023-10036-y</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Borghi, G., Herty, M., &amp;
Pareschi, L. (2023). An adaptive consensus based method for
multi-objective optimization with uniform Pareto front approximation.
Applied Mathematics &amp; Optimization, 88(2), 1–43.
https://doi.org/10.1007/s00245-023-10036-y</unstructured_citation>
          </citation>
          <citation key="fornasier2020consensus_sphere_convergence">
            <article_title>Consensus-based optimization on the sphere:
Convergence to global minimizers and machine learning</article_title>
            <author>Fornasier</author>
            <journal_title>Journal of Machine Learning Research
(JMLR)</journal_title>
            <volume>22</volume>
            <issn>1532-4435</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Fornasier, M., Huang, H., Pareschi,
L., &amp; Sünnen, P. (2021). Consensus-based optimization on the sphere:
Convergence to global minimizers and machine learning. Journal of
Machine Learning Research (JMLR), 22, Paper No. 237,
55.</unstructured_citation>
          </citation>
          <citation key="borghi2021constrained">
            <article_title>Constrained consensus-based
optimization</article_title>
            <author>Borghi</author>
            <journal_title>SIAM Journal on Optimization</journal_title>
            <issue>1</issue>
            <volume>33</volume>
            <doi>10.1137/22M1471304</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Borghi, G., Herty, M., &amp;
Pareschi, L. (2023). Constrained consensus-based optimization. SIAM
Journal on Optimization, 33(1), 211–236.
https://doi.org/10.1137/22M1471304</unstructured_citation>
          </citation>
          <citation key="huang2021MFLCBO">
            <article_title>On the mean-field limit for the
consensus-based optimization</article_title>
            <author>Huang</author>
            <journal_title>Mathematical Methods in the Applied
Sciences</journal_title>
            <issue>12</issue>
            <volume>45</volume>
            <doi>10.1002/mma.8279</doi>
            <issn>0170-4214</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Huang, H., &amp; Qiu, J. (2022). On
the mean-field limit for the consensus-based optimization. Mathematical
Methods in the Applied Sciences, 45(12), 7814–7831.
https://doi.org/10.1002/mma.8279</unstructured_citation>
          </citation>
          <citation key="huang2022consensus">
            <article_title>Consensus-based optimization for saddle point
problems</article_title>
            <author>Huang</author>
            <journal_title>SIAM Journal on Control and
Optimization</journal_title>
            <issue>2</issue>
            <volume>62</volume>
            <doi>10.1137/22M1543367</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Huang, H., Qiu, J., &amp; Riedl, K.
(2024). Consensus-based optimization for saddle point problems. SIAM
Journal on Control and Optimization, 62(2), 1093–1121.
https://doi.org/10.1137/22M1543367</unstructured_citation>
          </citation>
          <citation key="fornasier2023consensus">
            <article_title>Consensus-based optimisation with truncated
noise</article_title>
            <author>Fornasier</author>
            <journal_title>European Journal of Applied
Mathematics</journal_title>
            <doi>10.1017/S095679252400007X</doi>
            <cYear>2024</cYear>
            <unstructured_citation>Fornasier, M., Richtárik, P., Riedl,
K., &amp; Sun, L. (2024). Consensus-based optimisation with truncated
noise. European Journal of Applied Mathematics, 1–24.
https://doi.org/10.1017/S095679252400007X</unstructured_citation>
          </citation>
          <citation key="althaus2023consensus">
            <article_title>Consensus-based rare event
estimation</article_title>
            <author>Althaus</author>
            <doi>10.48550/arXiv.2304.09077</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Althaus, K., Papaioannou, I., &amp;
Ullmann, E. (2023). Consensus-based rare event estimation.
https://doi.org/10.48550/arXiv.2304.09077</unstructured_citation>
          </citation>
          <citation key="DR2023">
            <article_title>Optimization.jl: A unified optimization
package</article_title>
            <author>Dixit</author>
            <doi>10.5281/ZENODO.7738525</doi>
            <cYear>2023</cYear>
            <unstructured_citation>Dixit, V. K., &amp; Rackauckas, C.
(2023). Optimization.jl: A unified optimization package. Zenodo.
https://doi.org/10.5281/ZENODO.7738525</unstructured_citation>
          </citation>
          <citation key="KP1992">
            <volume_title>Numerical solution of stochastic differential
equations</volume_title>
            <author>Kloeden</author>
            <doi>10.1007/978-3-662-12616-5</doi>
            <isbn>9783662126165</isbn>
            <cYear>1992</cYear>
            <unstructured_citation>Kloeden, P. E., &amp; Platen, E.
(1992). Numerical solution of stochastic differential equations.
Springer Berlin Heidelberg.
https://doi.org/10.1007/978-3-662-12616-5</unstructured_citation>
          </citation>
          <citation key="pinnau2017consensus">
            <article_title>A consensus-based model for global
optimization and its mean-field limit</article_title>
            <author>Pinnau</author>
            <journal_title>Mathematical Models and Methods in Applied
Sciences</journal_title>
            <issue>01</issue>
            <volume>27</volume>
            <doi>10.1142/s0218202517400061</doi>
            <issn>1793-6314</issn>
            <cYear>2017</cYear>
            <unstructured_citation>Pinnau, R., Totzeck, C., Tse, O.,
&amp; Martin, S. (2017). A consensus-based model for global optimization
and its mean-field limit. Mathematical Models and Methods in Applied
Sciences, 27(01), 183–204.
https://doi.org/10.1142/s0218202517400061</unstructured_citation>
          </citation>
          <citation key="movckus1975bayesian">
            <article_title>On Bayesian methods for seeking the
extremum</article_title>
            <author>Močkus</author>
            <journal_title>Optimization techniques IFIP technical
conference</journal_title>
            <doi>10.1007/978-3-662-38527-2_55</doi>
            <isbn>9783662385272</isbn>
            <cYear>1975</cYear>
            <unstructured_citation>Močkus, J. (1975). On Bayesian
methods for seeking the extremum. In Optimization techniques IFIP
technical conference (pp. 400–404). Springer; Springer Berlin
Heidelberg.
https://doi.org/10.1007/978-3-662-38527-2_55</unstructured_citation>
          </citation>
          <citation key="mohan2012survey">
            <article_title>A survey: Ant colony optimization based
recent research and implementation on several engineering
domain</article_title>
            <author>Chandra Mohan</author>
            <journal_title>Expert Systems with
Applications</journal_title>
            <issue>4</issue>
            <volume>39</volume>
            <doi>10.1016/j.eswa.2011.09.076</doi>
            <issn>0957-4174</issn>
            <cYear>2012</cYear>
            <unstructured_citation>Chandra Mohan, B., &amp; Baskaran, R.
(2012). A survey: Ant colony optimization based recent research and
implementation on several engineering domain. Expert Systems with
Applications, 39(4), 4618–4627.
https://doi.org/10.1016/j.eswa.2011.09.076</unstructured_citation>
          </citation>
          <citation key="karaboga2014comprehensive">
            <article_title>A comprehensive survey: Artificial bee colony
(ABC) algorithm and applications</article_title>
            <author>Karaboga</author>
            <journal_title>Artificial intelligence
review</journal_title>
            <issue>1</issue>
            <volume>42</volume>
            <doi>10.1007/s10462-012-9328-0</doi>
            <issn>1573-7462</issn>
            <cYear>2012</cYear>
            <unstructured_citation>Karaboga, D., Gorkemli, B., Ozturk,
C., &amp; Karaboga, N. (2012). A comprehensive survey: Artificial bee
colony (ABC) algorithm and applications. Artificial Intelligence Review,
42(1), 21–57.
https://doi.org/10.1007/s10462-012-9328-0</unstructured_citation>
          </citation>
          <citation key="yang2009firefly">
            <article_title>Firefly algorithms for multimodal
optimization</article_title>
            <author>Yang</author>
            <journal_title>Lecture notes in computer
science</journal_title>
            <doi>10.1007/978-3-642-04944-6_14</doi>
            <issn>1611-3349</issn>
            <isbn>9783642049446</isbn>
            <cYear>2009</cYear>
            <unstructured_citation>Yang, X.-S. (2009). Firefly
algorithms for multimodal optimization. In Lecture notes in computer
science (pp. 169–178). Springer Berlin Heidelberg.
https://doi.org/10.1007/978-3-642-04944-6_14</unstructured_citation>
          </citation>
          <citation key="ackley2012connectionist">
            <volume_title>A connectionist machine for genetic
hillclimbing</volume_title>
            <author>Ackley</author>
            <series_title>The Kluwer International Series in Engineering
and Computer Science</series_title>
            <volume>28</volume>
            <doi>10.1007/978-1-4613-1997-9</doi>
            <issn>0893-3405</issn>
            <isbn>9781461319979</isbn>
            <cYear>1987</cYear>
            <unstructured_citation>Ackley, D. H. (1987). A connectionist
machine for genetic hillclimbing. In The Kluwer International Series in
Engineering and Computer Science (Vol. 28). Springer US.
https://doi.org/10.1007/978-1-4613-1997-9</unstructured_citation>
          </citation>
          <citation key="miranda2018pyswarms">
            <article_title>PySwarms: A research toolkit for particle
swarm optimization in Python</article_title>
            <author>Miranda</author>
            <journal_title>The Journal of Open Source
Software</journal_title>
            <issue>21</issue>
            <volume>3</volume>
            <doi>10.21105/joss.00433</doi>
            <issn>2475-9066</issn>
            <cYear>2018</cYear>
            <unstructured_citation>Miranda, L. J. (2018). PySwarms: A
research toolkit for particle swarm optimization in Python. The Journal
of Open Source Software, 3(21), 433.
https://doi.org/10.21105/joss.00433</unstructured_citation>
          </citation>
          <citation key="mogensen2018optim">
            <article_title>Optim: A mathematical optimization package
for Julia</article_title>
            <author>Mogensen</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>24</issue>
            <volume>3</volume>
            <doi>10.21105/joss.00615</doi>
            <issn>2475-9066</issn>
            <cYear>2018</cYear>
            <unstructured_citation>Mogensen, P., &amp; Riseth, A.
(2018). Optim: A mathematical optimization package for Julia. Journal of
Open Source Software, 3(24), 615.
https://doi.org/10.21105/joss.00615</unstructured_citation>
          </citation>
          <citation key="mejia2022metaheuristics">
            <article_title>Metaheuristics: A Julia package for
single-and multi-objective optimization</article_title>
            <author>Mejı́a-de-Dios</author>
            <journal_title>Journal of Open Source
Software</journal_title>
            <issue>78</issue>
            <volume>7</volume>
            <doi>10.21105/joss.04723</doi>
            <issn>2475-9066</issn>
            <cYear>2022</cYear>
            <unstructured_citation>Mejı́a-de-Dios, J.-A., &amp;
Mezura-Montes, E. (2022). Metaheuristics: A Julia package for single-and
multi-objective optimization. Journal of Open Source Software, 7(78),
4723. https://doi.org/10.21105/joss.04723</unstructured_citation>
          </citation>
          <citation key="carrillo2021consensus">
            <article_title>A consensus-based global optimization method
for high dimensional machine learning problems</article_title>
            <author>Carrillo</author>
            <journal_title>ESAIM: Control, Optimisation and Calculus of
Variations</journal_title>
            <volume>27</volume>
            <doi>10.1051/cocv/2020046</doi>
            <issn>1262-3377</issn>
            <cYear>2021</cYear>
            <unstructured_citation>Carrillo, J. A., Jin, S., Li, L.,
&amp; Zhu, Y. (2021). A consensus-based global optimization method for
high dimensional machine learning problems. ESAIM: Control, Optimisation
and Calculus of Variations, 27, S5.
https://doi.org/10.1051/cocv/2020046</unstructured_citation>
          </citation>
          <citation key="fornasier2021convergence">
            <article_title>Convergence of anisotropic consensus-based
optimization in mean-field law</article_title>
            <author>Fornasier</author>
            <journal_title>Applications of evolutionary
computation</journal_title>
            <doi>10.1007/978-3-031-02462-7_46</doi>
            <issn>1611-3349</issn>
            <isbn>978-3-031-02462-7</isbn>
            <cYear>2022</cYear>
            <unstructured_citation>Fornasier, M., Klock, T., &amp;
Riedl, K. (2022). Convergence of anisotropic consensus-based
optimization in mean-field law. In J. L. Jiménez Laredo, J. I. Hidalgo,
&amp; K. O. Babaagba (Eds.), Applications of evolutionary computation
(pp. 738–754). Springer.
https://doi.org/10.1007/978-3-031-02462-7_46</unstructured_citation>
          </citation>
          <citation key="klamroth2022consensus">
            <article_title>Consensus-based optimization for
multi-objective problems: A multi-swarm approach</article_title>
            <author>Klamroth</author>
            <journal_title>Journal of Global
Optimization</journal_title>
            <doi>10.1007/s10898-024-01369-1</doi>
            <issn>1573-2916</issn>
            <cYear>2024</cYear>
            <unstructured_citation>Klamroth, K., Stiglmayr, M., &amp;
Totzeck, C. (2024). Consensus-based optimization for multi-objective
problems: A multi-swarm approach. Journal of Global Optimization.
https://doi.org/10.1007/s10898-024-01369-1</unstructured_citation>
          </citation>
        </citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
