<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">8445</article-id>
<article-id pub-id-type="doi">10.21105/joss.08445</article-id>
<title-group>
<article-title>SideScanSonarEditor: A Python package for annotation of
side-scan sonar data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4764-7130</contrib-id>
<name>
<surname>Motylinski</surname>
<given-names>Michal</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7043-227X</contrib-id>
<name>
<surname>Plater</surname>
<given-names>Andrew J.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7577-0913</contrib-id>
<name>
<surname>Higham</surname>
<given-names>Jonathan E.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Geography and Planning, School of
Environmental Sciences, University of Liverpool, Liverpool,
UK</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-02-26">
<day>26</day>
<month>2</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>114</issue>
<fpage>8445</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python package</kwd>
<kwd>annotation</kwd>
<kwd>side-scan sonar</kwd>
<kwd>xtf</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Side-scan sonars are widely used instruments for high-resolution
  mapping of the seafloor, utilizing acoustic signals to generate
  detailed imagery. These systems play a crucial role in marine
  research, habitat assessment, underwater archaeology, and
  infrastructure inspections, providing valuable insights into seabed
  features and composition.</p>
  <p>Annotation of the targets is typically done using specialised
  software which does not produce results allowing for quick conversion
  to formats commonly used to train machine learning models. Our
  software <monospace>SideScanSonarEditor</monospace> is a free and
  open-source Python package which allows the user to read sonar data
  from XTF files, display it as images and allow further processing
  (<xref alt="“XTF File Format Information,” 2025" rid="ref-xtfU003A2025" ref-type="bibr">“XTF
  File Format Information,” 2025</xref>). The key features include the
  ability to fully analyze sonar imagery, easily manipulate it, and
  annotate objects of interest. The tool additionally allows for drawing
  of polygon shapes as well as rectangular shapes which coordinates are
  used to crop smaller image tiles. Together they can be used in the
  process of dataset creation for further sonar analysis or computer
  vision tasks such as object detection or segmentation.
  (<xref alt="[fig:overview]" rid="figU003Aoverview">[fig:overview]</xref>).</p>
  <p><monospace>SideScanSonarEditor</monospace> provides the following
  sonar image manipulation methods:</p>
  <list list-type="bullet">
    <list-item>
      <p>Decimation – across-track down sampling which might be useful
      when importing very large files that might exceed memory limits on
      some systems. The decimation factor directly determines the
      fraction of the data that is to be retained meaning with a factor
      of 1, 100% of the samples are loaded, with a factor of 2, 50%,
      factor of 3, 33% and so on. The setting range goes from 1-10 but
      in reality, values greater than 4 will produce errors or severely
      reduce the number of samples leading to the loss of a significant
      portion of data. For the purpose of this research, decimation is
      set to 1 at all times to ensure the highest number of horizontal
      features per target.</p>
    </list-item>
    <list-item>
      <p>Stretch – Along-track stretch factor which defines how many
      times each ping should be repeated. This method is applied to
      improve the visual representation of the features. Typically, when
      the data is displayed, the objects will appear stretched
      horizontally and compressed vertically. To compensate without
      losing across-track features the image is expanded vertically
      allowing for easier analysis and labelling of the targets. The
      stretching method, however, is not utilised when generating
      training data or during inference. The technique is used purely as
      a visual correction during the annotation process.</p>
    </list-item>
    <list-item>
      <p>Invert – Inversion of the colour palette which in some cases
      might help in visual recognition of targets.</p>
    </list-item>
    <list-item>
      <p>Colour mapping – Setting colour palette to highlight different
      features. Applying different mapping scales can help distinguish
      various targets on the image. Currently available options include
      two greyscale patterns a linear (grey) and logarithmic
      (greylog).</p>
    </list-item>
    <list-item>
      <p>Map range – Minimum and maximum mapping ranges are by default
      automatically calculated based on the intensity input data. Both
      can be manually modified to change the representation of the
      features for easier interpretation.</p>
    </list-item>
    <list-item>
      <p>Slant range correction - apply slant range correction to
      compensate for the geometric distortion of the return signal. The
      corrected image represents true seafloor distances allowing for
      better alignment with the navigation data
      (<xref alt="Chang et al., 2010" rid="ref-changU003A2010" ref-type="bibr">Chang
      et al., 2010</xref>).</p>
    </list-item>
  </list>
  <fig>
    <caption><p>SideScanSonarEditor app
    <styled-content id="figU003Aoverview"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="overview.png" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Side-scan sonar is a commonly used instrument for mapping of the
  seabed. These devices operate by being towed behind a vessel, emitting
  sonar pulses that reflect off the seabed to create detailed images.
  The raw data collected by the sonar consists of overlapping
  representations of the seabed that must be processed before they can
  be used for machine learning applications, such as target recognition
  and labeling
  (<xref alt="Motylinski et al., 2024" rid="ref-MotylinskiU003A2025" ref-type="bibr">Motylinski
  et al., 2024</xref>).</p>
  <p>Interpreting side-scan sonar data from sonar typically requires
  expensive proprietary software designed for in-depth analysis and
  post-processing. However, these software packages do not facilitate
  the extraction of imagery and annotations in a format suitable for
  training computer vision models or further processing
  (<xref alt="Lin et al., 2014" rid="ref-linU003A2014" ref-type="bibr">Lin
  et al., 2014</xref>). To train an automatic target recognition model,
  users must manually crop imagery in <monospace>SonarWiz</monospace>
  (or similar closed-source software) before annotating it using
  <monospace>LabelMe</monospace> or other standard tools
  (<xref alt="Wada, 2024" rid="ref-wadaU003A2024" ref-type="bibr">Wada,
  2024</xref>). This process is highly time-consuming, requiring manual
  visual analysis of sonar swaths in <monospace>SonarWiz</monospace> or
  <monospace>EdgeTech Discover</monospace> to identify and crop relevant
  areas
  (<xref alt="Chesapeake Technology - Makers of SonarWiz, 2025" rid="ref-chesapeakeU003A2025" ref-type="bibr"><italic>Chesapeake
  Technology - Makers of SonarWiz</italic>, 2025</xref>;
  <xref alt="EdgeTech, 2025" rid="ref-edgetechU003A2025" ref-type="bibr"><italic>EdgeTech</italic>,
  2025</xref>). After cropping, the images must then be manually
  re-analyzed and labeled in another software such as
  <monospace>LabelMe</monospace>, adding further to the labor-intensive
  workflow.</p>
  <p>To the best of our knowledge, there is currently no open-source
  software available for viewing, manipulating, and annotating side-scan
  sonar files. Even commercial software does not provide a streamlined
  workflow optimized for time efficiency. Our open-source and
  free-to-use software, <monospace>SideScanSonarEditor</monospace>,
  significantly simplifies and accelerates the annotation process for
  sonar data. The output format is designed for easy analysis, further
  processing, and seamless integration with object detection or
  segmentation models
  (<xref alt="Lin et al., 2014" rid="ref-linU003A2014" ref-type="bibr">Lin
  et al., 2014</xref>).</p>
  <p><monospace>SideScanSonarEditor</monospace> utilizes the pyxtf
  library to read complete XTF files and generates waterfall views of
  surveyed areas
  (<xref alt="Sture, 2025" rid="ref-oysstupyxtfU003A2025" ref-type="bibr">Sture,
  2025</xref>). The data is displayed as a collection of pings, with the
  scan direction oriented from bottom to top. The image view consists of
  two sections corresponding to the two sides of the tow-fish: the port
  side and the starboard side, with port-side data being horizontally
  flipped for accurate real-world representation of the seafloor. The
  software’s primary function is to generate waterfall images and enable
  efficient annotation of targets, as well as cropping tiles to create
  datasets ready for model training.</p>
</sec>
<sec id="future-work">
  <title>Future Work</title>
  <p>The side-scan sonar data can be saved in numerous different formats
  (XTF, JSF, GCF and more). In future software updates support for more
  formats will be added. Furthermore the data formats can hold
  additional information like bathymetry data which can also be analysed
  or used for machine learning purposes, thus support for these data
  types will be added in the future. Additional sonar data correction
  and image manipulation functions will also be added in the future
  including bottom tracking or color palette change. In current form the
  tool is very simple but future versions might include an improved
  drawing methods and more predefined shapes. More output formats may
  also be added in the future including PASCAL VOC and YOLO.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the Port City Innovation Hub (European
  Regional Development Fund).</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-oysstupyxtfU003A2025">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Sture</surname><given-names>Øystein</given-names></name>
      </person-group>
      <article-title>Oysstu/pyxtf</article-title>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-02-25">2025</year><month>02</month><day>25</day></date-in-citation>
      <uri>https://github.com/oysstu/pyxtf</uri>
    </element-citation>
  </ref>
  <ref id="ref-xtfU003A2025">
    <element-citation>
      <article-title>XTF file format information</article-title>
      <source>Exail</source>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-02-25">2025</year><month>02</month><day>25</day></date-in-citation>
      <uri>https://www.exail.com/resources/knowledge-center/xtf-file-format-information</uri>
    </element-citation>
  </ref>
  <ref id="ref-changU003A2010">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Chang</surname><given-names>Yet-Chung</given-names></name>
        <name><surname>Hsu</surname><given-names>Shu-Kun</given-names></name>
        <name><surname>Tsai</surname><given-names>Ching-Hui</given-names></name>
      </person-group>
      <article-title>SIDESCAN SONAR IMAGE PROCESSING:CORRECTING BRIGHTNESS VARIATION AND PATCHING GAPS</article-title>
      <source>Journal of Marine Science and Technology</source>
      <year iso-8601-date="2010-12">2010</year><month>12</month>
      <volume>18</volume>
      <issue>6</issue>
      <issn>2709-6998</issn>
      <uri>https://jmstt.ntou.edu.tw/journal/vol18/iss6/1</uri>
      <pub-id pub-id-type="doi">10.51400/2709-6998.1935</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-chesapeakeU003A2025">
    <element-citation>
      <article-title>Chesapeake Technology - Makers of SonarWiz</article-title>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-10-02">2025</year><month>10</month><day>02</day></date-in-citation>
      <uri>https://chesapeaketech.com/</uri>
    </element-citation>
  </ref>
  <ref id="ref-wadaU003A2024">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Wada</surname><given-names>Kentaro</given-names></name>
      </person-group>
      <article-title>Labelme: Image Polygonal Annotation with Python</article-title>
      <year iso-8601-date="2024-11">2024</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-11-15">2024</year><month>11</month><day>15</day></date-in-citation>
      <uri>https://github.com/wkentaro/labelme</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.5711226</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-linU003A2014">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lin</surname><given-names>Tsung-Yi</given-names></name>
        <name><surname>Maire</surname><given-names>Michael</given-names></name>
        <name><surname>Belongie</surname><given-names>Serge J</given-names></name>
        <name><surname>Bourdev</surname><given-names>Lubomir D</given-names></name>
        <name><surname>Girshick</surname><given-names>Ross B</given-names></name>
        <name><surname>Hays</surname><given-names>James</given-names></name>
        <name><surname>Perona</surname><given-names>Pietro</given-names></name>
        <name><surname>Ramanan</surname><given-names>Deva</given-names></name>
        <name><surname>Doll’a r</surname><given-names>Piotr</given-names></name>
        <name><surname>Zitnick</surname><given-names>C Lawrence</given-names></name>
      </person-group>
      <article-title>Microsoft COCO: Common Objects in Context</article-title>
      <source>CoRR</source>
      <year iso-8601-date="2014">2014</year>
      <volume>abs/1405.0312</volume>
      <uri>http://arxiv.org/abs/1405.0312</uri>
    </element-citation>
  </ref>
  <ref id="ref-MotylinskiU003A2025">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Motylinski</surname><given-names>Michal</given-names></name>
        <name><surname>Plater</surname><given-names>Andrew J</given-names></name>
        <name><surname>Higham</surname><given-names>Jonathan E</given-names></name>
      </person-group>
      <article-title>Computer vision methods for side scan sonar imagery</article-title>
      <source>Measurement Science and Technology</source>
      <publisher-name>IOP Publishing</publisher-name>
      <year iso-8601-date="2024-12">2024</year><month>12</month>
      <volume>36</volume>
      <issue>1</issue>
      <uri>https://dx.doi.org/10.1088/1361-6501/ad99f1</uri>
      <pub-id pub-id-type="doi">10.1088/1361-6501/ad99f1</pub-id>
      <fpage>015435</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-edgetechU003A2025">
    <element-citation>
      <article-title>EdgeTech</article-title>
      <year iso-8601-date="2025">2025</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-10-02">2025</year><month>10</month><day>02</day></date-in-citation>
      <uri>https://www.edgetech.com/</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
