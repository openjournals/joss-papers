<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">7932</article-id>
<article-id pub-id-type="doi">10.21105/joss.07932</article-id>
<title-group>
<article-title>ParquetDB: A Lightweight Python Parquet-Based
Database</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2867-1706</contrib-id>
<name>
<surname>Lang</surname>
<given-names>Logan L.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1164-2856</contrib-id>
<name>
<surname>Hernandez</surname>
<given-names>Eduardo R.</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9737-8074</contrib-id>
<name>
<surname>Choudhary</surname>
<given-names>Kamal</given-names>
</name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5968-0571</contrib-id>
<name>
<surname>Romero</surname>
<given-names>Aldo H.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Physics, West Virginia University,
Morgantown, United States</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Instituto de Ciencia de Materiales de Madrid, Madrid,
Spain</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>National Institute of Standards and Technology,
Gaithersburg, United States</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2025-02-14">
<day>14</day>
<month>2</month>
<year>2025</year>
</pub-date>
<volume>10</volume>
<issue>109</issue>
<fpage>7932</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Apache Parquet</kwd>
<kwd>Python</kwd>
<kwd>Database</kwd>
<kwd>Big Data</kwd>
<kwd>Pyarrow</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>ParquetDB is a Python library serving as a “middleware” solution,
  bridging the gap between file-based storage and full database systems.
  A key driver for its development was the need to support iterative
  research workflows, requiring schema evolvability, the ability to
  manage complex and evolving nested data structures without predefined
  rigidity, and the ability to handle-table and field-level metadata.
  Additionally, its “classically serverless” nature was a crucial design
  point for deployment in environments such as HPC clusters with limited
  connectivity. Leveraging Apache Parquet
  (<xref alt="“Parquet,” n.d." rid="ref-Parquet" ref-type="bibr">“Parquet,”
  n.d.</xref>;
  <xref alt="Apache Software Foundation, n.d." rid="ref-WelcomeApacheSoftware" ref-type="bibr"><italic>Apache
  Software Foundation</italic>, n.d.</xref>), it combines file storage
  portability with advanced querying capabilities, enabling efficient
  compression and read performance without dedicated server overhead.
  ParquetDB addresses limitations in both traditional approaches by
  seamlessly handling complex data types (arrays, nested structures,
  Python objects), simplifying data interaction compared to direct file
  manipulation or manual serialization. Performance benchmarks show
  competitive read/write speeds and effective query performance via
  predicate pushdown, demonstrating its utility for managing
  medium-to-large datasets where database complexity is unwarranted but
  basic file I/O is insufficient.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>The demand for efficient, scalable, and adaptable data storage
  solutions is critical across research domains. Traditional file
  formats (e.g., CSV, JSON, TXT) offer simplicity but suffer from
  inefficiencies, particularly with numerical data due to ASCII/UTF
  encoding overhead, leading to larger files and slower I/O. While
  binary formats like HDF5
  (<xref alt="HDF5, n.d." rid="ref-HDF5PythonH5py" ref-type="bibr"><italic>HDF5</italic>,
  n.d.</xref>) improve efficiency for large numerical datasets, they
  function primarily as structured file containers, lacking the rich
  querying APIs and transactional integrity features common in
  databases. These file-based approaches often require manual data
  relationship management and lack built-in indexing, hindering agility
  as projects scale or require rapid iteration.</p>
  <p>Database systems like SQLite
  (<xref alt="Allen &amp; Owens, 2010" rid="ref-allenDefinitiveGuideSQLite2010" ref-type="bibr">Allen
  &amp; Owens, 2010</xref>) or MongoDB
  (<xref alt="Guo, 2017" rid="ref-guoMongoDBsJavaScriptFuzzer2017" ref-type="bibr">Guo,
  2017</xref>) provide robust encoding, indexing, and querying.
  Relational databases ensure integrity via structured schemas but can
  be rigid when data models evolve
  (<xref alt="Pascal, 2000" rid="ref-pascalPracticalIssuesDatabase2000" ref-type="bibr">Pascal,
  2000</xref>). NoSQL options offer flexibility but may introduce
  consistency challenges or require complex optimization
  (<xref alt="Pivert, 2018" rid="ref-pivertNoSQLDataModels2018" ref-type="bibr">Pivert,
  2018</xref>). Furthermore, many databases involve server
  configurations or lack transparent file-based portability, adding
  overhead unsuitable for lightweight experimentation or simpler
  deployment scenarios. While SQLite is serverless and ubiquitous, its
  row-based nature can be less performant for analytical queries
  scanning wide datasets compared to columnar formats, and managing
  complex nested data can be cumbersome.</p>
  <p>Directly using libraries like Apache Arrow (PyArrow) to work with
  Parquet files offers access to columnar efficiency and querying
  primitives like predicate pushdown. However, this still requires
  developers to build abstractions for database-like operations (CRUD),
  manage schema consistency across multiple files, handle serialization
  of complex Python objects, and orchestrate data updates or deletions
  manually.</p>
  <p>While powerful dataframe manipulation libraries like Pandas
  (<xref alt="Pandas, n.d." rid="ref-PandasPythonData" ref-type="bibr"><italic>Pandas</italic>,
  n.d.</xref>), Dask
  (<xref alt="Dask, n.d." rid="ref-DaskScalePythona" ref-type="bibr"><italic>Dask</italic>,
  n.d.</xref>), and Polars
  (<xref alt="Polars, n.d." rid="ref-Polars" ref-type="bibr"><italic>Polars</italic>,
  n.d.</xref>), or embedded analytical databases such as DuckDB
  (<xref alt="DuckDB, n.d." rid="ref-InprocessSQLOLAP" ref-type="bibr"><italic>DuckDB</italic>,
  n.d.</xref>) are invaluable for many tasks, they may not holistically
  address the specific needs that motivated ParquetDB. For researchers
  dealing with evolving, complexly nested scientific data, ParquetDB
  offers a more streamlined approach to schema evolvability and native
  Python object persistence directly within a serverless Parquet-based
  ecosystem. This focus distinguishes it from tools that might require
  more manual setup for schema management across multiple files, or lack
  the same emphasis on integrated metadata handling and a ‘classically
  serverless’ model for environments like HPC clusters.</p>
  <p>ParquetDB addresses this gap, providing a “middleware” layer built
  upon Python and the Parquet format. It offers a familiar database-like
  interface (CRUD operations) while leveraging columnar storage for
  compression and read performance benefits. Crucially, ParquetDB adds
  value beyond direct Parquet file manipulation by automating schema
  management (including evolution), simplifying the storage/retrieval of
  complex Python objects, and providing a unified API to manage
  collections of Parquet files as a single logical datastore. It
  supports predicate and column pushdown for optimization within a
  lightweight, serverless architecture, offering a pragmatic balance for
  scenarios demanding more than basic files but less than a full
  database system, particularly where schema flexibility and ease of use
  are paramount. For a comprehensive feature list, visit our
  documentation (https://parquetdb.readthedocs.io/en/latest/).</p>
</sec>
<sec id="benchmarks">
  <title>Benchmarks</title>
  <p>We evaluated ParquetDB’s performance against SQLite and MongoDB
  using synthetic datasets (100 integer columns, varying record counts).
  Our first experiment compared write and read performance. ParquetDB’s
  creation times are competitive, performing second best behind SQLite
  as dataset size increases. For bulk read operations, ParquetDB
  initially lags slightly but significantly outperforms both competitors
  on larger datasets (beyond several hundred/thousand rows), benefiting
  from Parquet’s columnar efficiency (see Figure 1).</p>
  <fig>
    <caption><p>Benchmark Create and Read Times for Different Databases.
    Create time is plotted on the left y-axis, read time on the right
    y-axis, and the number of rows on the x-axis. A log plot is shown in
    the inset.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="benchmark_create_read_times.png" />
  </fig>
  <p>A “needle-in-a-haystack” benchmark assessed specific record
  retrieval. While lacking traditional B-tree indexes, ParquetDB uses
  predicate pushdown leveraging Parquet’s field-level statistics for
  efficient filtering without full scans. It is important to note that
  performance advantages depend on the workload; for instance, complex
  analytical queries involving aggregations or returning small, highly
  filtered results might favor the mature query engine and indexing of
  systems like SQLite. ParquetDB excels when querying or returning
  substantial portions of wide datasets. Detailed benchmarks are in our
  extended paper: Lang et al.
  (<xref alt="2025" rid="ref-langParquetDBLightweightPython2025" ref-type="bibr">2025</xref>).</p>
</sec>
<sec id="installation">
  <title>Installation</title>
  <p>For installation, please use pip:</p>
  <code language="python">pip install parquetdb</code>
  <p>For more details, please visit the GitHub repository:
  <ext-link ext-link-type="uri" xlink:href="https://github.com/lllangWV/ParquetDB">https://github.com/lllangWV/ParquetDB</ext-link>.
  The repository contains additional examples, API documentation, and
  guidelines for contributing to the project.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank the Pittsburgh Supercomputer Center (Bridges2) and San
  Diego Supercomputer Center (Expanse) through allocation DMR140031 from
  the Advanced Cyberinfrastructure Coordination Ecosystem: Services
  &amp; Support (ACCESS) program, which is supported by National Science
  Foundation grants #2138259, #2138286, #2138307, #2137603, and
  #2138296. We gratefully acknowledge the computational resources
  provided by the WVU Research Computing Dolly Sods HPC cluster,
  partially funded by NSF OAC-2117575. Additionally, we recognize the
  support from the West Virginia Higher Education Policy Commission
  through the Research Challenge Grant Program 2022 (Award RCG 23-007),
  as well as NASA EPSCoR (Award 80NSSC22M0173), for their contributions
  to this work. The work of E.R.H. is supported by MCIN/AEI/
  10.13039/501100011033/FEDER, UE through projects PID2022-139776NB-C66.
  K.C. thanks funding from the CHIPS Metrology Program, part of CHIPS
  for America, National Institute of Standards and Technology, U.S.
  Department of Commerce. Certain commercial equipment, instruments,
  software, or materials are identified in this paper in order to
  specify the experimental procedure adequately. Such identifications
  are not intended to imply recommendation or endorsement by NIST, nor
  are they intended to imply that the materials or equipment identified
  are necessarily the best available for the purpose.</p>
</sec>
</body>
<back>
<ref-list>
  <title></title>
  <ref id="ref-allenDefinitiveGuideSQLite2010">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Allen</surname><given-names>Grant</given-names></name>
        <name><surname>Owens</surname><given-names>Mike</given-names></name>
      </person-group>
      <source>The definitive guide to SQLite</source>
      <publisher-name>Apress</publisher-name>
      <publisher-loc>Berkeley, CA</publisher-loc>
      <year iso-8601-date="2010">2010</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-03-03">2025</year><month>03</month><day>03</day></date-in-citation>
      <isbn>978-1-4302-3226-1</isbn>
      <pub-id pub-id-type="doi">10.1007/978-1-4302-3226-1</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-DaskScalePythona">
    <element-citation>
      <article-title>Dask  Scale the Python tools you love</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-13">2025</year><month>05</month><day>13</day></date-in-citation>
      <uri>https://www.dask.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-guoMongoDBsJavaScriptFuzzer2017">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Guo</surname><given-names>Robert</given-names></name>
      </person-group>
      <article-title>MongoDB’s JavaScript fuzzer</article-title>
      <source>Commun. ACM</source>
      <year iso-8601-date="2017-04">2017</year><month>04</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-03-03">2025</year><month>03</month><day>03</day></date-in-citation>
      <volume>60</volume>
      <issue>5</issue>
      <issn>0001-0782</issn>
      <pub-id pub-id-type="doi">10.1145/3052937</pub-id>
      <fpage>43</fpage>
      <lpage>47</lpage>
    </element-citation>
  </ref>
  <ref id="ref-HDF5PythonH5py">
    <element-citation>
      <article-title>HDF5 for Python — H5py 3.13.0 documentation</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-04-28">2025</year><month>04</month><day>28</day></date-in-citation>
      <uri>https://docs.h5py.org/en/stable/index.html</uri>
    </element-citation>
  </ref>
  <ref id="ref-InprocessSQLOLAP">
    <element-citation>
      <article-title>An in-process SQL OLAP database management system</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-13">2025</year><month>05</month><day>13</day></date-in-citation>
      <uri>https://duckdb.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-langParquetDBLightweightPython2025">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Lang</surname><given-names>Logan</given-names></name>
        <name><surname>Hernandez</surname><given-names>Eduardo</given-names></name>
        <name><surname>Choudhary</surname><given-names>Kamal</given-names></name>
        <name><surname>Romero</surname><given-names>Aldo H.</given-names></name>
      </person-group>
      <article-title>ParquetDB: A lightweight Python Parquet-based database</article-title>
      <publisher-name>arXiv</publisher-name>
      <year iso-8601-date="2025-02">2025</year><month>02</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-02-14">2025</year><month>02</month><day>14</day></date-in-citation>
      <uri>https://arxiv.org/abs/2502.05311</uri>
      <pub-id pub-id-type="doi">10.48550/arXiv.2502.05311</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-PandasPythonData">
    <element-citation>
      <article-title>Pandas - Python data analysis library</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-13">2025</year><month>05</month><day>13</day></date-in-citation>
      <uri>https://pandas.pydata.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-Parquet">
    <element-citation>
      <article-title>Parquet</article-title>
      <source>Apache Parquet</source>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-10-21">2024</year><month>10</month><day>21</day></date-in-citation>
      <uri>https://parquet.apache.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-pascalPracticalIssuesDatabase2000">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Pascal</surname><given-names>Fabian</given-names></name>
      </person-group>
      <source>Practical issues in database management: A reference for the thinking practitioner</source>
      <publisher-name>Addison-Wesley Professional</publisher-name>
      <publisher-loc>Boston, Mass</publisher-loc>
      <year iso-8601-date="2000-01">2000</year><month>01</month>
      <edition>1st edition</edition>
      <isbn>978-0-201-48555-4</isbn>
    </element-citation>
  </ref>
  <ref id="ref-pivertNoSQLDataModels2018">
    <element-citation publication-type="book">
      <source>NoSQL data models: Trends and challenges</source>
      <person-group person-group-type="editor">
        <name><surname>Pivert</surname><given-names>Olivier</given-names></name>
      </person-group>
      <publisher-name>Wiley-ISTE</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
      <year iso-8601-date="2018-08">2018</year><month>08</month>
      <edition>1st edition</edition>
      <isbn>978-1-78630-364-6</isbn>
    </element-citation>
  </ref>
  <ref id="ref-Polars">
    <element-citation>
      <article-title>Polars</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-13">2025</year><month>05</month><day>13</day></date-in-citation>
      <uri>https://www.pola.rs/</uri>
    </element-citation>
  </ref>
  <ref id="ref-WelcomeApacheSoftware">
    <element-citation>
      <article-title>Welcome to the Apache Software Foundation</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-04-28">2025</year><month>04</month><day>28</day></date-in-citation>
      <uri>https://www.apache.org/</uri>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
