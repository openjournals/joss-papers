<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5195</article-id>
<article-id pub-id-type="doi">10.21105/joss.05195</article-id>
<title-group>
<article-title>ms3: A parser for MuseScore files, serving as data
factory for annotated music corpora</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1986-9545</contrib-id>
<name>
<surname>Hentschel</surname>
<given-names>Johannes</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4323-7257</contrib-id>
<name>
<surname>Rohrmeier</surname>
<given-names>Martin</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>École Polytechnique Fédérale de Lausanne,
Switzerland</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-01-17">
<day>17</day>
<month>1</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>88</issue>
<fpage>5195</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>python</kwd>
<kwd>music</kwd>
<kwd>scores</kwd>
<kwd>corpus</kwd>
<kwd>corpora</kwd>
<kwd>data</kwd>
<kwd>musescore</kwd>
<kwd>tab-separated values</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Digital Musicology is a vibrant and quickly growing discipline that
  addresses traditional and novel music-related research questions with
  digital and computational means
  (<xref alt="Honing, 2006" rid="ref-Honing2006_GrowingRoleObservation" ref-type="bibr">Honing,
  2006</xref>;
  <xref alt="Huron, 1999" rid="ref-Huron1999_NewEmpiricismSystematic" ref-type="bibr">Huron,
  1999</xref>;
  <xref alt="Urberg, 2017" rid="ref-Urberg2017_PastsFuturesDigital" ref-type="bibr">Urberg,
  2017</xref>). Research questions and methods often overlap with or
  draw on those from diverse disciplines such as music theory and
  analysis, composition history, mathematics, cognitive psychology,
  linguistics, anthropology, or computer science
  (<xref alt="Volk &amp; Honingh, 2012" rid="ref-Volk2012_MathematicalComputationalApproaches" ref-type="bibr">Volk
  &amp; Honingh, 2012</xref>;
  <xref alt="Wiggins, 2012" rid="ref-Wiggins2012_MusicMindMathematics" ref-type="bibr">Wiggins,
  2012</xref>). Corpus research, i.e., the computational study of
  representative collections of texts (in the case of linguistics) or
  notated music (in musicology), plays a prominent role in this
  trans-disciplinary quest to “make sense of music” through scientific
  models
  (<xref alt="London, 2013" rid="ref-London2013_BuildingRepresentativeCorpus" ref-type="bibr">London,
  2013</xref>;
  <xref alt="Moss, 2019" rid="ref-Moss2019_TransitionsTonalityModelBased" ref-type="bibr">Moss,
  2019</xref>;
  <xref alt="Shanahan, 2022" rid="ref-Shanahan2022_WhatHistoryComputational" ref-type="bibr">Shanahan,
  2022</xref>). <monospace>ms3</monospace> makes scores (symbolic
  representations of music) operational for computational approaches by
  representing their contents as sets of tabular files.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Music scores represent relations between sounding events by
  graphical means. Music notation software therefore is often concerned
  with problems of layout and easy-to-read rendering of symbols in line
  with the multitude of notational conventions
  (<xref alt="Read, 1979" rid="ref-Read1979_MusicNotationManual" ref-type="bibr">Read,
  1979</xref>;
  <xref alt="Ross, 2001" rid="ref-Ross2001_ArtMusicEngraving" ref-type="bibr">Ross,
  2001</xref>); rather than with the explicit encoding of the musical
  relations themselves. For example, the Free and Open Source Software
  <ext-link ext-link-type="uri" xlink:href="https://musescore.org/">MuseScore</ext-link>
  provides a full-featured yet intuitive interface for engraving music,
  but its native XML format does not explicitly encode the temporal
  positions of events such as notes and rests. Hence the need for a
  parser that extracts the implicit information and stores it in an
  interoperable format.</p>
  <p>Despite being one of the most widespread score encoding formats,
  current score parsers (e.g.,
  <xref alt="Cancino-Chacón et al., 2022" rid="ref-Cancino-Chacon2022_PartituraPythonPackage" ref-type="bibr">Cancino-Chacón
  et al., 2022</xref>;
  <xref alt="Cuthbert, 2010" rid="ref-Cuthbert2010_Music21ToolkitComputerAided" ref-type="bibr">Cuthbert,
  2010</xref>;
  <xref alt="Pugin et al., 2014" rid="ref-Pugin2014_VerovioLibraryEngraving" ref-type="bibr">Pugin
  et al., 2014</xref>), do not handle it without first performing a
  lossy conversion to the musicXML
  format<xref ref-type="fn" rid="fn1">1</xref>. The Python library
  <monospace>ms3</monospace> fills this gap. It loads the XML tree of a
  MuseScore file into working memory, computes the temporal positions of
  all encoded elements, and transforms those requested by the user into
  DataFrames
  (<xref alt="Petersohn, 2021" rid="ref-Petersohn2021_DataframeSystemsTheory" ref-type="bibr">Petersohn,
  2021</xref>). The DataFrames can be used by other Python programs and
  scripts, or written to Tab-Separated Values (TSV) to enable processing
  with other software and facilitate version
  control<xref ref-type="fn" rid="fn2">2</xref>. The most typical
  aspects that users extract from a score are tables containing notes,
  measures (bars), metadata, and text labels, in particular those
  representing analytical annotations. Moreover,
  <monospace>ms3</monospace> allows the user to transform scores by
  removing analytical labels after their extraction or by (re-)inserting
  annotations from TSV files (whether previously extracted or generated
  from scratch). This functionality turns MuseScore into a convenient
  score annotation tool enabling users to graphically insert into a
  score arbitrary textual labels, to then have
  <monospace>ms3</monospace> extract them with their temporal positions
  for further analysis. It comes with a command line interface that
  makes its data extraction, transformation, and validation
  functionalities accessible for productive everyday workflows.</p>
  <p><monospace>ms3</monospace> has already been used for creating
  several datasets, namely version 2 of the Annotated Beethoven Corpus
  (<xref alt="Neuwirth et al., 2018" rid="ref-Neuwirth2018_AnnotatedBeethovenCorpus" ref-type="bibr">Neuwirth
  et al., 2018</xref>), the Annotated Mozart Sonatas
  (<xref alt="Hentschel, Neuwirth, et al., 2021" rid="ref-Hentschel2021_AnnotatedMozartSonatas" ref-type="bibr">Hentschel,
  Neuwirth, et al., 2021</xref>), and an annotated corpus of 19th
  century piano music
  (<xref alt="Hentschel, Rammos, et al., in press" rid="ref-Hentschelinpress_AnnotatedCorpusTonal" ref-type="bibr">Hentschel,
  Rammos, et al., in press</xref>). It has been successful in formatting
  training and validation data for a chord inference algorithm and for
  inserting its analytical outputs into the respective scores
  (<xref alt="Mcleod &amp; Rohrmeier, 2021" rid="ref-Mcleod2021_ModularSystemHarmonic" ref-type="bibr">Mcleod
  &amp; Rohrmeier, 2021</xref>). Moreover, the library is at the heart
  of a semi-automated annotation workflow running on GitHub
  (<xref alt="Hentschel, Moss, et al., 2021" rid="ref-Hentschel2021_SemiautomatedWorkflowParadigm" ref-type="bibr">Hentschel,
  Moss, et al., 2021</xref>) and a dependency on the music corpus
  analysis library DiMCAT
  (<xref alt="Hentschel, McLeod, et al., in press" rid="ref-Hentschelinpress_IntroducingDiMCATProcessing" ref-type="bibr">Hentschel,
  McLeod, et al., in press</xref>).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Development of this software tool was supported by the Swiss
  National Science Foundation within the project “Distant Listening –
  The Development of Harmony over Three Centuries (1700–2000)” (Grant
  no. 182811). This project is being conducted at the Latour Chair in
  Digital and Cognitive Musicology, generously funded by Mr Claude
  Latour.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-Cancino-Chacon2022_PartituraPythonPackage">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cancino-Chacón</surname><given-names>Carlos Eduardo</given-names></name>
        <name><surname>Peter</surname><given-names>Silvan David</given-names></name>
        <name><surname>Karystinaios</surname><given-names>Emmanouil</given-names></name>
        <name><surname>Foscarin</surname><given-names>Francesco</given-names></name>
        <name><surname>Grachten</surname><given-names>Maarten</given-names></name>
        <name><surname>Widmer</surname><given-names>Gerhard</given-names></name>
      </person-group>
      <article-title>Partitura: A python package for symbolic music processing</article-title>
      <source>Proceedings of the music encoding conference (MEC2022)</source>
      <publisher-loc>Halifax, Canada</publisher-loc>
      <year iso-8601-date="2022">2022</year>
    </element-citation>
  </ref>
  <ref id="ref-Cuthbert2010_Music21ToolkitComputerAided">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cuthbert</surname><given-names>Michael Scott</given-names></name>
      </person-group>
      <article-title>Music21: A Toolkit for Computer-Aided Musicology and Symbolic Music Data</article-title>
      <source>Proceedings of the 11th International Society for Music Information Retrieval Conference, ISMIR</source>
      <publisher-name>International Society for Music Information Retrieval</publisher-name>
      <publisher-loc>Utrecht, Netherlands</publisher-loc>
      <year iso-8601-date="2010">2010</year>
      <isbn>978-90-393-5381-3</isbn>
      <fpage>637</fpage>
      <lpage>642</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hentschel2021_AnnotatedMozartSonatas">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hentschel</surname><given-names>Johannes</given-names></name>
        <name><surname>Neuwirth</surname><given-names>Markus</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>The Annotated Mozart Sonatas: Score, Harmony, and Cadence</article-title>
      <source>Transactions of the International Society for Music Information Retrieval</source>
      <year iso-8601-date="2021">2021</year>
      <volume>4</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.5334/tismir.63</pub-id>
      <fpage>67</fpage>
      <lpage>80</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hentschel2021_SemiautomatedWorkflowParadigm">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Hentschel</surname><given-names>Johannes</given-names></name>
        <name><surname>Moss</surname><given-names>Fabian C.</given-names></name>
        <name><surname>Neuwirth</surname><given-names>Markus</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin A</given-names></name>
      </person-group>
      <article-title>A semi-automated workflow paradigm for the distributed creation and curation of expert annotations</article-title>
      <source>Proceedings of the 22nd International Society for Music Information Retrieval Conference, ISMIR</source>
      <publisher-name>Zenodo</publisher-name>
      <publisher-loc>Online</publisher-loc>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <pub-id pub-id-type="doi">10.5281/ZENODO.5624417</pub-id>
      <fpage>262</fpage>
      <lpage>269</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Hentschelinpress_IntroducingDiMCATProcessing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hentschel</surname><given-names>Johannes</given-names></name>
        <name><surname>McLeod</surname><given-names>Andrew</given-names></name>
        <name><surname>Rammos</surname><given-names>Yannis</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>Introducing DiMCAT for processing and analyzing notated music on a very large scale</article-title>
      <source>Proceedings of the 24th International Society for Music Information Retrieval Conference, ISMIR</source>
    </element-citation>
  </ref>
  <ref id="ref-Hentschelinpress_AnnotatedCorpusTonal">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hentschel</surname><given-names>Johannes</given-names></name>
        <name><surname>Rammos</surname><given-names>Yannis</given-names></name>
        <name><surname>Neuwirth</surname><given-names>Markus</given-names></name>
        <name><surname>Moss</surname><given-names>Fabian Claude</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>An annotated corpus of tonal piano music from the long 19th century</article-title>
      <source>Empirical Musicology Review</source>
    </element-citation>
  </ref>
  <ref id="ref-Honing2006_GrowingRoleObservation">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Honing</surname><given-names>Henkjan</given-names></name>
      </person-group>
      <article-title>On the Growing Role of Observation, Formalization and Experimental Method in Musicology</article-title>
      <source>Empirical Musicology Review</source>
      <year iso-8601-date="2006">2006</year>
      <volume>1</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.18061/1811/21901</pub-id>
      <fpage>2</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Huron1999_NewEmpiricismSystematic">
    <element-citation publication-type="report">
      <person-group person-group-type="author">
        <name><surname>Huron</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>The New Empiricism: Systematic Musicology in a Postmodern Age</article-title>
      <publisher-name>The 1999 Ernest Bloch Lecture</publisher-name>
      <publisher-loc>University of California, Berkely</publisher-loc>
      <year iso-8601-date="1999">1999</year>
    </element-citation>
  </ref>
  <ref id="ref-London2013_BuildingRepresentativeCorpus">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>London</surname><given-names>Justin</given-names></name>
      </person-group>
      <article-title>Building a Representative Corpus of Classical Music</article-title>
      <source>Music Perception</source>
      <year iso-8601-date="2013-09">2013</year><month>09</month>
      <volume>31</volume>
      <issue>1</issue>
      <pub-id pub-id-type="doi">10.1525/mp.2013.31.1.68</pub-id>
      <fpage>68</fpage>
      <lpage>90</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Mcleod2021_ModularSystemHarmonic">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Mcleod</surname><given-names>Andrew</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin A.</given-names></name>
      </person-group>
      <article-title>A modular system for the harmonic analysis of musical scores using a large vocabulary</article-title>
      <source>Proceedings of the 22nd International Society for Music Information Retrieval Conference, ISMIR</source>
      <publisher-name>ISMIR</publisher-name>
      <publisher-loc>Online</publisher-loc>
      <year iso-8601-date="2021-11">2021</year><month>11</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-04-21">2023</year><month>04</month><day>21</day></date-in-citation>
      <pub-id pub-id-type="doi">10.5281/zenodo.5624433</pub-id>
      <fpage>435</fpage>
      <lpage>442</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Moss2019_TransitionsTonalityModelBased">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Moss</surname><given-names>Fabian Claude</given-names></name>
      </person-group>
      <article-title>Transitions of Tonality: A Model-Based Corpus Study</article-title>
      <publisher-name>École Polytechnique Fédérale de Lausanne</publisher-name>
      <publisher-loc>Lausanne, Switzerland</publisher-loc>
      <year iso-8601-date="2019">2019</year>
      <pub-id pub-id-type="doi">10.5075/epfl-thesis-9808</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Neuwirth2018_AnnotatedBeethovenCorpus">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Neuwirth</surname><given-names>Markus</given-names></name>
        <name><surname>Harasim</surname><given-names>Daniel</given-names></name>
        <name><surname>Moss</surname><given-names>Fabian C.</given-names></name>
        <name><surname>Rohrmeier</surname><given-names>Martin</given-names></name>
      </person-group>
      <article-title>The Annotated Beethoven Corpus (ABC): A Dataset of Harmonic Analyses of All Beethoven String Quartets</article-title>
      <source>Frontiers in Digital Humanities</source>
      <publisher-name>Frontiers</publisher-name>
      <year iso-8601-date="2018">2018</year>
      <volume>5</volume>
      <issue>July</issue>
      <issn>2297-2668</issn>
      <pub-id pub-id-type="doi">10.3389/fdigh.2018.00016</pub-id>
      <fpage>1</fpage>
      <lpage>5</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Petersohn2021_DataframeSystemsTheory">
    <element-citation publication-type="thesis">
      <person-group person-group-type="author">
        <name><surname>Petersohn</surname><given-names>Devin</given-names></name>
      </person-group>
      <article-title>Dataframe Systems: Theory, Architecture, and Implementation</article-title>
      <publisher-name>University of California</publisher-name>
      <publisher-loc>Berkeley</publisher-loc>
      <year iso-8601-date="2021">2021</year>
    </element-citation>
  </ref>
  <ref id="ref-Pugin2014_VerovioLibraryEngraving">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Pugin</surname><given-names>Laurent</given-names></name>
        <name><surname>Zitellini</surname><given-names>Rodolfo</given-names></name>
        <name><surname>Roland</surname><given-names>Perry</given-names></name>
      </person-group>
      <article-title>Verovio: A Library for Engraving MEI Music Notation into SVG</article-title>
      <source>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR</source>
      <publisher-loc>Taipei</publisher-loc>
      <year iso-8601-date="2014">2014</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2023-03-18">2023</year><month>03</month><day>18</day></date-in-citation>
      <fpage>107</fpage>
      <lpage>112</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Read1979_MusicNotationManual">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Read</surname><given-names>Gardner</given-names></name>
      </person-group>
      <source>Music notation: A manual of modern practice</source>
      <publisher-name>Taplinger Pub. Co</publisher-name>
      <publisher-loc>New York</publisher-loc>
      <year iso-8601-date="1979">1979</year>
      <edition>2d ed</edition>
      <isbn>978-0-8008-5453-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-Ross2001_ArtMusicEngraving">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <name><surname>Ross</surname><given-names>Ted</given-names></name>
      </person-group>
      <source>The art of music engraving &amp; processing</source>
      <publisher-name>npc Imaging</publisher-name>
      <publisher-loc>Santa Rosa, Calif.</publisher-loc>
      <year iso-8601-date="2001">2001</year>
      <isbn>978-0-9706231-1-9</isbn>
    </element-citation>
  </ref>
  <ref id="ref-Shanahan2022_WhatHistoryComputational">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Shanahan</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>What the history of computational musicology can tell us about the future of corpus studies</article-title>
      <source>Future Directions of Music Cognition Virtual Speaker Series</source>
      <publisher-name>Open Science Framework</publisher-name>
      <year iso-8601-date="2022-08">2022</year><month>08</month>
      <pub-id pub-id-type="doi">10.17605/OSF.IO/CB26R</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-Urberg2017_PastsFuturesDigital">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Urberg</surname><given-names>Michelle</given-names></name>
      </person-group>
      <article-title>Pasts and Futures of Digital Humanities in Musicology: Moving Towards a “Bigger Tent”</article-title>
      <source>Music Reference Services Quarterly</source>
      <year iso-8601-date="2017-10">2017</year><month>10</month>
      <volume>20</volume>
      <issue>3-4</issue>
      <issn>1058-8167</issn>
      <pub-id pub-id-type="doi">10.1080/10588167.2017.1404301</pub-id>
      <fpage>134</fpage>
      <lpage>150</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Volk2012_MathematicalComputationalApproaches">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Volk</surname><given-names>Anja</given-names></name>
        <name><surname>Honingh</surname><given-names>Aline</given-names></name>
      </person-group>
      <article-title>Mathematical and computational approaches to music: Challenges in an interdisciplinary enterprise</article-title>
      <source>Journal of Mathematics and Music</source>
      <year iso-8601-date="2012-07">2012</year><month>07</month>
      <volume>6</volume>
      <issue>2</issue>
      <issn>1745-9737</issn>
      <pub-id pub-id-type="doi">10.1080/17459737.2012.704154</pub-id>
      <fpage>73</fpage>
      <lpage>81</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Wiggins2012_MusicMindMathematics">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Wiggins</surname><given-names>Geraint A.</given-names></name>
      </person-group>
      <article-title>Music, mind and mathematics: Theory, reality and formality</article-title>
      <source>Journal of Mathematics and Music</source>
      <year iso-8601-date="2012-07">2012</year><month>07</month>
      <volume>6</volume>
      <issue>2</issue>
      <issn>1745-9737</issn>
      <pub-id pub-id-type="doi">10.1080/17459737.2012.694710</pub-id>
      <fpage>111</fpage>
      <lpage>123</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>For example, musicXML’s implicit encoding of
    temporal positions is limited to those where a note or rest event
    occurs. When converting MuseScore XML to musicXML, all score
    elements occurring between two such events are misplaced.</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>Version control is facilitated by the TSV files
    because, unlike the original XML source, they present score
    information with timestamps.</p>
  </fn>
</fn-group>
</back>
</article>
