<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">5459</article-id>
<article-id pub-id-type="doi">10.21105/joss.05459</article-id>
<title-group>
<article-title>Olaf: a lightweight, portable audio search
system</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7671-1907</contrib-id>
<name>
<surname>Six</surname>
<given-names>Joren</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>IPEM, Ghent University, Belgium</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-03-13">
<day>13</day>
<month>3</month>
<year>2023</year>
</pub-date>
<volume>8</volume>
<issue>87</issue>
<fpage>5459</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Acoustic fingerprinting</kwd>
<kwd>Music Information Retreival</kwd>
<kwd>ANSI C</kwd>
<kwd>Ruby</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Olaf stands for <bold>Overly Lightweight Acoustic
  Fingerprinting</bold> and solves the problem of finding short audio
  fragments in large digital audio archives. The content-based audio
  search algorithm implemented in Olaf can identify a short audio query
  in a large database of thousands of hours of audio using an acoustic
  fingerprinting technique.</p>
  <p>The dataflow in Olaf closely resembles the flow depicted in
  <xref alt="[fig:general]" rid="figU003Ageneral">[fig:general]</xref>.
  Audio is transformed to features, which are grouped in recognizable
  fingerprints. The fingerprints are compared with a database of
  reference fingerprints. If a match is found, it is reported or, in
  case of a true negative, the system reports that the audio is not
  present in the database. The properties of the acoustic fingerprinting
  system mainly depend on the selection of features, the information
  captured by the fingerprints, and the performance of the matching
  step.</p>
  <fig>
    <caption><p>A general acoustic fingerprinting system. Features are
    extracted from audio and combined into fingerprints. The
    fingerprints are matched with fingerprints in a reference database.
    Finally, a match is
    reported.<styled-content id="figU003Ageneral"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="media/docs/general_acoustic_fingerprinting_schema.png" />
  </fig>
  <p>The fingerprints of Olaf are based on peaks in a spectral
  representation of audio, an audio feature which has been proven to be
  a good candidate for audio matching
  (<xref alt="Six, 2020" rid="ref-six2020olaf" ref-type="bibr">Six,
  2020</xref>,
  <xref alt="2022" rid="ref-six2022panako" ref-type="bibr">2022</xref>;
  <xref alt="Six &amp; Leman, 2014" rid="ref-six2014panako" ref-type="bibr">Six
  &amp; Leman, 2014</xref>;
  <xref alt="Avery L. Wang, 2003" rid="ref-Wang2003a" ref-type="bibr">Avery
  L. Wang, 2003</xref>;
  <xref alt="A. Li-chun Wang &amp; Culbert, 2003" rid="ref-wang2003patent" ref-type="bibr">A.
  Li-chun Wang &amp; Culbert, 2003</xref>). Olaf combines either two or
  three spectral peaks into a fingerprint. Two-peak fingerprints allow
  matching shorter queries and improves matching noisy queries. The
  limited information in two peaks becomes a problem if the reference
  dataset becomes larger and false positive matches – fingerprint hash
  collisions – become more common. Three-peak fingerprints contain more
  bits of information, which makes false positives much less common.
  Matches become more reliable but shorter, or more distorted queries,
  might be missed. Three-peak fingerprints work well for longer or
  ‘cleaner’ queries in combination with larger reference datasets.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Audio search algorithms have been described for decades
  (<xref alt="Cano et al., 2005" rid="ref-cano2005fingerprinting_overview" ref-type="bibr">Cano
  et al., 2005</xref>;
  <xref alt="Fenet et al., 2011" rid="ref-fenet2011pitch_shift_fingerprinting" ref-type="bibr">Fenet
  et al., 2011</xref>;
  <xref alt="Haitsma &amp; Kalker, 2002" rid="ref-haitsma2002fingerprinter" ref-type="bibr">Haitsma
  &amp; Kalker, 2002</xref>;
  <xref alt="Herre et al., 2002" rid="ref-herre2002scalable" ref-type="bibr">Herre
  et al., 2002</xref>;
  <xref alt="Sonnleitner &amp; Widmer, 2014" rid="ref-sonnleitner2014quad_based_fingerprinter" ref-type="bibr">Sonnleitner
  &amp; Widmer, 2014</xref>;
  <xref alt="Avery L. Wang, 2003" rid="ref-Wang2003a" ref-type="bibr">Avery
  L. Wang, 2003</xref>) but have not been accessible for researchers due
  to the lack of proper, scalable, freely-available implementations.
  Olaf solves this problem by providing an acoustic fingerprinting
  system that can be used by researchers for digital music archive
  management, audio-to-audio alignment on embedded devices, or other
  uses.</p>
  <p>Six et al.
  (<xref alt="2018" rid="ref-six2018dupapps" ref-type="bibr">2018</xref>)
  and Six et al.
  (<xref alt="2023" rid="ref-six2023duplicates" ref-type="bibr">2023</xref>)
  describe the applications of acoustic fingerprints for digital music
  archive management. These range from meta-data quality verification -
  through the identification of duplicates - to merging archives with
  potential duplicate material. A less straightforward application of
  Olaf is audio-to-audio alignment and synchronization
  (<xref alt="Six &amp; Leman, 2015" rid="ref-six2015synchronizing" ref-type="bibr">Six
  &amp; Leman, 2015</xref>,
  <xref alt="2017" rid="ref-six2017framework" ref-type="bibr">2017</xref>).
  In that case the matching fingerprints are used to align, e.g.,
  multiple video recordings of the same event, by aligning the audio
  attached to each video.</p>
  <p>On a more meta-level Olaf also facilitates Music Information
  Retrieval (MIR) and acoustic fingerprinting research. Audio duplicate
  detection can be used to clean up and evaluate machine learning
  datasets
  (<xref alt="Weck &amp; Serra, 2023" rid="ref-weck2023data" ref-type="bibr">Weck
  &amp; Serra, 2023</xref>). Olaf can also serve as a baseline for
  specific acoustic fingerprinting cases such as broadcast audio
  monitoring
  (<xref alt="Cortès et al., 2022" rid="ref-cortes2022baf" ref-type="bibr">Cortès
  et al., 2022</xref>).</p>
  <p>The portability and low memory usage of Olaf allow it to run on
  microcontrollers such as the ESP32, RP2040, or similar chips with at
  least 250 kB memory. The memory usage to run a 20-second query on an
  index containing one hour of audio is less than 512
  kB<xref ref-type="fn" rid="fn1">1</xref>. The embedded variant takes
  considerably less memory since it does not need the key-value store
  and has a smaller index. This unique feature facilitates innovative
  IoT music recognition and music synchronization applications. Olaf
  also runs in the browser. A compilation emits a WebAssembly binary,
  which, together with the Web Audio API, enables browser based acoustic
  fingerprinting applications.</p>
  <p>Alternative systems with available implementations are by Chang et
  al. (<xref alt="2021" rid="ref-neuralfp" ref-type="bibr">2021</xref>),
  Panako<xref ref-type="fn" rid="fn2">2</xref> by Six
  (<xref alt="2022" rid="ref-six2022panako" ref-type="bibr">2022</xref>),
  audfprint by Ellis
  (<xref alt="2014" rid="ref-ellis2014labrosafp" ref-type="bibr">2014</xref>),
  PeakFP by Cortès et al.
  (<xref alt="2022" rid="ref-cortes2022baf" ref-type="bibr">2022</xref>),
  ChromaPrint by Lalinský &amp; contributors
  (<xref alt="2023" rid="ref-chromaprint" ref-type="bibr">2023</xref>),
  SpectroMap by López-García et al.
  (<xref alt="2022" rid="ref-spectromap" ref-type="bibr">2022</xref>)
  and Dejavu by Drevo
  (<xref alt="2020" rid="ref-dejavu" ref-type="bibr">2020</xref>). All
  have a different focus and trade-offs but none offer the portability
  to target browsers or have the low memory usage to target
  microcontrollers.</p>
</sec>
<sec id="design">
  <title>Design</title>
  <p>Simplicity and maintainability are two keywords in the design of
  Olaf. The code aims to be as readable and simple as possible. The code
  uses an object-oriented inspired approach to organize the ANSI C11
  (<xref alt="ISO, 2011" rid="ref-ISO1999" ref-type="bibr">ISO,
  2011</xref>) code. Opaque structs are used to store and encapsulate
  state information. Polymorphism is implemented by having a header file
  defining an interface which is then implemented in different ways in
  source files. The choice of implementation is done at <bold>compile
  time</bold>. For example, the database used by Olaf can be a key-value
  store or an in-memory database. To provide this functionality, the
  interface <monospace>olaf_db.h</monospace> has two implementations
  which provide either the key-value store or the in-memory database.
  The modularity of Olaf makes it relatively straightforward to stack
  Olaf’s building blocks for use on embedded devices, browsers and
  traditional computers.</p>
  <p>C has a long history, which should allow Olaf to stand the test of
  time. Arguably C is the most portable programming language and has
  been around for decades and will be available for decades to come.
  Boring technology enables longevity. Developing bug-free code in the C
  programming language is notoriously challenging. However, many bugs
  have been found by running Olaf on different platforms / contexts -
  Windows, browsers, embedded devices, musl - and, thanks to continuous
  integration. Each time Olaf is updated a battery of functional tests
  are executed automatically.</p>
  <p>For traditional computers, file handling and transcoding are
  governed by a companion Ruby script. This script expands lists of
  incoming audio files, transcodes audio files, checks incoming audio,
  checks for duplicate material, and validates arguments and input. The
  Ruby script essentially makes Olaf an easy-to-use CLI application and
  keeps the C parts of Olaf simple. The C core it is not concerned with,
  e.g., transcoding. Crucially, the C core trusts input and does not do
  much input validation and does not provide many guardrails. Since the
  interface is the Ruby script, this seems warranted.</p>
  <p>Olaf depends on two C libraries: a key-value store and an FFT
  library. LMDB
  (<xref alt="Chu, 2022" rid="ref-lmdb" ref-type="bibr">Chu,
  2022</xref>) serves as a high performance key-value store. PFFFT
  (<xref alt="Pommier, 2022" rid="ref-pffft" ref-type="bibr">Pommier,
  2022</xref>) is used to speed up FFT calculations. Additionally a hash
  table and a dequeue data structure are included from c-algorithms
  (<xref alt="Howard, 2020" rid="ref-calgorithms" ref-type="bibr">Howard,
  2020</xref>). Internal documentation follows the DoxyGen
  (<xref alt="Heesch, 2023" rid="ref-doxygen" ref-type="bibr">Heesch,
  2023</xref>) standards. Two papers give the rationale behind the
  algorithms
  (<xref alt="Six &amp; Leman, 2014" rid="ref-six2014panako" ref-type="bibr">Six
  &amp; Leman, 2014</xref>;
  <xref alt="Avery L. Wang, 2003" rid="ref-Wang2003a" ref-type="bibr">Avery
  L. Wang, 2003</xref>). Olaf can be compiled and installed using the
  <monospace>make</monospace> tool or with Zig
  (<xref alt="Kelley &amp; contributors, 2023" rid="ref-zig" ref-type="bibr">Kelley
  &amp; contributors, 2023</xref>) cross-compiler.</p>
  <p>To try Olaf yourself or adapt Olaf for your needs, the code and
  documentation of Olaf is hosted in a
  <ext-link ext-link-type="uri" xlink:href="https://github.com/JorenSix/Olaf">publicly-available
  GitHub repository</ext-link>.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Development of Olaf is partially funded by the Ghent University BOF
  Project PaPiOM.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-herre2002scalable">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Herre</surname><given-names>Jürgen</given-names></name>
        <name><surname>Hellmuth</surname><given-names>Oliver</given-names></name>
        <name><surname>Cremer</surname><given-names>Markus</given-names></name>
      </person-group>
      <article-title>Scalable robust audio fingerprinting using MPEG-7 content description</article-title>
      <source>Multimedia signal processing, 2002 IEEE workshop on</source>
      <publisher-name>IEEE</publisher-name>
      <year iso-8601-date="2002">2002</year>
      <pub-id pub-id-type="doi">10.1109/MMSP.2002.1203273</pub-id>
      <fpage>165</fpage>
      <lpage>168</lpage>
    </element-citation>
  </ref>
  <ref id="ref-Wang2003a">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>Avery L.</given-names></name>
      </person-group>
      <article-title>An industrial-strength audio search algorithm</article-title>
      <source>Proceedings of the 4th International Symposium on Music Information Retrieval (ISMIR 2003)</source>
      <publisher-loc>Baltimore, MD, USA</publisher-loc>
      <year iso-8601-date="2003">2003</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1416340</pub-id>
      <fpage>7</fpage>
      <lpage>13</lpage>
    </element-citation>
  </ref>
  <ref id="ref-fenet2011pitch_shift_fingerprinting">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Fenet</surname><given-names>Sébastien</given-names></name>
        <name><surname>Richard</surname><given-names>Gaël</given-names></name>
        <name><surname>Grenier</surname><given-names>Yves</given-names></name>
      </person-group>
      <article-title>A Scalable Audio Fingerprint Method with Robustness to Pitch-Shifting</article-title>
      <source>Proceedings of the 12th International Symposium on Music Information Retrieval (ISMIR 2011)</source>
      <year iso-8601-date="2011">2011</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1417593</pub-id>
      <fpage>121</fpage>
      <lpage>126</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2018dupapps">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Bressan</surname><given-names>Federica</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Applications of duplicate detection in music archives: From metadata comparison to storage optimisation</article-title>
      <source>Digital libraries and multimedia archives</source>
      <person-group person-group-type="editor">
        <name><surname>Serra</surname><given-names>Giuseppe</given-names></name>
        <name><surname>Tasso</surname><given-names>Carlo</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2018">2018</year>
      <isbn>978-3-319-73165-0</isbn>
      <pub-id pub-id-type="doi">10.1007/978-3-319-73165-0_10</pub-id>
      <fpage>101</fpage>
      <lpage>113</lpage>
    </element-citation>
  </ref>
  <ref id="ref-cano2005fingerprinting_overview">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Cano</surname><given-names>Pedro</given-names></name>
        <name><surname>Batlle</surname><given-names>Eloi</given-names></name>
        <name><surname>Kalker</surname><given-names>Ton</given-names></name>
        <name><surname>Haitsma</surname><given-names>Jaap</given-names></name>
      </person-group>
      <article-title>A review of audio fingerprinting</article-title>
      <source>The Journal of VLSI Signal Processing</source>
      <publisher-name>Springer Netherlands</publisher-name>
      <year iso-8601-date="2005">2005</year>
      <volume>41</volume>
      <issn>0922-5773</issn>
      <pub-id pub-id-type="doi">10.1007/s11265-005-4151-3</pub-id>
      <fpage>271</fpage>
      <lpage>284</lpage>
    </element-citation>
  </ref>
  <ref id="ref-sonnleitner2014quad_based_fingerprinter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Sonnleitner</surname><given-names>Reinhard</given-names></name>
        <name><surname>Widmer</surname><given-names>Gerhard</given-names></name>
      </person-group>
      <article-title>Quad-based audio fingerprinting robust to time and frequency scaling</article-title>
      <source>Proceedings of the 17th International Conference on Digital Audio Effects (DAFx-14)</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-ellis2014labrosafp">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Ellis</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>The 2014 LabROSA audio fingerprint system</article-title>
      <source>MIREX abstracts of the 15th International Symposium on Music Information Retrieval (ISMIR 2014)</source>
      <year iso-8601-date="2014">2014</year>
    </element-citation>
  </ref>
  <ref id="ref-neuralfp">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Chang</surname><given-names>Sungkyun</given-names></name>
        <name><surname>Lee</surname><given-names>Donmoon</given-names></name>
        <name><surname>Park</surname><given-names>Jeongsoo</given-names></name>
        <name><surname>Lim</surname><given-names>Hyungui</given-names></name>
        <name><surname>Lee</surname><given-names>Kyogu</given-names></name>
        <name><surname>Ko</surname><given-names>Karam</given-names></name>
        <name><surname>Han</surname><given-names>Yoonchang</given-names></name>
      </person-group>
      <article-title>Neural audio fingerprint for high-specific audio retrieval based on contrastive learning</article-title>
      <source>IEEE international conference on acoustics, speech and signal processing (ICASSP 2021)</source>
      <year iso-8601-date="2021">2021</year>
      <volume></volume>
      <pub-id pub-id-type="doi">10.1109/ICASSP39728.2021.9414337</pub-id>
      <fpage>3025</fpage>
      <lpage>3029</lpage>
    </element-citation>
  </ref>
  <ref id="ref-wang2003patent">
    <element-citation publication-type="patent">
      <person-group person-group-type="author">
        <name><surname>Wang</surname><given-names>A Li-chun</given-names></name>
        <name><surname>Culbert</surname><given-names>Daniel</given-names></name>
      </person-group>
      <article-title>Robust and invariant audio pattern matching</article-title>
      <source>Patent US7627477 B</source>
      <year iso-8601-date="2003">2003</year>
      <volume>2</volume>
    </element-citation>
  </ref>
  <ref id="ref-six2014panako">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Panako - A scalable acoustic fingerprinting system handling time-scale and pitch modification</article-title>
      <source>Proceedings of the 15th ISMIR Conference (ISMIR 2014)</source>
      <year iso-8601-date="2014">2014</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1416190</pub-id>
      <fpage>1</fpage>
      <lpage>6</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2017framework">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>A framework to provide fine-grained time-dependent context for active listening experiences</article-title>
      <source>Audio engineering society conference: 2017 AES international conference on semantic audio</source>
      <publisher-name>Audio Engineering Society</publisher-name>
      <year iso-8601-date="2017">2017</year>
    </element-citation>
  </ref>
  <ref id="ref-weck2023data">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weck</surname><given-names>Benno</given-names></name>
        <name><surname>Serra</surname><given-names>Xavier</given-names></name>
      </person-group>
      <article-title>Data leakage in cross-modal retrieval training: A case study</article-title>
      <source>arXiv e-prints</source>
      <year iso-8601-date="2023">2023</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.2302.12258</pub-id>
      <fpage>arXiv</fpage>
      <lpage>2302</lpage>
    </element-citation>
  </ref>
  <ref id="ref-haitsma2002fingerprinter">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Haitsma</surname><given-names>Jaap</given-names></name>
        <name><surname>Kalker</surname><given-names>Ton</given-names></name>
      </person-group>
      <article-title>A highly robust audio fingerprinting system.</article-title>
      <source>Proceedings of the 3th International Symposium on Music Information Retrieval (ISMIR 2002)</source>
      <year iso-8601-date="2002">2002</year>
      <pub-id pub-id-type="doi">10.5281/zenodo.1417973</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-six2020olaf">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
      </person-group>
      <article-title>OLAF: Overly lightweight acoustic fingerprinting</article-title>
      <source>Extended abstracts for the Late-Breaking Demo Session of the 21st International Society for Music Information Conference (ISMIR 2020) </source>
      <year iso-8601-date="2020">2020</year>
    </element-citation>
  </ref>
  <ref id="ref-six2022panako">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
      </person-group>
      <article-title>Panako: A scalable audio search system</article-title>
      <source>Journal of open source software</source>
      <year iso-8601-date="2022">2022</year>
      <volume>7</volume>
      <issue>78</issue>
      <pub-id pub-id-type="doi">10.21105/joss.04554</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-six2015synchronizing">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Leman</surname><given-names>Marc</given-names></name>
      </person-group>
      <article-title>Synchronizing multimodal recordings using audio-to-audio alignment: An application of acoustic fingerprinting to facilitate music interaction research</article-title>
      <source>Journal on Multimodal User Interfaces</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2015">2015</year>
      <volume>9</volume>
      <pub-id pub-id-type="doi">10.1007/s12193-015-0196-1</pub-id>
      <fpage>223</fpage>
      <lpage>229</lpage>
    </element-citation>
  </ref>
  <ref id="ref-ISO1999">
    <element-citation publication-type="book">
      <person-group person-group-type="author">
        <string-name>ISO</string-name>
      </person-group>
      <source>ISO/IEC 9899:1999 Information technology — Programming languages — C</source>
      <publisher-name>International Organization for Standardization</publisher-name>
      <publisher-loc>Geneva, Switzerland</publisher-loc>
      <year iso-8601-date="2011">2011</year>
    </element-citation>
  </ref>
  <ref id="ref-cortes2022baf">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>Cortès</surname><given-names>Guillem</given-names></name>
        <name><surname>Ciurana</surname><given-names>Alex</given-names></name>
        <name><surname>Molina</surname><given-names>Emilio</given-names></name>
        <name><surname>Miron</surname><given-names>Marius</given-names></name>
        <name><surname>Meyers</surname><given-names>Owen</given-names></name>
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Serra</surname><given-names>Xavier</given-names></name>
      </person-group>
      <article-title>BAF: an audio fingerprinting dataset for broadcast monitoring</article-title>
      <source>Proceedings of the 23rd International Society for Music Information Retrieval Conference (ISMIR 2022)</source>
      <publisher-loc>Bengalaru, India</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <uri>{http://dx.doi.org/10.5281/zenodo.7343030}</uri>
      <pub-id pub-id-type="doi">10.5281/zenodo.7343030</pub-id>
      <fpage>908</fpage>
      <lpage>916</lpage>
    </element-citation>
  </ref>
  <ref id="ref-six2023duplicates">
    <element-citation publication-type="chapter">
      <person-group person-group-type="author">
        <name><surname>Six</surname><given-names>Joren</given-names></name>
        <name><surname>Bressan</surname><given-names>Federica</given-names></name>
        <name><surname>Renders</surname><given-names>Koen</given-names></name>
      </person-group>
      <article-title>Duplicate detection for for digital audio archive management: Two case studies</article-title>
      <source>Advances in speech and music technology: Computational aspects and applications</source>
      <person-group person-group-type="editor">
        <name><surname>Biswas</surname><given-names>Anupam</given-names></name>
        <name><surname>Wennekes</surname><given-names>Emile</given-names></name>
        <name><surname>Wieczorkowska</surname><given-names>Alicja</given-names></name>
        <name><surname>Laskar</surname><given-names>Rabul Hussain</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2023">2023</year>
      <isbn>978-3-031-18444-4</isbn>
      <uri>https://doi.org/10.1007/978-3-031-18444-4_16</uri>
      <pub-id pub-id-type="doi">10.1007/978-3-031-18444-4_16</pub-id>
      <fpage>311</fpage>
      <lpage>329</lpage>
    </element-citation>
  </ref>
  <ref id="ref-calgorithms">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Howard</surname><given-names>Simon</given-names></name>
      </person-group>
      <article-title>C algorithms: A collection of common computer science algorithms</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/fragglet/c-algorithms</uri>
    </element-citation>
  </ref>
  <ref id="ref-pffft">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Pommier</surname><given-names>Julien</given-names></name>
      </person-group>
      <article-title>PFFFT: A pretty fast FFT</article-title>
      <source>BitBucket repository</source>
      <publisher-name>BitBucket</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://bitbucket.org/jpommier/pffft/src/master/</uri>
    </element-citation>
  </ref>
  <ref id="ref-zig">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Kelley</surname><given-names>Andrew</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>Zig: A general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.</article-title>
      <source>GitHub repository</source>
      <publisher-name>GitHub</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/ziglang/zig</uri>
    </element-citation>
  </ref>
  <ref id="ref-lmdb">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Chu</surname><given-names>Howard</given-names></name>
      </person-group>
      <article-title>LMDB: A general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.</article-title>
      <source>OpenLDAP repository</source>
      <publisher-name>OpenLDAP</publisher-name>
      <year iso-8601-date="2022">2022</year>
      <uri>https://git.openldap.org/openldap/openldap/tree/mdb.master</uri>
    </element-citation>
  </ref>
  <ref id="ref-doxygen">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Heesch</surname><given-names>Dimitri van</given-names></name>
      </person-group>
      <article-title>Doxygen: The de facto standard tool for generating documentation from annotated c++ sources.</article-title>
      <source>Doxygen website</source>
      <publisher-name>Doxygen</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://www.doxygen.nl/</uri>
    </element-citation>
  </ref>
  <ref id="ref-chromaprint">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Lalinský</surname><given-names>Lukáš</given-names></name>
        <name><surname>contributors</surname></name>
      </person-group>
      <article-title>Chromaprint: An audio fingerprint library developed for the AcoustID project.</article-title>
      <source>GitHub repository</source>
      <publisher-name>Github</publisher-name>
      <year iso-8601-date="2023">2023</year>
      <uri>https://github.com/acoustid/chromaprint</uri>
    </element-citation>
  </ref>
  <ref id="ref-dejavu">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Drevo</surname><given-names>Will</given-names></name>
      </person-group>
      <article-title>Dejavu: Audio fingerprinting and recognition algorithm implemented in python.</article-title>
      <source>GitHub repository</source>
      <publisher-name>Github</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <uri>https://github.com/worldveil/dejavu</uri>
    </element-citation>
  </ref>
  <ref id="ref-spectromap">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>López-García</surname><given-names>Aarón</given-names></name>
        <name><surname>Martínez-Rodríguez</surname><given-names>Brian</given-names></name>
        <name><surname>Liern</surname><given-names>Vicente</given-names></name>
      </person-group>
      <article-title>A proposal to compare the similarity between musical products. One more step for automated plagiarism detection?</article-title>
      <source>Mathematics and computation in music</source>
      <person-group person-group-type="editor">
        <name><surname>Montiel</surname><given-names>Mariana</given-names></name>
        <name><surname>Agustín-Aquino</surname><given-names>Octavio A.</given-names></name>
        <name><surname>Gómez</surname><given-names>Francisco</given-names></name>
        <name><surname>Kastine</surname><given-names>Jeremy</given-names></name>
        <name><surname>Lluis-Puebla</surname><given-names>Emilio</given-names></name>
        <name><surname>Milam</surname><given-names>Brent</given-names></name>
      </person-group>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
      <year iso-8601-date="2022">2022</year>
      <pub-id pub-id-type="doi">10.1007/978-3-031-07015-0_16</pub-id>
      <fpage>192</fpage>
      <lpage>204</lpage>
    </element-citation>
  </ref>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>A script to measure memory use can be found here:
    https://github.com/JorenSix/Olaf/blob/master/eval/olaf_memory_use.rb</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>Panako and Olaf implement similar algorithms, one
    in Java and the other in C. A direct comparison shows that Olaf is
    more than twice as fast as Panako:
    https://github.com/JorenSix/Olaf/tree/master/eval</p>
  </fn>
</fn-group>
</back>
</article>
